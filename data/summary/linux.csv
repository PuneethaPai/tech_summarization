command,doc_url,doc_text,man_entry,tldr_summary
utmpdump,,,,"# utmpdump

> Dump and load btmp, utmp and wtmp accounting files.

- Dump the `/var/log/wtmp` file to the standard output as plain text:

`utmpdump {{/var/log/wtmp}}`

- Load a previously dumped file into `/var/log/wtmp`:

`utmpdump -r {{dumpfile}} > {{/var/log/wtmp}}`
"
cpufreq-info,,,,"# cpufreq-info

> A tool to show CPU frequency information.

- Show CPU frequency information for all CPUs:

`cpufreq-info`

- Show CPU frequency information for the specified CPU:

`cpufreq-info -c {{cpu_number}}`

- Show the allowed minimum and maximum CPU frequency:

`cpufreq-info -l`

- Show the current minimum and maximum CPU frequency and policy in table format:

`cpufreq-info -o`

- Show available CPU frequency policies:

`cpufreq-info -g`

- Show current CPU work frequency in a human-readable format, according to the cpufreq kernel module:

`cpufreq-info -f -m`

- Show current CPU work frequency in a human-readable format, by reading it from hardware (only available to root):

`sudo cpufreq-info -w -m`
"
pihole,https://pi-hole.net,"




Pi-hole – A black hole for Internet advertisements





































































 





 





Skip to content



 

GitHub

Core
Web
FTL
API
Docker


Community

Log in with Discourse
My Account
Discourse
Reddit
Twitter


About

Documentation
Contact
Privacy
Trademark Rules And Brand Guidelines
Developing Apps For Pi-hole


Blog
Donate
 








Pi-hole® Network-wide Ad BlockingA black hole for Internet advertisementsInstallBecome A PatronDonate 











1. Install a supported operating system
You can run Pi-hole in a container, or deploy it directly to a supported operating system via our automated installer.
Docker install

Supported operating systems









2. Install Pi-hole
Our intelligent, automated installer asks you a few questions and then sets everything up for you.  Once complete, move onto step 3.
 Install Pi-hole 









3. Use Pi-hole as your DNS server
Configure your router’s DHCP options to force clients to use Pi-hole as their DNS server, or manually configure each device​ to use the Pi-hole as their DNS server.
Use Pi-hole as your DNS server









4. Block ads everywhere, even on the go
By pairing your Pi-hole with a VPN, you can have ad blocking on your cellular devices, helping with limited bandwidth data plans.
Pi-hole + VPN










Network-wide protection
Instead of browser plugins or other software on each computer, install Pi-hole in one place and your entire network is protected.



Block in-app advertisements
Network-level blocking allows you to block ads in non-traditional places such as mobile apps and smart TVs, regardless of hardware or OS.



Improve network performance
Since advertisements are blocked before they are downloaded, network performance is improved and will feel faster.



Monitor statistics
Our Web interface offers control of your Pi-hole and a central place to view statistics.  We also include an API for extending these stats.








Pi-hole is free, but powered by your donations.

Donate







Web Interface
In addition to blocking advertisements, Pi-hole has an informative Web interface that shows stats on all the domains being queried on your network.









Built-in DHCP Server
Pi-hole works fine with an existing DHCP server, but you can use Pi-hole’s to keep your network management in one place.









Manage White And Black Lists
Fine tune your experience by blacklisting or whitlisting domains.  Extend this capability with powerful regex statements.









Query Log
See all the domains being queried on your network, where they originated, and more.









Long Term Statistics
Queries are stored in a database and can be queried at any time.  Learn about what’s happening on your network over time.









Audit Log
Keep track of the most queried domains and add them to a white or blacklist from a central page.









Privacy Modes
Choose from four different privacy modes that works for your environment.









Other Settings
Control and configure other settings from the Web interface.








Our Team
The Pi-hole developers are spread across the globe and work on the project in their spare time.  We are a 100% remote team.




Dan Schaper
Co-founder




Adam Warner
Developer




Mark Drobnak
Developer




Dr. Dominic
Developer




Adam Hill
Docker Maintainer




Blayne Campbell
Developer









Patrons Get Special Perks And Early Information
Monthly patrons get access to special perks such as Pi-hole inspired art and special metal coins.  We also share information with patrons before the general public.
Become a patron













Subscribe to Blog via Email

Enter your email address to subscribe to this blog and receive notifications of new posts by email.
 

						Join 3,469 other subscribers						



							Email Address                        








	                        Subscribe                        





Follow Us on Social Media




 





                ©  2020 Pi-hole.               





















 
",,"# pihole

> Terminal interface for the Pi-Hole ad-blocking DNS server.
> More information: <https://pi-hole.net>.

- Check the Pi-hole daemon's status:

`pihole status`

- Monitor detailed system status:

`pihole chronometer`

- Start or stop the daemon:

`pihole {{enable|disable}}`

- Restart the daemon (not the server itself):

`pihole restartdns`

- Whitelist or blacklist a domain:

`pihole {{whitelist|blacklist}} {{example.com}}`

- Search the lists for a domain:

`pihole query {{example.com}}`
"
journalctl,,,,"# journalctl

> Query the systemd journal.

- Show all messages from this boot:

`journalctl -b`

- Show all messages from last boot:

`journalctl -b -1`

- Follow new messages (like `tail -f` for traditional syslog):

`journalctl -f`

- Show all messages by a specific unit:

`journalctl -u {{unit}}`

- Filter messages within a time range (either timestamp or placeholders like ""yesterday""):

`journalctl --since {{now|today|yesterday|tomorrow}} --until {{YYYY-MM-DD HH:MM:SS}}`

- Show all messages by a specific process:

`journalctl _PID={{pid}}`

- Show all messages by a specific executable:

`journalctl {{path/to/executable}}`
"
reboot,,,"
REBOOT(8)		  BSD System Manager's Manual		     REBOOT(8)

NAME
     halt, reboot -- stopping and restarting the system

SYNOPSIS
     halt [-lnqu]
     reboot [-lnq]

DESCRIPTION
     The halt and reboot utilities flush the file system cache to disk, send
     all running processes a SIGTERM (and subsequently a SIGKILL) and, respec-
     tively, halt or restart the system.  The action is logged, including
     entering a shutdown record into the wtmp(5) file.

     When the system is halted with the halt command, the system is powered
     off.

     The options are as follows:

     -l      The halt or reboot is not recorded in the system log.  This
	     option is intended for applications such as shutdown(8), that
	     call reboot or halt and log this themselves.

     -n      The file system cache is not flushed.  This option should proba-
	     bly not be used.

     -q      The system is halted or restarted quickly and ungracefully, and
	     only the flushing of the file system cache is performed (if the
	     -n option is not specified).  This option should probably not be
	     used.

     -u      The system is halted up until the point of removing system power,
	     but waits before removing power for 5 minutes so that an external
	     UPS (uninterruptible power supply) can forcibly remove power.
	     This simulates a dirty shutdown to permit a later automatic power
	     on. OS X uses this mode automatically with supported UPSs in
	     emergency shutdowns.

     Normally, the shutdown(8) utility is used when the system needs to be
     halted or restarted, giving users advance warning of their impending doom
     and cleanly terminating specific programs.

SIGTERM TO SIGKILL INTERVAL
     The SIGKILL will follow the SIGTERM by an intentionally indeterminate
     period of time.  Programs are expected to take only enough time to flush
     all dirty data and exit.  Developers are encouraged to file a bug with
     the OS vendor, should they encounter an issue with this functionality.

SEE ALSO
     wtmp(5), shutdown(8), sync(8)

HISTORY
     A reboot utility appeared in Version 6 AT&T UNIX.

BSD				 June 9, 1993				   BSD
","# reboot

> Reboot the system.

- Reboot immediately:

`reboot`

- Reboot immediately without gracefully shutting down:

`reboot -f`
"
systemctl,https://www.freedesktop.org/software/systemd/man/systemctl.html,"systemctlIndex Â·
  Directives systemd 246Namesystemctl â Control the systemd system and service managerSynopsissystemctl  [OPTIONS...]  COMMAND  [UNIT...]DescriptionÂ¶systemctl may be used to introspect and
    control the state of the ""systemd"" system and
    service manager. Please refer to
    systemd(1)
    for an introduction into the basic concepts and functionality this
    tool manages.CommandsÂ¶The following commands are understood:Unit CommandsÂ¶list-units [PATTERNâ¦]Â¶List units that systemd currently has in memory. This includes units that are
            either referenced directly or through a dependency, units that are pinned by applications programmatically,
            or units that were active in the past and have failed. By default only units which are active, have pending
            jobs, or have failed are shown; this can be changed with option --all. If one or more
            PATTERNs are specified, only units matching one of them are shown. The units
            that are shown are additionally filtered by --type= and --state= if those
            options are specified.Produces output similar to
              UNIT                         LOAD   ACTIVE SUB     DESCRIPTION
  sys-module-fuse.device       loaded active plugged /sys/module/fuse
  -.mount                      loaded active mounted Root Mount
  boot-efi.mount               loaded active mounted /boot/efi
  systemd-journald.service     loaded active running Journal Service
  systemd-logind.service       loaded active running Login Service
â user@1000.service            loaded failed failed  User Manager for UID 1000
  â¦
  systemd-tmpfiles-clean.timer loaded active waiting Daily Cleanup of Temporary Directories

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.

123 loaded units listed. Pass --all to see loaded but inactive units, too.
To show all installed unit files use 'systemctl list-unit-files'.
            
            The header and the last unit of a given type are underlined if the
            terminal supports that. A colored dot is shown next to services which
            were masked, not found, or otherwise failed.The LOAD column shows the load state, one of loaded,
            not-found, bad-setting, error,
            masked. The ACTIVE columns shows the general unit state, one of
            active, reloading, inactive,
            failed, activating, deactivating. The SUB
            column shows the unit-type-specific detailed state of the unit, possible values vary by unit type. The list
            of possible LOAD, ACTIVE, and SUB states is not constant and new systemd releases may both add and remove
            values. systemctl --state=help command maybe be used to display the
            current set of possible values.This is the default command.list-sockets [PATTERNâ¦]Â¶List socket units currently in memory, ordered by listening address.  If one or more
            PATTERNs are specified, only socket units matching one of them are
            shown. Produces output similar to
            
LISTEN           UNIT                        ACTIVATES
/dev/initctl     systemd-initctl.socket      systemd-initctl.service
â¦
[::]:22          sshd.socket                 sshd.service
kobject-uevent 1 systemd-udevd-kernel.socket systemd-udevd.service

5 sockets listed.
            Note: because the addresses might contains spaces, this output
            is not suitable for programmatic consumption.
            Also see --show-types, --all, and --state=.list-timers [PATTERNâ¦]Â¶List timer units currently in memory, ordered by the time they elapse next. If one or more
            PATTERNs are specified, only units matching one of them are shown.
            Produces output similar to
            
NEXT                         LEFT          LAST                         PASSED     UNIT                         ACTIVATES
n/a                          n/a           Thu 2017-02-23 13:40:29 EST  3 days ago ureadahead-stop.timer        ureadahead-stop.service
Sun 2017-02-26 18:55:42 EST  1min 14s left Thu 2017-02-23 13:54:44 EST  3 days ago systemd-tmpfiles-clean.timer systemd-tmpfiles-clean.service
Sun 2017-02-26 20:37:16 EST  1h 42min left Sun 2017-02-26 11:56:36 EST  6h ago     apt-daily.timer              apt-daily.service
Sun 2017-02-26 20:57:49 EST  2h 3min left  Sun 2017-02-26 11:56:36 EST  6h ago     snapd.refresh.timer          snapd.refresh.service
            
NEXT shows the next time the timer will run.LEFT shows how long till the next time the timer runs.LAST shows the last time the timer ran.PASSED shows how long has passed since the timer last ran.UNIT shows the name of the timerACTIVATES shows the name the service the timer activates when it runs.Also see --all and --state=.start PATTERNâ¦Â¶Start (activate) one or more units specified on the command line.Note that unit glob patterns expand to names of units currently in memory. Units which are
            not active and are not in a failed state usually are not in memory, and will not be matched by
            any pattern. In addition, in case of instantiated units, systemd is often unaware of the instance
            name until the instance has been started. Therefore, using glob patterns with
            start has limited usefulness. Also, secondary alias names of units are not
            considered.Option --all may be used to also operate on inactive units which are
            referenced by other loaded units. Note that this is not the same as operating on ""all"" possible
            units, because as the previous paragraph describes, such a list is ill-defined. Nevertheless,
            systemctl start --all GLOB may be useful if all the
            units that should match the pattern are pulled in by some target which is known to be loaded.
            stop PATTERNâ¦Â¶Stop (deactivate) one or more units specified on the command line.This command will fail if the unit does not exist or if stopping of the unit is prohibited (see
            RefuseManualStop= in
            systemd.unit(5)).
            It will not fail if any of the commands configured to stop the unit
            (ExecStop=, etc.) fail, because the manager will still forcibly terminate the
            unit.reload PATTERNâ¦Â¶Asks all units listed on the command line to reload
            their configuration. Note that this will reload the
            service-specific configuration, not the unit configuration
            file of systemd. If you want systemd to reload the
            configuration file of a unit, use the
            daemon-reload command. In other words:
            for the example case of Apache, this will reload Apache's
            httpd.conf in the web server, not the
            apache.service systemd unit
            file.This command should not be confused with the
            daemon-reload command.restart PATTERNâ¦Â¶Stop and then start one or more units specified on the command line. If the units are not running
            yet, they will be started.Note that restarting a unit with this command does not necessarily flush out all of the unit's
            resources before it is started again. For example, the per-service file descriptor storage facility (see
            FileDescriptorStoreMax= in
            systemd.service(5)) will
            remain intact as long as the unit has a job pending, and is only cleared when the unit is fully stopped and
            no jobs are pending anymore. If it is intended that the file descriptor store is flushed out, too, during a
            restart operation an explicit systemctl stop command followed by systemctl
            start should be issued.try-restart PATTERNâ¦Â¶Stop and then start one or more units specified on the
            command line if the units are running. This does nothing
            if units are not running.reload-or-restart PATTERNâ¦Â¶Reload one or more units if they support it. If not, stop and then start them instead. If the units
            are not running yet, they will be started.try-reload-or-restart PATTERNâ¦Â¶Reload one or more units if they support it. If not, stop and then start them instead. This does
            nothing if the units are not running.isolate UNITÂ¶Start the unit specified on the command line and its dependencies
            and stop all others, unless they have
            IgnoreOnIsolate=yes (see
            systemd.unit(5)).
            If a unit name with no extension is given, an extension of
            "".target"" will be assumed.This command is dangerous, since it will immediately stop processes that are not enabled in
            the new target, possibly including the graphical environment or terminal you are currently using.
            Note that this is allowed only on units where
            AllowIsolate= is enabled. See
            systemd.unit(5)
            for details.kill PATTERNâ¦Â¶Send a signal to one or more processes of the
            unit. Use --kill-who= to select which
            process to kill. Use --signal= to select
            the signal to send.clean PATTERNâ¦Â¶Remove the configuration, state, cache, logs or runtime data of the specified units. Use
            --what= to select which kind of resource to remove. For service units this may
            be used to remove the directories configured with ConfigurationDirectory=,
            StateDirectory=, CacheDirectory=,
            LogsDirectory= and RuntimeDirectory=, see
            systemd.exec(5)
            for details. For timer units this may be used to clear out the persistent timestamp data if
            Persistent= is used and --what=state is selected, see
            systemd.timer(5). This
            command only applies to units that use either of these settings. If --what= is
            not specified, both the cache and runtime data are removed (as these two types of data are
            generally redundant and reproducible on the next invocation of the unit).freeze PATTERNâ¦Â¶Freeze one or more units specified on the
            command line using cgroup freezerFreezing the unit will cause all processes contained within the cgroup corresponding to the unit
            to be suspended. Being suspended means that unit's processes won't be scheduled to run on CPU until thawed.
            Note that this command is supported only on systems that use unified cgroup hierarchy. Unit is automatically
            thawed just before we execute a job against the unit, e.g. before the unit is stopped.thaw PATTERNâ¦Â¶Thaw (unfreeze) one or more units specified on the
            command line.This is the inverse operation to the freeze command and resumes the execution of
            processes in the unit's cgroup.is-active PATTERNâ¦Â¶Check whether any of the specified units are active
            (i.e. running). Returns an exit code
            0 if at least one is active, or
            non-zero otherwise. Unless --quiet is
            specified, this will also print the current unit state to
            standard output.is-failed PATTERNâ¦Â¶Check whether any of the specified units are in a
            ""failed"" state. Returns an exit code
            0 if at least one has failed,
            non-zero otherwise. Unless --quiet is
            specified, this will also print the current unit state to
            standard output.status [PATTERNâ¦|PIDâ¦]]Â¶Show terse runtime status information about one or
            more units, followed by most recent log data from the
            journal. If no units are specified, show system status. If
            combined with --all, also show the status of
            all units (subject to limitations specified with
            -t). If a PID is passed, show information
            about the unit the process belongs to.This function is intended to generate human-readable
            output. If you are looking for computer-parsable output,
            use show instead. By default, this
            function only shows 10 lines of output and ellipsizes
            lines to fit in the terminal window. This can be changed
            with --lines and --full,
            see above. In addition, journalctl
            --unit=NAME or
            journalctl
            --user-unit=NAME use
            a similar filter for messages and might be more
            convenient.
            systemd implicitly loads units as necessary, so just running the status will
            attempt to load a file. The command is thus not useful for determining if something was already loaded or
            not.  The units may possibly also be quickly unloaded after the operation is completed if there's no reason
            to keep it in memory thereafter.
            ExampleÂ 1.Â Example output from systemctl status $ systemctl status bluetooth
â bluetooth.service - Bluetooth service
   Loaded: loaded (/usr/lib/systemd/system/bluetooth.service; enabled; vendor preset: enabled)
   Active: active (running) since Wed 2017-01-04 13:54:04 EST; 1 weeks 0 days ago
     Docs: man:bluetoothd(8)
 Main PID: 930 (bluetoothd)
   Status: ""Running""
    Tasks: 1
   Memory: 648.0K
      CPU: 435ms
   CGroup: /system.slice/bluetooth.service
           ââ930 /usr/lib/bluetooth/bluetoothd

Jan 12 10:46:45 example.com bluetoothd[8900]: Not enough free handles to register service
Jan 12 10:46:45 example.com bluetoothd[8900]: Current Time Service could not be registered
Jan 12 10:46:45 example.com bluetoothd[8900]: gatt-time-server: Input/output error (5)
The dot (""â"") uses color on supported terminals to summarize the unit state at a glance. White
            indicates an ""inactive"" or ""deactivating"" state. Red indicates a
            ""failed"" or ""error"" state and green indicates an
            ""active"", ""reloading"" or ""activating"" state.
            The ""Loaded:"" line in the output will show ""loaded"" if the unit has been loaded into
            memory. Other possible values for ""Loaded:"" include: ""error"" if there was a problem
            loading it, ""not-found"" if no unit file was found for this unit,
            ""bad-setting"" if an essential unit file setting could not be parsed and
            ""masked"" if the unit file has been masked. Along with showing the path to the unit file,
            this line will also show the enablement state.  Enabled commands start at boot.  See the full table of
            possible enablement states â including the definition of ""masked"" â in the documentation
            for the is-enabled command.
            The ""Active:"" line shows active state.  The value is usually ""active"" or
            ""inactive"". Active could mean started, bound, plugged in, etc depending on the unit type.
            The unit could also be in process of changing states, reporting a state of ""activating"" or
            ""deactivating"". A special ""failed"" state is entered when the service
            failed in some way, such as a crash, exiting with an error code or timing out. If the failed state is
            entered the cause will be logged for later reference.show [PATTERNâ¦|JOBâ¦]Â¶Show properties of one or more units, jobs, or the manager itself. If no argument is specified,
            properties of the manager will be shown. If a unit name is specified, properties of the unit are shown, and
            if a job ID is specified, properties of the job are shown. By default, empty properties are suppressed. Use
            --all to show those too. To select specific properties to show, use
            --property=. This command is intended to be used whenever computer-parsable output is
            required. Use status if you are looking for formatted human-readable output.Many properties shown by systemctl show map directly to configuration settings of
            the system and service manager and its unit files. Note that the properties shown by the command are
            generally more low-level, normalized versions of the original configuration settings and expose runtime
            state in addition to configuration. For example, properties shown for service units include the service's
            current main process identifier as ""MainPID"" (which is runtime state), and time settings
            are always exposed as properties ending in the ""â¦USec"" suffix even if a matching
            configuration options end in ""â¦Sec"", because microseconds is the normalized time unit used
            by the system and service manager.cat PATTERNâ¦Â¶Show backing files of one or more units. Prints the
            ""fragment"" and ""drop-ins"" (source files) of units. Each
            file is preceded by a comment which includes the file
            name. Note that this shows the contents of the backing files
            on disk, which may not match the system manager's
            understanding of these units if any unit files were
            updated on disk and the daemon-reload
            command wasn't issued since.set-property UNIT PROPERTY=VALUEâ¦Â¶Set the specified unit properties at runtime where
            this is supported. This allows changing configuration
            parameter properties such as resource control settings at
            runtime. Not all properties may be changed at runtime, but
            many resource control settings (primarily those in
            systemd.resource-control(5))
            may. The changes are applied immediately, and stored on disk
            for future boots, unless --runtime is
            passed, in which case the settings only apply until the
            next reboot. The syntax of the property assignment follows
            closely the syntax of assignments in unit files.Example: systemctl set-property foobar.service CPUWeight=200If the specified unit appears to be inactive, the
            changes will be only stored on disk as described
            previously hence they will be effective when the unit will
            be started.Note that this command allows changing multiple properties at the same time, which is
            preferable over setting them individually.Example: systemctl set-property foobar.service CPUWeight=200 MemoryMax=2G IPAccounting=yesLike with unit file configuration settings, assigning an empty setting usually resets a
            property to its defaults.Example: systemctl set-property avahi-daemon.service IPAddressDeny=help PATTERNâ¦|PIDâ¦Â¶Show manual pages for one or more units, if
            available. If a PID is given, the manual pages for the unit
            the process belongs to are shown.reset-failed [PATTERNâ¦]Â¶Reset the ""failed"" state of the specified units, or if no unit name is passed, reset
            the state of all units. When a unit fails in some way (i.e. process exiting with non-zero error code,
            terminating abnormally or timing out), it will automatically enter the ""failed"" state and
            its exit code and status is recorded for introspection by the administrator until the service is
            stopped/re-started or reset with this command.In addition to resetting the ""failed"" state of a unit it also resets various other
            per-unit properties: the start rate limit counter of all unit types is reset to zero, as is the restart
            counter of service units. Thus, if a unit's start limit (as configured with
            StartLimitIntervalSec=/StartLimitBurst=) is hit and the unit refuses
            to be started again, use this command to make it startable again.
list-dependencies
            [UNIT...]
          Â¶Shows units required and wanted by the specified
            units. This recursively lists units following the
            Requires=,
            Requisite=,
            ConsistsOf=,
            Wants=, BindsTo=
            dependencies. If no units are specified,
            default.target is implied.By default, only target units are recursively
            expanded. When --all is passed, all other
            units are recursively expanded as well.Options --reverse,
            --after, --before
            may be used to change what types of dependencies
            are shown.Note that this command only lists units currently loaded into memory by the service manager. In
            particular, this command is not suitable to get a comprehensive list at all reverse dependencies on a
            specific unit, as it won't list the dependencies declared by units currently not loaded.Unit File CommandsÂ¶list-unit-files [PATTERNâ¦]Â¶List unit files installed on the system, in combination with their enablement state (as reported by
            is-enabled). If one or more PATTERNs are specified, only unit
            files whose name matches one of them are shown (patterns matching unit file system paths are not
            supported).enable UNITâ¦, enable PATHâ¦Â¶Enable one or more units or unit instances. This will create a set of symlinks, as encoded in the
            [Install] sections of the indicated unit files. After the symlinks have been created,
            the system manager configuration is reloaded (in a way equivalent to daemon-reload), in
            order to ensure the changes are taken into account immediately. Note that this does
            not have the effect of also starting any of the units being enabled. If this is
            desired, combine this command with the --now switch, or invoke start
            with appropriate arguments later. Note that in case of unit instance enablement (i.e. enablement of units of
            the form foo@bar.service), symlinks named the same as instances are created in the
            unit configuration directory, however they point to the single template unit file they are instantiated
            from.This command expects either valid unit names (in which case various unit file directories are
            automatically searched for unit files with appropriate names), or absolute paths to unit files (in which
            case these files are read directly). If a specified unit file is located outside of the usual unit file
            directories, an additional symlink is created, linking it into the unit configuration path, thus ensuring
            it is found when requested by commands such as start. The file system where the linked
            unit files are located must be accessible when systemd is started (e.g. anything underneath
            /home or /var is not allowed, unless those directories are
            located on the root file system).This command will print the file system operations executed. This output may be suppressed by passing
            --quiet.
            Note that this operation creates only the symlinks suggested in the [Install]
            section of the unit files. While this command is the recommended way to manipulate the unit configuration
            directory, the administrator is free to make additional changes manually by placing or removing symlinks
            below this directory. This is particularly useful to create configurations that deviate from the suggested
            default installation. In this case, the administrator must make sure to invoke
            daemon-reload manually as necessary, in order to ensure the changes are taken into
            account.
            Enabling units should not be confused with starting (activating) units, as done by the
            start command. Enabling and starting units is orthogonal: units may be enabled without
            being started and started without being enabled. Enabling simply hooks the unit into various suggested
            places (for example, so that the unit is automatically started on boot or when a particular kind of
            hardware is plugged in). Starting actually spawns the daemon process (in case of service units), or binds
            the socket (in case of socket units), and so on.Depending on whether --system, --user, --runtime,
            or --global is specified, this enables the unit for the system, for the calling user only,
            for only this boot of the system, or for all future logins of all users.  Note that in the last case, no
            systemd daemon configuration is reloaded.Using enable on masked units is not supported and results in an error.disable UNITâ¦Â¶Disables one or more units. This removes all symlinks to the unit files backing the specified units
            from the unit configuration directory, and hence undoes any changes made by enable or
            link. Note that this removes all symlinks to matching unit files,
            including manually created symlinks, and not just those actually created by enable or
            link. Note that while disable undoes the effect of
            enable, the two commands are otherwise not symmetric, as disable may
            remove more symlinks than a prior enable invocation of the same unit created.This command expects valid unit names only, it does not accept paths to unit files.In addition to the units specified as arguments, all units are disabled that are listed in the
            Also= setting contained in the [Install] section of any of the unit
            files being operated on.This command implicitly reloads the system manager configuration after completing the operation. Note
            that this command does not implicitly stop the units that are being disabled. If this is desired, either
            combine this command with the --now switch, or invoke the stop command
            with appropriate arguments later.This command will print information about the file system operations (symlink removals)
            executed. This output may be suppressed by passing --quiet.
            This command honors --system, --user, --runtime
            and --global in a similar way as enable.reenable UNITâ¦Â¶Reenable one or more units, as specified on the command line. This is a combination of
            disable and enable and is useful to reset the symlinks a unit file is
            enabled with to the defaults configured in its [Install] section. This command expects
            a unit name only, it does not accept paths to unit files.preset UNITâ¦Â¶Reset the enable/disable status one or more unit files, as specified on
            the command line, to the defaults configured in the preset policy files. This
            has the same effect as disable or
            enable, depending how the unit is listed in the preset
            files.Use --preset-mode= to control whether units shall be
            enabled and disabled, or only enabled, or only disabled.If the unit carries no install information, it will be silently ignored
            by this command. UNIT must be the real unit name,
            any alias names are ignored silently.For more information on the preset policy format, see
            systemd.preset(5).
            For more information on the concept of presets, please consult the
            Preset
            document.preset-allÂ¶Resets all installed unit files to the defaults
            configured in the preset policy file (see above).Use --preset-mode= to control
            whether units shall be enabled and disabled, or only
            enabled, or only disabled.is-enabled UNITâ¦Â¶Checks whether any of the specified unit files are
            enabled (as with enable). Returns an
            exit code of 0 if at least one is enabled, non-zero
            otherwise. Prints the current enable status (see table).
            To suppress this output, use --quiet.
            To show installation targets, use --full.
            TableÂ 1.Â 
                is-enabled output
              NameDescriptionExit Code""enabled""Enabled via .wants/, .requires/ or Alias= symlinks (permanently in /etc/systemd/system/, or transiently in /run/systemd/system/).0""enabled-runtime""""linked""Made available through one or more symlinks to the unit file (permanently in /etc/systemd/system/ or transiently in /run/systemd/system/), even though the unit file might reside outside of the unit file search path.> 0""linked-runtime""""alias""The name is an alias (symlink to another unit file).0""masked""Completely disabled, so that any start operation on it fails (permanently in /etc/systemd/system/ or transiently in /run/systemd/systemd/).> 0""masked-runtime""""static""The unit file is not enabled, and has no provisions for enabling in the [Install] unit file section.0""indirect""The unit file itself is not enabled, but it has a non-empty Also= setting in the [Install] unit file section, listing other unit files that might be enabled, or it has an alias under a different name through a symlink that is not specified in Also=. For template unit files, an instance different than the one specified in DefaultInstance= is enabled.0""disabled""The unit file is not enabled, but contains an [Install] section with installation instructions.> 0""generated""The unit file was generated dynamically via a generator tool. See systemd.generator(7). Generated unit files may not be enabled, they are enabled implicitly by their generator.0""transient""The unit file has been created dynamically with the runtime API. Transient units may not be enabled.0""bad""The unit file is invalid or another error occurred. Note that is-enabled will not actually return this state, but print an error message instead. However the unit file listing printed by list-unit-files might show it.> 0mask UNITâ¦Â¶Mask one or more units, as specified on the command line. This will link these unit files to
            /dev/null, making it impossible to start them. This is a stronger version of
            disable, since it prohibits all kinds of activation of the unit, including enablement
            and manual activation. Use this option with care. This honors the --runtime option to only
            mask temporarily until the next reboot of the system. The --now option may be used to
            ensure that the units are also stopped. This command expects valid unit names only, it does not accept unit
            file paths.unmask UNITâ¦Â¶Unmask one or more unit files, as specified on the command line. This will undo the effect of
            mask. This command expects valid unit names only, it does not accept unit file
            paths.link PATHâ¦Â¶Link a unit file that is not in the unit file search paths into the unit file search path. This
            command expects an absolute path to a unit file. The effect of this may be undone with
            disable. The effect of this command is that a unit file is made available for commands
            such as start, even though it is not installed directly in the unit search path. The
            file system where the linked unit files are located must be accessible when systemd is started
            (e.g. anything underneath /home or /var is not allowed, unless
            those directories are located on the root file system).revert UNITâ¦Â¶Revert one or more unit files to their vendor versions. This command removes drop-in configuration
            files that modify the specified units, as well as any user-configured unit file that overrides a matching
            vendor supplied unit file. Specifically, for a unit ""foo.service"" the matching directories
            ""foo.service.d/"" with all their contained files are removed, both below the persistent and
            runtime configuration directories (i.e. below /etc/systemd/system and
            /run/systemd/system); if the unit file has a vendor-supplied version (i.e. a unit file
            located below /usr) any matching persistent or runtime unit file that overrides it is
            removed, too. Note that if a unit file has no vendor-supplied version (i.e. is only defined below
            /etc/systemd/system or /run/systemd/system, but not in a unit
            file stored below /usr), then it is not removed. Also, if a unit is masked, it is
            unmasked.Effectively, this command may be used to undo all changes made with systemctl
            edit, systemctl set-property and systemctl mask and puts
            the original unit file with its settings back in effect.add-wants TARGET
UNITâ¦, add-requires TARGET
UNITâ¦Â¶Adds ""Wants="" or ""Requires=""
            dependencies, respectively, to the specified
            TARGET for one or more units. This command honors --system,
            --user, --runtime and
            --global in a way similar to
            enable.edit UNITâ¦Â¶Edit a drop-in snippet or a whole replacement file if
            --full is specified, to extend or override the
            specified unit.Depending on whether --system (the default),
            --user, or --global is specified,
            this command creates a drop-in file for each unit either for the system,
            for the calling user, or for all futures logins of all users. Then,
            the editor (see the ""Environment"" section below) is invoked on
            temporary files which will be written to the real location if the
            editor exits successfully.If --full is specified, this will copy the
            original units instead of creating drop-in files.If --force is specified and any units do
            not already exist, new unit files will be opened for editing.If --runtime is specified, the changes will
            be made temporarily in /run and they will be
            lost on the next reboot.If the temporary file is empty upon exit, the modification of
            the related unit is canceled.After the units have been edited, systemd configuration is
            reloaded (in a way that is equivalent to daemon-reload).
            Note that this command cannot be used to remotely edit units
            and that you cannot temporarily edit units which are in
            /etc, since they take precedence over
            /run.get-defaultÂ¶Return the default target to boot into. This returns
            the target unit name default.target
            is aliased (symlinked) to.set-default TARGETÂ¶Set the default target to boot into. This sets
            (symlinks) the default.target alias
            to the given target unit.Machine CommandsÂ¶list-machines [PATTERNâ¦]Â¶List the host and all running local containers with
            their state. If one or more
            PATTERNs are specified, only
            containers matching one of them are shown.
            Job CommandsÂ¶list-jobs [PATTERNâ¦]Â¶List jobs that are in progress. If one or more
            PATTERNs are specified, only
            jobs for units matching one of them are shown.When combined with --after or --before the list is augmented with
            information on which other job each job is waiting for, and which other jobs are waiting for it, see
            above.cancel JOBâ¦Â¶Cancel one or more jobs specified on the command line
            by their numeric job IDs. If no job ID is specified, cancel
            all pending jobs.Environment CommandsÂ¶show-environmentÂ¶Dump the systemd manager environment block. This is the environment
            block that is passed to all processes the manager spawns. The environment
            block will be dumped in straight-forward form suitable for sourcing into
            most shells. If no special characters or whitespace is present in the variable
            values, no escaping is performed, and the assignments have the form
            ""VARIABLE=value"". If whitespace or characters which have
            special meaning to the shell are present, dollar-single-quote escaping is
            used, and assignments have the form ""VARIABLE=$'value'"".
            This syntax is known to be supported by
            bash(1),
            zsh(1),
            ksh(1),
            and
            busybox(1)'s
            ash(1),
            but not
            dash(1)
            or
            fish(1).
            set-environment VARIABLE=VALUEâ¦Â¶Set one or more systemd manager environment variables,
            as specified on the command line.unset-environment VARIABLEâ¦Â¶Unset one or more systemd manager environment
            variables. If only a variable name is specified, it will be
            removed regardless of its value. If a variable and a value
            are specified, the variable is only removed if it has the
            specified value.
import-environment
            [VARIABLEâ¦]
          Â¶Import all, one or more environment variables set on
            the client into the systemd manager environment block. If
            no arguments are passed, the entire environment block is
            imported. Otherwise, a list of one or more environment
            variable names should be passed, whose client-side values
            are then imported into the manager's environment
            block.Manager State CommandsÂ¶daemon-reloadÂ¶Reload the systemd manager configuration. This will
            rerun all generators (see
            systemd.generator(7)),
            reload all unit files, and recreate the entire dependency
            tree. While the daemon is being reloaded, all sockets
            systemd listens on behalf of user configuration will stay
            accessible.This command should not be confused with the
            reload command.daemon-reexecÂ¶Reexecute the systemd manager. This will serialize the
            manager state, reexecute the process and deserialize the
            state again. This command is of little use except for
            debugging and package upgrades. Sometimes, it might be
            helpful as a heavy-weight daemon-reload.
            While the daemon is being reexecuted, all sockets systemd listening
            on behalf of user configuration will stay accessible.
            log-level [LEVEL]Â¶If no argument is given, print the current log level of the manager. If an
          optional argument LEVEL is provided, then the command changes the
          current log level of the manager to LEVEL (accepts the same values as
          --log-level= described in
          systemd(1)).
          log-target [TARGET]Â¶If no argument is given, print the current log target of the manager. If an
          optional argument TARGET is provided, then the command changes the
          current log target of the manager to TARGET (accepts the same values as
          --log-target=, described in
          systemd(1)).
          service-watchdogs [yes|no]Â¶If no argument is given, print the current state of service runtime watchdogs of
          the manager. If an optional boolean argument is provided, then globally enables or disables the
          service runtime watchdogs (WatchdogSec=) and emergency actions (e.g.
          OnFailure= or StartLimitAction=); see
          systemd.service(5).
          The hardware watchdog is not affected by this setting.System CommandsÂ¶is-system-runningÂ¶Checks whether the system is operational. This
            returns success (exit code 0) when the system is fully up
            and running, specifically not in startup, shutdown or
            maintenance mode, and with no failed services. Failure is
            returned otherwise (exit code non-zero). In addition, the
            current state is printed in a short string to standard
            output, see the table below. Use --quiet to
            suppress this output.Use --wait to wait until the boot
            process is completed before printing the current state and
            returning the appropriate error status. If --wait
            is in use, states initializing or
            starting will not be reported, instead
            the command will block until a later state (such as
            running or degraded)
            is reached.TableÂ 2.Â is-system-running outputNameDescriptionExit CodeinitializingEarly bootup, before
                    basic.target is reached
                    or the maintenance state entered.
                    > 0startingLate bootup, before the job queue
                    becomes idle for the first time, or one of the
                    rescue targets are reached.> 0runningThe system is fully
                    operational.0degradedThe system is operational but one or more
                    units failed.> 0maintenanceThe rescue or emergency target is
                    active.> 0stoppingThe manager is shutting
                    down.> 0offlineThe manager is not
                    running. Specifically, this is the operational
                    state if an incompatible program is running as
                    system manager (PID 1).> 0unknownThe operational state could not be
                    determined, due to lack of resources or another
                    error cause.> 0defaultÂ¶Enter default mode. This is equivalent to systemctl isolate default.target. This
            operation is blocking by default, use --no-block to request asynchronous behavior.rescueÂ¶Enter rescue mode. This is equivalent to systemctl isolate rescue.target. This
            operation is blocking by default, use --no-block to request asynchronous behavior.emergencyÂ¶Enter emergency mode. This is equivalent to systemctl isolate
            emergency.target. This operation is blocking by default, use --no-block to
            request asynchronous behavior.haltÂ¶Shut down and halt the system. This is mostly equivalent to systemctl start halt.target
            --job-mode=replace-irreversibly --no-block, but also prints a wall message to all users. This command is
            asynchronous; it will return after the halt operation is enqueued, without waiting for it to complete. Note
            that this operation will simply halt the OS kernel after shutting down, leaving the hardware powered
            on. Use systemctl poweroff for powering off the system (see below).If combined with --force, shutdown of all running services is skipped, however all
            processes are killed and all file systems are unmounted or mounted read-only, immediately followed by the
            system halt.  If --force is specified twice, the operation is immediately executed without
            terminating any processes or unmounting any file systems. This may result in data loss. Note that when
            --force is specified twice the halt operation is executed by systemctl
            itself, and the system manager is not contacted. This means the command should succeed even when the system
            manager has crashed.poweroffÂ¶Shut down and power-off the system. This is mostly equivalent to systemctl start
            poweroff.target --job-mode=replace-irreversibly --no-block, but also prints a wall message to all
            users. This command is asynchronous; it will return after the power-off operation is enqueued, without
            waiting for it to complete.If combined with --force, shutdown of all running services is skipped, however all
            processes are killed and all file systems are unmounted or mounted read-only, immediately followed by the
            powering off. If --force is specified twice, the operation is immediately executed without
            terminating any processes or unmounting any file systems. This may result in data loss. Note that when
            --force is specified twice the power-off operation is executed by
            systemctl itself, and the system manager is not contacted. This means the command should
            succeed even when the system manager has crashed.rebootÂ¶Shut down and reboot the system. This is mostly equivalent to systemctl start reboot.target
            --job-mode=replace-irreversibly --no-block, but also prints a wall message to all users. This
            command is asynchronous; it will return after the reboot operation is enqueued, without waiting for it to
            complete.If combined with --force, shutdown of all running services is skipped, however all
            processes are killed and all file systems are unmounted or mounted read-only, immediately followed by the
            reboot. If --force is specified twice, the operation is immediately executed without
            terminating any processes or unmounting any file systems. This may result in data loss. Note that when
            --force is specified twice the reboot operation is executed by
            systemctl itself, and the system manager is not contacted. This means the command should
            succeed even when the system manager has crashed.If the switch --reboot-argument= is given, it will be passed as the optional
            argument to the reboot(2)
            system call.kexecÂ¶Shut down and reboot the system via kexec. This is equivalent to
            systemctl start kexec.target --job-mode=replace-irreversibly --no-block. This command is
            asynchronous; it will return after the reboot operation is enqueued, without waiting for it to
            complete.If combined with --force, shutdown of all running services is skipped, however all
            processes are killed and all file systems are unmounted or mounted read-only, immediately followed by the
            reboot.exit [EXIT_CODE]Â¶Ask the service manager to quit. This is only supported for user service managers (i.e. in
            conjunction with the --user option) or in containers and is equivalent to
            poweroff otherwise. This command is asynchronous; it will return after the exit
            operation is enqueued, without waiting for it to complete.The service manager will exit with the specified exit code, if
            EXIT_CODE is passed.switch-root ROOT [INIT]Â¶Switches to a different root directory and executes a new system manager process below it. This is
            intended for usage in initial RAM disks (""initrd""), and will transition from the initrd's system manager
            process (a.k.a. ""init"" process) to the main system manager process which is loaded from the actual host
            volume. This call takes two arguments: the directory that is to become the new root directory, and the path
            to the new system manager binary below it to execute as PID 1. If the latter is omitted or the empty
            string, a systemd binary will automatically be searched for and used as init. If the system manager path is
            omitted, equal to the empty string or identical to the path to the systemd binary, the state of the
            initrd's system manager process is passed to the main system manager, which allows later introspection of
            the state of the services involved in the initrd boot phase.suspendÂ¶Suspend the system. This will trigger activation of the special target unit
            suspend.target. This command is asynchronous, and will return after the suspend
            operation is successfully enqueued. It will not wait for the suspend/resume cycle to complete.hibernateÂ¶Hibernate the system. This will trigger activation of the special target unit
            hibernate.target. This command is asynchronous, and will return after the hibernation
            operation is successfully enqueued. It will not wait for the hibernate/thaw cycle to complete.hybrid-sleepÂ¶Hibernate and suspend the system. This will trigger activation of the special target unit
            hybrid-sleep.target. This command is asynchronous, and will return after the hybrid
            sleep operation is successfully enqueued. It will not wait for the sleep/wake-up cycle to complete.suspend-then-hibernateÂ¶Suspend the system and hibernate it after the delay specified in systemd-sleep.conf.
            This will trigger activation of the special target unit suspend-then-hibernate.target.
            This command is asynchronous, and will return after the hybrid sleep operation is successfully enqueued.
            It will not wait for the sleep/wake-up or hibernate/thaw cycle to complete.Parameter SyntaxÂ¶Unit commands listed above take either a single unit name (designated as UNIT),
      or multiple unit specifications (designated as PATTERNâ¦). In the first case, the
      unit name with or without a suffix must be given. If the suffix is not specified (unit name is ""abbreviated""),
      systemctl will append a suitable suffix, "".service"" by default, and a type-specific suffix in
      case of commands which operate only on specific unit types. For example,
      # systemctl start sshd and
      # systemctl start sshd.service
      are equivalent, as are
      # systemctl isolate default
      and
      # systemctl isolate default.target
      Note that (absolute) paths to device nodes are automatically converted to device unit names, and other (absolute)
      paths to mount unit names.
      # systemctl status /dev/sda
# systemctl status /home
      are equivalent to:
      # systemctl status dev-sda.device
# systemctl status home.mount
      In the second case, shell-style globs will be matched against the primary names of all units currently in memory;
      literal unit names, with or without a suffix, will be treated as in the first case. This means that literal unit
      names always refer to exactly one unit, but globs may match zero units and this is not considered an
      error.Glob patterns use
      fnmatch(3),
      so normal shell-style globbing rules are used, and
      ""*"", ""?"",
      ""[]"" may be used. See
      glob(7)
      for more details. The patterns are matched against the primary names of
      units currently in memory, and patterns which do not match anything
      are silently skipped. For example:
      # systemctl stop sshd@*.service
      will stop all sshd@.service instances. Note that alias names of units, and units that aren't
      in memory are not considered for glob expansion.
      For unit file commands, the specified UNIT should be the name of the unit file
      (possibly abbreviated, see above), or the absolute path to the unit file:
      # systemctl enable foo.service
      or
      # systemctl link /path/to/foo.service
OptionsÂ¶The following options are understood:-t, --type=Â¶The argument should be a comma-separated list of unit
          types such as service and
          socket.
          If one of the arguments is a unit type, when listing
          units, limit display to certain unit types. Otherwise, units
          of all types will be shown.As a special case, if one of the arguments is
          help, a list of allowed values will be
          printed and the program will exit.--state=Â¶The argument should be a comma-separated list of unit
          LOAD, SUB, or ACTIVE states. When listing units, show only
          those in the specified states. Use --state=failed
          to show only failed units.As a special case, if one of the arguments is
          help, a list of allowed values will be
          printed and the program will exit.-p, --property=Â¶When showing unit/job/manager properties with the
          show command, limit display to properties
          specified in the argument. The argument should be a
          comma-separated list of property names, such as
          ""MainPID"". Unless specified, all known
          properties are shown. If specified more than once, all
          properties with the specified names are shown. Shell
          completion is implemented for property names.For the manager itself,
          systemctlÂ show will show all available
          properties. Those properties are documented in
          systemd-system.conf(5).
          Properties for units vary by unit type, so showing any
          unit (even a non-existent one) is a way to list properties
          pertaining to this type. Similarly, showing any job will list
          properties pertaining to all jobs. Properties for units are
          documented in
          systemd.unit(5),
          and the pages for individual unit types
          systemd.service(5),
          systemd.socket(5),
          etc.-PÂ¶Equivalent to --value --property=, i.e. shows the
          value of the property without the property name or ""="". Note that using
          -P once will also affect all properties listed with
          -p/--property=.-a, --allÂ¶When listing units with list-units, also show inactive units and
          units which are following other units. When showing unit/job/manager properties, show all
          properties regardless whether they are set or not.To list all units installed in the file system, use the
          list-unit-files command instead.When listing units with list-dependencies, recursively show
          dependencies of all dependent units (by default only dependencies of target units are
          shown).When used with status, show journal messages in full, even if they include
          unprintable characters or are very long. By default, fields with unprintable characters are
          abbreviated as ""blob data"". (Note that the pager may escape unprintable characters again.)-r, --recursiveÂ¶When listing units, also show units of local
          containers. Units of local containers will be prefixed with
          the container name, separated by a single colon character
          ("":"").--reverseÂ¶Show reverse dependencies between units with
          list-dependencies, i.e. follow
          dependencies of type WantedBy=,
          RequiredBy=,
          PartOf=, BoundBy=,
          instead of Wants= and similar.
          --afterÂ¶With list-dependencies, show the
          units that are ordered before the specified unit. In other
          words, recursively list units following the
          After= dependency.Note that any After= dependency is
          automatically mirrored to create a
          Before= dependency. Temporal dependencies
          may be specified explicitly, but are also created implicitly
          for units which are WantedBy= targets
          (see
          systemd.target(5)),
          and as a result of other directives (for example
          RequiresMountsFor=). Both explicitly
          and implicitly introduced dependencies are shown with
          list-dependencies.When passed to the list-jobs command, for each printed job show which other jobs are
          waiting for it. May be combined with --before to show both the jobs waiting for each job as
          well as all jobs each job is waiting for.--beforeÂ¶With list-dependencies, show the
          units that are ordered after the specified unit. In other
          words, recursively list units following the
          Before= dependency.When passed to the list-jobs command, for each printed job show which other jobs it
          is waiting for. May be combined with --after to show both the jobs waiting for each job as
          well as all jobs each job is waiting for.--with-dependenciesÂ¶When used with status,
          cat, list-units, and
          list-unit-files, those commands print all
          specified units and the dependencies of those units.Options --reverse,
          --after, --before
          may be used to change what types of dependencies
          are shown.-l, --fullÂ¶Do not ellipsize unit names, process tree entries,
          journal output, or truncate unit descriptions in the output
          of status, list-units,
          list-jobs, and
          list-timers.Also, show installation targets in the output of
          is-enabled.--valueÂ¶When printing properties with show, only print the value, and skip the
          property name and ""="". Also see option -P above.--show-typesÂ¶When showing sockets, show the type of the socket.--job-mode=Â¶When queuing a new job, this option controls how to deal with
        already queued jobs. It takes one of ""fail"",
        ""replace"",
        ""replace-irreversibly"",
        ""isolate"",
        ""ignore-dependencies"",
        ""ignore-requirements"",
        ""flush"", or
        ""triggering"". Defaults to
        ""replace"", except when the
        isolate command is used which implies the
        ""isolate"" job mode.If ""fail"" is specified and a requested
        operation conflicts with a pending job (more specifically:
        causes an already pending start job to be reversed into a stop
        job or vice versa), cause the operation to fail.If ""replace"" (the default) is
        specified, any conflicting pending job will be replaced, as
        necessary.If ""replace-irreversibly"" is specified,
        operate like ""replace"", but also mark the new
        jobs as irreversible. This prevents future conflicting
        transactions from replacing these jobs (or even being enqueued
        while the irreversible jobs are still pending). Irreversible
        jobs can still be cancelled using the cancel
        command. This job mode should be used on any transaction which
        pulls in shutdown.target.""isolate"" is only valid for start
        operations and causes all other units to be stopped when the
        specified unit is started. This mode is always used when the
        isolate command is used.""flush"" will cause all queued jobs to
        be canceled when the new job is enqueued.If ""ignore-dependencies"" is specified,
        then all unit dependencies are ignored for this new job and
        the operation is executed immediately. If passed, no required
        units of the unit passed will be pulled in, and no ordering
        dependencies will be honored. This is mostly a debugging and
        rescue tool for the administrator and should not be used by
        applications.""ignore-requirements"" is similar to
        ""ignore-dependencies"", but only causes the
        requirement dependencies to be ignored, the ordering
        dependencies will still be honored.-T, --show-transactionÂ¶When enqueuing a unit job (for example as effect of a systemctl start
          invocation or similar), show brief information about all jobs enqueued, covering both the requested
          job and any added because of unit dependencies. Note that the output will only include jobs
          immediately part of the transaction requested. It is possible that service start-up program code
          run as effect of the enqueued jobs might request further jobs to be pulled in. This means that
          completion of the listed jobs might ultimately entail more jobs than the listed ones.--failÂ¶Shorthand for --job-mode=fail.When used with the kill command,
          if no units were killed, the operation results in an error.
          -i, --ignore-inhibitorsÂ¶When system shutdown or a sleep state is requested, ignore inhibitor locks. Applications can establish
          inhibitor locks to avoid that certain important operations (such as CD burning or suchlike) are interrupted
          by system shutdown or a sleep state. Any user may take these locks and privileged users may override these
          locks. If any locks are taken, shutdown and sleep state requests will normally fail (unless privileged) and a
          list of active locks is printed. However, if --ignore-inhibitors is specified, the
          established locks are ignored and not shown, and the operation attempted anyway, possibly requiring
          additional privileges.--dry-runÂ¶Just print what would be done. Currently supported by verbs
          halt, poweroff, reboot,
          kexec, suspend, hibernate,
          hybrid-sleep, suspend-then-hibernate,
          default, rescue,
          emergency, and exit.-q, --quietÂ¶Suppress printing of the results of various commands
          and also the hints about truncated log lines. This does not
          suppress output of commands for which the printed output is
          the only result (like show). Errors are
          always printed.--no-blockÂ¶Do not synchronously wait for the requested operation
          to finish. If this is not specified, the job will be
          verified, enqueued and systemctl will
          wait until the unit's start-up is completed. By passing this
          argument, it is only verified and enqueued. This option may not be
          combined with --wait.--waitÂ¶Synchronously wait for started units to terminate again.
          This option may not be combined with --no-block.
          Note that this will wait forever if any given unit never terminates
          (by itself or by getting stopped explicitly); particularly services
          which use ""RemainAfterExit=yes"".When used with is-system-running, wait
          until the boot process is completed before returning.--userÂ¶Talk to the service manager of the calling user,
      rather than the service manager of the system.--systemÂ¶Talk to the service manager of the system. This is the
      implied default.--failedÂ¶List units in failed state. This is equivalent to
          --state=failed.--no-wallÂ¶Do not send wall message before halt, power-off and reboot.--globalÂ¶When used with enable and
          disable, operate on the global user
          configuration directory, thus enabling or disabling a unit
          file globally for all future logins of all users.--no-reloadÂ¶When used with enable and
          disable, do not implicitly reload daemon
          configuration after executing the changes.--no-ask-passwordÂ¶When used with start and related
          commands, disables asking for passwords. Background services
          may require input of a password or passphrase string, for
          example to unlock system hard disks or cryptographic
          certificates. Unless this option is specified and the
          command is invoked from a terminal,
          systemctl will query the user on the
          terminal for the necessary secrets. Use this option to
          switch this behavior off. In this case, the password must be
          supplied by some other means (for example graphical password
          agents) or the service might fail. This also disables
          querying the user for authentication for privileged
          operations.--kill-who=Â¶When used with kill, choose which
          processes to send a signal to. Must be one of
          main, control or
          all to select whether to kill only the main
          process, the control process or all processes of the
          unit. The main process of the unit is the one that defines
          the life-time of it. A control process of a unit is one that
          is invoked by the manager to induce state changes of it. For
          example, all processes started due to the
          ExecStartPre=,
          ExecStop= or
          ExecReload= settings of service units are
          control processes. Note that there is only one control
          process per unit at a time, as only one state change is
          executed at a time. For services of type
          Type=forking, the initial process started
          by the manager for ExecStart= is a
          control process, while the process ultimately forked off by
          that one is then considered the main process of the unit (if
          it can be determined). This is different for service units
          of other types, where the process forked off by the manager
          for ExecStart= is always the main process
          itself. A service unit consists of zero or one main process,
          zero or one control process plus any number of additional
          processes. Not all unit types manage processes of these
          types however. For example, for mount units, control processes
          are defined (which are the invocations of
          /usr/bin/mount and
          /usr/bin/umount), but no main process
          is defined. If omitted, defaults to
          all.-s, --signal=Â¶When used with kill, choose which
          signal to send to selected processes. Must be one of the
          well-known signal specifiers such as SIGTERM, SIGINT or
          SIGSTOP. If omitted, defaults to
          SIGTERM.--what=Â¶Select what type of per-unit resources to remove when the clean command is
          invoked, see below. Takes one of configuration, state,
          cache, logs, runtime to select the
          type of resource. This option may be specified more than once, in which case all specified resource
          types are removed. Also accepts the special value all as a shortcut for
          specifying all five resource types. If this option is not specified defaults to the combination of
          cache and runtime, i.e. the two kinds of resources that
          are generally considered to be redundant and can be reconstructed on next invocation.-f, --forceÂ¶When used with enable, overwrite
          any existing conflicting symlinks.When used with edit, create all of the
          specified units which do not already exist.When used with halt, poweroff, reboot or
          kexec, execute the selected operation without shutting down all units. However, all
          processes will be killed forcibly and all file systems are unmounted or remounted read-only. This is hence a
          drastic but relatively safe option to request an immediate reboot. If --force is specified
          twice for these operations (with the exception of kexec), they will be executed
          immediately, without terminating any processes or unmounting any file systems. Warning: specifying
          --force twice with any of these operations might result in data loss. Note that when
          --force is specified twice the selected operation is executed by
          systemctl itself, and the system manager is not contacted. This means the command should
          succeed even when the system manager has crashed.--message=Â¶When used with halt, poweroff or reboot, set a
          short message explaining the reason for the operation. The message will be logged together with the default
          shutdown message.--nowÂ¶When used with enable, the units
          will also be started. When used with disable or
          mask, the units will also be stopped. The start
          or stop operation is only carried out when the respective enable or
          disable operation has been successful.--root=Â¶When used with
          enable/disable/is-enabled
          (and related commands), use the specified root path when looking for unit
          files. If this option is present, systemctl will operate on
          the file system directly, instead of communicating with the systemd
          daemon to carry out changes.--runtimeÂ¶When used with enable,
          disable, edit,
          (and related commands), make changes only temporarily, so
          that they are lost on the next reboot. This will have the
          effect that changes are not made in subdirectories of
          /etc but in /run,
          with identical immediate effects, however, since the latter
          is lost on reboot, the changes are lost too.Similarly, when used with
          set-property, make changes only
          temporarily, so that they are lost on the next
          reboot.--preset-mode=Â¶Takes one of ""full"" (the default),
          ""enable-only"",
          ""disable-only"". When used with the
          preset or preset-all
          commands, controls whether units shall be disabled and
          enabled according to the preset rules, or only enabled, or
          only disabled.-n, --lines=Â¶When used with status, controls the number of journal lines to show, counting from
          the most recent ones. Takes a positive integer argument, or 0 to disable journal output. Defaults to
          10.-o, --output=Â¶When used with status, controls the
          formatting of the journal entries that are shown. For the
          available choices, see
          journalctl(1).
          Defaults to ""short"".--firmware-setupÂ¶When used with the reboot command, indicate to the system's firmware to reboot into
          the firmware setup interface. Note that this functionality is not available on all systems.--boot-loader-menu=Â¶When used with the reboot command, indicate to the system's boot loader to show the
          boot loader menu on the following boot. Takes a time value as parameter â indicating the menu timeout. Pass
          zero in order to disable the menu timeout. Note that not all boot loaders support this
          functionality.--boot-loader-entry=Â¶When used with the reboot command, indicate to the system's boot loader to boot into
          a specific boot loader entry on the following boot. Takes a boot loader entry identifier as argument, or
          ""help"" in order to list available entries. Note that not all boot loaders support this
          functionality.--reboot-argument=Â¶This switch is used with reboot. The value is architecture and firmware specific. As an example, ""recovery""
            might be used to trigger system recovery, and ""fota"" might be used to trigger a
            âfirmware over the airâ update.--plainÂ¶When used with list-dependencies,
          list-units or list-machines,
          the output is printed as a list instead of a tree, and the bullet
          circles are omitted.-H, --host=Â¶Execute the operation remotely. Specify a hostname, or a
      username and hostname separated by ""@"", to
      connect to. The hostname may optionally be suffixed by a
      port ssh is listening on, separated by "":"", and then a
      container name, separated by ""/"", which
      connects directly to a specific container on the specified
      host. This will use SSH to talk to the remote machine manager
      instance. Container names may be enumerated with
      machinectl -H
      HOST. Put IPv6 addresses in brackets.-M, --machine=Â¶Execute operation on a local container. Specify a
      container name to connect to.--no-pagerÂ¶Do not pipe output into a pager.--no-legendÂ¶Do not print the legend, i.e. column headers and the
      footer with hints.-h, --helpÂ¶Print a short help text and exit.
    --versionÂ¶Print a short version string and exit.Exit statusÂ¶On success, 0 is returned, a non-zero failure code otherwise.systemctl uses the return codes defined by LSB, as defined in
    LSB 3.0.0.
    TableÂ 3.Â LSB return codesValueDescription in LSBUse in systemd0""program is running or service is OK""unit is active1""program is dead and /var/run pid file exists""unit not failed (used by is-failed)2""program is dead and /var/lock lock file exists""unused3""program is not running""unit is not active4""program or service status is unknown""no such unitThe mapping of LSB service states to systemd unit states is imperfect, so it is better to
    not rely on those return values but to look for specific unit states and substates instead.
    EnvironmentÂ¶$SYSTEMD_EDITORÂ¶Editor to use when editing units; overrides
        $EDITOR and $VISUAL. If neither
        $SYSTEMD_EDITOR nor $EDITOR nor
        $VISUAL are present or if it is set to an empty
        string or if their execution failed, systemctl will try to execute well
        known editors in this order:
        editor(1),
        nano(1),
        vim(1),
        vi(1).
        $SYSTEMD_PAGERÂ¶Pager to use when --no-pager is not given; overrides
      $PAGER. If neither $SYSTEMD_PAGER nor $PAGER are set, a
      set of well-known pager implementations are tried in turn, including
      less(1) and
      more(1), until one is found. If
      no pager implementation is discovered no pager is invoked. Setting this environment variable to an empty string
      or the value ""cat"" is equivalent to passing --no-pager.$SYSTEMD_LESSÂ¶Override the options passed to less (by default
      ""FRSXMK"").Users might want to change two options in particular:KÂ¶XÂ¶See
      less(1)
      for more discussion.$SYSTEMD_LESSCHARSETÂ¶Override the charset passed to less (by default ""utf-8"", if
      the invoking terminal is determined to be UTF-8 compatible).$SYSTEMD_COLORSÂ¶The value must be a boolean. Controls whether colorized output should be
      generated. This can be specified to override the decision that systemd makes based
      on $TERM and what the console is connected to.$SYSTEMD_URLIFYÂ¶The value must be a boolean. Controls whether clickable links should be generated in
      the output for terminal emulators supporting this. This can be specified to override the decision that
      systemd makes based on $TERM and other conditions.See AlsoÂ¶
systemd(1),
      journalctl(1),
      loginctl(1),
      machinectl(1),
      systemd.unit(5),
      systemd.resource-control(5),
      systemd.special(7),
      wall(1),
      systemd.preset(5),
      systemd.generator(7),
      glob(7)
",,"# systemctl

> Control the systemd system and service manager.
> More information: <https://www.freedesktop.org/software/systemd/man/systemctl.html>.

- List failed units:

`systemctl --failed`

- Start/Stop/Restart/Reload a service:

`systemctl start/stop/restart/reload {{unit}}`

- Show the status of a unit:

`systemctl status {{unit}}`

- Enable/Disable a unit to be started on bootup:

`systemctl enable/disable {{unit}}`

- Mask/Unmask a unit, prevent it to be started on bootup:

`systemctl mask/unmask {{unit}}`

- Reload systemd, scanning for new or changed units:

`systemctl daemon-reload`

- Check if a unit is active:

`systemctl is-active {{unit}}`

- Check if a unit is enabled:

`systemctl is-enabled {{unit}}`
"
tomb,,,,"# tomb

> Manage encrypted storage directories that can be safely transported and hidden in a filesystem.

- Create a new tomb with an initial size of 100MB:

`tomb dig -s {{100}} {{encrypted_directory.tomb}}`

- Create a new key file that can be used to lock a tomb; user will be prompted for a password for the key:

`tomb forge {{encrypted_directory.tomb.key}}`

- Initialize and lock an empty tomb using a key made with `forge`:

`tomb lock {{encrypted_directory.tomb}} -k {{encrypted_directory.tomb.key}}`

- Mount a tomb (by default in /media) using its key, making it usable as a regular filesystem directory:

`tomb open {{encrypted_directory.tomb}} -k {{encrypted_directory.tomb.key}}`

- Close a tomb (fails if the tomb is being used by a process):

`tomb close {{encrypted_directory.tomb}}`

- Forcefully close all open tombs, killing any applications using them:

`tomb slam all`

- List all open tombs:

`tomb list`
"
nmon,,,,"# nmon

> A system administrator, tuner, and benchmark tool.

- Start nmon:

`nmon`

- Save records to file (""-s 300 -c 288"" by default):

`nmon -f`

- Save records to file with a total of 240 measurements, by taking 30 seconds between each measurement:

`nmon -f -s {{30}} -c {{240}}`
"
rspamc,,,,"# rspamc

> Command line client for rspamd servers.

- Train the bayesian filter to recognise an email as spam:

`rspamc learn_spam {{path/to/email_file}}`

- Train the bayesian filter to recognise an email as ham:

`rspamc learn_ham {{path/to/email_file}}`

- Generate a manual report on an email:

`rspamc symbols {{path/to/email_file}}`

- Show server statistics:

`rspamc stat`
"
gs,,,,"# gs

> GhostScript is a PDF and PostScript interpreter.

- To view a file:

`gs -dQUIET -dBATCH {{file.pdf}}`

- Reduce PDF file size to 150 dpi images for reading on a ebook device:

`gs -dNOPAUSE -dQUIET -dBATCH -sDEVICE=pdfwrite -dPDFSETTINGS=/ebook -sOutputFile={{output.pdf}} {{input.pdf}}`

- Convert PDF file (pages 1 through 3) to an image with 150 dpi resolution:

`gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=jpeg -r150 -dFirstPage={{1}} -dLastPage={{3}} -sOutputFile={{output_%d.jpg}} {{input.pdf}}`

- Extract pages from a PDF file:

`gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile={{output.pdf}} {{input.pdf}}`

- Merge PDF files:

`gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile={{output.pdf}} {{input1.pdf}} {{input2.pdf}}`

- Convert from PostScript file to PDF file:

`gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile={{output.pdf}} {{input.ps}}`
"
pwdx,,,,"# pwdx

> Print working directory of a process.

- Print current working directory of a process:

`pwdx {{process_id}}`
"
flatpak,,,,"# flatpak

> Build, install and run flatpak applications and runtimes.

- Run an installed application:

`flatpak run {{name}}`

- Install an application from a remote source:

`flatpak install {{remote}} {{name}}`

- List all installed applications and runtimes:

`flatpak list`

- Update all installed applications and runtimes:

`flatpak update`

- Add a remote source:

`flatpak remote-add --if-not-exists {{remote_name}} {{remote_url}}`

- List all configured remote sources:

`flatpak remote-list`
"
inotify-wait,,,,"# inotifywait

> Waits for changes to one or more files.

- Run a command when a file changes:

`while inotifywait {{path/to/file}}; do {{command}}; done`

- Be quiet about watching for changes:

`while inotifywait --quiet {{path/to/file}}; do {{command}}; done`

- Watch a directory recursively for changes:

`while inotifywait --recursive {{path/to/directory}}; do {{command}}; done`

- Exclude files matching a regular expression:

`while inotifywait --recursive {{path/to/directory}} --exlude '{{regex}}'; do {{command}}; done`

- Wait at most 30 seconds:

`while inotifywait --timeout {{30}} {{path/to/file}}; do {{command}}; done`

- Only watch for file modification events:

`while inotifywait --event {{modify}} {{path/to/file}}; do {{command}}; done`
"
tcptraceroute,https://github.com/mct/tcptraceroute,"













GitHub - mct/tcptraceroute: A traceroute implementation using TCP packets








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















mct

/

tcptraceroute







    Watch
 
      11
    




      Star


      78
    




          Fork


        17
      





        A traceroute implementation using TCP packets
      



michael.toren.net/code/tcptraceroute/





            GPL-2.0 License
        




78
        stars
 

17
        forks
 




      Star





    Watch









Code

 



Issues
3
 



Pull requests
3
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



19
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




mct

Call `pcap_lib_version()` rather than access `pcap_version` directly



…



3772409

May 5, 2017





Call `pcap_lib_version()` rather than access `pcap_version` directly

Closes #5

Thanks!

3772409



Git stats





29
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.gitignore


 


 







AUTHORS


 


 







COPYING


 


 







ChangeLog


 


 







INSTALL


 


 







Makefile.am


 


 







Makefile.in


 


 







NEWS


 


 







README


 


 







VERSION


 


 







aclocal.m4


 


 







capture.c


 


 







capture.h


 


 







config.guess


 


 







config.h.in


 


 







config.sub


 


 







configure


 


 







configure.ac


 


 







datalink.c


 


 







datalink.h


 


 







examples.txt


 


 







install-sh


 


 







main.c


 


 







missing


 


 







mkinstalldirs


 


 







probe.c


 


 







probe.h


 


 







stamp-h.in


 


 







tcptraceroute.1


 


 







tcptraceroute.1.html


 


 







tcptraceroute.h


 


 







tcptraceroute.lsm


 


 







testsuite.pl


 


 







traceroute.cgi


 


 







util.c


 


 







util.h


 


 





        View code
      







        README
      


tcptraceroute -- A traceroute implementation using TCP packets
Copyright (c) 2001-2015  Michael C. Toren <mct@toren.net>

Updates are available from <http://michael.toren.net/code/tcptraceroute/>

Requires libnet <http://www.packetfactory.net/libnet> and libpcap
<http://www.tcpdump.org/>.  For compilation instructions, see the
INSTALL file.

This program is free software; you can redistribute it and/or modify it
under the terms of the GNU General Public License, version 2, as published
by the Free Software Foundation.

This program is distributed in the hope that it will be useful, but
WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
for more details.

A copy of the GNU GPL is available as /usr/doc/copyright/GPL on Debian
systems, or on the World Wide Web at http://www.gnu.org/copyleft/gpl.html
You can also obtain it by writing to the Free Software Foundation, Inc.,
59 Temple Place - Suite 330, Boston, MA 02111-1307, USA








About

      A traceroute implementation using TCP packets
    



michael.toren.net/code/tcptraceroute/


Resources



      Readme
 
License



        GPL-2.0 License
    







    Releases



19
tags







    Packages 0


        No packages published 













    Contributors 2





 

mct
Michael Toren
 




 

jbackman
Justin Backman
 






Languages














C
52.5%





Makefile
12.4%





Shell
11.2%





M4
7.3%





HTML
6.5%





Roff
5.3%





Perl
4.8%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# tcptraceroute

> A traceroute implementation using TCP packets.
> More information: <https://github.com/mct/tcptraceroute>.

- Trace the route to a host:

`tcptraceroute {{host}}`

- Specify the destination port and packet length in bytes:

`tcptraceroute {{host}} {{destination_port}} {{packet_length}}`

- Specify the local source port and source address:

`tcptraceroute {{host}} -p {{source_port}} -s {{source_address}}`

- Set the first and maximum TTL:

`tcptraceroute {{host}} -f {{first_ttl} -m {{max_ttl}}`

- Specify the wait time and number of queries per hop:

`tcptraceroute {{host}} -w {{wait_time}} -q {{number_of_queries}}`

- Specify the interface:

`tcptraceroute {{host}} -i {{interface}}`
"
fc-match,,,"FC-MATCH(1)							   FC-MATCH(1)



NAME
       fc-match - match available fonts

SYNOPSIS
       fc-match [ -asvVh ]  [ --all ]  [ --sort ]  [ --verbose ]  [  [ -f for-
       mat ]  [ --format format ]  ]  [ --version ]  [ --help ]

	[ pattern  [ element... ]   ]

DESCRIPTION
       fc-match matches pattern (empty pattern by default)  using  the	normal
       fontconfig matching rules to find the best font available. If --sort is
       given, the sorted list of best matching fonts is displayed.  The  --all
       option  works like --sort except that no pruning is done on the list of
       fonts.

       If any elements are specified, only those are printed.  Otherwise short
       file  name,  family,  and  style  are printed, unless verbose output is
       requested.

OPTIONS
       This program follows the usual  GNU  command  line  syntax,  with  long
       options	starting  with	two  dashes  (`-').  A	summary  of options is
       included below.

       -a     Displays sorted list of best matching fonts, but do not  do  any
	      pruning on the list.

       -s     Displays sorted list of best matching fonts.

       -v     Print  verbose  output of the whole font pattern for each match,
	      or elements if any is provided.

       -f     Format output according to the format specifier format.

       -V     Show version of the program and exit.

       -h     Show summary of options.

       pattern
	      Displays fonts matching pattern (uses empty pattern by default).

       element
	      If set, the element property is displayed for matching fonts.

SEE ALSO
       fc-list(1)  FcFontMatch(3)  FcFontSort(3)  FcPatternFormat(3) fc-cat(1)
       fc-cache(1) fc-pattern(1) fc-query(1) fc-scan(1)

       The fontconfig user's guide, in	HTML  format:  /usr/share/doc/fontcon-
       fig/fontconfig-user.html.

AUTHOR
       This manual page was updated by Patrick Lam <plam@csail.mit.edu>.



				 Aug 13, 2008			   FC-MATCH(1)
","# fc-match

> Match available fonts.

- Return a sorted list of best matching fonts:

`fc-match -s '{{DejaVu Serif}}'`
"
conky,https://github.com/brndnmtthws/conky,"













GitHub - brndnmtthws/conky: Light-weight system monitor for X.








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















brndnmtthws

/

conky








          Sponsor
        






              Sponsor brndnmtthws/conky
            












    Watch
 
      177
    




      Star


      4.2k
    




          Fork


        471
      





        Light-weight system monitor for X.
      



github.com/brndnmtthws/conky/wiki





            View license
        




4.2k
        stars
 

471
        forks
 




      Star





    Watch









Code

 



Issues
180
 



Pull requests
2
 



Actions

 



Projects
2
 



Wiki

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Wiki
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














4
branches



43
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 

 




BojanoN


   and   brndnmtthws

fixed nil value call error while converting old sytax config



…



1abae95

Aug 31, 2020





fixed nil value call error while converting old sytax config


1abae95



Git stats





3,522
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.github



Create FUNDING.yml



Jul 27, 2020







3rdparty/toluapp



Drop luajit support (Lua 5.1 API).



Dec 24, 2018







appimage



Test `make install` target, and release build.



Mar 9, 2019







bin



Fix python command for clang checks (2 -> 3).



Jan 8, 2020







cmake



Bump version for next release.



Jul 27, 2020







data



fix alignment in default conf



Oct 19, 2019







doc



Add missing mpd_comment variable.



Jul 27, 2020







extras



fixed nil value call error while converting old sytax config



Aug 31, 2020







logo



Add AppImage integration.



Jan 9, 2019







lua



Add clang 8 to builds.



Apr 14, 2019







src



Add missing mpd_comment variable.



Jul 27, 2020







tests



Add Tests in new Test files (#852)



Jun 20, 2019







.clang-format



Make GitLab build work with clang checks.



Feb 23, 2019







.clang-tidy



Make GitLab build work with clang checks.



Feb 23, 2019







.dockerignore



Refactor Dockerfile.



Feb 21, 2019







.editorconfig



Apply a bunch of code fixes from sonarcloud. (#492)



May 13, 2018







.gitignore



Add AppImage integration.



Jan 9, 2019







.gitlab-ci.yml



Fix image push commands in gitlab build.



Apr 14, 2019







.travis.yml



Fix for appimage build.



Jun 23, 2019







AUTHORS



Add Google LLC to AUTHORS



Mar 3, 2019







CMakeLists.txt



Add a separate option for building html documentation.



Mar 27, 2019







CONTRIBUTING.md



Reorganize, adjust wording.



Mar 4, 2019







COPYING



update copyright year to 2019



Jan 5, 2019







Dockerfile



Refactor Dockerfile.



Feb 21, 2019







LICENSE



GPLv3 is the default license.



Jan 25, 2018







LICENSE.BSD



Add note on GPL licensing.



Mar 3, 2019







README.cmake



Deprecate autotools, update docs to reflect cmake build system.



Jan 1, 2010







README.docker



Using X11 conky in a container



Feb 18, 2018







README.md



Update README.md



Nov 1, 2019







conky.desktop



Add AppImage integration.



Jan 9, 2019







sonar-project.properties



Add some basic unit tests.



Dec 24, 2018





        View code
      






        README.md
      








  

Conky is a free, light-weight system monitor for X, that displays
any kind of information on your desktop.
👉 Grab the latest release from GitHub.
📹 An introduction to Conky (YouTube).
Features
Conky can display more than 300 built-in objects, including support for:

A plethora of OS stats (uname, uptime, CPU usage, mem
usage, disk usage, ""top"" like process stats, and network
monitoring, just to name a few).
Built-in IMAP and POP3 support.
Built-in support for many popular music players (MPD,
XMMS2, Audacious).
Can be extended using built-in Lua support, or any of your
own scripts and programs (more).
Built-in Imlib2 and Cairo bindings for arbitrary drawing
with Lua (more).
Runs on Linux, FreeBSD, OpenBSD, DragonFlyBSD, NetBSD, Solaris, Haiku OS, and macOS!

... and much much more.
Conky can display information either as text, or using simple progress
bars and graph widgets, with different fonts and colours.
Screenshots



See the User Configs below for more screenshots and associated config files.
Quickstart
Conky comes bundled with many package managers. However, if you'd like to try the latest release of Conky, you can try the AppImage build. If you have jq and curl installed, run the following command to fetch the latest AppImage:
$ curl -sL -o conky-x86_64.AppImage \
    $(curl -sL https://api.github.com/repos/brndnmtthws/conky/releases/latest | \
    jq --raw-output '.assets[0] | .browser_download_url')
$ ls
conky-x86_64.AppImage
If you don't have jq and curl installed, go to
https://github.com/brndnmtthws/conky/releases/latest and fetch the latest
AppImage. Then:
$ chmod +x ./conky-x86_64.AppImage
$ ./conky-x86_64.AppImage -C > ~/.conkyrc
$ ./conky-x86_64.AppImage
And that's it! Check out the Wiki for more details on configuring Conky.
Note: To use the AppImage, you may need to install additional runtime libraries.
Documentation
The GitHub Wiki serves as a central hub for all of
Conky's documentation.

Installation
Configuration Settings
User Configs
Frequently Asked Questions

License
Conky is licensed under the terms of the GPLv3 license.
Contributing
Contributions are welcome from anyone.
Please read CONTRIBUTING.md for guidelines on contributing to Conky.








About

      Light-weight system monitor for X.
    



github.com/brndnmtthws/conky/wiki


Topics



  conky


  imlib2


  cairo


  lua


  c-plus-plus


  system-monitoring



Resources



      Readme
 
License



        View license
    







    Releases
      43





Conky v1.11.6

          Latest
 
Jul 27, 2020

 

        + 42 releases





Sponsor this project



 


 Sponsor
        

  Learn more about GitHub Sponsors







    Packages 0


        No packages published 













    Contributors 123





 



 



 



 



 



 



 



 



 



 



 



      + 112 contributors





Languages














C++
84.0%





C
6.4%





CMake
4.8%





Objective-C++
2.3%





Python
1.5%





Vim script
0.4%





Other
0.6%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# conky

> Light-weight system monitor for X.
> More information: <https://github.com/brndnmtthws/conky>.

- Launch with default, built-in config:

`conky`

- Create a new default config:

`conky -C > ~/.conkyrc`

- Launch conky with a given config file:

`conky -c {{path/to/config}}`

- Start in the background (daemonize):

`conky -d`

- Align conky on the desktop:

`conky -a {{{top,bottom,middle}_{left,right,middle}}}`

- Pause for 5 seconds at startup before launching:

`conky -p {{5}}`
"
wpa_cli,,,,"# wpa_cli

> Add and configure wlan interfaces.

- Scan for available networks:

`wpa_cli scan`

- Show scan results:

`wpa_cli scan_results`

- Add a network:

`wpa_cli add_network {{number}}`

- Set a network's SSID:

`wpa_cli set_network {{number}} ssid ""{{SSID}}""`

- Enable network:

`wpa_cli enable_network {{number}}`

- Save config:

`wpa_cli save_config`
"
mycli,,,,"# mycli

> A CLI for MySQL, MariaDB, and Percona with auto-completion and syntax highlighting.

- Connect to a database with the currently logged in user:

`mycli {{database_name}}`

- Connect to a database with the specified user:

`mycli -u {{user}} {{database_name}}`

- Connect to a database on the specified host with the specified user:

`mycli -u {{user}} -h {{host}} {{database_name}}`
"
apt,,,"apt(1)									apt(1)



NAME
       apt - annotation processing tool

SYNOPSIS
       apt  [ -classpath classpath ] [ -sourcepath sourcepath ] [ -d directory
       ] [ -s directory ] [ -factorypath path ] [ -factory class ] [ -print  ]
       [  -nocompile  ] [ -A [ key [ =val ] ] ] [ javac option ] sourcefiles [
       @files ]

DESCRIPTION
       The tool apt, annotation processing tool, includes a set of new reflec-
       tive APIs and supporting infrastructure to process program annotations.
       The apt reflective APIs provide a build-time,  source-based,  read-only
       view  of  program  structure.  These  reflective  APIs  are designed to
       cleanly model the JavaTM programming language's type system  after  the
       addition  of  generics.	First, apt runs annotation processors that can
       produce new source code and other files. Next, apt can  cause  compila-
       tion  of  both original and generated source files, easing development.
       The reflective APIs and other APIs used to interact with the  tool  are
       subpackages of com.sun.mirror.

       A  fuller  discussion  of how the tool operates as well as instructions
       for  developing	with  apt  are	in  Getting  Started   with   apt   at
       http://java.sun.com/j2se/1.5.0/docs/guide/apt/GettingStarted.html.

PARAMETERS
       Options may be in any order. For a discussion of parameters which apply
       to a specific option, see OPTIONS below.

       sourcefiles    Zero or more source files to be processed.

       @files	      One or more  files  that	list  source  files  or  other
		      options.

OPTIONS
   apt specific options
       -s dir	      Specify  the directory root under which processor-gener-
		      ated source files will be placed; files  are  placed  in
		      subdirectories based on package namespace.

       -nocompile     Do not compile sources files to class files.

       -print	      Print  out  textual  representation  of specified types;
		      perform no annotation processing or compilation.

       -A[key[=val]]  Options to pass to annotation processors	--  these  are
		      not  interpreted by apt directly, but are made available
		      for use by individual processors

       -factorypath path
		      Specify where to find annotation processor factories; if
		      this  option  is used, the classpath is not searched for
		      factories.

       -factory classname
		      Name of annotation processor factory  to	use;  bypasses
		      default discovery process

   Options shared with javac
       -d dir	      Specify  where  to  place  processor and javac generated
		      class files

       -cp path       or
       -classpath path
		      Specify where to find user class	files  and  annotation
		      processor  factories.  If  -factorypath  is  given,  the
		      classpath is not searched for factories.

       Consult the javac(1) man page for information on javac options.

NOTES
       The apt tool and its associated APIs may be changed  or	superseded  in
       future j2se releases.

SEE ALSO
       javac(1) java(1)



				 13 June 2004				apt(1)
","# apt

> Package management utility for Debian based distributions.
> Recommended replacement for apt-get when used interactively in Ubuntu versions 16.04 and later.

- Update the list of available packages and versions (it's recommended to run this before other `apt` commands):

`sudo apt update`

- Search for a given package:

`apt search {{package}}`

- Show information for a package:

`apt show {{package}}`

- Install a package, or update it to the latest available version:

`sudo apt install {{package}}`

- Remove a package (using `purge` instead also removes its configuration files):

`sudo apt remove {{package}}`

- Upgrade all installed packages to their newest available versions:

`sudo apt upgrade`

- List all packages:

`apt list`

- List installed packages:

`apt list --installed`
"
runit,,,,"# runit

> 3-stage init system.

- Start runit's 3-stage init scheme:

`runit`

- Shut down runit:

`kill --CONT {{runit_pid}}`
"
http_load,http://www.acme.com/software/http_load/,"




http_load



http_load - multiprocessing http test client
Fetch the software.



      http_load runs multiple http fetches in parallel, to test the throughput
      of a web server.
      However unlike most such test clients, it runs in a single process,
      so it doesn't bog down the client machine.
      It can be configured to do https fetches as well.
    

      You give it a file containing a list of URLs that may be fetched,
      a flag specifying how to start connections (either by rate or
      by number of simulated users), and a flag specifying when to quit
      (either after a given number of fetches or a given elapsed time).
      There are also optional flags for checksums, throttling, random jitter,
      and progress reports.
    

      Sample run:
    

% ./http_load -rate 5 -seconds 10 urls
49 fetches, 2 max parallel, 289884 bytes, in 10.0148 seconds
5916 mean bytes/connection
4.89274 fetches/sec, 28945.5 bytes/sec
msecs/connect: 28.8932 mean, 44.243 max, 24.488 min
msecs/first-response: 63.5362 mean, 81.624 max, 57.803 min
HTTP response codes:
  code 200 -- 49
    

      See the manual entry for more details.
    



      See also:
      http_ping,
      http_get,
      thttpd.
A page of other http load-test tools.
ACME Labs / Software / http_load



",,"# http_load

> A HTTP benchmarking tool.
> Runs multiple HTTP fetches in parallel to test the throughput of a web server.
> More information: <http://www.acme.com/software/http_load/>.

- Emulate 20 requests based on a given URL list file per second for 60 seconds:

`http_load -rate {{20}} -seconds {{60}} {{path/to/urls.txt}}`

- Emulate 5 concurrent requests based on a given URL list file for 60 seconds:

`http_load -parallel {{5}} -seconds {{60}} {{path/to/urls.txt}}`

- Emulate 1000 requests at 20 requests per second, based on a given URL list file:

`http_load -rate {{20}} -fetches {{1000}} {{path/to/urls.txt}}`

- Emulate 1000 requests at 5 concurrent requests at a time, based on a given URL list file:

`http_load -parallel {{5}} -fetches {{1000}} {{path/to/urls.txt}}`
"
pstree,,,,"# pstree

> A convenient tool to show running processes as a tree.

- Display a tree of processes:

`pstree`

- Display a tree of processes with PIDs:

`pstree -p`

- Display all process trees rooted at processes owned by specified user:

`pstree {{user}}`
"
nm,,,"NM(1)									 NM(1)



NAME
       nm - display name list (symbol table)

SYNOPSIS
       llvm-nm [ -agnoprumxjlPA ] [ - ] [ -t format ] [[ -arch arch_flag ]...]
       [ file ... ] [ -s segname sectname ]

       nm-classic [ -agnoprumxjlfPA [ s segname sectname ]] [ - ] [ -t	format
       ] [[ -arch arch_flag ]...] [ file ... ]

DESCRIPTION
       As  of  Xcode  8.0  the default nm(1) tool is llvm-nm(1).  They for the
       most part have the same options except for -f and -s which the  differ-
       ences are noted below.  More help on options for llvm-nm(1) is provided
       when running it with the --help option.

       Nm displays the name list (symbol table of nlist  structures)  of  each
       object  file  in  the  argument list.  In some cases, as with an object
       that has had strip(1) with its -T option used on the object,  that  can
       be different than the dyld information.	For that information use dyld-
       info(1).

       If an argument is an archive, a listing for each object file in the ar-
       chive  will be produced.  File can be of the form libx.a(x.o), in which
       case only symbols from that member of the object file are listed.  (The
       parentheses  have  to  be  quoted  to get by the shell.)  If no file is
       given, the symbols in a.out are listed.

       Each symbol name is  preceded  by  its  value  (blanks  if  undefined).
       Unless the -m option is specified, this value is followed by one of the
       following characters, representing the symbol type:  U  (undefined),  A
       (absolute),  T  (text  section symbol), D (data section symbol), B (bss
       section symbol), C  (common  symbol),  -  (for  debugger  symbol  table
       entries; see -a below), S (symbol in a section other than those above),
       or I (indirect symbol).	If the symbol  is  local  (non-external),  the
       symbol's  type  is  instead  represented by the corresponding lowercase
       letter.	A lower case u in a dynamic shared library indicates  a  unde-
       fined  reference  to  a	private external in another module in the same
       library.

       If  the	symbol	is  a  Objective  C  method,  the   symbol   name   is
       +-[Class_name(category_name)  method:name:],  where  `+'  is  for class
       methods, `-' is for instance methods, and  (category_name)  is  present
       only when the method is in a category.

       The output is sorted alphabetically by default.

       Options are:

       -a     Display  all  symbol table entries, including those inserted for
	      use by debuggers.

       -g     Display only global (external) symbols.

       -n     Sort numerically rather than alphabetically.

       -o     Prepend file or archive element name to each output line, rather
	      than only once.

       -p     Don't sort; display in symbol-table order.

       -r     Sort in reverse order.

       -u     Display only undefined symbols.

       -U     Don't display undefined symbols.

       -m     Display  the  N_SECT  type  symbols  (Mach-O  symbols)  as (seg-
	      ment_name, section_name) followed by  either  external  or  non-
	      external	and then the symbol name.  Undefined, common, absolute
	      and indirect symbols get	displayed  as  (undefined),  (common),
	      (absolute), and (indirect), respectively.

       -x     Display  the  symbol  table entry's fields in hexadecimal, along
	      with the name as a string.

       -j     Just display the symbol names (no value or type).

       -s segname sectname
	      List only those symbols in the section (segname,sectname).   For
	      llvm-nm(1)  this	option	must  be last on the command line, and
	      after the files.

       -l     List a pseudo symbol .section_start if  no  symbol  has  as  its
	      value  the  starting address of the section.  (This is used with
	      the -s option above.)

       -arch arch_type
	      Specifies the architecture, arch_type, of the file for nm(1)  to
	      operate  on  when  the file is a universal file (see arch(3) for
	      the currently known arch_types).	The arch_type can be ""all""  to
	      operate  on  all	architectures  in the file.  The default is to
	      display the symbols from only the host architecture, if the file
	      contains	it;  otherwise,  symbols  for all architectures in the
	      file are displayed.

       -f  format
	      For llvm-nm(1) this specifies the output format.	 Where	format
	      can be bsd, sysv, posix or darwin.

       -f     For  nm-classic(1)  this	displays the symbol table of a dynamic
	      library flat (as one file not separate modules).	This is  obso-
	      lete and not supported with llvm-nm(1).

       -A     Write the pathname or library name of an object on each line.

       -P     Write information in a portable output format.

       -t format
	      For the -P output, write the numeric value in the specified for-
	      mat. The format shall be dependent on the single character  used
	      as the format option-argument:

       d      The value shall be written in decimal (default).

       o      The value shall be written in octal.

       x      The value shall be written in hexadecimal.

       -L     Display  the  symbols in the bitcode files in the (__LLVM,__bun-
	      dle) section if present instead of the  object's	symbol	table.
	      This  is the default if the object has no symbol table and there
	      is an (__LLVM,__bundle) section.

SEE ALSO
       ar(1), ar(5), Mach-O(5), stab(5), nlist(3), dyldinfo(1)

BUGS
       Displaying Mach-O symbols with -m is too verbose.  Without the -m, sym-
       bols in the Objective C sections get displayed as an `s'.



Apple, Inc.			 May 23, 2017				 NM(1)
","# nm

> List symbol names in object files.

- List global (extern) functions in a file (prefixed with T):

`nm -g {{file.o}}`

- List only undefined symbols in a file:

`nm -u {{file.o}}`

- List all symbols, even debugging symbols:

`nm -a {{file.o}}`

- Demangle C++ symbols (make them readable):

`nm --demangle {{file.o}}`
"
xinput,,,,"# xinput

> List available input devices, query information about a device and change input device settings.

- List all input devices:

`xinput list`

- Disable an input:

`xinput disable {{id}}`

- Enable an input:

`xinput enable {{id}}`

- Disconnect an input from its master:

`xinput float {{id}}`

- Reattach an input as slave to a master:

`xinput reattach {{id}} {{master_id}}`
"
viewnior,,,,"# viewnior

> Simple and elegant image viewer.

- View an image:

`viewnior {{path/to/image.ext}}`

- View in fullscreen mode:

`viewnior --fullscreen {{path/to/image.ext}}`

- View fullscreen in slideshow mode:

`viewnior --slideshow {{path/to/image.ext}}`
"
cpulimit,http://cpulimit.sourceforge.net/,"

CPU limit










CPU Usage Limiter for Linux





What is it?
cpulimit is a simple program which attempts to limit the cpu usage of a process
(expressed in percentage, not in cpu time).
This is useful to control batch jobs, when you don't want them to eat too much cpu.
It does not act on the nice value or other scheduling priority stuff, but on the real cpu usage.
Also, it is able to adapt itself to the overall system load, dynamically and quickly.


News
23 May 2012
CPUlimit has moved to github. Follow me and stay tuned.


23 May 2012
Nerd enough? Check out my new blog :)


29 November 2010
Are you a Londoner? If so, why don't you check out my new project ?


26 August 2010
This is just to say I love open source. I really do. I'm receiving everyday new patches, suggestions, ports, feature requests (and even compliments).
This is the strength of open source, it grows thanks to the community.

Keep going!

25 July 2010
Are you a mathematician, physicist, scientist, or just a curious person? Check out my new project thomthom

14 May 2009
Do you like cpulimit?
Nominate it as the best tool for sysadmins!

26 November 2008
Abcuser has written a great HOWTO for Ubuntu users. Check it out here!

10 September 2008
A team of researchers is successfully using cpulimit on Mare Nostrum, one of the most powerful computers in Europe. And I'm not kidding :)

7 September 2008
Special thanks to Wyatt for the donation and for providing me a Mac OS X shell.

30 August 2008
I've received a lot of requests for porting cpulimit to Mac OS X. So I've decided to do it, maybe there will be also a GUI. Stay tuned!

10 August 2008
Big thanks to Alexander, who made a huge donation to cpulimit.

16 February 2008
As promised, the subprocesses control implementation is at last in cpulimit svn. Check it out!

10 February 2008
A subversion repository is available thanks to sourceforge.
You can get latest source code (still unstable!) running the command:
svn checkout https://cpulimit.svn.sourceforge.net/svnroot/cpulimit/trunk cpulimit
Or you can browse the code from the web interface.

8 February 2008
Started subprocesses control implementation, since a lot of people are asking about this feature.
So stay tuned for a new version.

18 January 2007
Now the project is listed on the FSF/UNESCO Free Software Directory. Very glad for that!

26 December 2006

New homepage at http://cpulimit.sourceforge.net

23 December 2006
Source uploaded to sourceforge.

9 August 2006
Started a new project at sourceforge. You can see it here.

How it works

Note that you don't need to read this paragraph in order to use cpulimit, you can safely skip it if you are not interested in tweaking cpulimit.
So, you are curious to know the secrets of cpulimit :) Of course there is no secret if you are a C developer, but I will try to explain to everyone.
The work of cpulimit is done all in userspace, so it doesn't interfere with the Linux scheduler.
Basically, the target process, which you can specify by pid, name, or command line, is continuosly paused and resumed by sending it SIGSTOP and SIGCONT signals. Signals are sent by cpulimit in appropriate moments, based on the limit specified by user and the process statistics read from /proc.
[To be continued...]

System Requirements
cpulimit should run on every Linux 2.2 or greater.
It has been reported by several users that cpulimit works fine even on SMP hardware, but consider that if you have more than one cpu there is
a little difference in the meaning of cpu usage (see below).
If you can modify the source code of cpulimit to make it run in another OS, please notify me, so I can publish your code.
I think that the only non-portable code is to iterate through the process list and get process statistics.

Instructions
Download last stable version from here or get the latest source code from Subversion repository with this command:
svn checkout https://cpulimit.svn.sourceforge.net/svnroot/cpulimit/trunk cpulimit
Then extract the source and compile with make:

tar zxf cpulimit-xxx.tar.gz
cd cpulimit-xxx
make


Executable file name is cpulimit. You may want to copy it in /usr/bin.

Examples of use

Limit the process 'bigloop' by executable name to 40% CPU:

cpulimit --exe bigloop --limit 40
cpulimit --exe /usr/local/bin/bigloop --limit 40

Limit a process by PID to 55% CPU:

cpulimit --pid 2960 --limit 55

Launch a process by command line and limit it to 40% (in development version only!):

cpulimit --limit 40 /etc/rc.d/rc.boinc start

Notes

If your machine has one processor you can limit the percentage from 0% to 100%, which means that if you set for example 50%, your process cannot use more than 500 ms of cpu time for each second.
But if your machine has four processors, percentage may vary from 0% to 400%, so setting the limit to 200% means to use no more than half of the available power. In any case, the percentage is the same of what you see when you run top.


cpulimit should run at least with the same user running the controlled process.
But it is much better if you run cpulimit as root, in order to have a higher priority and a more precise control.
Now cpulimit does limit also the children of the specified process. The code is still experimental, so let me know how it is.


cpulimit is written just for fun by Angelo Marletta.
Please send your feedback, bug reports, feature requests or just thanks:) to marlonx80 at hotmail dot com




































",,"# cpulimit

> A tool to throttle the CPU usage of other processes.
> More information: <http://cpulimit.sourceforge.net/>.

- Limit an existing process with PID 1234 to only use 25% of the CPU:

`cpulimit --pid {{1234}} --limit {{25%}}`

- Limit an existing program by its executable name:

`cpulimit --exe {{program}} --limit {{25}}`

- Launch a given program and limit it to only use 50% of the CPU:

`cpulimit --limit {{50}} -- {{program arg1 arg2 ...}}`

- Launch a program, limit its CPU usage to 50% and run cpulimit in the background:

`cpulimit --limit {{50}} --background -- {{program}}`

- Kill its process if the program's CPU usage goes over 50%:

`cpulimit --limit 50 --kill -- {{program}}`

- Throttle both it and its child processes so that none go about 25% CPU:

`cpulimit --limit {{25}} --monitor-forks -- {{program}}`
"
ip,,,"
IP(4)			 BSD Kernel Interfaces Manual			 IP(4)

NAME
     ip -- Internet Protocol

SYNOPSIS
     #include <sys/socket.h>
     #include <netinet/in.h>

     int
     socket(AF_INET, SOCK_RAW, proto);

DESCRIPTION
     IP is the transport layer protocol used by the Internet protocol family.
     Options may be set at the IP level when using higher-level protocols that
     are based on IP (such as TCP and UDP).  It may also be accessed through a
     ``raw socket'' when developing new protocols, or special-purpose applica-
     tions.

     There are several IP-level setsockopt(2) /getsockopt(2) options.
     IP_OPTIONS may be used to provide IP options to be transmitted in the IP
     header of each outgoing packet or to examine the header options on incom-
     ing packets.  IP options may be used with any socket type in the Internet
     family.  The format of IP options to be sent is that specified by the IP
     protocol specification (RFC-791), with one exception: the list of
     addresses for Source Route options must include the first-hop gateway at
     the beginning of the list of gateways.  The first-hop gateway address
     will be extracted from the option list and the size adjusted accordingly
     before use.  To disable previously specified options, use a zero-length
     buffer:

     setsockopt(s, IPPROTO_IP, IP_OPTIONS, NULL, 0);

     IP_TOS and IP_TTL may be used to set the type-of-service and time-to-live
     fields in the IP header for SOCK_STREAM and SOCK_DGRAM sockets. For exam-
     ple,

     int tos = IPTOS_LOWDELAY;	     /* see <netinet/in.h> */
     setsockopt(s, IPPROTO_IP, IP_TOS, &tos, sizeof(tos));

     int ttl = 60;		     /* max = 255 */
     setsockopt(s, IPPROTO_IP, IP_TTL, &ttl, sizeof(ttl));

     If the IP_RECVDSTADDR option is enabled on a SOCK_DGRAM socket, the
     recvmsg call will return the destination IP address for a UDP datagram.
     The msg_control field in the msghdr structure points to a buffer that
     contains a cmsghdr structure followed by the IP address.  The cmsghdr
     fields have the following values:

     cmsg_len = CMSG_LEN(sizeof(struct in_addr))
     cmsg_level = IPPROTO_IP
     cmsg_type = IP_RECVDSTADDR

     If the IP_RECVTOS option is enabled on a SOCK_DGRAM or SOCK_RAW socket,
     the recvmsg call will return the TOS (type of service) field of the IP
     header.  The msg_control field in the msghdr structure points to a buffer
     that contains a cmsghdr structure followed by the TOS.  The cmsghdr
     fields have the following values:

     cmsg_len = CMSG_LEN(sizeof(u_char))
     cmsg_level = IPPROTO_IP
     cmsg_type = IP_RECVTOS

   Multicast Options
     IP multicasting is supported only on AF_INET sockets of type SOCK_DGRAM
     and SOCK_RAW, and only on networks where the interface driver supports
     multicasting.

     The IP_MULTICAST_TTL option changes the time-to-live (TTL) for outgoing
     multicast datagrams in order to control the scope of the multicasts:

     u_char ttl;     /* range: 0 to 255, default = 1 */
     setsockopt(s, IPPROTO_IP, IP_MULTICAST_TTL, &ttl, sizeof(ttl));

     Datagrams with a TTL of 1 are not forwarded beyond the local network.
     Multicast datagrams with a TTL of 0 will not be transmitted on any net-
     work, but may be delivered locally if the sending host belongs to the
     destination group and if multicast loopback has not been disabled on the
     sending socket (see below).  Multicast datagrams with TTL greater than 1
     may be forwarded to other networks if a multicast router is attached to
     the local network.

     For hosts with multiple interfaces, each multicast transmission is sent
     from the primary network interface.  The IP_MULTICAST_IF option overrides
     the default for subsequent transmissions from a given socket:

     struct in_addr addr;
     setsockopt(s, IPPROTO_IP, IP_MULTICAST_IF, &addr, sizeof(addr));

     where ""addr"" is the local IP address of the desired interface or
     INADDR_ANY to specify the default interface.  An interface's local IP
     address and multicast capability can be obtained via the SIOCGIFCONF and
     SIOCGIFFLAGS ioctls.  Normal applications should not need to use this
     option.

     If a multicast datagram is sent to a group to which the sending host
     itself belongs (on the outgoing interface), a copy of the datagram is, by
     default, looped back by the IP layer for local delivery.  The
     IP_MULTICAST_LOOP option gives the sender explicit control over whether
     or not subsequent datagrams are looped back:

     u_char loop;    /* 0 = disable, 1 = enable (default) */
     setsockopt(s, IPPROTO_IP, IP_MULTICAST_LOOP, &loop, sizeof(loop));

     This option improves performance for applications that may have no more
     than one instance on a single host (such as a router demon), by eliminat-
     ing the overhead of receiving their own transmissions.  It should gener-
     ally not be used by applications for which there may be more than one
     instance on a single host (such as a conferencing program) or for which
     the sender does not belong to the destination group (such as a time
     querying program).

     A multicast datagram sent with an initial TTL greater than 1 may be
     delivered to the sending host on a different interface from that on which
     it was sent, if the host belongs to the destination group on that other
     interface.  The loopback control option has no effect on such delivery.

     A host must become a member of a multicast group before it can receive
     datagrams sent to the group.  To join a multicast group, use the
     IP_ADD_MEMBERSHIP option:

     struct ip_mreq mreq;
     setsockopt(s, IPPROTO_IP, IP_ADD_MEMBERSHIP, &mreq, sizeof(mreq));

     where mreq is the following structure:

     struct ip_mreq {
	 struct in_addr imr_multiaddr; /* multicast group to join */
	 struct in_addr imr_interface; /* interface to join on */
     }

     imr_interface should be INADDR_ANY to choose the default multicast inter-
     face, or the IP address of a particular multicast-capable interface if
     the host is multihomed.  Membership is associated with a single inter-
     face; programs running on multihomed hosts may need to join the same
     group on more than one interface.	Up to IP_MAX_MEMBERSHIPS (currently
     20) memberships may be added on a single socket.

     To drop a membership, use:

     struct ip_mreq mreq;
     setsockopt(s, IPPROTO_IP, IP_DROP_MEMBERSHIP, &mreq, sizeof(mreq));

     where mreq contains the same values as used to add the membership.  Mem-
     berships are dropped when the socket is closed or the process exits.

   Raw IP Sockets
     Raw IP sockets are connectionless, and are normally used with the sendto
     and recvfrom calls, though the connect(2) call may also be used to fix
     the destination for future packets (in which case the read(2) or recv(2)
     and write(2) or send(2) system calls may be used).

     If proto is 0, the default protocol IPPROTO_RAW is used for outgoing
     packets, and only incoming packets destined for that protocol are
     received.	If proto is non-zero, that protocol number will be used on
     outgoing packets and to filter incoming packets.

     Outgoing packets automatically have an IP header prepended to them (based
     on the destination address and the protocol number the socket is created
     with), unless the IP_HDRINCL option has been set.	Incoming packets are
     received with IP header and options intact.

     IP_HDRINCL indicates the complete IP header is included with the data and
     may be used only with the SOCK_RAW type.

     #include <netinet/ip.h>

     int hincl = 1;		     /* 1 = on, 0 = off */
     setsockopt(s, IPPROTO_IP, IP_HDRINCL, &hincl, sizeof(hincl));

     Unlike previous BSD releases, the program must set all the fields of the
     IP header, including the following:

     ip->ip_v = IPVERSION;
     ip->ip_hl = hlen >> 2;
     ip->ip_id = 0;  /* 0 means kernel set appropriate value */
     ip->ip_off = offset;
     ip->ip_len = len;

     Note that the ip_off and ip_len fields are in host byte order.

     If the header source address is set to INADDR_ANY, the kernel will choose
     an appropriate address.

DIAGNOSTICS
     A socket operation may fail with one of the following errors returned:

     [EISCONN]	      when trying to establish a connection on a socket which
		      already has one, or when trying to send a datagram with
		      the destination address specified and the socket is
		      already connected;

     [ENOTCONN]       when trying to send a datagram, but no destination
		      address is specified, and the socket hasn't been con-
		      nected;

     [ENOBUFS]	      when the system runs out of memory for an internal data
		      structure;

     [EADDRNOTAVAIL]  when an attempt is made to create a socket with a net-
		      work address for which no network interface exists.

     [EACESS]	      when an attempt is made to create a raw IP socket by a
		      non-privileged process.

     The following errors specific to IP may occur when setting or getting IP
     options:

     [EINVAL]	      An unknown socket option name was given.

     [EINVAL]	      The IP option field was improperly formed; an option
		      field was shorter than the minimum value or longer than
		      the option buffer provided.

SEE ALSO
     getsockopt(2), recv(2), send(2), icmp(4), inet(4), intro(4)

HISTORY
     The ip protocol appeared in 4.2BSD.

4.2 Berkeley Distribution      November 30, 1993     4.2 Berkeley Distribution
","# ip

> Show / manipulate routing, devices, policy routing and tunnels.

- List interfaces with detailed info:

`ip a`

- Display the routing table:

`ip r`

- Show neighbors (ARP table):

`ip n`

- Make an interface up/down:

`ip link set {{interface}} up/down`

- Add/Delete an ip address to an interface:

`ip addr add/del {{ip}}/{{mask}} dev {{interface}}`

- Add a default route:

`ip route add default via {{ip}} dev {{interface}}`
"
vncserver,,,,"# vncserver

> Launches a VNC (Virtual Network Computing) desktop.

- Launch a VNC Server on next available display:

`vncserver`

- Launch a VNC Server with specific screen geometry:

`vncserver --geometry {{width}}x{{height}}`

- Kill an instance of VNC Server running on a specific display:

`vncserver --kill :{{display_number}}`
"
lrzip,,,,"# lrzip

> A large file compression program.
> See also `lrunzip`, `lrztar`, `lrzuntar`.

- Compress a file with LZMA - slow compression, fast decompression:

`lrzip {{filename}}`

- Compress a file with BZIP2 - good middle ground for compression/speed:

`lrzip -b {{filename}}`

- Compress with ZPAQ - extreme compression, but very slow:

`lrzip -z {{filename}}`

- Compress with LZO - light compression, extremely fast decompression:

`lrzip -l {{filename}}`

- Compress a file and password protect/encrypt it:

`lrzip -e {{filename}}`

- Override the number of processor threads to use:

`lrzip -p {{8}} {{filename}}`
"
print,,,,"# print

> An alias to a `run-mailcap`'s action print.
> Originally `run-mailcap` is used to process mime-type/file.

- Print action can be used to print any file on default run-mailcap tool:

`print {{filename}}`

- With `run-mailcap`:

`run-mailcap --action=print {{filename}}`
"
vgcreate,,,,"# vgcreate

> Create volume groups combining multiple mass-storage devices.

- Create a new volume group called vg1 using the `/dev/sda1` device:

`vgcreate {{vg1}} {{/dev/sda1}}`

- Create a new volume group called vg1 using multiple devices:

`vgcreate {{vg1}} {{/dev/sda1}} {{/dev/sdb1}} {{/dev/sdc1}}`
"
lsusb,,,,"# lsusb

> Display information about USB buses and devices connected to them.

- List all the USB devices available:

`lsusb`

- List the USB hierarchy as a tree:

`lsusb -t`

- List verbose information about USB devices:

`lsusb --verbose`

- List detailed information about a USB device:

`lsusb -D {{device}}`

- List devices with a specified vendor and product id only:

`lsusb -d {{vendor}}:{{product}}`
"
authconfig,,,,"# authconfig

> A CLI interface for configuring system authentication resources.

- Display the current configuration (or dry run):

`authconfig --test`

- Configure the server to use a different password hashing algorithm:

`authconfig --update --passalgo={{algorithm}}`

- Enable LDAP authentication:

`authconfig --update --enableldapauth`

- Disable LDAP authentication:

`authconfig --update --disableldapauth`

- Enable Network Information Service (NIS):

`authconfig --update --enablenis`

- Enable Kerberos:

`authconfig --update --enablekrb5`

- Enable Winbind (Active Directory) authentication:

`authconfig --update --enablewinbindauth`

- Enable local authorization:

`authconfig --update --enablelocauthorize`
"
mkfs.ntfs,,,,"# mkfs.ntfs

> Creates a NTFS filesystem inside a partition.

- Create a NTFS filesystem inside partition 1 on device b (`sdb1`):

`mkfs.ntfs {{/dev/sdb1}}`

- Create filesystem with a volume-label:

`mkfs.ntfs -L {{volume_label}} {{/dev/sdb1}}`

- Create filesystem with specific UUID:

`mkfs.ntfs -U {{UUID}} {{/dev/sdb1}}`
"
nmcli,,,,"# nmcli

> A command line tool for controlling NetworkManager.

- Check the nmcli version:

`nmcli --version`

- Call general help:

`nmcli --help`

- Call help on a command:

`nmcli {{command}} --help`

- Execute an `nmcli` command:

`nmcli {{command}}`
"
adduser,,,,"# adduser

> User addition utility.

- Create a new user with a default home directory and prompt the user to set a password:

`adduser {{username}}`

- Create a new user without a home directory:

`adduser --no-create-home {{username}}`

- Create a new user with a home directory at the specified path:

`adduser --home {{path/to/home}} {{username}}`

- Create a new user with the specified shell set as the login shell:

`adduser --shell {{path/to/shell}} {{username}}`

- Create a new user belonging to the specified group:

`adduser --ingroup {{group}} {{username}}`

- Add an existing user to the specified group:

`adduser {{username}} {{group}}`
"
wpa_passphrase,,,,"# wpa_passphrase

> Generate a WPA-PSK key from an ASCII passphrase for a given SSID.

- Compute and display the WPA-PSK key for a given SSID reading the passphrase from stdin:

`wpa_passphrase {{SSID}}`

- Compute and display WPA-PSK key for a given SSID specifying the passphrase as an argument:

`wpa_passphrase {{SSID}} {{passphrase}}`
"
mknod,,,"
MKNOD(8)		  BSD System Manager's Manual		      MKNOD(8)

NAME
     mknod -- make device special file

SYNOPSIS
     mknod [-F format] name [c | b] major minor
     mknod [-F format] name [c | b] major unit subunit
     mknod name [c | b] number
     mknod name w

DESCRIPTION
     The mknod command creates device special files.

     To make nodes manually, the required arguments are:

     name    Device name, for example ``sd'' for a SCSI disk on an HP300 or a
	     ``pty'' for pseudo-devices.

     b | c | w
	     Type of device. If the device is a block type device such as a
	     tape or disk drive which needs both cooked and raw special files,
	     the type is b.  Whiteout nodes are type w.  All other devices are
	     character type devices, such as terminal and pseudo devices, and
	     are type c.

     major   The major device number is an integer number which tells the ker-
	     nel which device driver entry point to use.

     minor   The minor device number tells the kernel which one of several
	     similar devices the node corresponds to; for example, it may be a
	     specific serial port or pty.

     unit and subunit
	     The unit and subunit numbers select a subset of a device; for
	     example, the unit may specify a particular SCSI disk, and the
	     subunit a partition on that disk.	(Currently this form of speci-
	     fication is only supported by the bsdos format, for compatibility
	     with the BSD/OS mknod(8).)

     Device numbers for different operating systems may be packed in a differ-
     ent format.  To create device nodes that may be used by such an operating
     system (e.g. in an exported file system used for netbooting), the -F
     option is used.  The following formats are recognized: native, 386bsd,
     4bsd, bsdos, freebsd, hpux, isc, linux, netbsd, osf1, sco, solaris,
     sunos, svr3, svr4 and ultrix.

     Alternatively, a single opaque device number may be specified.

SEE ALSO
     mkfifo(1), mkfifo(2), mknod(2)

HISTORY
     A mknod command appeared in Version 6 AT&T UNIX.  The -F option appeared
     in NetBSD 1.4.

NetBSD 1.4		      September 11, 1998		    NetBSD 1.4
","# mknod

> Create block or character device special files.

- Create a block device:

`sudo mknod {{path/to/device_file}} b {{major_device_number}} {{minor_device_number}}`

- Create a character device:

`sudo mknod {{path/to/device_file}} c {{major_device_number}} {{minor_device_number}}`

- Create a FIFO (queue) device:

`sudo mknod {{path/to/device_file}} p`

- Create a device file with default SELinux security context:

`sudo mknod -Z {{path/to/device_file}} {{type}} {{major_device_number}} {{minor_device_number}}`
"
runsvchdir,,,,"# runsvchdir

> Change the directory `runsvdir` uses by default.

- Switch `runsvdir` directories:

`sudo runsvchdir {{/path/to/directory}}`
"
gnome-terminal,,,,"# gnome-terminal

> The GNOME Terminal emulator.

- Open a new GNOME terminal window:

`gnome-terminal`

- Run a specific command in a new terminal window:

`gnome-terminal -- {{command}}`

- Open a new tab in the last opened window instead:

`gnome-terminal --tab`

- Set the title of the new tab:

`gnome-terminal --tab --title ""{{title}}""`
"
i3lock,https://i3wm.org/i3lock,"


i3 - improved tiling wm









i3 - improved tiling WM

Docs
Screens
FAQ
Contact
Bugs



i3lock

  i3lock is a simple screen locker like slock. After starting it, you will see
  a white screen (you can configure the color/an image). You can return to your
  screen by entering your password.

Improvements


    i3lock forks, so you can combine it with an alias to suspend to RAM (run
    ""i3lock && echo mem > /sys/power/state"" to get a locked screen
    after waking up your computer from suspend to RAM)
  

    You can specify either a background color or a PNG image which will be
    displayed while your screen is locked.
  

    You can specify whether i3lock should bell upon a wrong password.
  

    i3lock uses PAM and therefore is compatible with LDAP etc.
  

Install

  Many distributions include i3lock as a (potentially optional) dependency
  of the i3 package (see Downloads). You can also
  look for the specific package in your distribution, e.g. on Debian and
  Debian-based distributions:


sudo apt-get install i3lock

Releases


i3lock-2.12.tar.bz2 (2019-07-21,
    GPG signature)
  

i3lock-2.11.1.tar.bz2 (2018-10-18,
    GPG signature)
  

i3lock-2.11.tar.bz2 (2018-10-10,
    GPG signature)
  

i3lock-2.10.tar.bz2 (2017-11-25,
    GPG signature)
  

i3lock-2.9.1.tar.bz2 (2017-06-21,
    GPG signature)
  

i3lock-2.9.tar.bz2 (2017-05-26,
    GPG signature)
  

i3lock-2.8.tar.bz2 (2016-06-04,
    GPG signature)
  

i3lock-2.7.tar.bz2 (2015-05-20,
    GPG signature)
  

i3lock-2.6.tar.bz2 (2014-07-18,
    GPG signature)
  

i3lock-2.5.tar.bz2 (2013-06-09,
    GPG signature)
  

i3lock-2.4.1.tar.bz2 (2012-06-02,
    GPG signature)
  

i3lock-2.4.tar.bz2 (2012-04-01,
    GPG signature)
  

i3lock-2.3.1.tar.bz2 (2012-03-15,
    GPG signature)
  

i3lock-2.3.tar.bz2 (2012-03-15,
    GPG signature)
  

i3lock-2.2.tar.bz2 (2011-11-06,
    GPG signature)
  

i3lock-2.1.tar.gz (2011-03-13,
    GPG signature)
  

i3lock-2.0.tar.gz (2010-09-05,
    GPG signature)
  
i3lock-1.0.tar.gz (2009-05-10,
  GPG signature)
i3lock-0.9.tar.gz

Development

  i3lock is currently developed at 
  https://github.com/i3/i3lock. Checkouts of the master branch are intended to
  be stable and working all the time. Integration of new features happens in a separate branch.




        © 2009-present Michael Stapelberg,
        Impressum,
        Source


",,"# i3lock

> Simple screen locker built for the i3 window manager.
> More information: <https://i3wm.org/i3lock>.

- Lock screen with a simple color background (rrggbb format):

`i3lock -c {{0000ff}}`

- Lock screen to a PNG background:

`i3lock -i {{path/to/picture.png}}`

- Disable the unlock indicator (removes feedback on keypress):

`i3lock -u`

- Display mouse pointer instead of hiding it ('default' for default pointer, 'win' for a MS Windows pointer):

`i3lock -p {{default|win}}`

- Lock screen to a PNG background displayed in multiple monitors, with enabled mouse pointer:

`i3lock -i {{path/to/picture.png}} -p {{default|win}} -t`
"
ss,,,,"# ss

> Utility to investigate sockets.

- Show all TCP/UDP/RAW/UNIX sockets:

`ss -a {{-t|-u|-w|-x}}`

- Filter TCP sockets by states, only/exclude:

`ss {{state/exclude}} {{bucket/big/connected/synchronized/...}}`

- Show all TCP sockets connected to the local HTTPS port (443):

`ss -t src :{{443}}`

- Show all TCP sockets listening on the local 8080 port:

`ss -lt src :{{8080}}`

- Show all TCP sockets along with processes connected to a remote ssh port:

`ss -pt dst :{{ssh}}`

- Show all UDP sockets connected on specific source and destination ports:

`ss -u 'sport == :{{source_port}} and dport == :{{destination_port}}'`

- Show all TCP IPv4 sockets locally connected on the subnet 192.168.0.0/16:

`ss -4t src {{192.168/16}}`
"
aptitude,,,,"# aptitude

> Debian and Ubuntu package management utility.

- Synchronize list of packages and versions available. This should be run first, before running subsequent aptitude commands:

`aptitude update`

- Install a new package and its dependencies:

`aptitude install {{package}}`

- Search for a package:

`aptitude search {{package}}`

- Search for an installed package (`?installed` is an aptitude search term):

`aptitude search '?installed({{package}})'`

- Remove a package and all packages depending on it:

`aptitude remove {{package}}`

- Upgrade installed packages to newest available versions:

`aptitude upgrade`

- Upgrade installed packages (like `aptitude upgrade`) including removing obsolete packages and installing additional packages to meet new package dependencies:

`aptitude full-upgrade`

- Put an installed package on hold to prevent it from being automatically upgraded:

`aptitude hold '?installed({{package}})'`
"
cewl,https://digi.ninja/projects/cewl.php,"

















CeWL - Custom Wordlist Generator - DigiNinja






















HomeHire meLabsBlogProjectsContact


































CeWL - Custom Word List generator 
HomeProjectsGeneralCeWL - Custom Word List


			Based on a discussion on PaulDotCom episode 129 about creating custom word lists by spidering a targets website and collecting unique words I decided to write CeWL, the Custom Word List generator. CeWL is a ruby app which spiders a given url to a specified depth, optionally following external links, and returns a list of words which can then be used for password crackers such as John the Ripper.
		

			CeWL also has an associated command line app, FAB (Files Already Bagged) which uses the same meta data extraction techniques to create author/creator lists from already downloaded.
		
Change Log
Version 5.2

			Loads of changes including:
		

Code refactoring by @g0tmi1k
Internationalisation - should now handle non-ASCII sites much better
Found more ways to pull words out of JavaScript content and other areas that aren't normal HTML
Lots of little bug fixes

Version 5.1

			Added the GPL-3+ licence to allow inclusion in Debian.
		

			Added a Gemfile to make installing gems easier.
		
Version 5.0

Adds proxy support from the command line and the ability to pass in
credentials for both basic and digest authentication. Usage is simple, check
the help (--help) for full information.


A few other smaller bug fixes as well.

Version 4.3

			CeWL now sorts the words found by count and optionally (new --count argument) includes the word count in the output. I've left the words in the case they are in the pages so ""Product"" is different to ""product"" I figure that if it is being used for password generation then the case may be significant so let the user strip it if they want to. There are also more improvments to the stability of the spider in this release.
		

			By default, CeWL sticks to just the site you have specified and will go to a depth of 2 links, this behaviour can be changed by passing arguments. Be careful if setting a large depth and allowing it to go offsite, you could end up drifting on to a lot of other domains. All words of three characters and over are output to stdout. This length can be increased and the words can be written to a file rather than screen so the app can be automated.
		
Version 4.2

			Version 4.2 fixes a pretty major bug that I found while fixing a smaller bug for @yorikv. The bug was related to a hack I had to put in place because of a problem I was having with the spider, while I was looking in to it I spotted this line which is the one that the spider uses to find new links in downloaded pages:
		
web_page.scan(/href=""(.*?)""/i).flatten.map do |link|

			This is fine if all the links look like this:
		
<a href=""test.php"">link</a>

			But if the link looks like either of these:
		
<a href='test.php'>link</a>
<a href=test.php>link</a>

			the regex will fail so the links will be ignored.
		

			To fix this up I've had to override the function that parses the page to find all the links, rather than use a regex I've changed it to use Nokogiri which is designed to parse a page looking for links rather than just running through it with a custom regex. This brings in a new dependency but I think it is worth it for the fix to the functionality. I also found another bug where a link like this:
		
<a href='#name'>local</a>

			which should be ignored as it just links to an internal name was actually being translated to '/#name' which may unintentionally mean referencing the index page. I've fixed this one as well after a lot of debugging to find how best to do it.
		

			A final addition is to allow a user to specify a depth of 0 which allows CeWL to spider a single page.
		

			I'm only putting this out as a point release as I'd like to rewrite the spidering to use a better spider, that will come out as the next major release.
		
Version 4.1

			Version 4.1 is mainly bug fixes but one important feature change is the addition of two new parameters, meta_file and email_file. Previously you specified the filename for email and metadata output as optional fields to the email and meta parameters but I found that if you used the parameters in a specific order you could end up with this:
		
./cewl.rb --email http://www.digininja.org

			This would take the URL as the output filename for the email parameter which isn't what is meant, hence removing the optional filename from the email parameter and adding the email_file parameter instead.
		

			The main change in version 4 is the upgrade to run with Ruby 1.9.x, this has been tested on various machines and on BT5 as that is a popular platform for running it and it appears to run fine. Another minor change is that Up to version 4 all HTML tags were stripped out before the page was parsed for words, this meant that text in alt and title tags were missed. I now grab the text from those tags before stripping the HTML to give those extra few works.
		
Version 3.0

			Version 3 of CeWL addresses a problem spotted by Josh Wright. The Spider gem doesn't handle JavaScript redirection URLs, for exmaple an index page containing just the following:
		
<script language=""JavaScript"">
self.location.href =
'http://www.FOO.com/FOO/connect/FOONet/Top+Navigator/Home';
</script>


			wasn't spidered because the redirect wasn't picked up. I now scan through a page looking for any lines containing ""location.href="" and then add the given URL to the list of pages to spider.
		
Version 2.0

			Version 2 of CeWL can also create two new lists, a list of email addresses found in mailto links and a list of author/creator names collected from meta data found in documents on the site. It can currently process documents in Office pre 2007, Office 2007 and PDF formats. This user data can then be used to create the list of usernames to be used in association with the password list.
		
Pronunciation

			Seeing as I was asked, CeWL is pronounced ""cool"".
		
Download

			The latest version is now available on GitHub. Tagged releases are also available in various distros, including Kali.
		

download cewl version 5.2
download cewl version 5.1
download cewl version 5.0
download cewl version 4.3
download cewl version 4.2
download cewl version 4.1
download cewl version 3.0

Installation

			CeWL needs the rubygems package to be installed along with the following gems:
		

nokogiri
mime-types
mini_exiftool
rubyzip
spider


			These can be installed by running
		
bundle install

		from the cewl directory. The mini_exiftool gem also requires the exiftool application to be installed.
		

			On BT5 there is a problem with the version of Ruby installed by default. To get around this I've found the following works well on a brand new BT5 install:
		
gem source -c
gem install --user-install spider http_configuration mini_exiftool zip mime-types

			To use the gems you may also need to set the following environment variable:
		
RUBYOPT=""rubygems""

			Then just save CeWL to a directory and make it executable.
		
Usage

			cewl [OPTION] ... URL
		

--help, -hShow help
--depth x, -d xThe depth to spider to, default 2
--min_word_length, -mThe minimum word length, this strips out all words under the specified length, default 3
--offsite, -oBy default, the spider will only visit the site specified. With this option it will also visit external sites
--write, -w fileWrite the ouput to the file rather than to stdout
--ua, -u user-agentChange the user agent
-vVerbose, show debug and extra output
--no-words, -nDon't output the wordlist
--meta, -a fileInclude meta data, optional output file
--email, -e fileInclude email addresses, optional output file
--meta_file fileFilename for metadata output
--email_file fileFilename for email output
--meta-temp-dir directoryThe directory used used by exiftool when parsing files, the default is /tmp
--count, -c:Show the count for each of the words found
--auth_typeDigest or basic
--auth_userAuthentication username
--auth_passAuthentication password
--proxy_hostProxy host
--proxy_portProxy port, default 8080
--proxy_usernameUsername for proxy, if required
--proxy_passwordPassword for proxy, if required
--verbose, -vVerbose
URLThe site to spider.

Common Problems

			Here are a couple of the common problems people have seen while trying to use CeWL and FAB.
		
Missing exiftool

		If you see this error while trying to run either CeWL or FAB
		

/usr/lib/ruby/gems/1.8/gems/mini_exiftool-1.0.1/lib/mini_exiftool.rb:246:in `exiftool_version': Command 'exiftool' not found (MiniExiftool::Error)
from /usr/lib/ruby/gems/1.8/gems/mini_exiftool-1.0.1/lib/mini_exiftool.rb:265
from /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:36:in `gem_original_require'
from /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:36:in `require'
from ./cewl_lib.rb:1
from /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require'
from /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `require'
from ./cewl.rb:58

			then the application can't access exiftool. Either install it or make sure it is in your path.
		
HTTPS Problem

			It has been reported that if you see this problem
		
/usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require': no such file to load -- net/https (LoadError)
from /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `require'
from /usr/lib/ruby/gems/1.8/gems/spider-0.4.4/lib/spider/spider_instance.rb:30
from /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `gem_original_require'
from /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:31:in `require'
from /usr/lib/ruby/gems/1.8/gems/spider-0.4.4/lib/spider.rb:26
from /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:36:in `gem_original_require'
from /usr/local/lib/site_ruby/1.8/rubygems/custom_require.rb:36:in `require'
from ./cewl.rb:56

			Then you need the Ruby libopenssl package. In Debian the package is called libopenssl-ruby.
		
Spider Missing Pages

			Someone has reported that the spider misses some pages which are have querystrings on them. I haven't been able to reproduce this in my tests. If anyone has this problem and can reproduce it please let me know and I'll investigate it further.
		


Table of Contents

Pronunciation
Download
Installation
Usage
Common Problems

Categories

Wifi
Networking
Metasploit
General


Support The Site

		I don't get paid for any of the projects on this site so if you'd like to support my work you can do so by using the affiliate links below where I either get account credits or cash back. Usually only pennies, but they all add up.
	


Buy me a smoothie











	All content created by Robin Wood unless otherwise stated
	




",,"# cewl

> URL spidering tool for making a cracking wordlist from web content.
> More information: <https://digi.ninja/projects/cewl.php>.

- Create a wordlist file from the given URL up to 2 links depth:

`cewl --depth {{2}} --write {{path/to/wordlist.txt}} {{url}}`

- Output an alpha-numeric wordlist from the given URL with words of minimum 5 characters:

`cewl --with-numbers --min_word_length {{5}} {{url}}`

- Output a wordlist from the given URL in debug mode including email addresses:

`cewl --debug --email {{url}}`

- Output a wordlist from the given URL using HTTP Basic or Digest authentication:

`cewl --auth_type {{basic|digest}} --auth_user {{username}} --auth_pass {{password}} {{url}}`

- Output a wordlist from the given URL through a proxy:

`cewl --proxy_host {{host}} --proxy_port {{port}} {{url}}`
"
mullvad,https://mullvad.net/,"


















Mullvad VPN - Privacy is a universal right




















































Mullvad VPN








Help
Servers
Blog
Policies
About



Log in


My account






Download














You have a right to privacy
In a society increasingly determined to erode that right, a fast, trustworthy and easy-to-use VPN is a good first step toward reclaiming it.


Generate account
What is a VPN?

















 
Compy







































































Evade hackers and trackers
When you connect to the internet with Mullvad, we ensure that the traffic to and from your computer is encrypted to the highest standards even if you are using a public WiFi network at a cafe or hotel.




Keep your privacy
We keep no activity logs, do not ask for personal information, and even encourage anonymous payments via cash or one of the cryptocurrencies we accept.  Your IP address is replaced by one of ours, ensuring that your device's activity and location are not linked to you.


 





































































































































































































Easy to use
Using Mullvad is straightforward and simple – just download and install the app. You won't need to waste time with setup configurations or a multi-step registration process. We built Mullvad with ease of use in mind.












Privacy is a universal right
Privacy is fundamental to a well-functioning society because it allows norms, ethics, and laws to be safely discussed and challenged. Without privacy, a free and open society can neither flourish nor exist.

That is why we provide a VPN service that helps keep your online activity, identity, and location private for only €5/month.


Generate account
What is a VPN?












Getting started with Mullvad







1. Generate an account number
The account number is the only thing you need to connect to Mullvad VPN. We ask for no email, no phone number, no personal information whatsoever.



























651805498695











































































































651805498695













































































2. Pay only €5/month (≈$5.50)
Just one flat rate of €5 per month for peace-of-mind privacy. If you’re not satisfied, we offer a 30-day money back guarantee.




3. Download Mullvad and you're set
Download the Mullvad VPN app, enter your account number, and you're ready to roll. Use your account on up to 5 devices.




























651805498695




























































































4. Become a privacy ninja
When protecting your online privacy, no single-step solution exists. Instead, it is about changing your habits and using certain tools. Read our guide.







Get started now
Generate account









Mullvad

Help
Servers
Blog
What is a VPN?
What is privacy?
Download
Press
Jobs



Policies

Open source
Privacy policy
Cookies
Terms of service
Partnerships and resellers
Reviews, ads and affiliates
Reporting a bug or vulnerability



Address

Mullvad VPN AB
Box 53049
400 14 Gothenburg
Sweden



Follow us




MullvadNet





@mullvadnet





mullvad





support@mullvad.net



GPG key




Onion service: xcln5hkbriyklr6n.onion
Language





English








العربيّة
Dansk
Deutsch
English
Español
فارسی
Suomi
Français
Italiano
日本語
한국어
Nederlands
Norsk
Polski
Português
Русский
Svenska
ภาษาไทย
Türkçe
繁體中文









",,"# mullvad

> CLI client for Mullvad VPN.
> More information: <https://mullvad.net/>.

- Link your mullvad account with the specified account number:

`mullvad account set {{account_number}}`

- Enable LAN access while VPN is on:

`mullvad lan set allow`

- Establish the VPN tunnel:

`mullvad connect`

- Check status of VPN tunnel:

`mullvad status`
"
konsole,https://konsole.kde.org,"




Konsole





























            Konsole
          


Changelog


Download


Get Involved


User support


Donation




      Made by KDE
    







Konsole
A powerful and customizable terminal emulator.





Konsole - KDE's Terminal Emulator

[konqi@kde ~]$ cd $HOME
[konqi@kde ~]$ echo ""Welcome home""
Welcome home
[konqi@kde ~]$ echo ""Konsole is KDE's Terminal Emulator""
Konsole is KDE's Terminal Emulator
[konqi@kde ~]$ cat konsole_features.txt
* Multiple tabs support
* Multiple profiles support
* Silence and Activity monitoring
* Bookmark support
* Searching
* Saving output
* Multiple splits in any tab
    
Screenshots



Some of Konsole's new features in 20.08 release.


Konsole is also integrated into multiple other KDE Applications making it easier to reach and more convenient. For example, KDevelop, Kate and Dolphin all use Konsole as an integrated terminal emulator.



Dolphin using the integrate Konsole widget.








                        Donate to KDE
                        Why Donate?











 €
                        Donate via PayPal

Other ways to donate






Community
Forums


News & Press
Announcements
KDE.news
Planet KDE




Post on Facebook
Share on Twitter
Share on Diaspora
Share on Mastodon
Share on LinkedIn
Share on Reddit
Share on YouTube
Share on PeerTube
Share on VK
Share on Instagram




                Maintained by 
                    KDE www


                KDE® and the K Desktop Environment® logo are registered trademarks of KDE e.V. |
                Legal





",,"# konsole

> Konsole: The KDE terminal emulator.
> More information: <https://konsole.kde.org>.

- Open a new Konsole in a specific directory:

`konsole --workdir {{path/to/directory}}`

- Run a specific command and do not close the window after it exits:

`konsole --noclose -e {{command}}`

- Open a new tab:

`konsole --new-tab`

- Open a Konsole in the background and bring to the front when Ctrl+Shift+F12 (by default) is pressed:

`konsole --background-mode`

- Open a Konsole with the emergency FALLBACK profile:

`konsole --fallback-profile`
"
lvextend,,,,"# lvextend

> Increase the size of a logical volume.

- Increase a volume's size to 120GB:

`lvextend --size {{120G}} {{logical_volume}}`

- Increase a volume's size by 40GB as well as the underlying filesystem:

`lvextend --size +{{40G}} -r {{logical_volume}}`

- Increase a volume's size to 100% of the free phyiscal volume space:

`lvextend --size {{100}}%FREE {{logical_volume}}`
"
dunstify,,,,"# dunstify

> A notification tool that is an extension of notify-send, but has more features based around dunst.
> Works with all options that work for notify-send.

- Show a notification with a given title and message:

`dunstify {{""Title""}} {{""Message""}}`

- Show a notification with specified urgency:

`dunstify {{""Title""}} {{""Message}}"" -u {{low|normal|critical}}`

- Specify a message ID (overwrites any previous messages with the same ID):

`dunstify {{""Title""}} {{""Message""}} -r {{123}}`

- To see other possible options:

`notify-send --help`
"
xeyes,,,,"# xeyes

> Display eyes on the screen that follow the mouse cursor.

- Launch xeyes on the local machine's default display:

`xeyes`

- Launch xeyes on a remote machine's display 0, screen 0:

`xeyes -display {{remote_host}}:{{0}}.{{0}}`
"
dmenu,,,,"# dmenu

> Dynamic menu.
> Creates a menu from a text input with each item on a new line.

- Display a menu of the output of the `ls` command:

`{{ls}} | dmenu`

- Display a menu with custom items separated by a new line (`\n`):

`echo -e ""{{red}}\n{{green}}\n{{blue}}"" | dmenu`

- Let the user choose between multiple items and save the selected one to a file:

`echo -e ""{{red}}\n{{green}}\n{{blue}}"" | dmenu > {{color.txt}}`

- Launch dmenu on a specific monitor:

`ls | dmenu -m {{1}}`

- Display dmenu at the bottom of the screen:

`ls | dmenu -b`
"
wipefs,,,,"# wipefs

> Wipe filesystem, raid, or partition-table signatures from a device.

- Display signatures for specified device:

`sudo wipefs {{/dev/sda}}`

- Wipe all available signatures for specified device:

`sudo wipefs --all {{/dev/sda}}`

- Perform dry run:

`sudo wipefs --all --no-act {{/dev/sda}}`

- Force wipe, even if the filesystem is mounted:

`sudo wipefs --all --force {{/dev/sda}}`
"
efibootbgr,https://linux.die.net/man/8/efibootmgr,"

efibootmgr(8): change EFI Boot Manager - Linux man page
















efibootmgr(8) - Linux man page
Name
efibootmgr - manipulate the EFI Boot Manager
Synopsis





efibootmgr [ -a ] [ -A ] [ -b XXXX ] [ -B XXXX ] [ -c ] [ -d DISK ] [ -e
1|3|-1 ] [ -E NUM ] [ -g ] [ -H XXXX ] [ -i NAME ] [ -l NAME ] [ -L
LABEL ] [ -n XXXX ] [ -N ] [ -o XXXX,YYYY,ZZZZ ... ] [ -O ] [ -p
PART ] [ -q ] [ -t seconds ] [ -T ] [ -u ] [ -U XXXX ] [ -v ] [ -V ] [ -w ] [
-@ file ]
Description
efibootmgr is a userspace application used to modify the Intel Extensible Firmware Interface (EFI) Boot Manager. This application can create and
destroy boot entries, change the boot order, change the next running boot option, and more.
Details on the EFI Boot Manager are available from the EFI Specification, v1.02 or later, available from: <URL:http://developer.intel.com>
Note: efibootmgr requires that the kernel support access to EFI non-volatile variables (through /proc/efi/vars on 2.4 kernels,
/sys/firmware/efi/vars on 2.6 kernels). modprobe efivars should do the trick.
Options
The following is a list of options accepted by efibootmgr:

-a | --active
Sets bootnum active
-A | --inactive
Sets bootnum inactive
-b | --bootnum XXXX
Modify BootXXXX (hex)
-B | --delete-bootnum
Delete bootnum (hex)
-c | --create
Create new variable bootnum and add to bootorder
-d | --disk DISK
The disk containing the loader (defaults to /dev/sda)
-e | --edd 1|3|-1
Force EDD 1.0 or 3.0 creation variables, or guess.
-E | --device NUM
EDD 1.0 device number (defaults to 0x80)
-g | --gpt
Force disk with invalid PMBR to be treated as GPT
-H | --acpi_hid XXXX
set the ACPI HID (used with -i)
-i | --iface NAME
create a netboot entry for the named interface
-l | --loader NAME
Specify a loader (defaults to \\elilo.efi)
-L | --label LABEL
Boot manager display label (defaults to ""Linux"")
-n | --bootnext XXXX
Set BootNext to XXXX (hex)
-N | --delete-bootnext
Delete BootNext
-o | --bootorder XXXX,YYYY,ZZZZ
Explicitly set BootOrder (hex)
-O | --delete-bootorder
Delete BootOrder
-p | --part PART
Partition number containing the bootloader (defaults to 1)
-q | --quiet
Quiet mode - supresses output.
--test filename
Don't write to NVRAM, write to filename.
-t | --timeout seconds
Boot Manager timeout, in seconds.
-T | --delete-timeout
Delete Timeout variable.
-u | --unicode | --UCS-2
pass extra command line arguments as UCS-2 (default is ASCII)
-U | --acpi_uid XXXX
set the ACPI UID (used with -i)
-v | --verbose
Verbose mode - prints additional information
-V | --version
Just print version string and exit.
-w | --write-signature
write unique signature to the MBR if needed
-@ | --append-binary-args
append extra variable args from file (use - to read from stdin). Data in file is appended as command line arguments to the boot loader command, with no
modification to the data, so you can pass any binary or text data necessary.
Examples
.
Displaying the Current Settings (must Be Root).
[root@localhost ~]# efibootmgr BootCurrent: 0004 BootNext: 0003 BootOrder: 0004,0000,0001,0002,0003 Timeout: 30 seconds Boot0000* Diskette Drive(device:0)
Boot0001* CD-ROM Drive(device:FF) Boot0002* Hard Drive(Device:80)/HD(Part1,Sig00112233) Boot0003* PXE Boot: MAC(00D0B7C15D91) Boot0004* Linux
This shows:


BootCurrent - the boot entry used to start the currently running system
BootOrder - the boot order as would appear in the boot manager. The boot manager tries to boot the first active entry in this list. If unsuccessful, it
tries the next entry, and so on.
BootNext - the boot entry which is scheduled to be run on next boot. This supercedes BootOrder for one boot only, and is deleted by the boot manager after
first use. This allows you to change the next boot behavior without changing BootOrder.
Timeout - the time in seconds between when the boot manager appears on the screen until when it automatically chooses the startup value from BootNext or
BootOrder.
Five boot entries (0000 - 0004), along with the active/inactive flag (* means active) and the name displayed on the screen.
.
Creating a New Boot Option
An OS installer would call efibootmgr -c. This assumes that /boot/efi is your EFI System Partition, and is mounted at /dev/sda1. This
creates a new boot option, called ""Linux"", and puts it at the top of the boot order list. Options may be passed to modify the default behavior. The default OS
Loader is elilo.efi.
.
Changing the Boot Order
Assuming the configuration in Example #1, efibootmgr -o 3,4 could be called to specify PXE boot first, then Linux boot.
.
Changing the Boot Order for the Next Boot Only
Assuming the configuration in Example #1, efibootmgr -n 4 could be called to specify that the Linux entry be taken on next boot.
.
Deleting a Boot Option
Assuming the configuration in Example #1, efibootmgr -b 4 -B could be called to delete entry 4 and remove it from the BootOrder.
.
Creating Network Boot Entries
A system administrator wants to create a boot option to network boot (PXE). Unfortunately, this requires knowing a little more information about your system
than can be easily found by efibootmgr, so you've got to pass additional information - the ACPI HID and UID values. These can generally be found by using the
EFI Boot Manager (in the EFI environment) to create a network boot entry, then using efibootmgr to print it verbosely. Here's one example: Boot003*
Acpi(PNP0A03,0)/PCI(5|0)/Mac(00D0B7F9F510) \ ACPI(a0341d0,0)PCI(0,5)MAC(00d0b7f9f510,0) In this case, the ACPI HID is ""0A0341d0"" and the UID is ""0"". For the
zx2000 gigE, the HID is ""222F"" and the UID is ""500"". For the rx2000 gigE, the HID is ""0002"" and the UID is ""100"". You create the boot entry with: efibootmgr
-c -i eth0 -H 222F -U 500 -L netboot
Bugs
Please direct any bugs, features, patches, etc. to Matt Domsch <Matt_Domsch@dell.com>.
Author
This man page was generated by dann frazier <dannf@debian.org> for the Debian GNU/Linux operating system, but may be used by others.
See Also
elilo(1)









Site Search











Library
linux docs
linux man pages
page load time


Toys
world sunlight
moon phase
trace explorer







",,"# efibootmgr

> Manipulate the UEFI Boot Manager (the Bootoptions).
> More information: https://linux.die.net/man/8/efibootmgr.

- List the current settings / bootnums:

`efibootmgr`

- List the filepaths:

`efibootmgr -v`

- Add UEFI Shell v2 as a boot option:

`sudo efibootmgr -c -d {{/dev/sda1}} -l {{\EFI\tools\Shell.efi}} -L ""{{UEFI Shell}}""`

- Change the current boot order:

`sudo efibootmgr -o {{0002,0008,0001,0005}}`

- Delete a boot option:

`sudo efibootmgr -b {{0008}} --delete-bootnum`
"
makepkg,https://wiki.archlinux.org/index.php/Makepkg,"


makepkg - ArchWiki





















Home Packages Forums Wiki Bugs Security AUR Download 








makepkg

From ArchWiki


Jump to navigation
Jump to search


Related articles
Creating packages
PKGBUILD
.SRCINFO
Arch User Repository
pacman
Official repositories
Arch Build System

makepkg is a script to automate the building of packages. The requirements for using the script are a build-capable Unix platform and a PKGBUILD.
makepkg is provided by the pacman package.

Contents

1 Configuration

1.1 Packager information
1.2 Package output
1.3 Signature checking


2 Usage
3 Tips and tricks

3.1 Reduce source download and extraction times
3.2 Building optimized binaries
3.3 Improving compile times

3.3.1 Parallel compilation
3.3.2 Building from files in memory
3.3.3 Using a compilation cache


3.4 Generate new checksums
3.5 Use other compression algorithms
3.6 Utilizing multiple cores on compression
3.7 Show packages with specific packager
3.8 Build 32-bit packages on a 64-bit system


4 Troubleshooting

4.1 Specifying install directory for QMAKE based packages
4.2 WARNING: Package contains reference to $srcdir
4.3 Makepkg fails to download dependencies when behind proxy

4.3.1 Enable proxy by setting its URL in XferCommand
4.3.2 Enable proxy via sudoer's env_keep


4.4 Makepkg fails, but make succeeds


5 See also


Configuration
See makepkg.conf(5) for details on configuration options for makepkg.
The system configuration is available in /etc/makepkg.conf, but user-specific changes can be made in $XDG_CONFIG_HOME/pacman/makepkg.conf or ~/.makepkg.conf. It is recommended to review the configuration prior to building packages.

Packager information
Each package is tagged with metadata identifying amongst others also the packager. By default, user-compiled packages are marked with Unknown Packager. If multiple users will be compiling packages on a system, or you are otherwise distributing your packages to other users, it is convenient to provide real contact. This can be done by setting the PACKAGER variable in makepkg.conf.
To check this on an installed package:

$ pacman -Qi package
...
Packager       : John Doe <john@doe.com>
...

To automatically produce signed packages, also set the GPGKEY variable in makepkg.conf.

Package output
By default, makepkg creates the package tarballs in the working directory and downloads source data directly to the src/ directory. Custom paths can be configured, for example to keep all built packages in ~/build/packages/ and all sources in ~/build/sources/.
Configure the following makepkg.conf variables if needed:

PKGDEST — directory for storing resulting packages
SRCDEST — directory for storing source data (symbolic links will be placed to src/ if it points elsewhere)
SRCPKGDEST — directory for storing resulting source packages (built with makepkg -S)
Tip: The PKGDEST directory can be cleaned up with e.g. paccache -c ~/build/packages/ as described in pacman#Cleaning the package cache.
Signature checking
Note: The signature checking implemented in makepkg does not use pacman's keyring, instead relying on the user's keyring.[1]
If a signature file in the form of .sig or .asc is part of the PKGBUILD source array, makepkg automatically attempts to verify it. In case the user's keyring does not contain the needed public key for signature verification, makepkg will abort the installation with a message that the PGP key could not be verified. 
If a needed public key for a package is missing, the PKGBUILD will most likely contain a validpgpkeys entry with the required key IDs. You can import it manually, or you can find it on a keyserver and import it from there.

Usage
Before continuing, install the base-devel group. Packages belonging to this group are not required to be listed as build-time dependencies (makedepends) in PKGBUILD files.

Note:
Make sure sudo is configured properly for commands passed to pacman.
Running makepkg itself as root is disallowed.[2] Besides how a PKGBUILD may contain arbitrary commands, building as root is generally considered unsafe.[3] Users who have no access to a regular user account should run makepkg as the nobody user.
To build a package, one must first create a PKGBUILD, or build script, as described in Creating packages. Existing scripts are available from the Arch Build System (ABS) tree or the AUR. Once in possession of a PKGBUILD, change to the directory where it is saved and run the following command to build the package:

$ makepkg

If required dependencies are missing, makepkg will issue a warning before failing. To build the package and install needed dependencies, add the flag -s/--syncdeps:

$ makepkg --syncdeps

Adding the -r/--rmdeps flag causes makepkg to remove the make dependencies later, which are no longer needed. If constantly building packages, consider using Pacman/Tips and tricks#Removing unused packages (orphans) once in a while instead.

Note:
These dependencies must be available in the configured repositories; see pacman#Repositories and mirrors for details. Alternatively, one can manually install dependencies prior to building (pacman -S --asdeps dep1 dep2).
Only global values are used when installing dependencies, i.e any override done in a split package's packaging function will not be used.

Once all dependencies are satisfied and the package builds successfully, a package file (pkgname-pkgver.pkg.tar.zst) will be created in the working directory. To install, use -i/--install (same as pacman -U pkgname-pkgver.pkg.tar.zst):

$ makepkg --install

To clean up leftover files and folders, such as files extracted to the $srcdir, add the option -c/--clean. This is useful for multiple builds of the same package or updating the package version, while using the same build folder. It prevents obsolete and remnant files from carrying over to the new builds:

$ makepkg --clean

For more, see makepkg(8).

Tips and tricks
Reduce source download and extraction times
Make use of SRCDEST, especially when building VCS packages, to save time acquiring and unpacking sources in subsequent rebuilds.

Building optimized binaries
A performance improvement of the packaged software can be achieved by enabling compiler optimizations for the host machine. The downside is that binaries compiled for a specific processor architecture will not run correctly on other machines. On x86_64 machines, there are rarely significant enough real world performance gains that would warrant investing the time to rebuild official packages.
However, it is very easy to reduce performance by using ""nonstandard"" compiler flags. Many compiler optimizations are only useful in certain situations and should not be indiscriminately applied to every package. Unless you can verify/benchmark that something is faster, there is a very good chance it is not! The Gentoo GCC optimization and Safe CFLAGS wiki articles provide more in-depth information about compiler optimization.
The options passed to a C/C++ compiler (e.g. gcc or clang) are controlled by the CFLAGS, CXXFLAGS, and CPPFLAGS environment variables. For use in the Arch build system, makepkg exposes these environment variables as configuration options in makepkg.conf. The default values are configured to produce generic binaries that can be installed on a wide range of machines.

Note:
Keep in mind that not all build systems use the variables configured in makepkg.conf. For example, cmake disregards the preprocessor options environment variable, CPPFLAGS. Consequently, many PKGBUILDs contain workarounds with options specific to the build system used by the packaged software.
The configuration provided with the source code in the Makefile or a specific argument in the compilation command line takes precedence and can potentially override the one in makepkg.conf.

GCC can automatically detect and enable safe architecture-specific optimizations. To use this feature, first remove any -march and -mtune flags, then add -march=native. For example:

/etc/makepkg.conf
CFLAGS=""-march=native -O2 -pipe -fstack-protector-strong -fno-plt""
CXXFLAGS=""${CFLAGS}""
To see what flags this enables on your machine, run:

$ gcc -march=native -v -Q --help=target

Note: If you specify different value than -march=native, then -Q --help=target will not work as expected.[4] You need to go through a compilation phase to find out which options are really enabled. See Gentoo:Safe CFLAGS#Manual for instructions.
Starting in pacman version 5.2.2, makepkg.conf also includes overrides for the RUSTFLAGS environment variable, for flags given to the Rust compiler. The Rust compiler can also detect and enable architecture-specific optimizations for your CPU, by adding -C target-cpu=native to the given RUSTFLAGS value:

/etc/makepkg.conf
RUSTFLAGS=""-C opt-level=2 -C target-cpu=native""
To see which CPU features this will enable, run:

$ rustc -C target-cpu=native --print cfg

Running --print cfg without -C target-cpu=native will print the default configuration. The opt-level parameter can be changed to 3, s, or z as desired. See The Rust compiler's documentation for details.

Improving compile times
Parallel compilation
The make build system uses the MAKEFLAGS environment variable to specify additional options for make. The variable can also be set in the makepkg.conf file.
Users with multi-core/multi-processor systems can specify the number of jobs to run simultaneously. This can be accomplished with the use of nproc to determine the number of available processors, e.g. MAKEFLAGS=""-j$(nproc)"". Some PKGBUILDs specifically override this with -j1, because of race conditions in certain versions or simply because it is not supported in the first place. Packages that fail to build because of this should be reported on the bug tracker (or in the case of AUR packages, to the package maintainer) after making sure that the error is indeed being caused by your MAKEFLAGS.
See make(1) for a complete list of available options.

Building from files in memory
As compiling requires many I/O operations and handling of small files, moving the working directory to a tmpfs may bring improvements in build times. 
The BUILDDIR variable can be temporarily exported to makepkg to set the build directory to an existing tmpfs. For example:

$ BUILDDIR=/tmp/makepkg makepkg

Persistent configuration can be done in makepkg.conf by uncommenting the BUILDDIR option, which is found at the end of the BUILD ENVIRONMENT section in the default /etc/makepkg.conf file. Setting its value to e.g. BUILDDIR=/tmp/makepkg will make use of the Arch's default /tmp temporary file system.

Note:
Avoid compiling larger packages in tmpfs to prevent running out of memory.
The tmpfs folder must be mounted without the noexec option, otherwise it will prevent built binaries from being executed.
Keep in mind that packages compiled in tmpfs will not persist across reboot. Consider setting the PKGDEST option appropriately to move the built package automatically to a persistent directory.

Using a compilation cache
The use of ccache can improve build times by caching the results of compilations for successive use.

Generate new checksums
Install pacman-contrib and run the following command in the same directory as the PKGBUILD file to generate new checksums:

$ updpkgsums

The checksums can also be obtained with e.g sha256sum and added to the sha256sums array by hand.

Use other compression algorithms
To speed up both packaging and installation, with the tradeoff of having larger package archives, you can change PKGEXT.
For example, the following skips compression of the package file, which will in turn have no need to be decompressed on install:

$ PKGEXT='.pkg.tar' makepkg

As another example, the following uses the lzop algorithm, with the lzop package required:

$ PKGEXT='.pkg.tar.lzo' makepkg

To make one of these settings permanent, set PKGEXT in /etc/makepkg.conf.

Utilizing multiple cores on compression
xz supports symmetric multiprocessing (SMP) via the --threads flag to speed up compression. For example, to let makepkg use as many CPU cores as possible to compress packages, edit COMPRESSXZ array in /etc/makepkg.conf:

COMPRESSXZ=(xz -c -z - --threads=0)

pigz is a drop-in, parallel implementation for gzip which by default uses all available CPU cores (the -p/--processes flag can be used to employ less cores):

COMPRESSGZ=(pigz -c -f -n)

pbzip2 is a drop-in, parallel implementation for bzip2 which also uses all available CPU cores by default. The -p# flag can be used to employ less cores (note: no space between the -p and number of cores).

COMPRESSBZ2=(pbzip2 -c -f)

zstd supports symmetric multiprocessing (SMP) via the --threads flag to speed up compression. For example, to let makepkg use as many CPU cores as possible to compress packages, edit COMPRESSZST array in /etc/makepkg.conf:

COMPRESSZST=(zstd -c -z -q - --threads=0)

Show packages with specific packager
expac is a pacman database extraction utility. This command shows all packages installed on the system with the packager named packagername:

$ expac ""%n %p"" | grep ""packagername"" | column -t

This shows all packages installed on the system with the packager set in the /etc/makepkg variable PACKAGER. This shows only packages that are in a repository defined in /etc/pacman.conf.

$ . /etc/makepkg.conf; grep -xvFf <(pacman -Qqm) <(expac ""%n\t%p"" | grep ""$PACKAGER$"" | cut -f1)

Build 32-bit packages on a 64-bit system
Warning: Errors have been reported when using this method to build the linux package.
First, enable the multilib repository and install multilib-devel.
Then create a 32-bit configuration file

~/.makepkg.i686.conf
CARCH=""i686""
CHOST=""i686-unknown-linux-gnu""
CFLAGS=""-m32 -march=i686 -mtune=generic -O2 -pipe -fstack-protector-strong""
CXXFLAGS=""${CFLAGS}""
LDFLAGS=""-m32 -Wl,-O1,--sort-common,--as-needed,-z,relro""
and invoke makepkg as such

$ linux32 makepkg --config ~/.makepkg.i686.conf

Troubleshooting
Specifying install directory for QMAKE based packages
The makefile generated by qmake uses the environment variable INSTALL_ROOT to specify where the program should be installed. Thus this package function should work:

PKGBUILD
...
package() {
	cd ""$srcdir/${pkgname%-git}""
	make INSTALL_ROOT=""$pkgdir"" install
}
...
Note, that qmake also has to be configured appropriately. For example put this in your .pro file:

YourProject.pro
...
target.path = /usr/local/bin
INSTALLS += target
...
WARNING: Package contains reference to $srcdir
Somehow, the literal strings contained in the variables $srcdir or $pkgdir ended up in one of the installed files in your package.
To identify which files, run the following from the makepkg build directory:

$ grep -R ""$PWD/src"" pkg/

One possible cause would be from the usage of __FILE__ macro in C/C++ code with full path passed to compiler.

Makepkg fails to download dependencies when behind proxy
When makepkg calls dependencies, it calls pacman to install the packages, which requires administrative privileges via sudo. However, sudo does not pass any environment variables to the privileged environment, and includes the proxy-related variables ftp_proxy, http_proxy, https_proxy, and no_proxy.
In order to have makepkg working behind a proxy you have to do one of the following methods.

Enable proxy by setting its URL in XferCommand
The XferCommand can be set to use the desired proxy URL in /etc/pacman.conf.  Add or uncomment the following line in your pacman.conf[5]:

/etc/pacman.conf
...
XferCommand = /usr/bin/curl -x http://username:password@proxy.proxyhost.com:80 -L -C - -f -o %o %u
...

Enable proxy via sudoer's env_keep
Alternatively, one may want to use sudoer's env_keep option, which enables preserving given variables the privileged environment. See Sudo#Environment variables for more information.

Makepkg fails, but make succeeds
If something manually compiles using make, but fails through makepkg, it is almost certainly because /etc/makepkg.conf sets a compilation variable to something reasonable that usually works, but that what you are compiling is incompatible with.  Try adding these flags to the PKGBUILD options array:
!buildflags, to prevent its default CPPFLAGS, CFLAGS, CXXFLAGS, and LDFLAGS.
!makeflags, to prevent its default MAKEFLAGS, in case you have edited /etc/makepkg.conf to enable parallel builds.
!debug, to prevent its default DEBUG_CFLAGS, and DEBUG_CXXFLAGS, in case your package is a debug build.
If any of these fix the problem, this could indicate you can report a bug upstream, if you isolate exactly which flag is causing the problem.

See also
makepkg(8)
makepkg.conf(5)
A Brief Tour of the Makepkg Process
makepkg source code




Retrieved from ""https://wiki.archlinux.org/index.php?title=Makepkg&oldid=635338""
Categories: Package developmentAbout ArchCommands




Navigation menu


Personal tools

Create accountLog in 



Namespaces

PageDiscussion 




Variants







Views

ReadView sourceView history 



More





Search



 







Navigation


Main pageTable of contentsGetting involvedWiki newsRandom page 



Interaction


HelpContributingRecent changesRecent talksNew pagesStatisticsRequests 



Tools


What links hereRelated changesSpecial pagesPrintable versionPermanent linkPage information 



In other languages


العربيةΕλληνικάEspañolفارسیFrançaisItaliano日本語NederlandsPortuguêsРусскийСрпски / srpski中文（简体）‎ 






 This page was last edited on 14 September 2020, at 09:39.
Content is available under GNU Free Documentation License 1.3 or later unless otherwise noted.


Privacy policy
About ArchWiki
Disclaimers










",,"# makepkg

> Creates a package installable with the `pacman` package manager.
> Runs the commands from a PKGBUILD file to build the package.
> More information: <https://wiki.archlinux.org/index.php/Makepkg>.

- Make a package (run in the same directory as a PKGBUILD):

`makepkg`

- Make a package and install its dependencies:

`makepkg --syncdeps`

- Same as above, but install the package with `pacman` when done:

`makepkg --syncdeps --install`

- Make a package, but skip source checksums:

`makepkg --skipchecksums`
"
calc,,,,"# calc

> An interactive arbitrary-precision calculator on the terminal.

- Start calc in interactive mode:

`calc`

- Perform a calculation in non-interactive mode:

`calc -p '{{85 * (36 / 4)}}'`
"
chcpu,,,,"# chcpu

> Enable/disable a system's CPUs.

- Disable CPUs via a list of CPU ID numbers:

`chcpu -d {{1,3}}`

- Enable a set of CPUs via a range of CPU ID numbers:

`chcpu -e {{1-10}}`
"
xclip,,,,"# xclip

> X11 clipboard manipulation tool, similar to `xsel`.
> Handles the X primary and secondary selections, plus the system clipboard (`Ctrl + C`/`Ctrl + V`).

- Copy the output from a command to the X11 primary selection area (clipboard):

`echo 123 | xclip`

- Copy the output from a command to a given X11 selection area:

`echo 123 | xclip -selection {{primary|secondary|clipboard}}`

- Copy the contents of a file to the system clipboard, using short notation:

`echo 123 | xclip -sel clip`

- Copy the contents of a file into the system clipboard:

`xclip -sel clip {{input_file.txt}}`

- Copy the contents of a PNG image into the system clipboard (can be pasted in other programs correctly):

`xclip -sel clip -t image/png {{input_file.png}}`

- Paste the contents of the X11 primary selection area to the console:

`xclip -o`

- Paste the contents of the system clipboard to the console:

`xclip -o -sel clip`

- Paste the contents of the system clipboard into a file:

`xclip -o -sel clip > {{output_file.txt}}`
"
update-alternatives,,,,"# update-alternatives

> A convenient tool for maintaining symbolic links to determine default commands.

- Add a symbolic link:

`sudo update-alternatives --install {{path/to/symlink}} {{command_name}} {{path/to/command_binary}} {{priority}}`

- Configure a symbolic link for ""java"":

`sudo update-alternatives --config {{java}}`

- Remove a symbolic link:

`sudo update-alternatives --remove {{java}} {{/opt/java/jdk1.8.0_102/bin/java}}`

- Display information about a specified command:

`update-alternatives --display {{java}}`

- Display all commands and their current selection:

`update-alternatives --get-selections`
"
pkgmk,,,,"# pkgmk

> Make a binary package for use with pkgadd on CRUX.

- Make and download a package:

`pkgmk -d`

- Install the package after making it:

`pkgmk -d -i`

- Upgrade the package after making it:

`pkgmk -d -u`

- Ignore the footprint when making a package:

`pkgmk -d -if`

- Ignore the MD5 sum when making a package:

`pkgmk -d -im`

- Update the package's footprint:

`pkgmk -uf`
"
dnf,https://dnf.readthedocs.io/," 



DNF, the next-generation replacement for YUM — dnf latest documentation




























 dnf
          

          
          

                latest
              










DNF Use Cases
DNF Command Reference
DNF Configuration Reference
DNF Automatic
DNF API Reference
DNF Userâs FAQ
Modularity
Stored Transaction JSON Format
DNF Release Notes
Changes in DNF CLI compared to YUM
Changes in DNF plugins compared to YUM plugins
Changes in DNF plugins compared to YUM utilities
Changes in the DNF hook API compared to YUM
Changes in DNF-2 compared to DNF-1







dnf





Docs »
DNF, the next-generation replacement for YUM

 Edit on GitHub







DNF, the next-generation replacement for YUMÂ¶
Contents:


DNF Use Cases
DNF Command Reference
DNF Configuration Reference
DNF Automatic
DNF API Reference
DNF Userâs FAQ
Modularity
Stored Transaction JSON Format
DNF Release Notes
Changes in DNF CLI compared to YUM
Changes in DNF plugins compared to YUM plugins
Changes in DNF plugins compared to YUM utilities
Changes in the DNF hook API compared to YUM
Changes in DNF-2 compared to DNF-1


DNF Plugins and components

DNF Plugins Core
DNF Plugins Extras
`Hawkey`_

Indices and tables

Index
Module Index
Search Page






Next 




        © Copyright 2020
      
        
          Revision 5d2be3b0.
        


  Built with Sphinx using a theme provided by Read the Docs. 








 Read the Docs
      v: latest
      



Versions
latest
stable


Downloads
pdf
html
epub


On Read the Docs

Project Home


Builds



      Free document hosting provided by Read the Docs.

    



",,"# dnf

> Package management utility for RHEL, Fedora, and CentOS (replaces yum).
> More information: <https://dnf.readthedocs.io/>.

- Upgrade installed packages to the newest available versions:

`sudo dnf upgrade`

- Search packages via keywords:

`dnf search {{keywords}}`

- Display details about a package:

`dnf info {{package}}`

- Install a new package:

`sudo dnf install {{package}}`

- Install a new package and assume yes to all questions:

`sudo dnf -y install {{package}}`

- Remove a package:

`sudo dnf remove {{package}}`

- List installed packages:

`dnf list --installed`

- Find which packages provide a given file:

`dnf provides {{file}}`
"
http-prompt,http://example.com,"

Example Domain







Example Domain
This domain is for use in illustrative examples in documents. You may use this
    domain in literature without prior coordination or asking for permission.
More information...


",,"# http-prompt

> An interactive command-line HTTP client featuring autocomplete and syntax highlighting.

- Launch a session targeting the default url of http://localhost:8000 or the previous session:

`http-prompt`

- Launch a session with a given url:

`http-prompt {{http://example.com}}`

- Launch a session with some initial options:

`http-prompt {{localhost:8000/api}} --auth {{username:password}}`
"
trash,https://github.com/andreafrancia/trash-cli,"













GitHub - andreafrancia/trash-cli: Command line interface to the freedesktop.org trashcan.








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















andreafrancia

/

trash-cli







    Watch
 
      39
    




      Star


      1.6k
    




          Fork


        106
      





        Command line interface to the freedesktop.org trashcan.
      



            GPL-2.0 License
        




1.6k
        stars
 

106
        forks
 




      Star





    Watch









Code

 



Issues
73
 



Pull requests
10
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



17
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




andreafrancia

Refactor: moved CleanableTrashcan to empty.py



…



130e812

Aug 20, 2019





Refactor: moved CleanableTrashcan to empty.py


130e812



Git stats





797
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






docs



Update upstream URL for safe-rm



Jan 1, 2014







integration_tests



Refactor: removed module cmds.py



Aug 20, 2019







man/man1



Add a reference to trash-rm(1) to all man pges



Dec 31, 2016







tasks



Fix mkdir option in tasks/make-disk.osx



Jan 4, 2017







trashcli



Refactor: moved CleanableTrashcan to empty.py



Aug 20, 2019







unit_tests



Refactor: now also 'now' is injected



Jan 25, 2017







.ackrc



Add configuration for ack



Dec 25, 2016







.ctags



Tweak ctags



Dec 31, 2016







.gitignore



Add integration test for the whole trash-put script



Jan 24, 2017







COPYING



First import.



Jul 24, 2007







CREDITS.txt



Add credit for Lee Yeoh



Jan 19, 2017







DONE.txt



Write-up history for next release 0.12.4



Apr 12, 2012







HISTORY.txt



Update HISTORY.txt



Jan 22, 2017







MANIFEST.in



fixed inclusion of README.rst when creating distribution package



Jun 21, 2012







README.rst



Update README.rst



Aug 15, 2017







TODO.txt



Clean TODO.txt



Dec 31, 2016







Vagrantfile



Switch to ubuntu/yakkety64 that is supposed to present bug #52 (crash…



Dec 26, 2016







bugs.txt



Some refactors



Aug 12, 2012







check_release_installation.py



Add check for easy_install3 installation



Jan 13, 2017







install-rpm.sh



Made



Dec 23, 2008







requirements-dev.txt



Remove dependency from dingus and fudge.



Apr 12, 2012







setup.cfg



Now trash-list checks for sticky bit and symlinks.



Apr 11, 2012







setup.py



Refactor: removed module cmds.py



Aug 20, 2019







trash-put



Add integration test for the whole trash-put script



Jan 24, 2017







trash-rm



Now the integration test use the generated trash-rm script, and the g…



Jan 24, 2017





        View code
      






        README.rst
      


trash-cli - Command Line Interface to FreeDesktop.org Trash.

trash-cli trashes files recording the original path, deletion date, and
permissions. It uses the same trashcan used by KDE, GNOME, and XFCE, but you
can invoke it from the command line (and scripts).
It provides these commands:
trash-put           trash files and directories.
trash-empty         empty the trashcan(s).
trash-list          list trashed files.
trash-restore       restore a trashed file.
trash-rm            remove individual files from the trashcan.


Usage
Trash a file:
$ trash-put foo

List trashed files:
$ trash-list
2008-06-01 10:30:48 /home/andrea/bar
2008-06-02 21:50:41 /home/andrea/bar
2008-06-23 21:50:49 /home/andrea/foo

Search for a file in the trashcan:
$ trash-list | grep foo
2007-08-30 12:36:00 /home/andrea/foo
2007-08-30 12:39:41 /home/andrea/foo

Restore a trashed file:
$ trash-restore
0 2007-08-30 12:36:00 /home/andrea/foo
1 2007-08-30 12:39:41 /home/andrea/bar
2 2007-08-30 12:39:41 /home/andrea/bar2
3 2007-08-30 12:39:41 /home/andrea/foo2
4 2007-08-30 12:39:41 /home/andrea/foo
What file to restore [0..4]: 4
$ ls foo
foo

Remove all files from the trashcan:
$ trash-empty

Remove only the files that have been deleted more than <days> ago:
$ trash-empty <days>

Example:
$ date
Tue Feb 19 20:26:52 CET 2008
$ trash-list
2008-02-19 20:11:34 /home/einar/today
2008-02-18 20:11:34 /home/einar/yesterday
2008-02-10 20:11:34 /home/einar/last_week
$ trash-empty 7
$ trash-list
2008-02-19 20:11:34 /home/einar/today
2008-02-18 20:11:34 /home/einar/yesterday
$ trash-empty 1
$ trash-list
2008-02-19 20:11:34 /home/einar/today

Remove only files matching a pattern:
$ trash-rm \*.o

Note: you need to use quotes in order to protect the pattern from shell expansion.

FAQ

How to create a top level .Trash dir?
Steps
sudo mkdir --parent /.Trash
sudo chmod a+rw /.Trash
sudo chmod +t /.Trash


Can I alias rm to trash-put?
You can but you shouldn't. In the early days I thought it was a good idea to do
that but now I changed my mind.
Although the interface of trash-put seems to be compatible with rm, it has
different semantics which will cause you problems. For example, while rm
requires -R for deleting directories trash-put does not.

But sometimes I forget to use trash-put, really can't I?
You could alias rm to something that will remind you to not use it:
alias rm='echo ""This is not the command you are looking for.""; false'

Then, if you really want to use rm, simply prepend a slash to bypass the alias:
\rm file-without-hope

Note that Bash aliases are used only in interactive shells, so using
this alias should not interfere with scripts that expect to use rm.

Installation

The easy way
Requirements:


Python 2.7 or Python 3
setuptools (use apt-get install python-setuptools on Debian)


Installation command:
easy_install trash-cli


From sources
System-wide installation:
git clone https://github.com/andreafrancia/trash-cli.git
cd trash-cli
sudo python setup.py install

User-only installation:
git clone https://github.com/andreafrancia/trash-cli.git
cd trash-cli
python setup.py install --user


Bugs and feedback
If you discover a bug please report it here:

https://github.com/andreafrancia/trash-cli/issues
You can also email me to andrea@andreafrancia.it. On Twitter I'm @andreafrancia.

Development
Environment setup:
virtualenv env --no-site-packages
source env/bin/activate
pip install -r requirements-dev.txt

Running tests:
nosetests unit_tests           # run only unit tests
nosetests integration_tests    # run all integration tests
nosetests -A 'not stress_test' # run all tests but stress tests
nosetests                      # run all tests

Check the installation process before release:
python check_release_installation.py

Profiling unit tests:
pip install gprof2dot
nosetests --with-profile --profile-stats-file stats.pf --profile-restrict=unit_tests unit_tests
gprof2dot -w  -f pstats stats.pf | dot -Tsvg >| stats.svg
open stats.svg









About

      Command line interface to the freedesktop.org trashcan.
    
Topics



  python


  linux


  trashcan



Resources



      Readme
 
License



        GPL-2.0 License
    







    Releases



17
tags







    Packages 0


        No packages published 







        Used by 71
 




























            + 63
          







    Contributors 13





 



 



 



 



 



 



 



 



 



 



 



      + 2 contributors





Languages









Python
99.5%





Shell
0.5%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# trash

> A CLI for managing your trashcan / recycling bin.
> More information: <https://github.com/andreafrancia/trash-cli>.

- Delete a file (send to trash):

`trash {{path/to/file}}`

- List files in trash:

`trash-list`

- Restore file from trash:

`trash-restore`

- Empty trash:

`trash-empty`

- Empty trash, keeping files trashed less than {{10}} days ago:

`trash-empty {{10}}`

- Remove all files named 'foo' from the trash:

`trash-rm foo`

- Remove all files with a given original location:

`trash-rm {{/absolute/path/to/file_or_directory}}`
"
ptx,,,,"# ptx

> Generate a permuted index of words from one or more text files.

- Generate a permuted index where the first field of each line is an index reference:

`ptx --references {{path/to/file}}`

- Generate a permuted index with automatically generated index references:

`ptx --auto-reference {{path/to/file}}`

- Generate a permuted index with a fixed width:

`ptx --width={{width_in_columns}} {{path/to/file}}`

- Generate a permuted index with a list of filtered words:

`ptx --only-file={{path/to/filter}} {{path/to/file}}`

- Generate a permuted index with SYSV-style behaviors:

`ptx --traditional {{path/to/file}}`
"
pkg-config,https://www.freedesktop.org/wiki/Software/pkg-config/,"


pkg-config


















www/ 

Software/ 



pkg-config






Edit
Page History
Repo Info





pkg-config
pkg-config is a helper tool used when compiling applications and
libraries. It helps you insert the correct compiler options on the
command line so an application can use gcc -o test test.c `pkg-config
--libs --cflags glib-2.0` for instance, rather than hard-coding values
on where to find glib (or other libraries). It is language-agnostic, so
it can be used for defining the location of documentation tools, for
instance.
The program is free software and licensed under the
GPL version 2 or any later
version (at your option).
pkg-config works on multiple platforms: Linux and other UNIX-like
operating systems, Mac OS X and Windows. It does not require anything
but a reasonably well working C compiler and a C library, but can use an
installed glib if that is present. (A copy of recent glib2 is shipped
together with pkg-config versions since 0.27, and this is sufficient for
pkg-config to compile and work properly.)
The first implementation was written in shell, by James Henstridge.
Later, it was rewritten in C by Havoc Pennington. It also grew an
autoconf macro written by Tim Janik, later rewritten by Scott James
Remnant. The current maintainers are
Tollef Fog Heen tfheen@err.no and
Dan Nicholson dbn.lists@gmail.com.
The current release of pkg-config is version
0.29.2
and can be found in
/releases.
pkg-config is available from the git repository
at git://anongit.freedesktop.org/pkg-config (browse)
Bugs can be filed in the
Freedesktop.org bug tracker
There is a mailing list for development and user questions at
pkg-config@lists.freedesktop.org
(Archives)
(Subscribe)
New and veteran users alike may find
Dan Nicholsonâs Guide to pkg-config
informative, particularly
the FAQ section
which provides examples of where the Requires.private field is
appropriate.





Links:

Software


Last edited Mon May  7 16:24:22 2018







","pkg-config(1)							 pkg-config(1)



NAME
       pkg-config - Return metainformation about installed libraries

SYNOPSIS
       pkg-config  [--modversion]  [--version]	[--help] [--atleast-pkgconfig-
       version=VERSION] [--print-errors]  [--short-errors]  [--silence-errors]
       [--errors-to-stdout]   [--debug]  [--cflags]  [--libs]  [--libs-only-L]
       [--libs-only-l] [--cflags-only-I]  [--libs-only-other]  [--cflags-only-
       other]  [--variable=VARIABLENAME] [--define-variable=VARIABLENAME=VARI-
       ABLEVALUE] [--print-variables] [--uninstalled]  [--exists]  [--atleast-
       version=VERSION]    [--exact-version=VERSION]   [--max-version=VERSION]
       [--validate]   [--list-all]    [--print-provides]    [--print-requires]
       [--print-requires-private] [LIBRARIES...]

DESCRIPTION
       The  pkg-config program is used to retrieve information about installed
       libraries in the system.  It is typically  used	to  compile  and  link
       against	one  or more libraries.  Here is a typical usage scenario in a
       Makefile:

       program: program.c
	    cc program.c `pkg-config --cflags --libs gnomeui`

       pkg-config retrieves information about packages from  special  metadata
       files.  These  files  are named after the package, and has a .pc exten-
       sion.   On  most  systems,  pkg-config  looks  in   /usr/lib/pkgconfig,
       /usr/share/pkgconfig,		/usr/local/lib/pkgconfig	   and
       /usr/local/share/pkgconfig for these files.  It will additionally  look
       in the colon-separated (on Windows, semicolon-separated) list of direc-
       tories specified by the PKG_CONFIG_PATH environment variable.

       The package name specified on the pkg-config command line is defined to
       be the name of the metadata file, minus the .pc extension. If a library
       can install multiple versions simultaneously, it must give each version
       its  own  name (for example, GTK 1.2 might have the package name ""gtk+""
       while GTK 2.0 has ""gtk+-2.0"").

       In addition to specifying a package name on the command line, the  full
       path  to  a  given .pc file may be given instead. This allows a user to
       directly query a particular .pc file.

OPTIONS
       The following options are supported:

       --modversion
	      Requests that the version information of the libraries specified
	      on  the  command	line be displayed.  If pkg-config can find all
	      the libraries on the command line, each library's version string
	      is  printed  to  stdout, one version per line. In this case pkg-
	      config exits successfully. If one or more libraries is  unknown,
	      pkg-config exits with a nonzero code, and the contents of stdout
	      are undefined.

       --version
	      Displays the version of pkg-config and terminates.

       --atleast-pkgconfig-version=VERSION
	      Requires at least the given version of pkg-config.

       --help Displays a help message and terminates.

       --print-errors
	      If one or more of the modules on	the  command  line,  or  their
	      dependencies,  are not found, or if an error occurs in parsing a
	      .pc file, then this option  will	cause  errors  explaining  the
	      problem	to  be	printed.  With	""predicate""  options  such  as
	      ""--exists"" pkg-config runs silently  by  default,  because  it's
	      usually used in scripts that want to control what's output. This
	      option can be used  alone  (to  just  print  errors  encountered
	      locating modules on the command line) or with other options. The
	      PKG_CONFIG_DEBUG_SPEW  environment   variable   overrides   this
	      option.

       --short-errors
	      Print short error messages.

       --silence-errors
	      If  one  or  more  of  the modules on the command line, or their
	      dependencies, are not found, or if an error occurs in parsing  a
	      a  .pc  file,  then  this option will keep errors explaining the
	      problem from being printed. With	""predicate""  options  such  as
	      ""--exists""  pkg-config  runs  silently  by default, because it's
	      usually used in scripts that want to control what's  output.  So
	      this  option  is	only useful with options such as ""--cflags"" or
	      ""--modversion""  that  print  errors  by  default.  The  PKG_CON-
	      FIG_DEBUG_SPEW environment variable overrides this option.

       --errors-to-stdout
	      If printing errors, print them to stdout rather than the default
	      stderr

       --debug
	      Print debugging information. This is slightly different than the
	      PKG_CONFIG_DEBUG_SPEW  environment  variable,  which also enable
	      ""--print-errors"".


       The following options are used to compile and link programs:

       --cflags
	      This prints pre-processor and compile flags required to  compile
	      the  packages on the command line, including flags for all their
	      dependencies. Flags are ""compressed"" so that each identical flag
	      appears  only  once.  pkg-config exits with a nonzero code if it
	      can't find metadata for one or more of the packages on the  com-
	      mand line.

       --cflags-only-I
	      This  prints  the -I part of ""--cflags"". That is, it defines the
	      header search path but doesn't specify anything else.

       --cflags-only-other
	      This prints parts of ""--cflags"" not covered  by  ""--cflags-only-
	      I"".

       --libs This  option is identical to ""--cflags"", only it prints the link
	      flags. As with ""--cflags"", duplicate flags are merged (maintain-
	      ing proper ordering), and flags for dependencies are included in
	      the output.

       --libs-only-L
	      This prints the -L/-R part of ""--libs"". That is, it defines  the
	      library  search path but doesn't specify which libraries to link
	      with.

       --libs-only-l
	      This prints the -l part of ""--libs"" for the libraries  specified
	      on  the command line. Note that the union of ""--libs-only-l"" and
	      ""--libs-only-L"" may be smaller than ""--libs"", due to flags  such
	      as -rdynamic.

       --libs-only-other
	      This prints the parts of ""--libs"" not covered by ""--libs-only-L""
	      and ""--libs-only-l"", such as ""--pthread"".

       --variable=VARIABLENAME
	      This returns the value of a variable defined in a package's  .pc
	      file.  Most  packages define the variable ""prefix"", for example,
	      so you can say:
		$ pkg-config --variable=prefix glib-2.0
		/usr/

       --define-variable=VARIABLENAME=VARIABLEVALUE
	      This sets a global value for a variable, overriding the value in
	      any  .pc	files. Most packages define the variable ""prefix"", for
	      example, so you can say:
		$ pkg-config --print-errors --define-variable=prefix=/foo \
			     --variable=prefix glib-2.0
		/foo

       --print-variables
	      Returns a list of all variables defined in the package.


       --uninstalled
	      Normally if you request the package ""foo"" and the package  ""foo-
	      uninstalled""  exists,  pkg-config will prefer the ""-uninstalled""
	      variant. This  allows  compilation/linking  against  uninstalled
	      packages.  If you specify the ""--uninstalled"" option, pkg-config
	      will return successfully	if  any  ""-uninstalled""  packages  are
	      being used, and return failure (false) otherwise.  (The PKG_CON-
	      FIG_DISABLE_UNINSTALLED environment  variable  keeps  pkg-config
	      from  implicitly	choosing  ""-uninstalled""  packages, so if that
	      variable is set, they will only have been used  if  you  pass  a
	      name like ""foo-uninstalled"" on the command line explicitly.)

       --exists

       --atleast-version=VERSION

       --exact-version=VERSION

       --max-version=VERSION
	      These  options  test  whether the package or list of packages on
	      the command line are known to pkg-config, and optionally whether
	      the  version  number of a package meets certain constraints.  If
	      all packages exist and meet the specified  version  constraints,
	      pkg-config  exits  successfully.	Otherwise  it exits unsuccess-
	      fully. Only the first VERSION comparing option will be  honored.
	      Subsequent options of this type will be ignored.

	      Rather  than using the version-test options, you can simply give
	      a version constraint after each package name, for example:
		$ pkg-config --exists 'glib-2.0 >= 1.3.4 libxml = 1.8.3'
	      Remember to use --print-errors if you want error messages.  When
	      no  output  options  are	supplied  to  pkg-config,  --exists is
	      implied.

       --validate
	      Checks the syntax of a package's .pc file for validity. This  is
	      the  same as --exists except that dependencies are not verified.
	      This can be useful for package developers to test their .pc file
	      prior to release:
		$ pkg-config --validate ./my-package.pc

       --msvc-syntax
	      This  option  is available only on Windows. It causes pkg-config
	      to output -l  and  -L  flags  in	the  form  recognized  by  the
	      Microsoft  Visual  C++  command-line compiler, cl. Specifically,
	      instead of -Lx:/some/path it  prints  /libpath:x/some/path,  and
	      instead  of -lfoo it prints foo.lib. Note that the --libs output
	      consists of flags for the linker, and should be placed on the cl
	      command line after a /link switch.

       --define-prefix
	      --dont-define-prefix  These  options  control whether pkg-config
	      overrides the value of the variable prefix  in  each  .pc  file.
	      With  --define-prefix, pkg-config uses the installed location of
	      the .pc file to determine the prefix. --dont-define-prefix  pre-
	      vents this behavior. The default is usually --define-prefix.

	      When this feature is enabled and a .pc file is found in a direc-
	      tory named pkgconfig, the prefix for that package is assumed  to
	      be  the  grandparent  of the directory where the file was found,
	      and the prefix variable is overridden for that file accordingly.

	      If  the value of a variable in a .pc file begins with the origi-
	      nal, non-overridden, value of  the  prefix  variable,  then  the
	      overridden value of prefix is used instead. This allows the fea-
	      ture to work even when the variables have been expanded  in  the
	      .pc file.

       --prefix-variable=PREFIX
	      Set  the	name of the variable that pkg-config overrides instead
	      of prefix when using the --define-prefix feature.

       --static
	      Output  libraries  suitable  for	static	linking.   That  means
	      including  any  private libraries in the output.	This relies on
	      proper tagging in the .pc files, else  a	too  large  number  of
	      libraries will ordinarily be output.

       --list-all
	      List all modules found in the pkg-config path.

       --print-provides
	      List all modules the given packages provides.

       --print-requires
	      List all modules the given packages requires.

       --print-requires-private
	      List  all modules the given packages requires for static linking
	      (see --static).

ENVIRONMENT VARIABLES
       PKG_CONFIG_PATH
	      A colon-separated  (on  Windows,	semicolon-separated)  list  of
	      directories to search for .pc files.  The default directory will
	      always be searched after searching  the  path;  the  default  is
	      libdir/pkgconfig:datadir/pkgconfig  where  libdir  is the libdir
	      for pkg-config and datadir is the datadir for pkg-config when it
	      was installed.

       PKG_CONFIG_DEBUG_SPEW
	      If set, causes pkg-config to print all kinds of debugging infor-
	      mation and report all errors.

       PKG_CONFIG_TOP_BUILD_DIR
	      A value to set for the magic variable pc_top_builddir which  may
	      appear in .pc files. If the environment variable is not set, the
	      default value '$(top_builddir)'  will  be  used.	This  variable
	      should  refer to the top builddir of the Makefile where the com-
	      pile/link flags reported by pkg-config will be used.  This  only
	      matters when compiling/linking against a package that hasn't yet
	      been installed.

       PKG_CONFIG_DISABLE_UNINSTALLED
	      Normally if you request the package ""foo"" and the package  ""foo-
	      uninstalled""  exists,  pkg-config will prefer the ""-uninstalled""
	      variant. This  allows  compilation/linking  against  uninstalled
	      packages.  If this environment variable is set, it disables said
	      behavior.

       PKG_CONFIG_SYSTEM_INCLUDE_PATH
	      A path variable containing system directories  searched  by  the
	      compiler.  This is normally /usr/include.

       CPATH  C_INCLUDE_PATH  CPLUS_INCLUDE_PATH Additional paths to append to
	      PKG_CONFIG_SYSTEM_INCLUDE_PATH.  These correspond to environment
	      variables  used  by  many  compilers to affect the header search
	      path. These are ignored on Windows builds when --msvc-syntax  is
	      in use.

       INCLUDE
	      Additional  paths to append to PKG_CONFIG_SYSTEM_INCLUDE_PATH on
	      Windows builds when --msvc-syntax is in use. This corresponds to
	      the  environment variable used by MSVC to add directories to the
	      include file search path.

       PKG_CONFIG_ALLOW_SYSTEM_CFLAGS
	      Don't strip system paths	out  of  Cflags.  See  PKG_CONFIG_SYS-
	      TEM_INCLUDE_PATH for the definition of system paths.

       PKG_CONFIG_SYSTEM_LIBRARY_PATH
	      A  path  variable  containing system directories searched by the
	      linker.  This is normally /usr/lib:/lib but is dependent on  the
	      pkg-config  build  and  can  contain  other  directories such as
	      /usr/lib64.

       PKG_CONFIG_ALLOW_SYSTEM_LIBS
	      Don't strip  system  paths  out  of  Libs.  See  PKG_CONFIG_SYS-
	      TEM_LIBRARY_PATH for the definition of system paths.

       PKG_CONFIG_SYSROOT_DIR
	      Modify  -I  and -L to use the directories located in target sys-
	      root.  this option is useful when cross-compiling packages  that
	      use  pkg-config  to  determine CFLAGS and LDFLAGS. -I and -L are
	      modified to point to the new system  root.  this	means  that  a
	      -I/usr/include/libfoo will become -I/var/target/usr/include/lib-
	      foo with a PKG_CONFIG_SYSROOT_DIR  equal	to  /var/target  (same
	      rule apply to -L)

       PKG_CONFIG_LIBDIR
	      Replaces	 the  default  pkg-config  search  directory,  usually
	      /usr/lib/pkgconfig:/usr/share/pkgconfig.

       PKG_CONFIG_$PACKAGE_$VARIABLE
	      Overrides the variable VARIABLE  in  the	package  PACKAGE.  The
	      environment  variable  should  have the package name and package
	      variable upper cased with non-alphanumeric characters  converted
	      to underscores. For example, setting PKG_CONFIG_GLADEUI_2_0_CAT-
	      ALOGDIR  will  override  the  variable   ""catalogdir""   in   the
	      ""gladeui-2.0"" package.

PKG-CONFIG DERIVED VARIABLES
       pkg-config  sets a few metadata variables that can be used in .pc files
       or queried at runtime.

       pc_path
	      The default search path used by pkg-config  when	searching  for
	      .pc files. This can be used in a query for the pkg-config module
	      itself itself:
		$ pkg-config --variable pc_path pkg-config

       pcfiledir
	      The installed location of the .pc file.  This  can  be  used  to
	      query  the location of the .pc file for a particular module, but
	      it can also be used to make .pc files relocatable. For instance:
	      prefix=${pcfiledir}/../..
	      exec_prefix=${prefix}
	      libdir=${exec_prefix}/lib
	      includedir=${prefix}/include

       pc_sysrootdir
	      The  sysroot  directory set by the user. When the sysroot direc-
	      tory has not been set, this value is /.  See the PKG_CONFIG_SYS-
	      ROOT_DIR environment variable for more details.

       pc_top_builddir
	      Location of the user's top build directory when calling pkg-con-
	      fig.  This is useful to dynamically set paths in uninstalled .pc
	      files. See the PKG_CONFIG_TOP_BUILD_DIR environment variable for
	      more details.

WINDOWS SPECIALITIES
       The pkg-config default search path is ignored on Windows. Instead,  the
       search path is constructed by using the installed directory of pkg-con-
       fig and then appending lib\pkgconfig and share\pkgconfig.  This can  be
       augmented   or	replaced  using  the  standard	environment  variables
       described above.

AUTOCONF MACROS
       PKG_CHECK_MODULES(VARIABLE-PREFIX, MODULES [,ACTION-IF-FOUND  [,ACTION-
       IF-NOT-FOUND]])

	      The macro PKG_CHECK_MODULES can be used in configure.ac to check
	      whether modules exist. A typical usage would be:
	       PKG_CHECK_MODULES([MYSTUFF], [gtk+-2.0 >= 1.3.5 libxml = 1.8.4])

	      This  would  result in MYSTUFF_LIBS and MYSTUFF_CFLAGS substitu-
	      tion variables, set to the libs and cflags for the given	module
	      list.   If  a  module  is  missing  or has the wrong version, by
	      default configure will abort with  a  message.  To  replace  the
	      default	   action,     specify	   an	  ACTION-IF-NOT-FOUND.
	      PKG_CHECK_MODULES will not print any error messages if you spec-
	      ify  your  own  ACTION-IF-NOT-FOUND.   However,  it will set the
	      variable MYSTUFF_PKG_ERRORS, which you can use to  display  what
	      went wrong.

	      Note   that  if  there  is  a  possibility  the  first  call  to
	      PKG_CHECK_MODULES might  not  happen,  you  should  be  sure  to
	      include  an explicit call to PKG_PROG_PKG_CONFIG in your config-
	      ure.ac.

	      Also note that repeated usage of VARIABLE-PREFIX is  not	recom-
	      mended.  After the first successful usage, subsequent calls with
	      the same VARIABLE-PREFIX will simply use the _LIBS  and  _CFLAGS
	      variables set from the previous usage without calling pkg-config
	      again.

       PKG_PREREQ(MIN-VERSION)
	      Checks that the version of the pkg-config autoconf macros in use
	      is at least MIN-VERSION. This can be used to ensure a particular
	      pkg-config macro will be available.

       PKG_PROG_PKG_CONFIG([MIN-VERSION])

	      Defines the PKG_CONFIG variable to the  best  pkg-config	avail-
	      able,  useful  if  you  need  pkg-config	but  don't want to use
	      PKG_CHECK_MODULES.

	      If the first call to PKG_PROG_PKG_CONFIG is conditional, then it
	      will  not  work  correctly in all cases. Since many of the other
	      macros such as PKG_CHECK_MODULES require PKG_PROG_PKG_CONFIG  to
	      know which pkg-config program to run, PKG_PROG_PKG_CONFIG may be
	      run for the first time from a  conditional  from	one  of  these
	      macros.  Therefore, if any of the pkg-config macros will be used
	      under a conditional, it's best to run PKG_PROG_PKG_CONFIG before
	      any of the other macros are used.


       PKG_CHECK_MODULES_STATIC(VARIABLE-PREFIX,   MODULES   [,ACTION-IF-FOUND
       [,ACTION-IF-NOT-FOUND]])
	      Enables	static	linking  through  --static  prior  to  calling
	      PKG_CHECK_MODULES.

       PKG_CHECK_EXISTS(MODULES, [ACTION-IF-FOUND], [ACTION-IF-NOT-FOUND])

	      Check to see whether a particular set of modules exists.	 Simi-
	      lar  to PKG_CHECK_MODULES(), but does not set variables or print
	      errors.

	      Similar to PKG_CHECK_MODULES, make sure that the first  instance
	      of  this	or  PKG_CHECK_MODULES  is called, or make sure to call
	      PKG_PROG_PKGCONFIG manually.


       PKG_INSTALLDIR(DIRECTORY)

	      Substitutes the variable pkgconfigdir as the  location  where  a
	      module  should  install  pkg-config  .pc	files.	By default the
	      directory is $libdir/pkgconfig, but the default can  be  changed
	      by passing DIRECTORY.  The user can override through the --with-
	      pkgconfigdir parameter.

       PKG_NOARCH_INSTALLDIR(DIRECTORY)

	      Substitutes the variable	noarch_pkgconfigdir  as  the  location
	      where  a	module	should install arch-independent pkg-config .pc
	      files. By default the directory is $datadir/pkgconfig,  but  the
	      default  can be changed by passing DIRECTORY. The user can over-
	      ride through the --with-noarch-pkgconfigdir parameter.

       PKG_CHECK_VAR(VARIABLE,	MODULE,  CONFIG-VARIABLE,   [ACTION-IF-FOUND],
       [ACTION-IF-NOT-FOUND])

	      Retrieves the value of the pkg-config  variable  CONFIG-VARIABLE
	      from  MODULE and stores it in VARIABLE. Note that repeated usage
	      of VARIABLE is not recommended as the check will be  skipped  if
	      the variable is already set.


METADATA FILE SYNTAX
       To  add a library to the set of packages pkg-config knows about, simply
       install a .pc file. You should install this file to libdir/pkgconfig.

       Here is an example file:
       # This is a comment
       prefix=/home/hp/unst   # this defines a variable
       exec_prefix=${prefix}  # defining another variable in terms of the first
       libdir=${exec_prefix}/lib
       includedir=${prefix}/include

       Name: GObject				# human-readable name
       Description: Object/type system for GLib # human-readable description
       Version: 1.3.1
       URL: http://www.gtk.org
       Requires: glib-2.0 = 1.3.1
       Conflicts: foobar <= 4.5
       Libs: -L${libdir} -lgobject-1.3
       Libs.private: -lm
       Cflags: -I${includedir}/glib-2.0 -I${libdir}/glib/include

       You would normally generate the file using configure, so that the  pre-
       fix, etc. are set to the proper values.	The GNU Autoconf manual recom-
       mends generating files like .pc files at build time rather than config-
       ure time, so when you build the .pc file is a matter of taste and pref-
       erence.

       Files have two kinds of line: keyword lines start with a keyword plus a
       colon,  and variable definitions start with an alphanumeric string plus
       an equals sign. Keywords are defined in advance and have special  mean-
       ing  to	pkg-config;  variables do not, you can have any variables that
       you wish (however, users may expect to  retrieve  the  usual  directory
       name variables).

       Note that variable references are written ""${foo}""; you can escape lit-
       eral ""${"" as ""$${"".

       Name:  This field should be a human-readable name for the package. Note
	      that it is not the name passed as an argument to pkg-config.

       Description:
	      This should be a brief description of the package

       URL:   An  URL where people can get more information about and download
	      the package

       Version:
	      This  should  be	the  most-specific-possible  package   version
	      string.

       Requires:
	      This  is a comma-separated list of packages that are required by
	      your package. Flags from dependent packages will be merged in to
	      the flags reported for your package. Optionally, you can specify
	      the version of the required package (using the operators	=,  <,
	      >,  >=,  <=);  specifying a version allows pkg-config to perform
	      extra sanity checks. You may only mention the same  package  one
	      time  on	the  Requires:	line.  If  the version of a package is
	      unspecified, any version will be used with no checking.

       Requires.private:
	      A list of packages required by this package. The difference from
	      Requires	is that the packages listed under Requires.private are
	      not taken into account when a flag list is computed for  dynami-
	      cally linked executable (i.e., when --static was not specified).
	      In the situation where each .pc file corresponds to  a  library,
	      Requires.private shall be used exclusively to specify the depen-
	      dencies between the libraries.

       Conflicts:
	      This optional line allows pkg-config to perform additional  san-
	      ity  checks, primarily to detect broken user installations.  The
	      syntax is the same as Requires: except that  you	can  list  the
	      same  package  more than once here, for example ""foobar = 1.2.3,
	      foobar = 1.2.5, foobar >= 1.3"", if you have reason to do so.  If
	      a  version isn't specified, then your package conflicts with all
	      versions of the mentioned package.  If a user tries to use  your
	      package  and  a  conflicting package at the same time, then pkg-
	      config will complain.

       Libs:  This line should give the link flags specific to	your  package.
	      Don't  add  any flags for required packages; pkg-config will add
	      those automatically.

       Libs.private:
	      This line should list any private  libraries  in	use.   Private
	      libraries  are  libraries  which	are  not  exposed through your
	      library, but are needed in the case of static linking. This dif-
	      fers  from Requires.private in that it references libraries that
	      do not have package files installed.

       Cflags:
	      This line should list the compile flags specific to  your  pack-
	      age.  Don't add any flags for required packages; pkg-config will
	      add those automatically.

AUTHOR
       pkg-config was written by James Henstridge, rewritten  by  Martijn  van
       Beers, and rewritten again by Havoc Pennington. Tim Janik, Owen Taylor,
       and Raja Harinath submitted suggestions and  some  code.   gnome-config
       was  written  by  Miguel de Icaza, Raja Harinath and various hackers in
       the GNOME team.	It was inspired by Owen Taylor's gtk-config program.

BUGS
       pkg-config does not handle mixing of  parameters  with  and  without  =
       well.  Stick with one.

       Bugs can be reported at http://bugs.freedesktop.org/ under the pkg-con-
       fig component.



								 pkg-config(1)
","# pkg-config

> Provide the details of installed libraries for compiling applications.
> More information: <https://www.freedesktop.org/wiki/Software/pkg-config/>.

- Get the list of libraries and their dependencies:

`pkg-config --libs {{library1 library2 ...}}`

- Get the list of libraries, their dependencies, and proper cflags for gcc:

`pkg-config --cflags --libs {{library1 library2 ...}}`

- Compile your code with libgtk-3, libwebkit2gtk-4.0 and all their dependencies:

`c++ example.cpp $(pkg-config --cflags --libs gtk+-3.0 webkit2gtk-4.0) -o example`
"
as,,,"AS(1)									 AS(1)



NAME
       as - Mac OS X Mach-O GNU-based assemblers

SYNOPSIS
       as [ option ...	] [ file ...  ]

DESCRIPTION
       The  as	command  translates assembly code in the named files to object
       code.  If no files are specified, as reads from stdin.	All  undefined
       symbols	in  the  assembly  are	treated  as global.  The output of the
       assembly is left in the file a.out by default.

       The program /usr/bin/as is actually a driver that  executes  assemblers
       for specific target architectures.  If no target architecture is speci-
       fied, it defaults to the architecture of the host it is running on.

OPTIONS
       -o name
	      Name the output file name instead of a.out.

       -arch arch_type
	      Specifies the target architecture, arch_type, of	the  assembler
	      to be executed.  The target assemblers for each architecture are
	      in	    /usr/libexec/gcc/darwin/arch_type/as	    or
	      /usr/local/libexec/gcc/darwin/arch_type/as.   There  is only one
	      assembler for an architecture family.  If the  specified	target
	      architecture is a machine-specific implementation, the assembler
	      for   that    architecture    family    is    executed	(e.g.,
	      /usr/libexec/gcc/darwin/ppc/as  for -arch ppc604e).  See arch(3)
	      for the currently known arch_types.

       -arch_multiple
	      Precede any displayed messages with a line stating  the  program
	      name  (as) and the architecture (from the -arch arch_type flag),
	      to distinguish which architecture the error messages  refer  to.
	      When  the cc(1) driver program is run with multiple -arch flags,
	      it invokes as with the -arch_multiple option.

       -force_cpusubtype_ALL
	      By default, the assembler will produce the CPU subtype  ALL  for
	      the  object file it is assembling if it finds no implementation-
	      specific instructions.  Also  by	default,  the  assembler  will
	      allow  implementation-specific instructions and will combine the
	      CPU subtype for those specific implementations.	The  combining
	      of  specific  implementations is architecture-dependent; if some
	      combination of instructions is not allowed, an error  is	gener-
	      ated.    With   the  optional  -force_cpusubtype_ALL  flag,  all
	      instructions are allowed and the object file's CPU subtype  will
	      be  the  ALL subtype.  If the target architecture specified is a
	      machine-specific	implementation	(e.g.,	-arch  ppc603,	 -arch
	      i486),  the  assembler will flag as errors instructions that are
	      not supported on that  architecture,  and  it  will  produce  an
	      object  file  with the CPU subtype for that specific implementa-
	      tion (even if no implementation-specific instructions are used).
	      The  -force_cpusubtype_ALL  flag	is the default for all x86 and
	      x86_64 architectures.

       -dynamic
	      Enables dynamic linking features.  This is the default.

       -static
	      Causes the assembler to treat  as  an  error  any  features  for
	      dynamic linking.	Also causes the .text directive to not include
	      the pure_instructions section attribute.

       --     Use stdin for the assembly source input.

       -n     Instructs the assembler not to assume  that  the	assembly  file
	      starts  with  a .text directive.	Use this option when an output
	      file is not to contain a (__TEXT,__text) section or this section
	      is not to be first one in the output file.

       -f     Fast;  no  need  for  the assembler preprocessor (``app'').  The
	      assembler preprocessor can also be turned off  by  starting  the
	      assembly	file  with  ""#NO_APP\n"".   This is intended for use by
	      compilers which produce assembly code in a strict ""clean"" format
	      that  specifies  exactly where whitespace can go.  The assembler
	      preprocessor needs to be	run  on  hand-written  assembly  files
	      and/or  files  that have been preprocessed by the C preprocessor
	      cpp.  This is typically needed when assembler files  are	assem-
	      bled  through  the use of the cc(1) command, which automatically
	      runs the C preprocessor on assembly source files.  The assembler
	      preprocessor strips out excess spaces, turns single-quoted char-
	      acters into a decimal constants, and turns # <number> <filename>
	      <level>  into  .line <number>;.file <filename>  pairs.  When the
	      assembler preprocessor has been turned off by a  ""#NO_APP\n""  at
	      the start of a file, it can be turned back on and off again with
	      pairs of ""#APP\n"" and ""#NO_APP\n"" at the	beginnings  of	lines.
	      This  is	used  by the compiler to wrap assembly statements pro-
	      duced from asm() statements.

       -g     Produce debugging information for the symbolic  debugger	gdb(1)
	      so  that	the assembly source can be debugged symbolically.  The
	      debugger depends on correct use of the C preprocessor's #include
	      directive  or  the  assembler's .include directive:  Any include
	      file that produces instructions in the  (__TEXT,__text)  section
	      must be included while a .text directive is in effect.  In other
	      words, there must be a .text directive before the  include,  and
	      the  .text  directive  must still be in effect at the end of the
	      include file.  Otherwise, the debugger will get confused when in
	      that assembly file.

       -v     Display  the version of the assembler (both the Mac OS X version
	      and the GNU version it is based on).

       -V     Print the path and the command line of the assembler the	assem-
	      bler driver is using.

       -Idir  Add  the	directory dir to the list of directories to search for
	      files included with the .include directive.  The	default  place
	      to search is the current directory.

       -W     Suppress warnings.

       -L     Save  non-global	defined  labels  beginning  with an 'L'; these
	      labels are normally discarded to save  space  in	the  resultant
	      symbol table.  The compiler generates such temporary labels.

       -q     Use  the	clang(1) integrated assembler instead of the GNU based
	      system assembler.  This is the  default  for  the  x86  and  arm
	      architectures.

       -Q     Use the GNU based system assembler.

Assembler options for the PowerPC processors
       -static_branch_prediction_Y_bit
	      Treat  a	single trailing '+' or '-' after a conditional PowerPC
	      branch instruction as a static branch prediction that  sets  the
	      Y-bit  in the opcode.  Pairs of trailing ""++"" or ""--"" always set
	      the AT-bits. This is the default for Mac OS X.

       -static_branch_prediction_AT_bits
	      Treat a single trailing '+' or '-' after a  conditional  PowerPC
	      branch  instruction  as a static branch prediction that sets the
	      AT-bits in the opcode. Pairs of trailing ""++"" or ""--"" always set
	      the  AT-bits  but  with  this option a warning is issued if this
	      syntax is used.  With this flag the assembler behaves  like  the
	      IBM tools.

       -no_ppc601
	      Treat any PowerPC 601 instructions as an error.

FILES
       a.out	 output file

SEE ALSO
       The  Mac  OS  X	Assembler Reference in the Xcode documentation viewer:
       Perform a title search for ""assembler"" in Apple > Developer Tools  Ref-
       erence Library.
       The assembler source in the cctools module of the Darwin sources.
       cc(1), ld(1), nm(1), otool(1), arch(3), Mach-O(5)



Apple Inc.		       February 12, 2015			 AS(1)
","# as

> Portable GNU assembler.
> Primarily intended to assemble output from `gcc` to be used by `ld`.

- Assemble a file, writing the output to a.out:

`as {{file.s}}`

- Assemble the output to a given file:

`as {{file.s}} -o {{out.o}}`

- Generate output faster by skipping whitespace and comment preprocessing. (Should only be used for trusted compilers):

`as -f {{file.s}}`

- Include a given path to the list of directories to search for files specified in .include directives:

`as -I {{path/to/directory}} {{file.s}}`
"
genkernel,,,,"# genkernel

> Gentoo Linux utility to compile and install kernels.

- Automatically compile and install a generic kernel:

`sudo genkernel all`

- Build and install the bzImage|initramfs|kernel|ramdisk only:

`sudo genkernel {{bzImage|initramfs|kernel|ramdisk}}`

- Apply changes to the kernel configuration before compiling and installing:

`sudo genkernel --menuconfig all`

- Generate a kernel with a custom name:

`sudo genkernel --kernname={{custom_name}} all`

- Use a kernel source outside of the default directory /usr/src/linux:

`sudo genkernel --kerneldir={{path/to/directory}} all`
"
ipcrm,,,"
ipcrm(1)		  BSD General Commands Manual		      ipcrm(1)

NAME
     ipcrm -- remove the specified message queues, semaphore sets, and shared
     memory segments

SYNOPSIS
     ipcrm [-M shmkey] [-m shmid] [-Q msgkey] [-q msqid] [-S semkey]
	   [-s semid] ...

DESCRIPTION
     Ipcrm removes the specified message queues, semaphores and shared memory
     segments.	These System V IPC objects can be specified by their creation
     id or any associated key.

     The following options are used to specify which IPC objects will be
     removed.  Any number and combination of these options can be used:

     -M shmkey
	     Mark the shared memory segment associated with key shmkey for
	     removal.  This marked segment will be destroyed after the last
	     detach.

     -m shmid
	     Mark the shared memory segment associated with id shmid for
	     removal.  This marked segment will be destroyed after the last
	     detach.

     -Q msgkey
	     Remove the message queue associated with key msgkey from the sys-
	     tem.

     -q msqid
	     Remove the message queue associated with the id msqid from the
	     system.

     -S semkey
	     Remove the semaphore set associated with key semkey from the sys-
	     tem.

     -s semid
	     Removes the semaphore set associated with id semid from the sys-
	     tem.

     The identifiers and keys associated with these System V IPC objects can
     be determined by using ipcs(1)

SEE ALSO
     ipcs(1)

BSD				August 8, 1994				   BSD
","# ipcrm

> Delete IPC (Inter-process Communication) resources.

- Delete a shared memory segment by ID:

`ipcrm --shmem-id {{shmem_id}}`

- Delete a shared memory segment by key:

`ipcrm --shmem-key {{shmem_key}}`

- Delete an IPC queue by ID:

`ipcrm --queue-id {{ipc_queue_id}}`

- Delete an IPC queue by key:

`ipcrm --queue-key {{ipc_queue_key}}`

- Delete a semaphore by ID:

`ipcrm --semaphore-id {{semaphore_id}}`

- Delete a semaphore by key:

`ipcrm --semaphore-key {{semaphore_key}}`

- Delete all IPC resources:

`ipcrm --all`
"
larasail,https://github.com/thedevdojo/larasail,"













GitHub - thedevdojo/larasail: LaraSail - Set Sail with your Laravel app on DigitalOcean








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















thedevdojo

/

larasail







    Watch
 
      15
    




      Star


      291
    




          Fork


        54
      





        LaraSail - Set Sail with your Laravel app on DigitalOcean
      



devdojo.com/blog/chitchat/larasail-laravel-on-digital-ocean





291
        stars
 

54
        forks
 




      Star





    Watch









Code

 



Issues
6
 



Pull requests
0
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



1
tag




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




bobbyiliev

Added CONTRIBUTING.md file (#36)



…



c72b25c

Sep 22, 2020





Added CONTRIBUTING.md file (#36)


c72b25c



Git stats





74
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.larasail



Certbot install fix for Ubuntu 20.04 (#34)



Aug 19, 2020







CONTRIBUTING.md



Added CONTRIBUTING.md file (#36)



Sep 22, 2020







README.md



Added CONTRIBUTING.md file (#36)



Sep 22, 2020







install



#8 - Let's Encrypt integration (#17)



Jun 17, 2020





        View code
      






        README.md
      



LaraSail
LaraSail is a CLI tool for Laravel to help you Sail the Servers of the DigitalOcean


You'll need a DigitalOcean Account before getting started (Signup here), then you'll need to create a New Droplet. Make sure to select Ubuntu Server:

Installation
SSH into your server and run the following command:
curl -sL https://github.com/thedevdojo/larasail/archive/master.tar.gz | tar xz && source larasail-master/install

You can make sure it's installed by running
larasail -h

Setup Your Laravel Server
larasail setup

The default configuration will install Nginx, PHP 7.4, and MySQL 5.7. If you wish to use PHP 7.1, PHP 7.2, or PHP 7.3, you can include the argument php71/php72/php73 like so:
larasail setup php71 # Install with PHP 7.1
larasail setup php72 # Install with PHP 7.2
larasail setup php73 # Install with PHP 7.3

Creating a New Site
You can now Clone a Repo or Create a New Laravel app within the /var/www folder:
cd /var/www && laravel new mywebsite

Then, you'll need to setup a new Nginx Host by running:
larasail host mywebsite.com /var/www/mywebsite

larasail host accepts 2 parameters:

Your website domain (website.com)
The location of the files for your site (/var/www/website/public)

Finally, point your Domain to the IP address of your new server... And Wallah, you're ready to rock 🤘 with your new Laravel website.
Passwords
When installing and setting up Larasail there are 2 passwords that are randomly generated.

The password for the new larasail user created on the server.
The default MySQL password

To get the larasail user password you can type in the following command:
larasail pass

And the password for the larasail user will be displayed. Next, to get the default MySQL root password you can type the following command:
larasail mysqlpass

And the MySQL root password will be displayed.
Switching to Larasail user
When you SSH into your server you may want to Switch Users back to the larasail user, You can do so with the following command:
su - larasail

Make sure to star this repo and watch this repo for future updates. Thanks for checking out Larasail ⛵
Contributing
If you are contributing, please read the contributing file before submitting your pull requests.








About

      LaraSail - Set Sail with your Laravel app on DigitalOcean
    



devdojo.com/blog/chitchat/larasail-laravel-on-digital-ocean


Resources



      Readme
 






    Releases



1
tags







    Packages 0


        No packages published 













    Contributors 3





 



 



 







Languages








Shell
100.0%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# larasail

> A CLI tool for managing Laravel on Digital Ocean servers.
> More information: <https://github.com/thedevdojo/larasail>.

- Set up the server with Laravel dependencies using the default PHP version:

`larasail setup`

- Set up the server with Laravel dependencies using a specific PHP version:

`larasail setup {{php71}}`

- Add a new Laravel site:

`larasail host {{domain}} {{path/to/site_directory}}`

- Retrieve the Larasail user password:

`larasail pass`

- Retrieve the Larasail MySQL password:

`larasail mysqlpass`
"
yum,,,,"# yum

> Package management utility for RHEL, Fedora, and CentOS (for older versions).

- Synchronize list of packages and versions available. This should be run first, before running subsequent yum commands:

`yum update`

- Install a new package:

`yum install {{package}}`

- Install a new package and assume yes to all questions (also works with update, great for automated updates):

`yum -y install {{package}}`

- Find the package that provides a particular command:

`yum provides {{command}}`

- Remove a package:

`yum remove {{package}}`

- Upgrade installed packages to newest available versions:

`yum upgrade`
"
tcpkill,,,,"# tcpkill

> Kills specified in-progress TCP connections.

- Kill in-progress connections at a specified interface, host and port:

`tcpkill -i {{eth1}} host {{192.95.4.27}} and port {{2266}}`
"
jobs,,,"
BUILTIN(1)		  BSD General Commands Manual		    BUILTIN(1)

NAME
     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,
     breaksw, builtins, case, cd, chdir, command, complete, continue, default,
     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,
     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,
     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,
     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,
     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,
     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,
     telltc, test, then, time, times, trap, true, type, ulimit, umask,
     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,
     where, which, while -- shell built-in commands

SYNOPSIS
     builtin [-options] [args ...]

DESCRIPTION
     Shell builtin commands are commands that can be executed within the run-
     ning shell's process.  Note that, in the case of csh(1) builtin commands,
     the command is executed in a subshell if it occurs as any component of a
     pipeline except the last.

     If a command specified to the shell contains a slash ``/'', the shell
     will not execute a builtin command, even if the last component of the
     specified command matches the name of a builtin command.  Thus, while
     specifying ``echo'' causes a builtin command to be executed under shells
     that support the echo builtin command, specifying ``/bin/echo'' or
     ``./echo'' does not.

     While some builtin commands may exist in more than one shell, their oper-
     ation may be different under each shell which supports them.  Below is a
     table which lists shell builtin commands, the standard shells that sup-
     port them and whether they exist as standalone utilities.

     Only builtin commands for the csh(1) and sh(1) shells are listed here.
     Consult a shell's manual page for details on the operation of its builtin
     commands.	Beware that the sh(1) manual page, at least, calls some of
     these commands ``built-in commands'' and some of them ``reserved words''.
     Users of other shells may need to consult an info(1) page or other
     sources of documentation.

     Commands marked ``No**'' under External do exist externally, but are
     implemented as scripts using a builtin command of the same name.

	   Command	 External    csh(1)    sh(1)
	   !		 No	     No        Yes
	   %		 No	     Yes       No
	   .		 No	     No        Yes
	   :		 No	     Yes       Yes
	   @		 No	     Yes       Yes
	   {		 No	     No        Yes
	   }		 No	     No        Yes
	   alias	 No**	     Yes       Yes
	   alloc	 No	     Yes       No
	   bg		 No**	     Yes       Yes
	   bind 	 No	     No        Yes
	   bindkey	 No	     Yes       No
	   break	 No	     Yes       Yes
	   breaksw	 No	     Yes       No
	   builtin	 No	     No        Yes
	   builtins	 No	     Yes       No
	   case 	 No	     Yes       Yes
	   cd		 No**	     Yes       Yes
	   chdir	 No	     Yes       Yes
	   command	 No**	     No        Yes
	   complete	 No	     Yes       No
	   continue	 No	     Yes       Yes
	   default	 No	     Yes       No
	   dirs 	 No	     Yes       No
	   do		 No	     No        Yes
	   done 	 No	     No        Yes
	   echo 	 Yes	     Yes       Yes
	   echotc	 No	     Yes       No
	   elif 	 No	     No        Yes
	   else 	 No	     Yes       Yes
	   end		 No	     Yes       No
	   endif	 No	     Yes       No
	   endsw	 No	     Yes       No
	   esac 	 No	     No        Yes
	   eval 	 No	     Yes       Yes
	   exec 	 No	     Yes       Yes
	   exit 	 No	     Yes       Yes
	   export	 No	     No        Yes
	   false	 Yes	     No        Yes
	   fc		 No**	     No        Yes
	   fg		 No**	     Yes       Yes
	   filetest	 No	     Yes       No
	   fi		 No	     No        Yes
	   for		 No	     No        Yes
	   foreach	 No	     Yes       No
	   getopts	 No**	     No        Yes
	   glob 	 No	     Yes       No
	   goto 	 No	     Yes       No
	   hash 	 No	     No        Yes
	   hashstat	 No	     Yes       No
	   history	 No	     Yes       No
	   hup		 No	     Yes       No
	   if		 No	     Yes       Yes
	   jobid	 No	     No        Yes
	   jobs 	 No**	     Yes       Yes
	   kill 	 Yes	     Yes       No
	   limit	 No	     Yes       No
	   local	 No	     No        Yes
	   log		 No	     Yes       No
	   login	 Yes	     Yes       No
	   logout	 No	     Yes       No
	   ls-F 	 No	     Yes       No
	   nice 	 Yes	     Yes       No
	   nohup	 Yes	     Yes       No
	   notify	 No	     Yes       No
	   onintr	 No	     Yes       No
	   popd 	 No	     Yes       No
	   printenv	 Yes	     Yes       No
	   pushd	 No	     Yes       No
	   pwd		 Yes	     No        Yes
	   read 	 No**	     No        Yes
	   readonly	 No	     No        Yes
	   rehash	 No	     Yes       No
	   repeat	 No	     Yes       No
	   return	 No	     No        Yes
	   sched	 No	     Yes       No
	   set		 No	     Yes       Yes
	   setenv	 No	     Yes       No
	   settc	 No	     Yes       No
	   setty	 No	     Yes       No
	   setvar	 No	     No        Yes
	   shift	 No	     Yes       Yes
	   source	 No	     Yes       No
	   stop 	 No	     Yes       No
	   suspend	 No	     Yes       No
	   switch	 No	     Yes       No
	   telltc	 No	     Yes       No
	   test 	 Yes	     No        Yes
	   then 	 No	     No        Yes
	   time 	 Yes	     Yes       No
	   times	 No	     No        Yes
	   trap 	 No	     No        Yes
	   true 	 Yes	     No        Yes
	   type 	 No	     No        Yes
	   ulimit	 No	     No        Yes
	   umask	 No**	     Yes       Yes
	   unalias	 No**	     Yes       Yes
	   uncomplete	 No	     Yes       No
	   unhash	 No	     Yes       No
	   unlimit	 No	     Yes       No
	   unset	 No	     Yes       Yes
	   unsetenv	 No	     Yes       No
	   until	 No	     No        Yes
	   wait 	 No**	     Yes       Yes
	   where	 No	     Yes       No
	   which	 Yes	     Yes       No
	   while	 No	     Yes       Yes

SEE ALSO
     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),
     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)

HISTORY
     The builtin manual page first appeared in FreeBSD 3.4.

AUTHORS
     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.

BSD			       February 23, 2005			   BSD
","# jobs

> BASH builtin for viewing information about processes spawned by the current shell.

- View jobs spawned by the current shell:

`jobs`

- List jobs and their process ids:

`jobs -l`

- Display information about jobs with changed status:

`jobs -n`

- Display process id of process group leader:

`jobs -p`

- Display running processes:

`jobs -r`

- Display stopped processes:

`jobs -s`
"
mssh,,,,"# mssh

> GTK+ based SSH client for interacting with multiple SSH servers at once.

- Open a new window and connect to multiple SSH servers:

`mssh {{user@host1}} {{user@host2}} {{...}}`

- Open a new window and connect to a group of servers predefined in `~/.mssh_clusters`:

`mssh --alias {{alias_name}}`
"
runsv,,,,"# runsv

> Start and manage a runit service.

- Start a runit service as the current user:

`runsv {{path/to/service}}`

- Start a runit service as root:

`sudo runsv {{path/to/service}}`
"
popd,,,"
BUILTIN(1)		  BSD General Commands Manual		    BUILTIN(1)

NAME
     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,
     breaksw, builtins, case, cd, chdir, command, complete, continue, default,
     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,
     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,
     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,
     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,
     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,
     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,
     telltc, test, then, time, times, trap, true, type, ulimit, umask,
     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,
     where, which, while -- shell built-in commands

SYNOPSIS
     builtin [-options] [args ...]

DESCRIPTION
     Shell builtin commands are commands that can be executed within the run-
     ning shell's process.  Note that, in the case of csh(1) builtin commands,
     the command is executed in a subshell if it occurs as any component of a
     pipeline except the last.

     If a command specified to the shell contains a slash ``/'', the shell
     will not execute a builtin command, even if the last component of the
     specified command matches the name of a builtin command.  Thus, while
     specifying ``echo'' causes a builtin command to be executed under shells
     that support the echo builtin command, specifying ``/bin/echo'' or
     ``./echo'' does not.

     While some builtin commands may exist in more than one shell, their oper-
     ation may be different under each shell which supports them.  Below is a
     table which lists shell builtin commands, the standard shells that sup-
     port them and whether they exist as standalone utilities.

     Only builtin commands for the csh(1) and sh(1) shells are listed here.
     Consult a shell's manual page for details on the operation of its builtin
     commands.	Beware that the sh(1) manual page, at least, calls some of
     these commands ``built-in commands'' and some of them ``reserved words''.
     Users of other shells may need to consult an info(1) page or other
     sources of documentation.

     Commands marked ``No**'' under External do exist externally, but are
     implemented as scripts using a builtin command of the same name.

	   Command	 External    csh(1)    sh(1)
	   !		 No	     No        Yes
	   %		 No	     Yes       No
	   .		 No	     No        Yes
	   :		 No	     Yes       Yes
	   @		 No	     Yes       Yes
	   {		 No	     No        Yes
	   }		 No	     No        Yes
	   alias	 No**	     Yes       Yes
	   alloc	 No	     Yes       No
	   bg		 No**	     Yes       Yes
	   bind 	 No	     No        Yes
	   bindkey	 No	     Yes       No
	   break	 No	     Yes       Yes
	   breaksw	 No	     Yes       No
	   builtin	 No	     No        Yes
	   builtins	 No	     Yes       No
	   case 	 No	     Yes       Yes
	   cd		 No**	     Yes       Yes
	   chdir	 No	     Yes       Yes
	   command	 No**	     No        Yes
	   complete	 No	     Yes       No
	   continue	 No	     Yes       Yes
	   default	 No	     Yes       No
	   dirs 	 No	     Yes       No
	   do		 No	     No        Yes
	   done 	 No	     No        Yes
	   echo 	 Yes	     Yes       Yes
	   echotc	 No	     Yes       No
	   elif 	 No	     No        Yes
	   else 	 No	     Yes       Yes
	   end		 No	     Yes       No
	   endif	 No	     Yes       No
	   endsw	 No	     Yes       No
	   esac 	 No	     No        Yes
	   eval 	 No	     Yes       Yes
	   exec 	 No	     Yes       Yes
	   exit 	 No	     Yes       Yes
	   export	 No	     No        Yes
	   false	 Yes	     No        Yes
	   fc		 No**	     No        Yes
	   fg		 No**	     Yes       Yes
	   filetest	 No	     Yes       No
	   fi		 No	     No        Yes
	   for		 No	     No        Yes
	   foreach	 No	     Yes       No
	   getopts	 No**	     No        Yes
	   glob 	 No	     Yes       No
	   goto 	 No	     Yes       No
	   hash 	 No	     No        Yes
	   hashstat	 No	     Yes       No
	   history	 No	     Yes       No
	   hup		 No	     Yes       No
	   if		 No	     Yes       Yes
	   jobid	 No	     No        Yes
	   jobs 	 No**	     Yes       Yes
	   kill 	 Yes	     Yes       No
	   limit	 No	     Yes       No
	   local	 No	     No        Yes
	   log		 No	     Yes       No
	   login	 Yes	     Yes       No
	   logout	 No	     Yes       No
	   ls-F 	 No	     Yes       No
	   nice 	 Yes	     Yes       No
	   nohup	 Yes	     Yes       No
	   notify	 No	     Yes       No
	   onintr	 No	     Yes       No
	   popd 	 No	     Yes       No
	   printenv	 Yes	     Yes       No
	   pushd	 No	     Yes       No
	   pwd		 Yes	     No        Yes
	   read 	 No**	     No        Yes
	   readonly	 No	     No        Yes
	   rehash	 No	     Yes       No
	   repeat	 No	     Yes       No
	   return	 No	     No        Yes
	   sched	 No	     Yes       No
	   set		 No	     Yes       Yes
	   setenv	 No	     Yes       No
	   settc	 No	     Yes       No
	   setty	 No	     Yes       No
	   setvar	 No	     No        Yes
	   shift	 No	     Yes       Yes
	   source	 No	     Yes       No
	   stop 	 No	     Yes       No
	   suspend	 No	     Yes       No
	   switch	 No	     Yes       No
	   telltc	 No	     Yes       No
	   test 	 Yes	     No        Yes
	   then 	 No	     No        Yes
	   time 	 Yes	     Yes       No
	   times	 No	     No        Yes
	   trap 	 No	     No        Yes
	   true 	 Yes	     No        Yes
	   type 	 No	     No        Yes
	   ulimit	 No	     No        Yes
	   umask	 No**	     Yes       Yes
	   unalias	 No**	     Yes       Yes
	   uncomplete	 No	     Yes       No
	   unhash	 No	     Yes       No
	   unlimit	 No	     Yes       No
	   unset	 No	     Yes       Yes
	   unsetenv	 No	     Yes       No
	   until	 No	     No        Yes
	   wait 	 No**	     Yes       Yes
	   where	 No	     Yes       No
	   which	 Yes	     Yes       No
	   while	 No	     Yes       Yes

SEE ALSO
     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),
     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)

HISTORY
     The builtin manual page first appeared in FreeBSD 3.4.

AUTHORS
     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.

BSD			       February 23, 2005			   BSD
","# popd

> Remove a directory placed on the directory stack by the `pushd` command.

- Remove the top directory from the stack and cd to it:

`popd`

- Remove the Nth directory (starting from zero to the left from the list printed with `dirs`):

`popd +N`

- Remove the Nth directory (starting from zero to the right from the list printed with `dirs`):

`popd -N`
"
ipcmk,,,,"# ipcmk

> Create IPC (Inter-process Communication) resources.

- Create a shared memory segment:

`ipcmk --shmem {{segment_size_in_bytes}}`

- Create a semaphore:

`ipcmk --semaphore {{element_size}}`

- Create a message queue:

`ipcmk --queue`

- Create a shared memory segment with specific permissions (default is 0644):

`ipcmk --shmem {{segment_size_in_bytes}} {{octal_permissons}}`
"
pushd,,,"
BUILTIN(1)		  BSD General Commands Manual		    BUILTIN(1)

NAME
     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,
     breaksw, builtins, case, cd, chdir, command, complete, continue, default,
     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,
     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,
     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,
     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,
     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,
     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,
     telltc, test, then, time, times, trap, true, type, ulimit, umask,
     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,
     where, which, while -- shell built-in commands

SYNOPSIS
     builtin [-options] [args ...]

DESCRIPTION
     Shell builtin commands are commands that can be executed within the run-
     ning shell's process.  Note that, in the case of csh(1) builtin commands,
     the command is executed in a subshell if it occurs as any component of a
     pipeline except the last.

     If a command specified to the shell contains a slash ``/'', the shell
     will not execute a builtin command, even if the last component of the
     specified command matches the name of a builtin command.  Thus, while
     specifying ``echo'' causes a builtin command to be executed under shells
     that support the echo builtin command, specifying ``/bin/echo'' or
     ``./echo'' does not.

     While some builtin commands may exist in more than one shell, their oper-
     ation may be different under each shell which supports them.  Below is a
     table which lists shell builtin commands, the standard shells that sup-
     port them and whether they exist as standalone utilities.

     Only builtin commands for the csh(1) and sh(1) shells are listed here.
     Consult a shell's manual page for details on the operation of its builtin
     commands.	Beware that the sh(1) manual page, at least, calls some of
     these commands ``built-in commands'' and some of them ``reserved words''.
     Users of other shells may need to consult an info(1) page or other
     sources of documentation.

     Commands marked ``No**'' under External do exist externally, but are
     implemented as scripts using a builtin command of the same name.

	   Command	 External    csh(1)    sh(1)
	   !		 No	     No        Yes
	   %		 No	     Yes       No
	   .		 No	     No        Yes
	   :		 No	     Yes       Yes
	   @		 No	     Yes       Yes
	   {		 No	     No        Yes
	   }		 No	     No        Yes
	   alias	 No**	     Yes       Yes
	   alloc	 No	     Yes       No
	   bg		 No**	     Yes       Yes
	   bind 	 No	     No        Yes
	   bindkey	 No	     Yes       No
	   break	 No	     Yes       Yes
	   breaksw	 No	     Yes       No
	   builtin	 No	     No        Yes
	   builtins	 No	     Yes       No
	   case 	 No	     Yes       Yes
	   cd		 No**	     Yes       Yes
	   chdir	 No	     Yes       Yes
	   command	 No**	     No        Yes
	   complete	 No	     Yes       No
	   continue	 No	     Yes       Yes
	   default	 No	     Yes       No
	   dirs 	 No	     Yes       No
	   do		 No	     No        Yes
	   done 	 No	     No        Yes
	   echo 	 Yes	     Yes       Yes
	   echotc	 No	     Yes       No
	   elif 	 No	     No        Yes
	   else 	 No	     Yes       Yes
	   end		 No	     Yes       No
	   endif	 No	     Yes       No
	   endsw	 No	     Yes       No
	   esac 	 No	     No        Yes
	   eval 	 No	     Yes       Yes
	   exec 	 No	     Yes       Yes
	   exit 	 No	     Yes       Yes
	   export	 No	     No        Yes
	   false	 Yes	     No        Yes
	   fc		 No**	     No        Yes
	   fg		 No**	     Yes       Yes
	   filetest	 No	     Yes       No
	   fi		 No	     No        Yes
	   for		 No	     No        Yes
	   foreach	 No	     Yes       No
	   getopts	 No**	     No        Yes
	   glob 	 No	     Yes       No
	   goto 	 No	     Yes       No
	   hash 	 No	     No        Yes
	   hashstat	 No	     Yes       No
	   history	 No	     Yes       No
	   hup		 No	     Yes       No
	   if		 No	     Yes       Yes
	   jobid	 No	     No        Yes
	   jobs 	 No**	     Yes       Yes
	   kill 	 Yes	     Yes       No
	   limit	 No	     Yes       No
	   local	 No	     No        Yes
	   log		 No	     Yes       No
	   login	 Yes	     Yes       No
	   logout	 No	     Yes       No
	   ls-F 	 No	     Yes       No
	   nice 	 Yes	     Yes       No
	   nohup	 Yes	     Yes       No
	   notify	 No	     Yes       No
	   onintr	 No	     Yes       No
	   popd 	 No	     Yes       No
	   printenv	 Yes	     Yes       No
	   pushd	 No	     Yes       No
	   pwd		 Yes	     No        Yes
	   read 	 No**	     No        Yes
	   readonly	 No	     No        Yes
	   rehash	 No	     Yes       No
	   repeat	 No	     Yes       No
	   return	 No	     No        Yes
	   sched	 No	     Yes       No
	   set		 No	     Yes       Yes
	   setenv	 No	     Yes       No
	   settc	 No	     Yes       No
	   setty	 No	     Yes       No
	   setvar	 No	     No        Yes
	   shift	 No	     Yes       Yes
	   source	 No	     Yes       No
	   stop 	 No	     Yes       No
	   suspend	 No	     Yes       No
	   switch	 No	     Yes       No
	   telltc	 No	     Yes       No
	   test 	 Yes	     No        Yes
	   then 	 No	     No        Yes
	   time 	 Yes	     Yes       No
	   times	 No	     No        Yes
	   trap 	 No	     No        Yes
	   true 	 Yes	     No        Yes
	   type 	 No	     No        Yes
	   ulimit	 No	     No        Yes
	   umask	 No**	     Yes       Yes
	   unalias	 No**	     Yes       Yes
	   uncomplete	 No	     Yes       No
	   unhash	 No	     Yes       No
	   unlimit	 No	     Yes       No
	   unset	 No	     Yes       Yes
	   unsetenv	 No	     Yes       No
	   until	 No	     No        Yes
	   wait 	 No**	     Yes       Yes
	   where	 No	     Yes       No
	   which	 Yes	     Yes       No
	   while	 No	     Yes       Yes

SEE ALSO
     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),
     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)

HISTORY
     The builtin manual page first appeared in FreeBSD 3.4.

AUTHORS
     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.

BSD			       February 23, 2005			   BSD
","# pushd

> Place a directory on a stack so it can be accessed later.
> See also `popd` to switch back to original directory.

- Switch to directory and push it on the stack:

`pushd < {{directory}}`

- Switch first and second directories on the stack:

`pushd`

- Rotate stack by making the 5th element the top of the stack:

`pushd +4`
"
ceph,https://ceph.io,"


Ceph Homepage - Ceph

















































































Menu





Documentation
Blog
Wiki
IRC / Lists
The Ceph Foundation
Download
 



Search

 








Search

 Discover

Introduction to Ceph
Blog
Videos
Resources


Use

Get Ceph
Install Ceph
Use cases
Users


Code

Github
Issue tracking
Build status


Get Involved

Foundation
Community

Ceph Community Meetings


Contribute
Team
User Survey
Events


 Documentation
Blog
Wiki
IRC / Lists
The Ceph Foundation
Download
 







Discover

Introduction to Ceph
Blog
Videos
Resources


Use

Get Ceph
Install Ceph
Use cases
Users


Code

Github
Issue tracking
Build status


Get Involved

Foundation
Community

Ceph Community Meetings


Contribute
Team
User Survey
Events


 














WALKTHROUGH KRBD I/O FLOW
A live code walkthrough with Q/A.

Join us Live!








STS Tech Talk
Pritha Srivastava on August 27th at 17:00 UTC will be sharing about the Secure Token Service (STS) in the Rados Gateway.

Join us Live!








EDGE APPLICATIONS
Hear from Red Hat summer interns on their latest project with Ceph.

Watch now!








THE FUTURE OF STORAGE™
Ceph is a unified, distributed storage system designed for excellent performance, reliability and scalability.









GET INVOLVED
Anyone can contribute to Ceph, and not just by writing lines of code!

Read more








FACE-TO-FACE
There are tons of places to come talk to us face-to-face. Come join us for Ceph Days, Conferences, Cephalocon, or others!

Read more















									Object storage								

Ceph provides seamless access to objects using native language bindings or radosgw (RGW), a REST interface that’s compatible with applications written for S3 and Swift.


									Read more								









									Block storage								

Ceph’s RADOS Block Device (RBD) provides access to block device images that are striped and replicated across the entire storage cluster.


									Read more								









									File system								

Ceph provides a POSIX-compliant network file system (CephFS) that aims for high performance, large data storage, and maximum compatibility with legacy applications.


									Read more								








Latest Tweets 
Ceph Science Working Group 2020-09-23 recording is now available https://t.co/NLGfObtn9k https://t.co/fdCGiiXemG@Ceph9 hours agoRT @Cypress_XT: ✅ Upgraded to #Ceph Octopus
🆗 Autoscale in progress...
✅ Convert cluster from ceph-deploy to #cephadm

Mind blowed once aga…@Ceph10 hours agoRT @Cypress_XT: ✅ Upgraded to #Ceph Octopus
🆗 Autoscale in progress...
⬛️ Convert cluster from ceph-deploy to cephadm https://t.co/P5l4TOam…@Ceph10 hours ago




	Privacy & Cookies: This site uses cookies. By continuing to use this website, you agree to their use. 
To find out more, including how to control cookies, see here:
	
		Cookie Policy	

 







PLANET

View all							






September 17, 2020


																									The [InfoSec] Stack																							





September 16, 2020


																									SUSE publishes first steps towards Windows clients																							





July 24, 2020


																									SUSE Enterprise Storage delivers best CephFS benchmark on Ar...																							










BLOG

View all							






September 2020, 16


																									v15.2.5 Octopus released																							


This is the fifth release of the Ceph Octopus stable release series. This release brings a range of fixes across all components. We recommend that all Octopus users upgrade to this release. Notable Changes¶ CephFS: Automatic static subtree partitioning policies may now be configured using the new distributed and random... 




 

												abhishekl											





September 2020, 15


																									December 2020 Outreachy: Ceph &...																							





 

												Mike Perez											





September 2020, 01


																									Ceph Community Newsletter, August 2...																							





 

												Mike Perez											































top








Ceph Storage

Object Storage
Block Storage
File System
Getting Started
Use Cases



Community

Blog
Featured Developers
Events
Contribute
Careers



Resources

Getting help
Mailing Lists & IRC
Publications
Logos
Ceph Tech Talks















© 2019 All rights reserved.


Code of Conduct
Terms Of Service
Privacy Statement
Trademarks
Security
 
































",,"# ceph

> A unified storage system.
> More information: <https://ceph.io>.

- Check cluster health status:

`ceph status`

- Check cluster usage stats:

`ceph df`

- Get the statistics for the placement groups in a cluster:

`ceph pg dump --format {{plain}}`

- Create a storage pool:

`ceph osd pool create {{pool_name}} {{page_number}}`

- Delete a storage pool:

`ceph osd pool delete {{pool_name}}`

- Rename a storage pool:

`ceph osd pool rename {{current_name}} {{new_name}}`

- Self-repair pool storage:

`ceph pg repair {{pool_name}}`
"
pkgrm,,,,"# pkgrm

> Remove a package from a CRUX system.

- Remove an installed package:

`pkgrm {{package_name}}`
"
stress,,,,"# stress

> A tool to stress test CPU, memory, and IO on a Linux system.

- Spawn 4 workers to stress test CPU:

`stress -c {{4}}`

- Spawn 2 workers to stress test IO and timeout after 5 seconds:

`stress -i {{2}} -t {{5}}`

- Spawn 2 workers to stress test memory (each worker allocates 256M bytes):

`stress -m {{2}} --vm-bytes {{256M}}`

- Spawn 2 workers spinning on write()/unlink() (each worker writes 1G bytes):

`stress -d {{2}} --hdd-bytes {{1GB}}`
"
mkfs.ext4,,,,"# mkfs.ext4

> Creates an ext4 filesystem inside a partition.

- Create an ext4 filesystem inside partition 1 on device b (`sdb1`):

`sudo mkfs.ext4 {{/dev/sdb1}}`

- Create an ext4 filesystem with a volume-label:

`sudo mkfs.ext4 -L {{volume_label}} {{/dev/sdb1}}`
"
free,,,"
MALLOC(3)		 BSD Library Functions Manual		     MALLOC(3)

NAME
     calloc, free, malloc, realloc, reallocf, valloc -- memory allocation

SYNOPSIS
     #include <stdlib.h>

     void *
     calloc(size_t count, size_t size);

     void
     free(void *ptr);

     void *
     malloc(size_t size);

     void *
     realloc(void *ptr, size_t size);

     void *
     reallocf(void *ptr, size_t size);

     void *
     valloc(size_t size);

DESCRIPTION
     The malloc(), calloc(), valloc(), realloc(), and reallocf() functions
     allocate memory.  The allocated memory is aligned such that it can be
     used for any data type, including AltiVec- and SSE-related types.	The
     free() function frees allocations that were created via the preceding
     allocation functions.

     The malloc() function allocates size bytes of memory and returns a
     pointer to the allocated memory.

     The calloc() function contiguously allocates enough space for count
     objects that are size bytes of memory each and returns a pointer to the
     allocated memory.	The allocated memory is filled with bytes of value
     zero.

     The valloc() function allocates size bytes of memory and returns a
     pointer to the allocated memory.  The allocated memory is aligned on a
     page boundary.

     The realloc() function tries to change the size of the allocation pointed
     to by ptr to size, and returns ptr.  If there is not enough room to
     enlarge the memory allocation pointed to by ptr, realloc() creates a new
     allocation, copies as much of the old data pointed to by ptr as will fit
     to the new allocation, frees the old allocation, and returns a pointer to
     the allocated memory.  If ptr is NULL, realloc() is identical to a call
     to malloc() for size bytes.  If size is zero and ptr is not NULL, a new,
     minimum sized object is allocated and the original object is freed.  When
     extending a region allocated with calloc(3), realloc(3) does not guaran-
     tee that the additional memory is also zero-filled.

     The reallocf() function is identical to the realloc() function, except
     that it will free the passed pointer when the requested memory cannot be
     allocated.  This is a FreeBSD specific API designed to ease the problems
     with traditional coding styles for realloc causing memory leaks in
     libraries.

     The free() function deallocates the memory allocation pointed to by ptr.
     If ptr is a NULL pointer, no operation is performed.

RETURN VALUES
     If successful, calloc(), malloc(), realloc(), reallocf(), and valloc()
     functions return a pointer to allocated memory.  If there is an error,
     they return a NULL pointer and set errno to ENOMEM.

     For realloc(), the input pointer is still valid if reallocation failed.
     For reallocf(), the input pointer will have been freed if reallocation
     failed.

     The free() function does not return a value.

DEBUGGING ALLOCATION ERRORS
     A number of facilities are provided to aid in debugging allocation errors
     in applications.  These facilities are primarily controlled via environ-
     ment variables.  The recognized environment variables and their meanings
     are documented below.

ENVIRONMENT
     The following environment variables change the behavior of the alloca-
     tion-related functions.

     MallocDebugReport		  If set, specifies where messages are writ-
				  ten. Set to ""stderr"" to write messages to
				  the standard error stream, ""none"" to discard
				  all messages and ""crash"" to write messages
				  to standard error only for a condition that
				  is about to cause a crash. When not set,
				  message are written to the standard error
				  stream if it appears to be a terminal (that
				  is, if isatty(STDERR_FILENO) returns a non-
				  zero value) and are otherwise discarded.

     MallocGuardEdges		  If set, add a guard page before and after
				  each large block.

     MallocDoNotProtectPrelude	  If set, do not add a guard page before large
				  blocks, even if the MallocGuardEdges envi-
				  ronment variable is set.

     MallocDoNotProtectPostlude   If set, do not add a guard page after large
				  blocks, even if the MallocGuardEdges envi-
				  ronment variable is set.

     MallocStackLogging 	  The default behavior if this is set is to
				  record all allocation and deallocation
				  events to an on-disk log, along with stacks,
				  so that tools like leaks(1) and
				  malloc_history(1) can be used.

				  Set to ""vm"" to record only allocation of
				  virtual memory regions allocated by system
				  calls and mach traps, such as by mmap(1)

				  Set to ""malloc"" to record only allocations
				  via malloc(3) and related interfaces, not
				  virtual memory regions.

				  Set to ""lite"" to record current allocations
				  only, not history.   These are recorded by
				  in-memory data structures, instead of an on-
				  disk log.

     MallocStackLoggingNoCompact  If set, record all stacks in a manner that
				  is compatible with the malloc_history pro-
				  gram.

     MallocStackLoggingDirectory  If set, records stack logs to the directory
				  specified instead of saving them to the
				  default location (/tmp).

     MallocScribble		  If set, fill memory that has been allocated
				  with 0xaa bytes.  This increases the likeli-
				  hood that a program making assumptions about
				  the contents of freshly allocated memory
				  will fail.  Also if set, fill memory that
				  has been deallocated with 0x55 bytes.  This
				  increases the likelihood that a program will
				  fail due to accessing memory that is no
				  longer allocated. Note that due to the way
				  in which freed memory is managed internally,
				  the 0x55 pattern may not appear in some
				  parts of a deallocated memory block.

     MallocCheckHeapStart <s>	  If set, specifies the number of allocations
				  <s> to wait before begining periodic heap
				  checks every <n> as specified by
				  MallocCheckHeapEach.	If
				  MallocCheckHeapStart is set but
				  MallocCheckHeapEach is not specified, the
				  default check repetition is 1000.

     MallocCheckHeapEach <n>	  If set, run a consistency check on the heap
				  every <n> operations.  MallocCheckHeapEach
				  is only meaningful if MallocCheckHeapStart
				  is also set.

     MallocCheckHeapSleep <t>	  Sets the number of seconds to sleep (waiting
				  for a debugger to attach) when
				  MallocCheckHeapStart is set and a heap cor-
				  ruption is detected.	The default is 100
				  seconds.  Setting this to zero means not to
				  sleep at all.  Setting this to a negative
				  number means to sleep (for the positive num-
				  ber of seconds) only the very first time a
				  heap corruption is detected.

     MallocCheckHeapAbort <b>	  When MallocCheckHeapStart is set and this is
				  set to a non-zero value, causes abort(3) to
				  be called if a heap corruption is detected,
				  instead of any sleeping.

     MallocErrorAbort		  If set, causes abort(3) to be called if an
				  error was encountered in malloc(3) or
				  free(3) , such as a calling free(3) on a
				  pointer previously freed.

     MallocCorruptionAbort	  Similar to MallocErrorAbort but will not
				  abort in out of memory conditions, making it
				  more useful to catch only those errors which
				  will cause memory corruption.  MallocCorrup-
				  tionAbort is always set on 64-bit processes.

     MallocHelp 		  If set, print a list of environment vari-
				  ables that are paid heed to by the alloca-
				  tion-related functions, along with short
				  descriptions.  The list should correspond to
				  this documentation.

DIAGNOSTIC MESSAGES
SEE ALSO
     leaks(1), malloc_history(1), abort(3), malloc_size(3),
     malloc_zone_malloc(3), posix_memalign(3), libgmalloc(3)

BSD				 Aug 13, 2008				   BSD
","# free

> Display amount of free and used memory in the system.

- Display system memory:

`free`

- Display memory in Bytes/KB/MB/GB:

`free -{{b|k|m|g}}`

- Display memory in human readable units:

`free -h`

- Refresh the output every 2 seconds:

`free -s {{2}}`
"
httpie,https://example.com,"

Example Domain







Example Domain
This domain is for use in illustrative examples in documents. You may use this
    domain in literature without prior coordination or asking for permission.
More information...


",,"# httpie

> A user friendly command line HTTP tool.

- Send a GET request (default method with no request data):

`http {{https://example.com}}`

- Send a POST request (default method with request data):

`http {{https://example.com}} {{hello=World}}`

- Send a POST request with redirected input:

`http {{https://example.com}} < {{file.json}}`

- Send a PUT request with a given json body:

`http PUT {{https://example.com/todos/7}} {{hello=world}}`

- Send a DELETE request with a given request header:

`http DELETE {{https://example.com/todos/7}} {{API-Key:foo}}`

- Show the whole HTTP exchange (both request and response):

`http -v {{https://example.com}}`

- Download a file:

`http --download {{https://example.com}}`
"
whatis,,,"whatis(1)							     whatis(1)



NAME
       whatis - search the whatis database for complete words.

SYNOPSIS
       whatis keyword ...

DESCRIPTION
       whatis  searches  a set of database files containing short descriptions
       of system commands for keywords and displays the result on the standard
       output.	Only complete word matches are displayed.

       The  whatis  database  is  created using the command /usr/libexec/make-
       whatis.

AUTHOR
       John W. Eaton was the  original	author	of  man.   Zeyd  M.  Ben-Halim
       released  man  1.2,  and  Andries Brouwer followed up with versions 1.3
       thru 1.5p.  Federico  Lucifredi	<flucifredi@acm.org>  is  the  current
       maintainer.

SEE ALSO
       apropos(1), man(1).



			      September 19, 2005		     whatis(1)
","# whatis

> Display one-line descriptions from manual pages.

- Display a description from a man page:

`whatis {{command}}`

- Don't cut the description off at the end of the line:

`whatis --long {{command}}`

- Display descriptions for all commands matching a glob:

`whatis --wildcard {{net*}}`

- Search man page descriptions with a regular expression:

`whatis --regex '{{wish[0-9]\.[0-9]}}'`
"
dstat,http://dag.wieers.com/home-made/dstat,"

DAG: Dstat: Versatile resource statistics tool


























Blog
About me
Bookmarks
Curriculum vitae
Events
Home-made

 · Apt/Yum RPM repository
 · Cars
 · DAR
 · Dconf
 · Distcc compilers
 · Dstat

 ·  · Features
 ·  · Screenshot
 ·  · Download
 ·  · Mailinglist
 ·  · Sourcecode
 ·  · Documentation

 · Dwall
 · Dweb
 · Dwscan
 · mrepo
 · PyTone plugins
 · QLogic Autoconf
 · Sarah
 · Soapbox
 · Squidguard
 · unoconv
 · wascii
 · wiipresent
Howtos
Photo archive
RPM packages
Websites
TODO






Shortcuts:
Dconf ·
			Dstat ·
			Dwall ·
			Dweb ·
			Dwscan ·
			Lyrics ·
			mrepo ·
			Pixies.. ·
			RPMs ·
			unoconv ·
			wascii ·
			wiipresent ·
			Yam ·
		


Google Site Search:






























» Dag Wieers » Home-made » Dstat: Versatile resource statistics tool 
Dstat: Versatile resource statistics tool



Dstat is a versatile replacement for vmstat, iostat, netstat and ifstat.
Dstat overcomes some of their limitations and adds some extra features,
more counters and flexibility. Dstat is handy for monitoring systems
during performance tuning tests, benchmarks or troubleshooting.


Dstat allows you to view all of your system resources in real-time, you
can eg. compare disk utilization in combination with interrupts from your
IDE controller, or compare the network bandwidth numbers directly
with the disk throughput (in the same interval).


Dstat gives you detailed selective information in columns and clearly
indicates in what magnitude and unit the output is displayed. Less
confusion, less mistakes. And most importantly, it makes it very easy
to write plugins to collect your own counters and extend in ways you
never expected.


Dstat's output by default is designed for being interpreted by
humans in real-time, however you can export details to CSV output
to a file to be imported later into Gnumeric or Excel to generate
graphs.

Features

 Combines vmstat, iostat, ifstat, netstat information and more
	 Shows stats in exactly the same timeframe
	 Enable/order counters as they make most sense during analysis/troubleshooting
	 Modular design
	 Written in python so easily extendable for the task at hand
	 Easy to extend, add your own counters (please contribute those)
	 Includes many external plugins to show how easy it is to add counters
	 Can summarize grouped block/network devices and give total numbers
	 Can show interrupts per device
	 Very accurate timeframes, no timeshifts when system is stressed
	 Shows exact units and limits conversion mistakes
	 Indicate different units with different colors
	 Show intermediate results when delay > 1
	 Allows to export CSV output, which can be imported in Gnumeric and Excel to make graphs

External plugins
Here are the existing plugins, send me your own plugins.

[dag@moria ~]# dstat --list
internal:
        aio, cpu, cpu24, disk, disk24, disk24old, epoch, fs, int, int24, io, ipc, load, lock, 
        mem, net, page, page24, proc, raw, socket, swap, swapold, sys, tcp, time, udp, unix, 
        vm
/usr/share/dstat:
        battery, battery-remain, cpufreq, dbus, disk-recsize, disk-tps, disk-util, dstat, 
        dstat-cpu, dstat-ctxt, dstat-mem, fan, freespace, gpfs, gpfs-ops, helloworld, 
        innodb-buffer, innodb-io, innodb-ops, lustre, mem-adv, memcache-hits, mysql-io, 
        mysql-keys, mysql5-cmds, mysql5-conn, mysql5-io, mysql5-keys, net-packets, nfs3, 
        nfs3-ops, nfsd3, nfsd3-ops, ntp, pcap-ssh, postfix, power, proc-count, proc-count2, 
        proc-count3, qmail, rpc, rpcd, sendmail, snooze, squid, test, thermal, top-bio, 
        top-bio-adv, top-childwait, top-cpu, top-cpu-adv, top-cpu2, top-cpu3, top-cputime, 
        top-cputime-avg, top-int, top-io, top-io-adv, top-latency, top-latency-avg, top-mem, 
        top-oom, top-tcp-ports, utmp, vm-memctl, vmk-hba, vmk-int, vmk-nic, vz-cpu, vz-io, 
        vz-ubc, wifi


See the Manual for options and a summary of each external plugin.

Future

 Add /etc/dstat.conf configuration file to customize
	 Create a complete counter/object model structure
	 Interface directly with rrdtool for real-time graphing
	 Create client-server application model for remote graphing
	 See Github for more details

Screenshot 1
[dag@moria ~]$ dstat --help
Usage: dstat [-afv] [options..] [delay [count]]
Versatile tool for generating system resource statistics

Dstat options:
  -c, --cpu              enable cpu stats
     -C 0,3,total           include cpu0, cpu3 and total
  -d, --disk             enable disk stats
     -D total,hda           include hda and total
  -g, --page             enable page stats
  -i, --int              enable interrupt stats
     -I 5,eth2              include int5 and interrupt used by eth2
  -l, --load             enable load stats
  -m, --mem              enable memory stats
  -n, --net              enable network stats
     -N eth1,total          include eth1 and total
  -p, --proc             enable process stats
  -r, --io               enable io stats (I/O requests completed)
  -s, --swap             enable swap stats
     -S swap1,total         include swap1 and total
  -t, --time             enable time/date output
  -T, --epoch            enable time counter (seconds since epoch)
  -y, --sys              enable system stats

  --aio                  enable aio stats
  --fs, --filesystem     enable fs stats
  --ipc                  enable ipc stats
  --lock                 enable lock stats
  --raw                  enable raw stats
  --socket               enable socket stats
  --tcp                  enable tcp stats
  --udp                  enable udp stats
  --unix                 enable unix stats
  --vm                   enable vm stats

  --plugin-name          enable plugins by plugin name (see manual)
  --list                 list all available plugins

  -a, --all              equals -cdngy (default)
  -f, --full             automatically expand -C, -D, -I, -N and -S lists
  -v, --vmstat           equals -pmgdsc -D total

  --float                force float values on screen
  --integer              force integer values on screen

  --bw, --blackonwhite   change colors for white background terminal
  --nocolor              disable colors (implies --noupdate)
  --noheaders            disable repetitive headers
  --noupdate             disable intermediate updates
  --output file          write CSV output to file

delay is the delay in seconds between each update (default: 1)
count is the number of updates to display before exiting (default: unlimited)

Screenshot 2
Only in black and white :)
[dag@moria ~]# dstat
----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--
usr sys idl wai hiq siq| read  writ| recv  send|  in   out | int   csw 
  5   0  93   0   0   0| 154k   84k|   0     0 |   0     0 |1081  1116 
 13   0  87   0   0   0|   0     0 |   0     0 |   0     0 |1036   696 
  8   0  92   0   1   0|   0  8192B|   0     0 |   0     0 |1073   936 
  0   0  99   0   0   1|   0     0 |   0     0 |   0     0 |1072   940 
  1   1  97   0   2   0|   0     0 |   0     0 |   0     0 |1252  1727 
  1   1  98   0   1   0|   0     0 |   0     0 |   0     0 |1126  1191 
  1   0  99   0   0   0|   0     0 |   0     0 |   0     0 |1045   908 
  0   0  99   0   0   0|   0    44k|   0     0 |   0     0 |1051   904 
  1   1  99   0   0   0|   0     0 |   0     0 |   0     0 |1036   850 
  1   0 100   0   0   0|   0     0 |   0     0 |   0     0 |1029   757 

Screenshot 3
[dag@moria ~]$ dstat -c --top-cpu -d --top-bio --top-latency
----total-cpu-usage---- -most-expensive- -dsk/total- ----most-expensive---- --highest-total--
usr sys idl wai hiq siq|  cpu process   | read  writ|  block i/o process   | latency process 
  5   0  94   0   0   0|firefox      3.6| 148k   81k|init [5]     98k   50B|pdflush        21
  2   1  98   0   0   0|wnck-applet  0.5|   0     0 |                      |at-spi-regist   5
  2   1  98   0   0   0|firefox      0.5|   0     0 |                      |Xorg            1
  1   2  97   0   0   1|                |   0     0 |                      |Xorg            1
  1   1  98   0   0   0|                |   0     0 |                      |ksoftirqd/1    10
  1   1  97   0   0   0|firefox      0.5|   0     0 |                      |ksoftirqd/0     5
  2   1  97   0   0   0|firefox      0.5|   0     0 |firefox       0    28k|ksoftirqd/0     5
  2   1  97   0   0   0|firefox      0.5|   0     0 |                      |Xorg            1
  1   1  97   0   0   0|firefox      0.5|   0     0 |                      |ksoftirqd/0     6
  2   1  98   0   0   0|firefox      0.5|   0     0 |                      |ksoftirqd/0     6
  1   2  98   0   0   0|                |   0     0 |                      |ksoftirqd/1     8
  2   1  98   0   0   0|iwlagn       0.5|   0    72k|kjournald     0    32k|ksoftirqd/1    12
  1   1  97   0   0   0|                |   0     0 |                      |iwlagn/0        1
  1   1  98   0   0   0|firefox      0.5|   0     0 |                      |ksoftirqd/1     8

Real screenshot
Here are 2 screenshots of older dstat versions in action.

Dstat 0.4 on a Power5 system that is being stress tested.


Dstat 0.3 (first release) on 5 RHEL3 nodes in a cluster from a Windows terminal.

Bug reports
If you've found a bug, please check the
Github issue-tracker 
for known problems and send me updates if you have more information to
provide.

Please also copy&paste the output of the problem, with a description,
the version of the kernel and if appropriate the involved /proc entries.

Dstat has a --debug option to profile plugins and show what plugins and
/proc entries are affected. Dstat also shows some more information with
the --version option that might be useful.


Download
The following packages (in order of appearance) are available.


 Red Hat Enterprise Linux / CentOS  Fedora  Gentoo  OpenSUSE  Debian  Mandriva  Alt Linux  cAos  Ubuntu Breezy  Linspire  Sourcemage  rPath  PLD Linux  Slackware  Tiny Core Linux

or grab the latest 0.7.3 tarball at:

	https://github.com/dagwieers/dstat/archive/0.7.3.tar.gz
Mailinglist
There's a mailinglist about dstat and some other related tools at:
http://lists.repoforge.org/mailman/listinfo/tools
Sourcecode
You can have access to the latest changes via subversion from:


 https://github.com/dagwieers/dstat
Documentation
The current asciidoc manual page is found here:

 https://github.com/dagwieers/dstat/blob/master/docs/dstat.1.adoc

Subversion also holds the current documentation and example config-files,
so please look there for more information. If you have improvements, found
a bug or have a great idea, please mail me so we can look at how to integrate
it.


 ChangeLog  COPYING  README  TODO  WISHLIST  /docs/
What users have to say
I found some comments about dstat on blogs, here's what they say:


 http://www.michael-prokop.at/blog/?p=298  http://tadek.pietraszek.org/blog/2005/09/14/monitoring-resource-usage-in-linux/  http://patrick.wagstrom.net/weblog/linux/dstat-for-fun-and-profit.xml  http://www.linuxjournal.com/article/9003





Anything to add/change to this page? Send me your thoughts!Copyright © 1995-2009 Dag Wieërs. All rights reserved.Last modified on: Mon 28 March 2016 






",,"# dstat

> Versatile tool for generating system resource statistics.
> More information: <http://dag.wieers.com/home-made/dstat>.

- Display CPU, disk, net, paging and system statistics:

`dstat`

- Display statistics every 5 seconds and 4 updates only:

`dstat {{5}} {{4}}`

- Display CPU and memory statistics only:

`dstat --cpu --mem`

- List all available dstat plugins:

`dstat --list`

- Display the process using the most memory and most CPU:

`dstat --top-mem --top-cpu`

- Display battery percentage and remaining battery time:

`dstat --battery --battery-remain`
"
manpath,,,"man(1)									man(1)



NAME
       man - format and display the on-line manual pages

SYNOPSIS
       man  [-acdfFhkKtwW]  [--path]  [-m system] [-p string] [-C config_file]
       [-M pathlist] [-P pager] [-B browser] [-H htmlpager] [-S  section_list]
       [section] name ...


DESCRIPTION
       man formats and displays the on-line manual pages.  If you specify sec-
       tion, man only looks in that section of the manual.  name  is  normally
       the  name of the manual page, which is typically the name of a command,
       function, or file.  However, if name contains  a  slash	(/)  then  man
       interprets  it  as a file specification, so that you can do man ./foo.5
       or even man /cd/foo/bar.1.gz.

       See below for a description of where man  looks	for  the  manual  page
       files.


OPTIONS
       -C  config_file
	      Specify  the  configuration  file  to  use; the default is /pri-
	      vate/etc/man.conf.  (See man.conf(5).)

       -M  path
	      Specify the list of directories to search for man pages.	 Sepa-
	      rate  the directories with colons.  An empty list is the same as
	      not specifying -M at all.  See SEARCH PATH FOR MANUAL PAGES.

       -P  pager
	      Specify which pager to use.  This option overrides the  MANPAGER
	      environment  variable,  which  in turn overrides the PAGER vari-
	      able.  By default, man uses /usr/bin/less -is.

       -B     Specify which browser to use on HTML files.  This  option  over-
	      rides  the  BROWSER  environment	variable. By default, man uses
	      /usr/bin/less-is,

       -H     Specify a command that renders HTML files as text.  This	option
	      overrides  the  HTMLPAGER  environment variable. By default, man
	      uses /bin/cat,

       -S  section_list
	      List is a colon separated list of  manual  sections  to  search.
	      This option overrides the MANSECT environment variable.

       -a     By default, man will exit after displaying the first manual page
	      it finds.  Using this option forces man to display all the  man-
	      ual pages that match name, not just the first.

       -c     Reformat	the  source man page, even when an up-to-date cat page
	      exists.  This can be meaningful if the cat  page	was  formatted
	      for  a screen with a different number of columns, or if the pre-
	      formatted page is corrupted.

       -d     Don't actually display the man  pages,  but  do  print  gobs  of
	      debugging information.

       -D     Both display and print debugging info.

       -f     Equivalent to whatis.

       -F or --preformat
	      Format only - do not display.

       -h     Print a help message and exit.

       -k     Equivalent to apropos.

       -K     Search  for  the	specified  string in *all* man pages. Warning:
	      this is probably very slow!  It  helps  to  specify  a  section.
	      (Just  to  give  a  rough idea, on my machine this takes about a
	      minute per 500 man pages.)

       -m  system
	      Specify an alternate set of man pages to	search	based  on  the
	      system name given.

       -p  string
	      Specify  the  sequence  of  preprocessors to run before nroff or
	      troff.  Not all installations will have a full set of preproces-
	      sors.   Some of the preprocessors and the letters used to desig-
	      nate them are: eqn (e), grap (g), pic (p), tbl (t), vgrind  (v),
	      refer  (r).   This  option  overrides the MANROFFSEQ environment
	      variable.

       -t     Use /usr/bin/groff -Tps -mandoc -c to format  the  manual  page,
	      passing  the  output  to	stdout.   The default output format of
	      /usr/bin/groff -Tps -mandoc -c is Postscript, refer to the  man-
	      ual  page  of /usr/bin/groff -Tps -mandoc -c for ways to pick an
	      alternate format.

       Depending on the selected  format  and  the  availability  of  printing
       devices,  the  output  may  need  to  be  passed through some filter or
       another before being printed.

       -w or --path
	      Don't actually display the man pages, but  do  print  the  loca-
	      tion(s) of the files that would be formatted or displayed. If no
	      argument is given: display (on stdout) the list  of  directories
	      that  is	searched by man for man pages. If manpath is a link to
	      man, then ""manpath"" is equivalent to ""man --path"".

       -W     Like -w, but print file names one per line,  without  additional
	      information.   This is useful in shell commands like man -aW man
	      | xargs ls -l


CAT PAGES
       Man will try to save the formatted man pages, in order to save  format-
       ting time the next time these pages are needed.	Traditionally, format-
       ted versions of pages in DIR/manX are saved in DIR/catX, but other map-
       pings   from   man   dir   to   cat  dir  can  be  specified  in  /pri-
       vate/etc/man.conf.  No cat pages are saved when the required cat direc-
       tory  does  not	exist.	No cat pages are saved when they are formatted
       for a line length different from 80.   No  cat  pages  are  saved  when
       man.conf contains the line NOCACHE.

       It is possible to make man suid to a user man. Then, if a cat directory
       has owner man and mode 0755 (only writable by man), and the  cat  files
       have  owner  man  and  mode  0644 or 0444 (only writable by man, or not
       writable at all), no ordinary user can change  the  cat	pages  or  put
       other  files  in the cat directory. If man is not made suid, then a cat
       directory should have mode 0777 if all users should be  able  to  leave
       cat pages there.

       The  option  -c	forces	reformatting a page, even if a recent cat page
       exists.


HTML PAGES
       Man will find HTML pages if they live in directories named as  expected
       to  be  "".html"", thus a valid name for an HTML version of the ls(1) man
       page would be /usr/share/man/htmlman1/ls.1.html.


SEARCH PATH FOR MANUAL PAGES
       man uses a sophisticated method of finding manual page files, based  on
       the   invocation   options   and   environment	variables,  the  /pri-
       vate/etc/man.conf configuration file, and some built in conventions and
       heuristics.

       First  of  all, when the name argument to man contains a slash (/), man
       assumes it is a file specification itself, and there  is  no  searching
       involved.

       But in the normal case where name doesn't contain a slash, man searches
       a variety of directories for a file that could be a manual page for the
       topic named.

       If  you	specify  the -M pathlist option, pathlist is a colon-separated
       list of the directories that man searches.

       If you don't specify -M but set the MANPATH environment	variable,  the
       value  of  that	variable  is  the  list  of  the  directories that man
       searches.

       If you don't specify an explicit path list  with  -M  or  MANPATH,  man
       develops  its  own path list based on the contents of the configuration
       file /private/etc/man.conf.  The MANPATH statements in  the  configura-
       tion  file  identify  particular  directories  to include in the search
       path.

       Furthermore, the MANPATH_MAP statements add to the search path  depend-
       ing  on your command search path (i.e. your PATH environment variable).
       For each directory that may be in  the  command	search	path,  a  MAN-
       PATH_MAP  statement  specifies  a directory that should be added to the
       search path for manual page files.  man looks at the PATH variable  and
       adds the corresponding directories to the manual page file search path.
       Thus, with the proper use of MANPATH_MAP, when you  issue  the  command
       man  xyz,  you  get a manual page for the program that would run if you
       issued the command xyz.

       In addition, for each directory in the command search path (we'll  call
       it  a  ""command	directory"")  for  which  you do not have a MANPATH_MAP
       statement, man automatically looks for a manual page directory ""nearby""
       namely as a subdirectory in the command directory itself or in the par-
       ent directory of the command directory.

       You can disable the automatic ""nearby"" searches by  including  a  NOAU-
       TOPATH statement in /private/etc/man.conf.

       In  each  directory in the search path as described above, man searches
       for a file named topic.section, with an optional suffix on the  section
       number  and  possibly  a compression suffix.  If it doesn't find such a
       file, it then looks in any subdirectories named manN or catN where N is
       the  manual section number.  If the file is in a catN subdirectory, man
       assumes it is a formatted manual page file (cat page).  Otherwise,  man
       assumes it is unformatted.  In either case, if the filename has a known
       compression suffix (like .gz), man assumes it is gzipped.

       If you want to see where (or if) man would find the manual page	for  a
       particular topic, use the --path (-w) option.


ENVIRONMENT
       MANPATH
	      If  MANPATH is set, man uses it as the path to search for manual
	      page files.  It overrides the configuration file and  the  auto-
	      matic  search  path,  but  is  overridden  by  the -M invocation
	      option.  See SEARCH PATH FOR MANUAL PAGES.

       MANPL  If MANPL is set, its value is used as the display  page  length.
	      Otherwise, the entire man page will occupy one (long) page.

       MANROFFSEQ
	      If  MANROFFSEQ is set, its value is used to determine the set of
	      preprocessors run before running nroff or  troff.   By  default,
	      pages are passed through the tbl preprocessor before nroff.

       MANSECT
	      If  MANSECT  is set, its value is used to determine which manual
	      sections to search.

       MANWIDTH
	      If MANWIDTH is set, its value is	used  as  the  width  manpages
	      should  be displayed.  Otherwise the pages may be displayed over
	      the whole width of your screen.

       MANPAGER
	      If MANPAGER is set, its value is used as the name of the program
	      to  use to display the man page.	If not, then PAGER is used. If
	      that has no value either, /usr/bin/less -is is used.

       BROWSER
	      The name of a browser to use for displaying HTML	manual	pages.
	      If it is not set, /usr/bin/less -is is used.

       HTMLPAGER
	      The  command to use for rendering HTML manual pages as text.  If
	      it is not set, /bin/cat is used.

       LANG   If LANG is set, its value defines the name of  the  subdirectory
	      where  man first looks for man pages. Thus, the command `LANG=dk
	      man 1 foo' will cause man to  look  for  the  foo  man  page  in
	      .../dk/man1/foo.1,  and  if  it cannot find such a file, then in
	      .../man1/foo.1, where ... is a directory on the search path.

       NLSPATH, LC_MESSAGES, LANG
	      The environment variables NLSPATH and LC_MESSAGES (or LANG  when
	      the  latter  does not exist) play a role in locating the message
	      catalog.	(But the English messages are  compiled  in,  and  for
	      English no catalog is required.)	Note that programs like col(1)
	      called by man also use e.g. LC_CTYPE.

       PATH   PATH helps determine the search path for manual page files.  See
	      SEARCH PATH FOR MANUAL PAGES.

       SYSTEM SYSTEM is used to get the default alternate system name (for use
	      with the -m option).

BUGS
       The -t option only works if a troff-like program is installed.
       If you see blinking  \255  or  <AD>  instead  of  hyphens,  put	`LESS-
       CHARSET=latin1' in your environment.

TIPS
       If you add the line

	 (global-set-key  [(f1)]  (lambda () (interactive) (manual-entry (cur-
       rent-word))))

       to your .emacs file, then hitting F1 will give you the man page for the
       library call at the current cursor position.

       To  get	a  plain  text	version  of a man page, without backspaces and
       underscores, try

	 # man foo | col -b > foo.mantxt

AUTHOR
       John W. Eaton was the  original	author	of  man.   Zeyd  M.  Ben-Halim
       released  man  1.2,  and  Andries Brouwer followed up with versions 1.3
       thru 1.5p.  Federico  Lucifredi	<flucifredi@acm.org>  is  the  current
       maintainer.

SEE ALSO
       apropos(1), whatis(1), less(1), groff(1), man.conf(5).



			      September 19, 2005			man(1)
","# manpath

> Determine the search path for manual pages.

- Display the search path used to find man pages:

`manpath`

- Show the entire global manpath:

`manpath --global`
"
qsub,,,,"# qsub

> Submits a script to the queue management system TORQUE.

- Submit a script with default settings (depends on TORQUE settings):

`qsub {{script.sh}}`

- Submit a script with a specified wallclock runtime limit of 1 hour, 2 minutes and 3 seconds:

`qsub -l walltime={{1}}:{{2}}:{{3}} {{script.sh}}`

- Submit a script that is executed on 2 nodes using 4 cores per node:

`qsub -l nodes={{2}}:ppn={{4}} {{script.sh}}`

- Submit a script to a specific queue. Note that different queues can have different maximum and minimum runtime limits:

`qsub -q {{queue_name}} {{script.sh}}`
"
lsmod,,,,"# lsmod

> Shows the status of linux kernel modules.
> See also `modprobe`, which loads kernel modules.

- List all currently loaded kernel modules:

`lsmod`
"
vncviewer,,,,"# vncviewer

> Launches a VNC (Virtual Network Computing) client.

- Launch a VNC client which connects to a host on a given display:

`vncviewer {{host}}:{{display_number}}`

- Launch in full-screen mode:

`vncviewer -FullScreen {{host}}:{{display_number}}`

- Launch a VNC client with a specific screen geometry:

`vncviewer --geometry {{width}}x{{height}} {{host}}:{{display_number}}`

- Launch a VNC client which connects to a host on a given port:

`vncviewer {{host}}::{{port}}`
"
photorec,https://www.cgsecurity.org/wiki/PhotoRec,"


PhotoRec - CGSecurity


























Cookies help us deliver our services. By using our services, you agree to our use of cookies. More information 





PhotoRec 
From CGSecurity 

					Jump to:					navigation, 					search


 English  中文  Deutsch  Español  Français  Magyar  Italiano  Русский  Türkçe




 Latest stable version



7.1



July 7, 2019





PhotoRec, Digital Picture and File Recovery

PhotoRec is file data recovery software designed to recover lost files including video, documents and archives from hard disks, CD-ROMs, and lost pictures (thus the Photo Recovery name) from digital camera memory. PhotoRec ignores the file system and goes after the underlying data, so it will still work even if your media's file system has been severely damaged or reformatted.
PhotoRec is free - this open source multi-platform application is distributed under GNU General Public License (GPLV v2+). PhotoRec is a companion program to TestDisk, an application for recovering lost partitions on a wide variety of file systems and making non-bootable disks bootable again.
You can download them from this link.
For more safety, PhotoRec uses read-only access to handle the drive or memory card you are about to recover lost data from.
Important: As soon as a picture or file is accidentally deleted, or you discover any missing, do NOT save any more pictures or files to that memory device or hard disk drive; otherwise you may overwrite your lost data. This means that while using PhotoRec, you must not choose to write the recovered files to the same partition they were stored on.

Contents

1 Operating systems
2 File systems
3 Media
4 Known file formats
5 How PhotoRec works
6 Other topics
7 Problems?


Operating systems
PhotoRec runs under

DOS/Windows 9x
Windows 10/8.1/8/7/Vista/XP, Windows Server 2016/2012/2008/2003
Linux
FreeBSD, NetBSD, OpenBSD
Sun Solaris
Mac OS X
and can be compiled on almost every Unix system.
 Download TestDisk & PhotoRec

File systems
PhotoRec ignores the file system; this way it works even if the file system is severely damaged.
It can recover lost files from at least 

FAT
NTFS
exFAT
ext2/ext3/ext4 filesystem
HFS+
ReiserFS includes some special optimizations centered around tails, a name for files and end portions of files that are smaller than a filesystem block. In order to increase performance, ReiserFS is able to store files inside the b*tree leaf nodes themselves, rather than storing the data somewhere else on the disk and pointing to it. Unfortunately, PhotoRec isn't able to deal with this - that's why it doesn't work well with ReiserFS.

Media
PhotoRec works with hard disks, CD-ROMs, memory cards (CompactFlash, Memory Stick, Secure Digital/SD, SmartMedia, Microdrive, MMC, etc.), USB memory drives, DD raw image, EnCase E01 image, etc.
PhotoRec has been successfully tested with various portable media players including iPod and the following Digital Cameras:

Canon EOS 10D, 60D, 80D, 300D
Casio Exilim EX-Z 750
Fujifilm X-T10
HP PhotoSmart 620, 850, 935
Nikon CoolPix 775, 950, 5700
Olympus C350N, C860L, Mju 400 Digital, Stylus 300
Sony Alpha DSLR, DSC-P9, NEX-6
Pentax K20D
Praktica DCZ-3.4
Known file formats
PhotoRec searches for known file headers. If there is no data fragmentation, which is often the case, it can recover the whole file.
PhotoRec recognizes and recovers numerous file formats including ZIP, Office, PDF, HTML, JPEG and various graphics file formats.
The whole  list of file formats recovered by PhotoRec contains more than 480 file extensions (about 300 file families).
Want to know if PhotoRec can recover your files ? Upload a sample file via the PhotoRec online checker (BETA).

How PhotoRec works
FAT, NTFS, ext2/ext3/ext4 file systems store files in data blocks (also called clusters under Windows). The cluster or block size remains at a constant number of sectors after being initialized during the formatting of the file system. In general, most operating systems try to store the data in a contiguous way so as to minimize data fragmentation. The seek time of mechanical drives is significant for writing and reading data to/from a hard disk, so that's why it's important to keep the fragmentation to a minimum level.
When a file is deleted, the meta-information about this file (file name, date/time, size, location of the first data block/cluster, etc.) is lost; for example, in an ext3/ext4 file system, the names of deleted files are still present, but the location of the first data block is removed. This means the data is still present on the file system, but only until some or all of it is overwritten by new file data.
To recover these lost files, PhotoRec first tries to find the data block (or cluster) size. If the file system is not corrupted, this value can be read from the superblock (ext2/ext3/ext4) or volume boot record (FAT, NTFS). Otherwise, PhotoRec reads the media, sector by sector, searching for the first ten files, from which it calculates the block/cluster size from their locations. Once this block size is known, PhotoRec reads the media block by block (or cluster by cluster). Each block is checked against a signature database which comes with the program and has grown in the type of files it can recover ever since PhotoRec's first version came out.
For example, PhotoRec identifies a JPEG file when a block begins with:

0xff, 0xd8, 0xff, 0xe0
0xff, 0xd8, 0xff, 0xe1
or 0xff, 0xd8, 0xff, 0xfe
If PhotoRec has already started to recover a file, it stops its recovery, checks the consistency of the file when possible and starts to save the new file (which it determined from the signature it found).
If the data is not fragmented, the recovered file should be either identical to or larger than the original file in size. In some cases, PhotoRec can learn the original file size from the file header, so the recovered file is truncated to the correct size. If, however, the recovered file ends up being smaller than its header specifies, it is discarded. Some files, such as *.MP3 types, are data streams. In this case, PhotoRec parses the recovered data, then stops the recovery when the stream ends.
When a file is recovered successfully, PhotoRec checks the previous data blocks to see if a file signature was found but the file wasn't able to be successfully recovered (that is, the file was too small), and it tries again. This way, some fragmented files can be successfully recovered.

Other topics
testdisk.pdf More than 60 pages about data recovery using TestDisk & PhotoRec and other tools
Working with CD-R/CR-RW/DVD/floppy...
PhotoRec Step By Step
Recover data from an iPhone
How to help 
After Using PhotoRec: Some ideas to sort recovered files
PhotoRec FAQ
Scripted run: Running PhotoRec without user interaction (Batch mode).
Developers How to contribute code to TestDisk & PhotoRec
Problems?
Don't hesitate to visit the PhotoRec forum if you have

some difficulties using PhotoRec,
some ideas to improve it
If there is a file format you would like to be added, feel free to contact the developer Christophe GRENIER.





 
						Retrieved from ""https://www.cgsecurity.org/mw/index.php?title=PhotoRec&oldid=9035""					
Category: Data Recovery 



Navigation menu


Personal tools

Log in 



Namespaces

Page 




Variants









Views

ReadView source 



More














Data Recovery


TestDiskPhotoRecdownloadForum 



Donate














 


Password recovery


CmosPwdLilo PasswordChntpw for dos 



Security


Publications 



Misc


Mon CV (FR)PGP Public KeyEuro coinsRollerLinks 



Share

 










 This page was last edited on 23 July 2019, at 10:50.
Content is available under GNU Free Documentation License 1.2 unless otherwise noted.


About CGSecurity






",,"# photorec

> Deleted file recovery tool.
> It is recommended to write recovered files to a disk separate to the one being recovered from.
> More information: <https://www.cgsecurity.org/wiki/PhotoRec>.

- Run PhotoRec on a specific device:

`sudo photorec {{/dev/sdb}}`

- Run PhotoRec on a disk image (image.dd):

`sudo photorec {{path/to/image.dd}}`
"
scanimage,http://sane-project.org/man/scanimage.1.html,"

scanimage.1


scanimage.1



scanimage(1)             SANE Scanner Access Now Easy             scanimage(1)



NAME
       scanimage - scan an image



SYNOPSIS
       scanimage  [-d|--device-name  dev]  [--format format] [-i|--icc-profile
       profile]   [-L|--list-devices]   [-f|--formatted-device-list    format]
       [-b|--batch  [=format]]  [--batch-start  start]  [--batch-count  count]
       [--batch-increment  increment]   [--batch-double]   [--accept-md5-only]
       [-p|--progress]    [-o|--output-file]    [-n|--dont-scan]   [-T|--test]
       [-A|--all-options]   [-h|--help]    [-v|--verbose]    [-B|--buffer-size
       [=size]] [-V|--version] [device-specific-options]



DESCRIPTION
       scanimage  is  a  command-line  interface  to control image acquisition
       devices such as flatbed scanners or cameras.  The device is  controlled
       via  command-line  options.   After  command-line processing, scanimage
       normally proceeds to acquire an image.  The image data  is  written  to
       standard  output  in  one of the PNM (portable aNyMaP) formats (PBM for
       black-and-white images, PGM for grayscale images,  and  PPM  for  color
       images), TIFF format (black-and-white, grayscale or color), PNG format,
       or JPEG format (compression level 75).  scanimage accesses image acqui-
       sition devices through the SANE (Scanner Access Now Easy) interface and
       can thus support any device for which there exists a SANE backend  (try
       apropos sane- to get a list of available backends).



EXAMPLES
       To get a list of devices:

         scanimage -L

       To scan with default settings to the file image.pnm:

         scanimage >image.pnm

       To  scan 100x100 mm to the file image.tiff (-x and -y may not be avail-
       able with all devices):

         scanimage -x 100 -y 100 --format=tiff >image.tiff

       To print all available options:

         scanimage -h



OPTIONS
       Parameters are separated by a blank from single-character options (e.g.
       -d   epson)   and   by   a   ""=""  from  multi-character  options  (e.g.
       --device-name=epson).

       The -d or --device-name options must be followed by a SANE  device-name
       like  `epson:/dev/sg0'  or  `hp:/dev/usbscanner0'.  A (partial) list of
       available devices can be obtained with the --list-devices  option  (see
       below).   If  no device-name is specified explicitly, scanimage reads a
       device-name from the environment variable SANE_DEFAULT_DEVICE.  If this
       variable is not set, scanimage will attempt to open the first available
       device.

       The --format format option selects how image data is written  to  stan-
       dard  output or the file specified by the --output-file option.  format
       can be pnm, tiff, png, or jpeg.  If --format is not specified,  PNM  is
       written by default.

       The -i or --icc-profile option is used to include an ICC profile into a
       TIFF file.

       The -L or --list-devices option requests a (partial)  list  of  devices
       that are available.  The list is not complete since some devices may be
       available, but are not listed in any of the configuration files  (which
       are typically stored in directory /usr/local/etc/sane.d).  This is par-
       ticularly the case when accessing scanners through the network.   If  a
       device is not listed in a configuration file, the only way to access it
       is by its full device name.  You may need to consult your system admin-
       istrator to find out the names of such devices.

       The   -f   or   --formatted-device-list   option   works   similar   to
       --list-devices, but requires a format string.  scanimage  replaces  the
       placeholders %d %v %m %t %i %n with the device name, vendor name, model
       name, scanner type, an index number and newline respectively. The  com-
       mand

              scanimage  -f  ""  scanner number %i device %d is a %t, model %m,
              produced by %v ""

       will produce something like:

              scanner number 0  device sharp:/dev/sg1 is  a  flatbed  scanner,
              model JX250 SCSI, produced by SHARP

       The  --batch* options provide the features for scanning documents using
       document feeders.  --batch [format] is used to specify  the  format  of
       the  filename  that each page will be written to.  Each page is written
       out to a single file.  If format  is  not  specified,  the  default  of
       out%d.pnm  (or  out%d.tif for --format tiff, out%d.png for --format png
       or out%d.jpg for -- format jpeg) will be used.  This option  is  incom-
       patible  with  the  --output-path  option.  format is given as a printf
       style string with one integer parameter.  --batch-start  start  selects
       the  page  number  to  start  naming  files with. If this option is not
       given, the counter will start at 1.  --batch-count count specifies  the
       number  of pages to attempt to scan.  If not given, scanimage will con-
       tinue scanning until the scanner returns a state other  than  OK.   Not
       all  scanners  with  document feeders signal when the ADF is empty, use
       this command to work around them.  With --batch-increment increment you
       can  change  the  amount that the number in the filename is incremented
       by.  Generally this is used when you are  scanning  double-sided  docu-
       ments  on  a  single-sided document feeder.  A specific command is pro-
       vided to aid this: --batch-double will automatically set the  increment
       to  2.   --batch-prompt  will ask for pressing RETURN before scanning a
       page. This can be used for scanning multiple pages without an automatic
       document feeder.

       The  --accept-md5-only  option only accepts user authorization requests
       that support MD5 security. The SANE network daemon (saned)  is  capable
       of doing such requests. See saned(8).

       The  -p  or --progress option requests that scanimage prints a progress
       counter. It shows how much image data of the current image has  already
       been received by scanimage (in percent).

       The  -o or --output-file option requests that scanimage saves the scan-
       ning output to the given path. This option  is  incompatible  with  the
       --batch  option.  The  program will try to guess --format from the file
       name.  If that is not possible, it will  print  an  error  message  and
       exit.

       The  -n  or  --dont-scan  option  requests that scanimage only sets the
       options provided by the user but doesn't actually perform a scan.  This
       option can be used to e.g. turn off the scanner's lamp (if supported by
       the backend).

       The -T or --test option requests that scanimage performs a  few  simple
       sanity  tests to make sure the backend works as defined by the SANE API
       (in particular the sane_read function is exercised by this test).

       The -A or --all-options option requests that scanimage lists all avail-
       able options exposed the backend, including button options.  The infor-
       mation is printed on standard output and no scan will be done.

       The -h or --help options request help information.  The information  is
       printed on standard output and in this case, no attempt will be made to
       acquire an image.

       The -v or --verbose options increase the verbosity of the operation  of
       scanimage.   The option may be specified repeatedly, each time increas-
       ing the verbosity level.

       The -B option without argument changes the input buffer size  from  the
       default  32KB  to  1MB.   For finer grained control, use --buffer-size=
       followed by the number of KB.

       The -V or --version option requests that scanimage prints  the  program
       and  package  name, the version number of the SANE distribution that it
       came with and the version of the backend that it loads. Usually  that's
       the  dll  backend. If more information about the version numbers of the
       backends are necessary, the DEBUG variable for the dll backend  can  be
       used. Example: SANE_DEBUG_DLL=3 scanimage -L.

       As  you  might  imagine,  much of the power of scanimage comes from the
       fact that it can control any SANE backend.  Thus, the exact set of com-
       mand-line  options  depends on the capabilities of the selected device.
       To see the options for a device named dev, invoke scanimage via a  com-
       mand-line of the form:

              scanimage --help --device-name dev

       The  documentation for the device-specific options printed by --help is
       best explained with a few examples:

        -l 0..218mm [0]
           Top-left x position of scan area.

              The description above shows that option  -l  expects  an  option
              value in the range from 0 to 218 mm.  The value in square brack-
              ets indicates that the current option value is 0 mm. Most  back-
              ends  provide  similar  geometry options for top-left y position
              (-t), width (-x) and height of scan-area (-y).

        --brightness -100..100% [0]
           Controls the brightness of the acquired image.

              The description above shows that option --brightness expects  an
              option  value  in the range from -100 to 100 percent.  The value
              in square brackets indicates that the current option value is  0
              percent.

        --default-enhancements
           Set default values for enhancement controls.

              The  description  above shows that option --default-enhancements
              has no option value.  It should be thought of as having an imme-
              diate  effect  at  the  point  of  the  command-line at which it
              appears.  For example, since this option resets the --brightness
              option,  the  option-pair --brightness 50 --default-enhancements
              would effectively be a no-op.

        --mode Lineart|Gray|Color [Gray]
           Selects the scan mode (e.g., lineart or color).

              The description above shows that option --mode accepts an  argu-
              ment  that  must  be one of the strings Lineart, Gray, or Color.
              The value in the square bracket indicates  that  the  option  is
              currently set to Gray.  For convenience, it is legal to abbrevi-
              ate the string values as long as they remain unique.  Also,  the
              case  of  the spelling doesn't matter.  For example, option set-
              ting --mode col is identical to --mode Color.

        --custom-gamma[=(yes|no)] [inactive]
           Determines whether a builtin or a custom gamma-table
           should be used.

              The description above shows that option  --custom-gamma  expects
              either no option value, a ""yes"" string, or a ""no"" string.  Spec-
              ifying the option with no  value  is  equivalent  to  specifying
              ""yes"".   The  value in square-brackets indicates that the option
              is not currently active.  That is, attempting to set the  option
              would  result in an error message.  The set of available options
              typically depends on the settings of other options.   For  exam-
              ple,  the  --custom-gamma  table  might  be  active  only when a
              grayscale or color scan-mode has been requested.

              Note that the --help option is processed only  after  all  other
              options  have been processed.  This makes it possible to see the
              option settings for a particular mode by specifying  the  appro-
              priate  mode-options along with the --help option.  For example,
              the command-line:

              scanimage --help --mode color

              would print the option settings that  are  in  effect  when  the
              color-mode is selected.

        --gamma-table 0..255,...
           Gamma-correction table.  In color mode this option
           equally affects the red, green, and blue channels
           simultaneously (i.e., it is an intensity gamma table).

              The  description  above  shows that option --gamma-table expects
              zero or more values in the range 0 to 255.  For example, a legal
              value  for this option would be ""3,4,5,6,7,8,9,10,11,12"".  Since
              it's cumbersome to specify long vectors in this form,  the  same
              can  be  expressed  by  the abbreviated form ""[0]3-[9]12"".  What
              this means is that the first vector element is  set  to  3,  the
              9-th element is set to 12 and the values in between are interpo-
              lated linearly.  Of course, it is possible to  specify  multiple
              such  linear segments.  For example, ""[0]3-[2]3-[6]7,[7]10-[9]6""
              is   equivalent   to   ""3,3,3,4,5,6,7,10,8,6"".    The    program
              gamma4scanimage  can  be used to generate such gamma tables (see
              gamma4scanimage(1) for details).

        --filename <string> [/tmp/input.ppm]
           The filename of the image to be loaded.

              The description above is an example of an option that  takes  an
              arbitrary string value (which happens to be a filename).  Again,
              the value in brackets show that the option is current set to the
              filename /tmp/input.ppm.



ENVIRONMENT
       SANE_DEFAULT_DEVICE
              The default device-name.



FILES
       /usr/local/etc/sane.d
              This  directory holds various configuration files.  For details,
              please refer to the manual pages listed below.

       ~/.sane/pass
              This file contains lines of the form

              user:password:resource

              scanimage uses this information  to  answer  user  authorization
              requests  automatically.  The file must have 0600 permissions or
              stricter. You should use  this  file  in  conjunction  with  the
              --accept-md5-only  option  to  avoid  server-side  attacks.  The
              resource may contain any character but is limited to 127 charac-
              ters.



SEE ALSO
       sane(7),    gamma4scanimage(1),   xscanimage(1),   xcam(1),   xsane(1),
       scanadf(1), sane-dll(5), sane-net(5), sane-""backendname""(5)



AUTHOR
       David Mosberger, Andreas Beck, Gordon Matzigkeit, Caskey  Dickson,  and
       many  others.   For questions and comments contact the sane-devel mail-
       inglist (see http://www.sane-project.org/mailing-lists.html).



BUGS
       For vector options, the help output currently has no indication  as  to
       how many elements a vector-value should have.

                                  10 Jul 2008                     scanimage(1)



Man(1) output converted with
man2html


",,"# scanimage

> Scan images with the Scanner Access Now Easy API.
> More information: <http://sane-project.org/man/scanimage.1.html>.

- List available scanners to ensure the target device is connected and recognized:

`scanimage -L`

- Scan an image and save it to a file:

`scanimage --format={{pnm|tiff|png|jpeg}} > {{path/to/new_image}}`
"
mpstat,,,,"# mpstat

> Report CPU statistics.

- Display CPU statistics every 2 seconds:

`mpstat {{2}}`

- Display 5 reports, one by one, at 2 second intervals:

`mpstat {{2}} {{5}}`

- Display 5 reports, one by one, from a given processor, at 2 second intervals:

`mpstat -P {{0}} {{2}} {{5}}`
"
dbus-daemon,,,,"# dbus-daemon

> The D-Bus message daemon, allowing multiple programs to exchange messages.

- Run the daemon with a configuration file:

`dbus-daemon --config-file {{path/to/file}}`

- Run the daemon with the standard per-login-session message bus configuration:

`dbus-daemon --session`

- Run the daemon with the standard systemwide message bus configuration:

`dbus-daemon --system`

- Set the address to listen on and override the configuration value for it:

`dbus-daemon --address {{address}}`

- Output the process id to `stdout`:

`dbus-daemon --print-pid`

- Force the message bus to write to the system log for messages:

`dbus-daemon --syslog`
"
iostat,,,"
IOSTAT(8)		  BSD System Manager's Manual		     IOSTAT(8)

NAME
     iostat -- report I/O statistics

SYNOPSIS
     iostat [-CUdKIoT?] [-c count] [-n devs] [-w wait] [drives]

DESCRIPTION
     Iostat displays kernel I/O statistics on terminal, device and cpu opera-
     tions.  The first statistics that are printed are averaged over the sys-
     tem uptime.  To get information about the current activity, a suitable
     wait time should be specified, so that the subsequent sets of printed
     statistics will be averaged over that time.

     The options are as follows:

     -?    Display a usage statement and exit.

     -C    Display CPU statistics.  This is on by default, unless -d is speci-
	   fied.

     -c    Repeat the display count times.  If no wait interval is specified,
	   the default is 1 second.

     -d    Display only device statistics.  If this flag is turned on, only
	   device statistics will be displayed, unless -C or -U or -T is also
	   specfied to enable the display of CPU, load average or TTY statis-
	   tics.

     -I    Display total statstics for a given time period, rather than aver-
	   age statistics for each second during that time period.

     -K    In the blocks transferred display (-o), display block count in
	   kilobytes rather then the device native block size.

     -n    Display up to devs number of devices.  iostat will display fewer
	   devices if there aren't devs devices present.

     -o    Display old-style iostat device statistics.	Sectors per second,
	   transfers per second, and miliseconds per seek are displayed.  If
	   -I is specified, total blocks/sectors, total transfers, and
	   miliseconds per seek are displayed.

     -T    Display TTY statistics.  This is on by default, unless -d is speci-
	   fied.

     -U    Display system load averages.  This is on by default, unless -d is
	   specified.

     -w    Pause wait seconds between each display.  If no repeat count is
	   specified, the default is infinity.

     Iostat displays its information in the following format:

     tty
	   tin	   characters read from terminals
	   tout    characters written to terminals

     devices
	   Device operations.  The header of the field is the device name and
	   unit number.  iostat will display as many devices as will fit in a
	   standard 80 column screen, or the maximum number of devices in the
	   system, whichever is smaller.  If -n is specified on the command
	   line, iostat will display the smaller of the requested number of
	   devices, and the maximum number of devices in the system.  To force
	   iostat to display specific drives, their names may be supplied on
	   the command line.  iostat will not display more devices than will
	   fit in an 80 column screen, unless the -n argument is given on the
	   command line to specify a maximum number of devices to display, or
	   the list of specified devices exceeds 80 columns.  If fewer devices
	   are specified on the command line than will fit in an 80 column
	   screen, iostat will show only the specified devices.

	   The standard iostat device display shows the following statistics:

	   KB/t    kilobytes per transfer
	   tps	   transfers per second
	   MB/s    megabytes per second

	   The standard iostat device display, with the -I flag specified,
	   shows the following statistics:

	   KB/t    kilobytes per transfer
	   xfrs    total number of transfers
	   MB	   total number of megabytes transferred

	   The old-style iostat display (using -o) shows the following statis-
	   tics:

	   sps	   sectors transferred per second
	   tps	   transfers per second
	   msps    average milliseconds per transaction

	   The old-style iostat display, with the -I flag specified, shows the
	   following statistics:

	   blk	   total blocks/sectors transferred
	   xfr	   total transfers
	   msps    average milliseconds per transaction

     cpu
	   us	   % of cpu time in user mode
	   sy	   % of cpu time in system mode
	   id	   % of cpu time in idle mode

EXAMPLES
	   iostat -w 1 disk0 disk2

     Display statistics for the first and third disk devices device every sec-
     ond ad infinitum.

	   iostat -c 2

     Display the statistics for the first four devices in the system twice,
     with a one second display interval.

	   iostat -Iw 3

     Display total statistics every three seconds ad infinitum.

	   iostat -odICTw 2 -c 9

     Display total statistics using the old-style output format 9 times, with
     a two second interval between each measurement/display.  The -d flag gen-
     erally disables the TTY and CPU displays, but since the -T and -C flags
     are given, the TTY and CPU displays will be displayed.

SEE ALSO
     fstat(1), netstat(1), nfsstat(1), ps(1), pstat(8)

     The sections starting with ``Interpreting system activity'' in Installing
     and Operating 4.3BSD.

HISTORY
     This version of iostat first appeared in FreeBSD 3.0.

BSD			      September 27, 2001			   BSD
","# iostat

> Report statistics for devices and partitions.

- Display a report of CPU and disk statistics since system startup:

`iostat`

- Display a report of CPU and disk statistics with units converted to megabytes:

`iostat -m`

- Display CPU statistics:

`iostat -c`

- Display disk statistics with disk names (including LVM):

`iostat -N`

- Display extended disk statistics with disk names for device ""sda"":

`iostat -xN {{sda}}`

- Display incremental reports of CPU and disk statistics every 2 seconds:

`iostat {{2}}`
"
nethogs,,,,"# nethogs

> Monitor bandwidth usage per process.

- Start nethogs as root (default device is eth0):

`sudo nethogs`

- Monitor bandwidth on specific device:

`sudo nethogs {{device}}`

- Monitor bandwidth on multiple devices:

`sudo nethogs {{device1}} {{device2}}`

- Specify refresh rate:

`sudo nethogs -t {{seconds}}`
"
ldconfig,,,,"# ldconfig

> Configure symlinks and cache for shared library dependencies.

- Update symlinks and rebuild the cache (usually run when a new library is installed):

`sudo ldconfig`

- Update the symlinks for a given directory:

`sudo ldconfig -n {{path/to/directory}}`

- Print the libraries in the cache and check whether a given library is present:

`ldconfig -p | grep {{library_name}}`
"
f5fpc,,,,"# f5fpc

> A proprietry commercial SSL VPN client by BIG-IP Edge.

- Open a new VPN connection:

`sudo f5fpc --start`

- Open a new VPN connection to a specific host:

`sudo f5fpc --start --host {{host.example.com}}`

- Specify a username (user will be prompted for a password):

`sudo f5fpc --start --host {{host.example.com}} --username {{user}}`

- Show the current VPN status:

`sudo f5fpc --info`

- Shutdown the VPN connection:

`sudo f5fpc --stop`
"
vrms,https://debian.pages.debian.net/vrms/,"The Virtual Richard M. Stallman (vrms) package
In the early 1980's Richard M.
Stallman created the GNU project,
whose goal was to provide the world with a Free Operating System
(with the word ""Free"" with the same meaning as in ""Freedom"").
Since then, a lot of Free Software was developed and entire
operating systems based only on Free Software were
created.  Unfortunately, some data is still stored in a format
that is proprietary, secret and non-standard, made by corporations
that want to retain control over the users of the software that
generates such data.
This, of course, is meant to keep the users following the newer
versions of the software that ""control"" the users' data (so that
the users can still have access to their own creations).
Also, unfortunately, most of the time, the software for
manipulating such data is not Free in the sense desired by Richard
Stallman. Software that does not allow all the freedoms stipulated
by Richard Stallman is called non-free software.
The vrms program provides the facility for users
of Debian-based Operating
Systems (like, e.g., Ubuntu)
to detect if their systems have any non-free software installed,
so that the users can keep their installations only with software
that doesn't pose any legal problems.
The package is now maintained (on
Debian's salsa system) by
a team of developers including Bdale
Garbee (one of the original authors),
Rogério Brito and
Holger Levsen, with
the help of many contributers.
The source code is maintained with a version control system called
Git. Anybody can
obtain the source code for the vrms package from salsa.debian.org
and any collaboration is highly appreciated.
This page was made using Free Software
only.  Free Software is much more than zero-cost
software!
Last updated: 2018-10-15
by Holger Levsen.",,"# vrms

> Report non-free packages installed on Debian-based OSes.
> More information: <https://debian.pages.debian.net/vrms/>.

- List non-free and contrib packages (and their description):

`vrms`

- Only output the package names:

`vrms --sparse`
"
sv,,,,"# sv

> Control a running runsv service.

- Start a service:

`sudo sv up {{path/to/service}}`

- Stop a service:

`sudo sv down {{path/to/service}}`

- Get service status:

`sudo sv status {{path/to/service}}`
"
pkginfo,,,,"# pkginfo

> Query the package database on a CRUX system.

- List installed packages and their versions:

`pkginfo -i`

- List files owned by a package:

`pkginfo -l {{package_name}}`

- List the owner(s) of files matching a pattern:

`pkginfo -o {{pattern}}`

- Print the footprint of a file:

`pkginfo -f {{file}}`
"
netstat,,,"
NETSTAT(1)		  BSD General Commands Manual		    NETSTAT(1)

NAME
     netstat -- show network status

SYNOPSIS
     netstat [-AaLlnW] [-f address_family | -p protocol]
     netstat [-gilns] [-v] [-f address_family] [-I interface]
     netstat -i | -I interface [-w wait] [-c queue] [-abdgqRtS]
     netstat -s [-s] [-f address_family | -p protocol] [-w wait]
     netstat -i | -I interface -s [-f address_family | -p protocol]
     netstat -m [-m]
     netstat -r [-Aaln] [-f address_family]
     netstat -rs [-s]

DESCRIPTION
     The netstat command symbolically displays the contents of various net-
     work-related data structures.  There are a number of output formats,
     depending on the options for the information presented.  The first form
     of the command displays a list of active sockets for each protocol.  The
     second form presents the contents of one of the other network data struc-
     tures according to the option selected. Using the third form, with a wait
     interval specified, netstat will continuously display the information
     regarding packet traffic on the configured network interfaces.  The
     fourth form displays statistics for the specified protocol or address
     family. If a wait interval is specified, the protocol information over
     the last interval seconds will be displayed.  The fifth form displays
     per-interface statistics for the specified protocol or address family.
     The sixth form displays mbuf(9) statistics.  The seventh form displays
     routing table for the specified address family.  The eighth form displays
     routing statistics.

     The options have the following meaning:

     -A    With the default display, show the address of any protocol control
	   blocks associated with sockets and the flow hash; used for debug-
	   ging.

     -a    With the default display, show the state of all sockets; normally
	   sockets used by server processes are not shown. With the routing
	   table display (option -r, as described below), show protocol-cloned
	   routes (routes generated by a RTF_PRCLONING parent route); normally
	   these routes are not shown.

     -b    With the interface display (option -i, as described below), show
	   the number of bytes in and out.

     -c queue
	   With the queue statistics (option -q, as described below), show
	   only those for the specified queue.

     -d    With either interface display (option -i or an interval, as
	   described below), show the number of dropped packets.

     -f address_family
	   Limit statistics or address control block reports to those of the
	   specified address family.  The following address families are rec-
	   ognized: inet, for AF_INET, inet6, for AF_INET6 and unix, for
	   AF_UNIX.

     -g    Show information related to multicast (group address) membership.
	   If the -s option is also present, show extended interface group
	   management statistics.  If the -v option is specified, show link-
	   layer memberships; they are suppressed by default.  Source lists
	   for each group will also be printed.  Specifiying -v twice will
	   print the control plane timers for each interface and the source
	   list counters for each group.  If the -i is specified, only that
	   interface will be shown.  If the -f is specified, only information
	   for the address family will be displayed.

     -I interface
	   Show information about the specified interface; used with a wait
	   interval as described below.  If the -s option is present, show
	   per-interface protocol statistics on the interface for the speci-
	   fied address_family or protocol, or for all protocol families.

     -i    Show the state of interfaces which have been auto-configured
	   (interfaces statically configured into a system, but not located at
	   boot time are not shown).  If the -a options is also present, mul-
	   ticast addresses currently in use are shown for each Ethernet
	   interface and for each IP interface address.  Multicast addresses
	   are shown on separate lines following the interface address with
	   which they are associated.  If the -s option is present, show per-
	   interface statistics on all interfaces for the specified
	   address_family or protocol, or for all protocol families.

     -L    Show the size of the various listen queues.	The first count shows
	   the number of unaccepted connections.  The second count shows the
	   amount of unaccepted incomplete connections.  The third count is
	   the maximum number of queued connections.

     -l    Print full IPv6 address.

     -m    Show statistics recorded by the memory management routines (the
	   network stack manages a private pool of memory buffers). More
	   detailed information about the buffers, which includes their cache
	   related statistics, can be obtained by using -mm or -m -m option.

     -n    Show network addresses as numbers (normally netstat interprets
	   addresses and attempts to display them symbolically).  This option
	   may be used with any of the display formats.

     -p protocol
	   Show statistics about protocol, which is either a well-known name
	   for a protocol or an alias for it.  Some protocol names and aliases
	   are listed in the file /etc/protocols.  The special protocol name
	   ``bdg'' is used to show bridging statistics.  A null response typi-
	   cally means that there are no interesting numbers to report.  The
	   program will complain if protocol is unknown or if there is no sta-
	   tistics routine for it.

     -q    Show network interface send queue statistics.  By default all
	   queues are displayed, unless specified with -c.  This option
	   requires specifying an interface with -I option.  More detailed
	   information about the queues, which includes their queueing algo-
	   rithm related statistics, can be obtained by using -qq or -q -q
	   option.

     -r    Show the routing tables.  Use with -a to show protocol-cloned
	   routes.  When -s is also present, show routing statistics instead.
	   When -l is also present, netstat assumes more columns are there and
	   the maximum transmission unit.  More detailed information about the
	   route metrics are displayed with -ll for TCP round trip times -lll
	   for all metrics.  Use the -z flags to display only entries with
	   non-zero RTT values.  (``mtu'') are also displayed.

     -R    Show reachability information.  Use with -i to show link-layer
	   reachability information for a given interface.

     -s    Show per-protocol statistics.  If this option is repeated, counters
	   with a value of zero are suppressed.  For security reasons, root
	   privileges are required to read TCP statistics and in the absence
	   of such privileges all TCP counters will be reported as zero.

     -S    Show interface link status and interface state information about
	   the specified interface.  This option requires specifying an inter-
	   face with -I option.

     -v    Increase verbosity level.

     -W    In certain displays, avoid truncating addresses even if this causes
	   some fields to overflow.

     -w wait
	   Show network interface or protocol statistics at intervals of wait
	   seconds.

     -x    Show extended link-layer reachability information in addition to
	   that shown by the -R flag.

OUTPUT
     The default display, for active sockets, shows the local and remote
     addresses, send and receive queue sizes (in bytes), protocol, and the
     internal state of the protocol.  Address formats are of the form
     ``host.port'' or ``network.port'' if a socket's address specifies a net-
     work but no specific host address.  If known, the host and network
     addresses are displayed symbolically according to the databases
     /etc/hosts and /etc/networks, respectively.  If a symbolic name for an
     address is unknown, or if the -n option is specified, the address is
     printed numerically, according to the address family.  For more informa-
     tion regarding the Internet ``dot format'', refer to inet(3)).  Unspeci-
     fied, or ``wildcard'', addresses and ports appear as ``*''.

     Internet domain socket states:

     CLOSED:  The socket is not in use.

     LISTEN:  The socket is listening for incoming connections.  Unconnected
     listening sockets like these are only displayed when using the -a option.

     SYN_SENT:	The socket is actively trying to establish a connection to a
     remote peer.

     SYN_RCVD:	The socket has passively received a connection request from a
     remote peer.

     ESTABLISHED:  The socket has an established connection between a local
     application and a remote peer.

     CLOSE_WAIT:  The socket connection has been closed by the remote peer,
     and the system is waiting for the local application to close its half of
     the connection.

     LAST_ACK:	The socket connection has been closed by the remote peer, the
     local application has closed its half of the connection, and the system
     is waiting for the remote peer to acknowledge the close.

     FIN_WAIT_1:  The socket connection has been closed by the local
     application, the remote peer has not yet acknowledged the close, and the
     system is waiting for it to close its half of the connection.

     FIN_WAIT_2:  The socket connection has been closed by the local
     application, the remote peer has acknowledged the close, and the system
     is waiting for it to close its half of the connection.

     CLOSING:  The socket connection has been closed by the local application
     and the remote peer simultaneously, and the remote peer has not yet
     acknowledged the close attempt of the local application.

     TIME_WAIT:  The socket connection has been closed by the local
     application, the remote peer has closed its half of the connection, and
     the system is waiting to be sure that the remote peer received the last
     acknowledgement.

     The interface display provides a table of cumulative statistics regarding
     packets transferred, errors, and collisions.  The network addresses of
     the interface and the maximum transmission unit (``mtu'') are also dis-
     played.

     The routing table display indicates the available routes and their sta-
     tus.  Each route consists of a destination host or network and a gateway
     to use in forwarding packets.  The flags field shows a collection of
     information about the route stored as binary choices.  The individual
     flags are discussed in more detail in the route(8) and route(4) manual
     pages.  The mapping between letters and flags is:

     1	     RTF_PROTO1       Protocol specific routing flag #1
     2	     RTF_PROTO2       Protocol specific routing flag #2
     3	     RTF_PROTO3       Protocol specific routing flag #3
     B	     RTF_BLACKHOLE    Just discard packets (during updates)
     b	     RTF_BROADCAST    The route represents a broadcast address
     C	     RTF_CLONING      Generate new routes on use
     c	     RTF_PRCLONING    Protocol-specified generate new routes on use
     D	     RTF_DYNAMIC      Created dynamically (by redirect)
     G	     RTF_GATEWAY      Destination requires forwarding by intermediary
     H	     RTF_HOST	      Host entry (net otherwise)
     I	     RTF_IFSCOPE      Route is associated with an interface scope
     i	     RTF_IFREF	      Route is holding a reference to the interface
     L	     RTF_LLINFO       Valid protocol to link address translation
     M	     RTF_MODIFIED     Modified dynamically (by redirect)
     m	     RTF_MULTICAST    The route represents a multicast address
     R	     RTF_REJECT       Host or net unreachable
     r	     RTF_ROUTER       Host is a default router
     S	     RTF_STATIC       Manually added
     U	     RTF_UP	      Route usable
     W	     RTF_WASCLONED    Route was generated as a result of cloning
     X	     RTF_XRESOLVE     External daemon translates proto to link address
     Y	     RTF_PROXY	      Proxying; cloned routes will not be scoped

     Direct routes are created for each interface attached to the local host;
     the gateway field for such entries shows the address of the outgoing
     interface.  The refcnt field gives the current number of active uses of
     the route.  Connection oriented protocols normally hold on to a single
     route for the duration of a connection while connectionless protocols
     obtain a route while sending to the same destination.  The use field pro-
     vides a count of the number of packets sent using that route.  The inter-
     face entry indicates the network interface utilized for the route.  A
     route which is marked with the RTF_IFSCOPE flag is instantiated for the
     corresponding interface.  A cloning route which is marked with the
     RTF_PROXY flag will not generate new routes that are associated with its
     interface scope.

     When netstat is invoked with the -w option and a wait interval argument,
     it displays a running count of statistics related to network interfaces
     or protocols.  An obsolete version of this option used a numeric parame-
     ter with no option, and is currently supported for backward compatibil-
     ity.  By default, this display summarizes information for all interfaces.
     Information for a specific interface may be displayed with the -I option.

SEE ALSO
     nfsstat(1), ps(1), inet(4), unix(4), hosts(5), networks(5), protocols(5),
     route(8), services(5), iostat(8),

HISTORY
     The netstat command appeared in 4.2BSD.

     IPv6 support was added by WIDE/KAME project.

BUGS
     The notion of errors is ill-defined.

Darwin				 June 15, 2001				Darwin
","# netstat

> Displays network-related information such as open connections, open socket ports, etc.

- List all ports:

`netstat -a`

- List all listening ports:

`netstat -l`

- List listening TCP ports:

`netstat -t`

- Display PID and program names:

`netstat -p`

- List information continuously:

`netstat -c`

- List routes and do not resolve IP to hostname:

`netstat -rn`

- List listening TCP and UDP ports (+ user and process if you're root):

`netstat -lepunt`

- Print the routing table:

`netstat -nr`
"
xtrlock,,,,"# xtrlock

> Lock the X display until the user supplies their password.

- Lock the display and show a padlock instead of the cursor:

`xtrlock`

- Display a blank screen as well as the padlock cursor:

`xtrlock -b`

- Fork the xtrlock process and return immediately:

`xtrlock -f`
"
eject,,,,"# eject

> Eject cds, floppy disks and tape drives.

- Display the default device:

`eject -d`

- Eject the default device:

`eject`

- Eject a specific device (the default order is cd-rom, scsi, floppy and tape):

`eject {{/dev/cdrom}}`

- Toggle whether a device's tray is open or closed:

`eject -T {{/dev/cdrom}}`

- Eject a cd drive:

`eject -r {{/dev/cdrom}}`

- Eject a floppy drive:

`eject -f {{/mnt/floppy}}`

- Eject a tape drive:

`eject -q {{/mnt/tape}}`
"
a2dissite,https://manpages.debian.org/buster/apache2/a2dissite.8.en.html,"



a2dissite(8) — apache2 — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / apache2
     
     
     
     / a2dissite(8)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


EXIT STATUS


EXAMPLES


FILES


SEE ALSO


AUTHOR







other versions




buster 2.4.38-3+deb10u3


buster-backports 2.4.43-1~bpo10+1


testing 2.4.43-1


unstable 2.4.43-1






Scroll to navigation



A2ENSITE(8)
System Manager's Manual
A2ENSITE(8)




NAME¶
a2ensite, a2dissite - enable or disable an apache2 site / virtual host


SYNOPSIS¶
a2ensite [ [-q|--quiet] site]
a2dissite [ [-q|--quiet] site]


DESCRIPTION¶
This manual page documents briefly the a2ensite and a2dissite
  commands.
a2ensite is a script that enables the specified site (which
    contains a <VirtualHost> block) within the apache2
    configuration. It does this by creating symlinks within
    /etc/apache2/sites-enabled. Likewise, a2dissite disables a
    site by removing those symlinks. It is not an error to enable a site which
    is already enabled, or to disable one which is already disabled.
Apache treats the very first virtual host enabled specially as
    every request not matching any actual directive is being redirected there.
    Thus it should be called 000-default in order to sort before the
    remaining hosts to be loaded first.


OPTIONS¶

-q, --quiet
Don't show informative messages.
-m, --maintmode
Enables the maintainer mode, that is the program invocation is effectuated
      automatically by a maintainer script. This switch should not be used by
      end users.
-p, --purge
When disabling a module, purge all traces of the module in the internal
      state data base.



EXIT STATUS¶
a2ensite and a2dissite exit with status 0 if all sites are
  processed successfully, 1 if errors occur, 2 if an invalid option was used.


EXAMPLES¶
a2dissite 000-default
Disables the default site.


FILES¶

/etc/apache2/sites-available
Directory with files giving information on available sites.
/etc/apache2/sites-enabled
Directory with links to the files in sites-available for enabled
      sites.



SEE ALSO¶
apache2ctl(8).


AUTHOR¶
This manual page was written by Stefan Fritsch <sf@debian.org> (based on
  the a2enmod manual page by Daniel Stone <daniel@sfarc.net>) for the
  Debian GNU/Linux distribution.




8 June 2007










Source file:


a2dissite.8.en.gz (from apache2 2.4.38-3+deb10u3)




Source last updated:


2019-04-07T18:15:40Z




Converted to HTML:


2020-08-08T10:05:57Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# a2dissite

> Disable an Apache virtual host on Debian-based OSes.
> More information: <https://manpages.debian.org/buster/apache2/a2dissite.8.en.html>.

- Disable a virtual host:

`sudo a2dissite {{virtual_host}}`

- Don't show informative messages:

`sudo a2dissite --quiet {{virtual_host}}`
"
create_ap,,,,"# create_ap

> Create an AP (Access Point) at any channel.

- Create an open network with no passphrase:

`create_ap {{wlan0}} {{eth0}} {{access_point_ssid}}`

- Use a WPA + WPA2 passphrase:

`create_ap {{wlan0}} {{eth0}} {{access_point_ssid}} {{passphrase}}`

- Create an access point without Internet sharing:

`create_ap -n {{wlan0}} {{acces_point_ssid}} {{passphrase}}`

- Create a bridged network with Internet sharing:

`create_ap -m bridge {{wlan0}} {{eth0}} {{access_point_ssid}} {{passphrase}}`

- Create a bridged network with Internet sharing and a pre-configured bridge interface:

`create_ap -m bridge {{wlan0}} {{br0}} {{access_point_ssid}} {{passphrase}}`

- Create an access port for Internet sharing from the same WiFi interface:

`create_ap {{wlan0}} {{wlan0}} {{access_point_ssid}} {{passphrase}}`

- Choose a different WiFi adapter driver:

`create_ap --driver {{wifi_adapter}} {{wlan0}} {{eth0}} {{access_point_ssid}} {{passphrase}}`
"
vgs,https://man7.org/linux/man-pages/man8/vgs.8.html,"




vgs(8) - Linux manual page









man7.org > Linux > man-pages



Linux/UNIX system programming training






vgs(8) — Linux manual page




NAME | SYNOPSIS | DESCRIPTION | USAGE | OPTIONS | VARIABLES | ENVIRONMENT VARIABLES | NOTES | SEE ALSO | COLOPHON













 



VGS(8)                     System Manager's Manual                    VGS(8)

NAME          top
       vgs - Display information about volume groups

SYNOPSIS          top
       vgs
           [ option_args ]
           [ position_args ]

DESCRIPTION          top
       vgs produces formatted output about VGs.

USAGE          top
       vgs
           [ -a|--all ]
           [ -o|--options String ]
           [ -S|--select String ]
           [ -O|--sort String ]
           [    --aligned ]
           [    --binary ]
           [    --configreport log|vg|lv|pv|pvseg|seg ]
           [    --foreign ]
           [    --ignorelockingfailure ]
           [    --logonly ]
           [    --nameprefixes ]
           [    --noheadings ]
           [    --nosuffix ]
           [    --readonly ]
           [    --reportformat basic|json ]
           [    --rows ]
           [    --separator String ]
           [    --shared ]
           [    --unbuffered ]
           [    --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E ]
           [    --unquoted ]
           [ COMMON_OPTIONS ]
           [ VG|Tag ... ]

       Common options for lvm:
           [ -d|--debug ]
           [ -h|--help ]
           [ -q|--quiet ]
           [ -t|--test ]
           [ -v|--verbose ]
           [ -y|--yes ]
           [    --commandprofile String ]
           [    --config String ]
           [    --driverloaded y|n ]
           [    --lockopt String ]
           [    --longhelp ]
           [    --nolocking ]
           [    --profile String ]
           [    --version ]

OPTIONS          top
       --aligned
              Use with --separator to align the output columns

       -a|--all
              List all VGs. Equivalent to not specifying any VGs.

       --binary
              Use binary values ""0"" or ""1"" instead of descriptive literal
              values for columns that have exactly two valid values to
              report (not counting the ""unknown"" value which denotes that
              the value could not be determined).

       --commandprofile String
              The command profile to use for command configuration.  See
              lvm.conf(5) for more information about profiles.

       --config String
              Config settings for the command. These override lvm.conf
              settings.  The String arg uses the same format as lvm.conf, or
              may use section/field syntax.  See lvm.conf(5) for more
              information about config.

       --configreport log|vg|lv|pv|pvseg|seg
              See lvmreport(7).

       -d|--debug ...
              Set debug level. Repeat from 1 to 6 times to increase the
              detail of messages sent to the log file and/or syslog (if
              configured).

       --driverloaded y|n
              If set to no, the command will not attempt to use device-
              mapper.  For testing and debugging.

       --foreign
              Report/display foreign VGs that would otherwise be skipped.
              See lvmsystemid(7) for more information about foreign VGs.

       -h|--help
              Display help text.

       --ignorelockingfailure
              Allows a command to continue with read-only metadata
              operations after locking failures.

       --lockopt String
              Used to pass options for special cases to lvmlockd.  See
              lvmlockd(8) for more information.

       --logonly
              Suppress command report and display only log report.

       --longhelp
              Display long help text.

       --nameprefixes
              Add an ""LVM2_"" prefix plus the field name to the output.
              Useful with --noheadings to produce a list of field=value
              pairs that can be used to set environment variables (for
              example, in udev rules).

       --noheadings
              Suppress the headings line that is normally the first line of
              output.  Useful if grepping the output.

       --nolocking
              Disable locking.

       --nosuffix
              Suppress the suffix on output sizes. Use with --units (except
              h and H) if processing the output.

       -o|--options String
              Comma-separated, ordered list of fields to display in columns.
              String arg syntax is: [+|-|#]Field1[,Field2 ...]  The prefix +
              will append the specified fields to the default fields, - will
              remove the specified fields from the default fields, and #
              will compact specified fields (removing them when empty for
              all rows.)  Use -o help to view the list of all available
              fields.  Use separate lists of fields to add, remove or
              compact by repeating the -o option: -o+field1,field2 -o-
              field3,field4 -o#field5.  These lists are evaluated from left
              to right.  Use field name lv_all to view all LV fields, vg_all
              all VG fields, pv_all all PV fields, pvseg_all all PV segment
              fields, seg_all all LV segment fields, and pvseg_all all PV
              segment columns.  See the lvm.conf report section for more
              config options.  See lvmreport(7) for more information about
              reporting.

       --profile String
              An alias for --commandprofile or --metadataprofile, depending
              on the command.

       -q|--quiet ...
              Suppress output and log messages. Overrides --debug and
              --verbose.  Repeat once to also suppress any prompts with
              answer 'no'.

       --readonly
              Run the command in a special read-only mode which will read
              on-disk metadata without needing to take any locks. This can
              be used to peek inside metadata used by a virtual machine
              image while the virtual machine is running. No attempt will be
              made to communicate with the device-mapper kernel driver, so
              this option is unable to report whether or not LVs are
              actually in use.

       --reportformat basic|json
              Overrides current output format for reports which is defined
              globally by the report/output_format setting in lvm.conf.
              basic is the original format with columns and rows.  If there
              is more than one report per command, each report is prefixed
              with the report name for identification. json produces report
              output in JSON format. See lvmreport(7) for more information.

       --rows
              Output columns as rows.

       -S|--select String
              Select objects for processing and reporting based on specified
              criteria.  The criteria syntax is described by --select help
              and lvmreport(7).  For reporting commands, one row is
              displayed for each object matching the criteria.  See
              --options help for selectable object fields.  Rows can be
              displayed with an additional ""selected"" field (-o selected)
              showing 1 if the row matches the selection and 0 otherwise.
              For non-reporting commands which process LVM entities, the
              selection is used to choose items to process.

       --separator String
              String to use to separate each column. Useful if grepping the
              output.

       --shared
              Report/display shared VGs that would otherwise be skipped when
              lvmlockd is not being used on the host.  See lvmlockd(8) for
              more information about shared VGs.

       -O|--sort String
              Comma-separated ordered list of columns to sort by. Replaces
              the default selection. Precede any column with - for a reverse
              sort on that column.

       -t|--test
              Run in test mode. Commands will not update metadata.  This is
              implemented by disabling all metadata writing but nevertheless
              returning success to the calling function. This may lead to
              unusual error messages in multi-stage operations if a tool
              relies on reading back metadata it believes has changed but
              hasn't.

       --unbuffered
              Produce output immediately without sorting or aligning the
              columns properly.

       --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E
              All sizes are output in these units: human-(r)eadable with '<'
              rounding indicator, (h)uman-readable, (b)ytes, (s)ectors,
              (k)ilobytes, (m)egabytes, (g)igabytes, (t)erabytes,
              (p)etabytes, (e)xabytes.  Capitalise to use multiples of 1000
              (S.I.) instead of 1024.  Custom units can be specified, e.g.
              --units 3M.

       --unquoted
              When used with --nameprefixes, output values in the
              field=value pairs are not quoted.

       -v|--verbose ...
              Set verbose level. Repeat from 1 to 4 times to increase the
              detail of messages sent to stdout and stderr.

       --version
              Display version information.

       -y|--yes
              Do not prompt for confirmation interactively but always assume
              the answer yes. Use with extreme caution.  (For automatic no,
              see -qq.)

VARIABLES          top
       VG
              Volume Group name.  See lvm(8) for valid names.

       Tag
              Tag name.  See lvm(8) for information about tag names and
              using tags in place of a VG, LV or PV.

       String
              See the option description for information about the string
              content.

       Size[UNIT]
              Size is an input number that accepts an optional unit.  Input
              units are always treated as base two values, regardless of
              capitalization, e.g. 'k' and 'K' both refer to 1024.  The
              default input unit is specified by letter, followed by |UNIT.
              UNIT represents other possible input units: bBsSkKmMgGtTpPeE.
              b|B is bytes, s|S is sectors of 512 bytes, k|K is kilobytes,
              m|M is megabytes, g|G is gigabytes, t|T is terabytes, p|P is
              petabytes, e|E is exabytes.  (This should not be confused with
              the output control --units, where capital letters mean
              multiple of 1000.)

ENVIRONMENT VARIABLES          top
       See lvm(8) for information about environment variables used by lvm.
       For example, LVM_VG_NAME can generally be substituted for a required
       VG parameter.

NOTES          top
       The vg_attr bits are:

       1  Permissions: (w)riteable, (r)ead-only

       2  Resi(z)eable

       3  E(x)ported

       4  (p)artial: one or more physical volumes belonging to the volume
          group are missing from the system

       5  Allocation policy: (c)ontiguous, c(l)ing, (n)ormal, (a)nywhere

       6  (c)lustered, (s)hared

SEE ALSO          top
       lvm(8) lvm.conf(5) lvmconfig(8)

       pvchange(8) pvck(8) pvcreate(8) pvdisplay(8) pvmove(8) pvremove(8)
       pvresize(8) pvs(8) pvscan(8)

       vgcfgbackup(8) vgcfgrestore(8) vgchange(8) vgck(8) vgcreate(8)
       vgconvert(8) vgdisplay(8) vgexport(8) vgextend(8) vgimport(8)
       vgimportclone(8) vgmerge(8) vgmknodes(8) vgreduce(8) vgremove(8)
       vgrename(8) vgs(8) vgscan(8) vgsplit(8)

       lvcreate(8) lvchange(8) lvconvert(8) lvdisplay(8) lvextend(8)
       lvreduce(8) lvremove(8) lvrename(8) lvresize(8) lvs(8) lvscan(8)

       lvm-fullreport(8) lvm-lvpoll(8) lvm2-activation-generator(8)
       blkdeactivate(8) lvmdump(8)

       dmeventd(8) lvmpolld(8) lvmlockd(8) lvmlockctl(8) cmirrord(8)
       lvmdbusd(8)

       lvmsystemid(7) lvmreport(7) lvmraid(7) lvmthin(7) lvmcache(7)

COLOPHON          top
       This page is part of the lvm2 (Logical Volume Manager 2) project.
       Information about the project can be found at 
       â¨http://www.sourceware.org/lvm2/â©.  If you have a bug report for this
       manual page, see â¨https://github.com/lvmteam/lvm2/issuesâ©.  This page
       was obtained from the tarball
       https://github.com/lvmteam/lvm2/archive/v2_03_10.tar.gz fetched from
       â¨https://github.com/lvmteam/lvm2/releasesâ© on 2020-08-13.  If you
       discover any rendering problems in this HTML version of the page, or
       you believe there is a better or more up-to-date source for the page,
       or you have corrections or improvements to the information in this
       COLOPHON (which is not part of the original manual page), send a mail
       to man-pages@man7.org

Red Hat, Inc.         LVM TOOLS 2.03.10(2) (2020-08-09)               VGS(8)


Pages that refer to this page: 
    lvmreport(7),  
    lvmsystemid(7),  
    fullreport(8),  
    lvchange(8),  
    lvconvert(8),  
    lvcreate(8),  
    lvdisplay(8),  
    lvextend(8),  
    lvm(8),  
    lvm-config(8),  
    lvmconfig(8),  
    lvmdiskscan(8),  
    lvm-dumpconfig(8),  
    lvm-fullreport(8),  
    lvm-lvpoll(8),  
    lvpoll(8),  
    lvreduce(8),  
    lvremove(8),  
    lvrename(8),  
    lvresize(8),  
    lvs(8),  
    lvscan(8),  
    pvchange(8),  
    pvck(8),  
    pvcreate(8),  
    pvdisplay(8),  
    pvmove(8),  
    pvremove(8),  
    pvresize(8),  
    pvs(8),  
    pvscan(8),  
    vgcfgbackup(8),  
    vgcfgrestore(8),  
    vgchange(8),  
    vgck(8),  
    vgconvert(8),  
    vgcreate(8),  
    vgdisplay(8),  
    vgexport(8),  
    vgextend(8),  
    vgimport(8),  
    vgimportclone(8),  
    vgmerge(8),  
    vgmknodes(8),  
    vgreduce(8),  
    vgremove(8),  
    vgrename(8),  
    vgs(8),  
    vgscan(8),  
    vgsplit(8)








            HTML rendering created 2020-08-13
            by Michael Kerrisk, 
            author of 
            The Linux Programming Interface, 
            maintainer of the 
            Linux man-pages project.
        

            For details of in-depth
            Linux/UNIX system programming training courses
            that I teach, look here.
        

            Hosting by jambit GmbH.
        



























",,"# vgs

> Display information about LVM volume groups.
> More information: https://man7.org/linux/man-pages/man8/vgs.8.html .

- Display information about volume groups:

`vgs`

- Display all volume groups:

`vgs -a`

- Change default display to show more details:

`vgs -v`

- Display only specific fields:

`vgs -o {{field_name_1}},{{field_name_2}}`

- Append field to default display:

`vgs -o +{{field_name}}`

- Suppress heading line:

`vgs --noheadings`

- Use separator to separate fields:

`vgs --separator =`
"
ifdown,,,,"# ifdown

> Disable network interfaces.

- Disable interface eth0:

`ifdown {{eth0}}`

- Disable all interfaces which are enabled:

`ifdown -a`
"
rtorrent,,,,"# rtorrent

> Download torrents over the command line.

- Add a torrent file or magnet to be downloaded:

`rtorrent {{torrent_or_magnet}}`

- Start the download:

`<Ctrl>S`

- View details about downloading torrent:

`->`

- Close rtorrent safely:

`<Ctrl>Q`
"
trap,,,"
BUILTIN(1)		  BSD General Commands Manual		    BUILTIN(1)

NAME
     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,
     breaksw, builtins, case, cd, chdir, command, complete, continue, default,
     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,
     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,
     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,
     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,
     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,
     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,
     telltc, test, then, time, times, trap, true, type, ulimit, umask,
     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,
     where, which, while -- shell built-in commands

SYNOPSIS
     builtin [-options] [args ...]

DESCRIPTION
     Shell builtin commands are commands that can be executed within the run-
     ning shell's process.  Note that, in the case of csh(1) builtin commands,
     the command is executed in a subshell if it occurs as any component of a
     pipeline except the last.

     If a command specified to the shell contains a slash ``/'', the shell
     will not execute a builtin command, even if the last component of the
     specified command matches the name of a builtin command.  Thus, while
     specifying ``echo'' causes a builtin command to be executed under shells
     that support the echo builtin command, specifying ``/bin/echo'' or
     ``./echo'' does not.

     While some builtin commands may exist in more than one shell, their oper-
     ation may be different under each shell which supports them.  Below is a
     table which lists shell builtin commands, the standard shells that sup-
     port them and whether they exist as standalone utilities.

     Only builtin commands for the csh(1) and sh(1) shells are listed here.
     Consult a shell's manual page for details on the operation of its builtin
     commands.	Beware that the sh(1) manual page, at least, calls some of
     these commands ``built-in commands'' and some of them ``reserved words''.
     Users of other shells may need to consult an info(1) page or other
     sources of documentation.

     Commands marked ``No**'' under External do exist externally, but are
     implemented as scripts using a builtin command of the same name.

	   Command	 External    csh(1)    sh(1)
	   !		 No	     No        Yes
	   %		 No	     Yes       No
	   .		 No	     No        Yes
	   :		 No	     Yes       Yes
	   @		 No	     Yes       Yes
	   {		 No	     No        Yes
	   }		 No	     No        Yes
	   alias	 No**	     Yes       Yes
	   alloc	 No	     Yes       No
	   bg		 No**	     Yes       Yes
	   bind 	 No	     No        Yes
	   bindkey	 No	     Yes       No
	   break	 No	     Yes       Yes
	   breaksw	 No	     Yes       No
	   builtin	 No	     No        Yes
	   builtins	 No	     Yes       No
	   case 	 No	     Yes       Yes
	   cd		 No**	     Yes       Yes
	   chdir	 No	     Yes       Yes
	   command	 No**	     No        Yes
	   complete	 No	     Yes       No
	   continue	 No	     Yes       Yes
	   default	 No	     Yes       No
	   dirs 	 No	     Yes       No
	   do		 No	     No        Yes
	   done 	 No	     No        Yes
	   echo 	 Yes	     Yes       Yes
	   echotc	 No	     Yes       No
	   elif 	 No	     No        Yes
	   else 	 No	     Yes       Yes
	   end		 No	     Yes       No
	   endif	 No	     Yes       No
	   endsw	 No	     Yes       No
	   esac 	 No	     No        Yes
	   eval 	 No	     Yes       Yes
	   exec 	 No	     Yes       Yes
	   exit 	 No	     Yes       Yes
	   export	 No	     No        Yes
	   false	 Yes	     No        Yes
	   fc		 No**	     No        Yes
	   fg		 No**	     Yes       Yes
	   filetest	 No	     Yes       No
	   fi		 No	     No        Yes
	   for		 No	     No        Yes
	   foreach	 No	     Yes       No
	   getopts	 No**	     No        Yes
	   glob 	 No	     Yes       No
	   goto 	 No	     Yes       No
	   hash 	 No	     No        Yes
	   hashstat	 No	     Yes       No
	   history	 No	     Yes       No
	   hup		 No	     Yes       No
	   if		 No	     Yes       Yes
	   jobid	 No	     No        Yes
	   jobs 	 No**	     Yes       Yes
	   kill 	 Yes	     Yes       No
	   limit	 No	     Yes       No
	   local	 No	     No        Yes
	   log		 No	     Yes       No
	   login	 Yes	     Yes       No
	   logout	 No	     Yes       No
	   ls-F 	 No	     Yes       No
	   nice 	 Yes	     Yes       No
	   nohup	 Yes	     Yes       No
	   notify	 No	     Yes       No
	   onintr	 No	     Yes       No
	   popd 	 No	     Yes       No
	   printenv	 Yes	     Yes       No
	   pushd	 No	     Yes       No
	   pwd		 Yes	     No        Yes
	   read 	 No**	     No        Yes
	   readonly	 No	     No        Yes
	   rehash	 No	     Yes       No
	   repeat	 No	     Yes       No
	   return	 No	     No        Yes
	   sched	 No	     Yes       No
	   set		 No	     Yes       Yes
	   setenv	 No	     Yes       No
	   settc	 No	     Yes       No
	   setty	 No	     Yes       No
	   setvar	 No	     No        Yes
	   shift	 No	     Yes       Yes
	   source	 No	     Yes       No
	   stop 	 No	     Yes       No
	   suspend	 No	     Yes       No
	   switch	 No	     Yes       No
	   telltc	 No	     Yes       No
	   test 	 Yes	     No        Yes
	   then 	 No	     No        Yes
	   time 	 Yes	     Yes       No
	   times	 No	     No        Yes
	   trap 	 No	     No        Yes
	   true 	 Yes	     No        Yes
	   type 	 No	     No        Yes
	   ulimit	 No	     No        Yes
	   umask	 No**	     Yes       Yes
	   unalias	 No**	     Yes       Yes
	   uncomplete	 No	     Yes       No
	   unhash	 No	     Yes       No
	   unlimit	 No	     Yes       No
	   unset	 No	     Yes       Yes
	   unsetenv	 No	     Yes       No
	   until	 No	     No        Yes
	   wait 	 No**	     Yes       Yes
	   where	 No	     Yes       No
	   which	 Yes	     Yes       No
	   while	 No	     Yes       Yes

SEE ALSO
     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),
     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)

HISTORY
     The builtin manual page first appeared in FreeBSD 3.4.

AUTHORS
     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.

BSD			       February 23, 2005			   BSD
","# trap

> Automatically execute commands after receiving signals by processes or the operating system.
> Can be used to perform cleanups for interruptions by the user or other actions.

- List available signals to set traps for:

`trap -l`

- List active traps for the current shell:

`trap -p`

- Set a trap to execute commands when one or more signals are detected:

`trap 'echo ""Caught signal {{SIGHUP}}""' {{SIGHUP}}`

- Remove active traps:

`trap - {{SIGHUP}} {{SIGINT}}`
"
fstrim,,,,"# fstrim

> Discard unused blocks on a mounted filesystem.
> Only supported by flash memory devices such as SSDs and microSD cards.

- Trim unused blocks on all mounted partitions that support it:

`sudo fstrim --all`

- Trim unused blocks on a specified partition:

`sudo fstrim {{/}}`

- Display statistics after trimming:

`sudo fstrim --verbose {{/}}`
"
ifup,,,,"# ifup

> Tool used to enable network interfaces.

- Enable interface eth0:

`ifup {{eth0}}`

- Enable all the interfaces defined with ""auto"" in /etc/network/interfaces:

`ifup -a`
"
speedometer,http://excess.org/speedometer,,,"# speedometer

> Python script that shows a network traffic graph in the terminal.
> More information: <http://excess.org/speedometer>.

- Show graph for a specific interface:

`speedometer -r {{eth0}} -t {{eth0}}`
"
phar,,,"PHAR(1) 			 User Commands			       PHAR(1)



NAME
       phar, phar.phar - PHAR (PHP archive) command line tool

SYNOPSIS
       phar <command> [options] ...


DESCRIPTION
       The PHAR file format provides a way to put entire PHP applications into
       a single file called a ""phar"" (PHP Archive) for easy  distribution  and
       installation.

       With the phar command you can create, update or extract PHP archives.

       Commands: add compress delete extract help help-list info list meta-del
       meta-get meta-set pack sign stub-get stub-set tree version


add command
       Add entries to a PHAR package.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       ...	      Any number of input files and directories. If -i	is  in
		      use  then  ONLY  files  and  matching  the given regular
		      expression are being packed. If -x is given  then  files
		      matching that regular expression are NOT being packed.

       Optional arguments:

       -a alias       Provide an alias name for the phar file.

       -c algo	      Compression algorithm (see COMPRESSION )

       -i regex       Specifies a regular expression for input files.

       -l level       Number  of  preceding  subdirectories to strip from file
		      entries

       -x regex       Regular expression for input files to exclude.


compress command
       Compress or uncompress all files or a selected entry.

       Required arguments:

       -c algo	      Compression algorithm (see COMPRESSION )

       -f file	      Specifies the phar file to work on.

       Optional arguments:

       -e entry       Name of entry to work on	(must  include	PHAR  internal
		      directory name if any).


delete command
       Delete entry from a PHAR archive

       Required arguments:

       -e entry       Name  of	entry  to  work on (must include PHAR internal
		      directory name if any).

       -f file	      Specifies the phar file to work on.


extract command
       Extract a PHAR package to a directory.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       Optional arguments:

       -i regex       Specifies a regular expression for input files.

       -x regex       Regular expression for input files to exclude.

       ...	      Directory to extract to (defaults to '.').



help command
       This help or help for a selected command.

       Optional arguments:

       ...	      Optional command to retrieve help for.


help-list command
       Lists available commands.


info command
       Get information about a PHAR package.

       By using -k it is possible to return a single value.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       Optional arguments:

       -k index       Subscription index to work on.


list command
       List contents of a PHAR archive.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       Optional arguments:

       -i regex       Specifies a regular expression for input files.

       -x regex       Regular expression for input files to exclude.



meta-del command
       Delete meta information of a PHAR entry or a PHAR package.

       If -k is given then the metadata is expected to be  an  array  and  the
       given index is being deleted.

       If something was deleted the return value is 0 otherwise it is 1.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       Optional arguments:

       -e entry       Name  of	entry  to  work on (must include PHAR internal
		      directory name if any).

       -k index       Subscription index to work on.


meta-get command
       Get meta information of a PHAR entry or a PHAR  package	in  serialized
       from. If no output file is specified for meta data then stdout is being
       used.  You can also specify a particular index using -k. In  that  case
       the  metadata  is  expected  to	be an array and the value of the given
       index is returned using echo rather than using serialize. If that index
       does not exist or no meta data is present then the return value is 1.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       Optional arguments:

       -e entry       Name  of	entry  to  work on (must include PHAR internal
		      directory name if any).

       -k index       Subscription index to work on.


meta-set command
       Set meta data of a PHAR entry or a PHAR package using serialized input.
       If  no  input file is specified for meta data then stdin is being used.
       You can also specify a particular index using  -k.  In  that  case  the
       metadata is expected to be an array and the value of the given index is
       being set.  If the metadata is not present or empty a new array will be
       created.   If  the metadata is present and a flat value then the return
       value is 1. Also using -k the input is been taken directly rather  then
       being serialized.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       -m meta	      Meta data to store with entry (serialized php data).

       Optional arguments:

       -e entry       Name  of	entry  to  work on (must include PHAR internal
		      directory name if any).

       -k index       Subscription index to work on.


pack command
       Pack files into a PHAR archive.

       When using -s <stub>, then the stub file is  being  excluded  from  the
       list  of input files/dirs.To create an archive that contains PEAR class
       PHP_Archive then point -p argument to PHP/Archive.php.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       ...	      Any number of input files and directories. If -i	is  in
		      use  then  ONLY  files  and  matching  the given regular
		      expression are being packed. If -x is given  then  files
		      matching that regular expression are NOT being packed.

       Optional arguments:

       -a alias       Provide an alias name for the phar file.

       -b bang	      Hash-bang    line    to	 start	 the   archive	 (e.g.
		      #!/usr/bin/php).	The hash mark itself '#!' and the new-
		      line character are optional.

       -c algo	      Compression algorithm (see COMPRESSION )

       -h hash	      Selects the hash algorithm (see HASH )

       -i regex       Specifies a regular expression for input files.

       -l level       Number  of  preceding  subdirectories to strip from file
		      entries

       -p loader      Location of  PHP_Archive	class  file  (pear  list-files
		      PHP_Archive).You	can  use '0' or '1' to locate it auto-
		      matically using the mentioned pear command.  When  using
		      '0'  the	command does not error out when the class file
		      cannot be located.  This	switch	also  adds  some  code
		      around  the  stub  so that class PHP_Archive gets regis-
		      tered  as  phar://  stream  wrapper  if  necessary.  And
		      finally this switch will add the file phar.inc from this
		      package and load it to ensure class Phar is present.

       -s stub	      Select the stub file.

       -x regex       Regular expression for input files to exclude.

       -y key	      Private key for OpenSSL signing.


sign command
       Set signature hash algorithm.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       -h hash	      Selects the hash algorithm (see HASH )

       Optional arguments:

       -y key	      Private key for OpenSSL signing.


stub-get command
       Get the stub of a PHAR file. If no output file  is  specified  as  stub
       then stdout is being used.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       Optional arguments:

       -s stub	      Select the stub file.


stub-set command
       Set the stub of a PHAR file. If no input file is specified as stub then
       stdin is being used.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       Optional arguments:

       -b bang	      Hash-bang   line	 to   start    the    archive	 (e.g.
		      #!/usr/bin/php).	The hash mark itself '#!' and the new-
		      line character are optional.

       -p loader      Location of  PHP_Archive	class  file  (pear  list-files
		      PHP_Archive).You	can  use '0' or '1' to locate it auto-
		      matically using the mentioned pear command.  When  using
		      '0'  the	command does not error out when the class file
		      cannot be located.  This	switch	also  adds  some  code
		      around  the  stub  so that class PHP_Archive gets regis-
		      tered  as  phar://  stream  wrapper  if  necessary.  And
		      finally this switch will add the file phar.inc from this
		      package and load it to ensure class Phar is present.

       -s stub	      Select the stub file.



tree command
       Get a directory tree for a PHAR archive.

       Required arguments:

       -f file	      Specifies the phar file to work on.

       Optional arguments:

       -i regex       Specifies a regular expression for input files.

       -x regex       Regular expression for input files to exclude.


version command
       Get information about the PHAR environment and the tool version.



COMPRESSION
       Algorithms:

       0	      No compression

       none	      No compression

       auto	      Automatically select compression algorithm

       gz	      GZip compression

       gzip	      GZip compression

       bz2	      BZip2 compression

       bzip2	      BZip2 compression


HASH
       Algorithms:



		      md5	     MD5

       sha1	      SHA1

       sha256	      SHA256

       sha512	      SHA512

       openssl	      OpenSSL


SEE ALSO
       For a more or less complete description of PHAR look here:
       http://php.net/phar


BUGS
       You can view the list of known bugs or report any  new  bug  you
       found at:
       http://bugs.php.net

AUTHORS
       The PHP Group: Thies C. Arntzen, Stig Bakken, Andi Gutmans, Ras-
       mus Lerdorf, Sam Ruby, Sascha Schumann, Zeev Suraski,  Jim  Win-
       stead, Andrei Zmievski.

       Work  for  the  PHP  archive  was done by Gregory Beaver, Marcus
       Boerger.

       A List of active developers can be found here:
       http://www.php.net/credits.php

       And last but not least PHP was developed with the help of a huge
       amount of contributors all around the world.

VERSION INFORMATION
       This manpage describes phar, version 7.1.33.

COPYRIGHT
       Copyright (C) 1997-2018 The PHP Group

       This  source file is subject to version 3.01 of the PHP license,
       that is bundled with this package in the file  LICENSE,	and  is
       available through the world-wide-web at the following url:
       http://www.php.net/license/3_01.txt

       If  you did not receive a copy of the PHP license and are unable
       to obtain it through the world-wide-web, please send a  note  to
       license@php.net so we can mail you a copy immediately.



The PHP Group			     2018			       PHAR(1)
","# phar

> Create, update or extract PHP archives (PHAR).

- Add space-separated files or directories to a Phar file:

`phar add -f {{path/to/phar_file}} {{files_or_directories}}`

- Display the contents of a Phar file:

`phar list -f {{path/to/phar_file}}`

- Delete the specified file or directory from a Phar file:

`phar delete -f {{path/to/phar_file}} -e {{file_or_directory}}`

- Display full usage information and available hashing/compression algorithms:

`phar help`

- Compress or uncompress files and directories in a Phar file:

`phar compress -f {{path/to/phar_file}} -c {{algorithm}}`

- Get information about a Phar file:

`phar info -f {{path/to/phar_file}}`

- Sign a Phar file with a specific hash algorithm:

`phar sign -f {{path/to/phar_file}} -h {{algorithm}}`

- Sign a Phar file with an OpenSSL private key:

`phar sign -f {{path/to/phar_file}} -h openssl -y {{path/to/private_key}}`
"
nmtui,,,,"# nmtui

> Text user interface for controlling NetworkManager.
> Use arrow keys to navigate, enter to select an option.

- Open the user interface:

`nmtui`

- Show a list of available connections, with the option to activate or deactivate them:

`nmtui connect`

- Connect to a given network:

`nmtui connect {{name|uuid|device|SSID}}`

- Edit/Add/Delete a given network:

`nmtui edit {{name|id}}`

- Set the system hostname:

`nmtui hostname`
"
alpine,,,,"# alpine

> An email client and Usenet newsgroup program with a pico/nano-inspired interface.
> Supports most modern email services through IMAP.

- Open alpine normally:

`alpine`

- Open alpine directly to the message composition screen to send an email to a given email address:

`alpine {{email@example.net}}`

- Quit alpine:

`'q' then 'y'`
"
file,,,"
FILE(1) 		  BSD General Commands Manual		       FILE(1)

NAME
     file -- determine file type

SYNOPSIS
     file [-bcdDhiIkLnNprsvz] [--extension] [--mime-encoding] [--mime-type]
	  [-f namefile] [-m magicfiles] [-P name=value] [-M magicfiles] file
     file -C [-m magicfiles]
     file [--help]

DESCRIPTION
     This manual page documents version 5.04 of the file command.

     file tests each argument in an attempt to classify it.  There are three
     sets of tests, performed in this order: filesystem tests, magic tests,
     and language tests.  The first test that succeeds causes the file type to
     be printed.

     The type printed will usually contain one of the words text (the file
     contains only printing characters and a few common control characters and
     is probably safe to read on an ASCII terminal), executable (the file con-
     tains the result of compiling a program in a form understandable to some
     UNIX kernel or another), or data meaning anything else (data is usually
     ``binary'' or non-printable).  Exceptions are well-known file formats
     (core files, tar archives) that are known to contain binary data.	When
     modifying magic files or the program itself, make sure to preserve these
     keywords.	Users depend on knowing that all the readable files in a
     directory have the word ``text'' printed.	Don't do as Berkeley did and
     change ``shell commands text'' to ``shell script''.

     The filesystem tests are based on examining the return from a stat(2)
     system call.  The program checks to see if the file is empty, or if it's
     some sort of special file.  Any known file types appropriate to the sys-
     tem you are running on (sockets, symbolic links, or named pipes (FIFOs)
     on those systems that implement them) are intuited if they are defined in
     the system header file <sys/stat.h>.

     The magic tests are used to check for files with data in particular fixed
     formats.  The canonical example of this is a binary executable (compiled
     program) a.out file, whose format is defined in <elf.h>, <a.out.h> and
     possibly <exec.h> in the standard include directory.  These files have a
     ``magic number'' stored in a particular place near the beginning of the
     file that tells the UNIX operating system that the file is a binary exe-
     cutable, and which of several types thereof.  The concept of a ``magic''
     has been applied by extension to data files.  Any file with some invari-
     ant identifier at a small fixed offset into the file can usually be
     described in this way.  The information identifying these files is read
     from the compiled magic file /usr/share/file/magic.mgc, or the files in
     the directory /usr/share/file/magic if the compiled file does not exist.

     If a file does not match any of the entries in the magic file, it is
     examined to see if it seems to be a text file.  ASCII, ISO-8859-x, non-
     ISO 8-bit extended-ASCII character sets (such as those used on Macintosh
     and IBM PC systems), UTF-8-encoded Unicode, UTF-16-encoded Unicode, and
     EBCDIC character sets can be distinguished by the different ranges and
     sequences of bytes that constitute printable text in each set.  If a file
     passes any of these tests, its character set is reported.	ASCII,
     ISO-8859-x, UTF-8, and extended-ASCII files are identified as ``text''
     because they will be mostly readable on nearly any terminal; UTF-16 and
     EBCDIC are only ``character data'' because, while they contain text, it
     is text that will require translation before it can be read.  In addi-
     tion, file will attempt to determine other characteristics of text-type
     files.  If the lines of a file are terminated by CR, CRLF, or NEL,
     instead of the Unix-standard LF, this will be reported.  Files that con-
     tain embedded escape sequences or overstriking will also be identified.

     Once file has determined the character set used in a text-type file, it
     will attempt to determine in what language the file is written.  The lan-
     guage tests look for particular strings (cf.  <names.h>) that can appear
     anywhere in the first few blocks of a file.  For example, the keyword .br
     indicates that the file is most likely a troff(1) input file, just as the
     keyword struct indicates a C program.  These tests are less reliable than
     the previous two groups, so they are performed last.  The language test
     routines also test for some miscellany (such as tar(1) archives).

     Any file that cannot be identified as having been written in any of the
     character sets listed above is simply said to be ``data''.

OPTIONS
     --apple
	     Causes the file command to output the file type and creator code
	     as used by older MacOS versions. The code consists of eight let-
	     ters, the first describing the file type, the latter the creator.

     -b, --brief
	     Do not prepend filenames to output lines (brief mode).

     -C, --compile
	     Write a magic.mgc output file that contains a pre-parsed version
	     of the magic file or directory.

     -c, --checking-printout
	     Cause a checking printout of the parsed form of the magic file.
	     This is usually used in conjunction with the -m flag to debug a
	     new magic file before installing it.

     -C, --compile
	     Write a magic.mgc output file that contains a pre-parsed version
	     of the magic file or directory.

     -d      Apply the default system tests; this is the default behavior
	     unless -M is specified.

     -D      Print debugging messages.

     -E      On filesystem errors (file not found etc), instead of handling
	     the error as regular output as POSIX mandates and keep going,
	     issue an error message and exit.

     -e, --exclude testname
	     Exclude the test named in testname from the list of tests made to
	     determine the file type.  Valid test names are:

	     apptype   EMX application type (only on EMX).

	     ascii     Various types of text files (this test will try to
		       guess the text encoding, irrespective of the setting of
		       the `encoding' option).

	     encoding  Different text encodings for soft magic tests.

	     tokens    Ignored for backwards compatibility.

	     cdf       Prints details of Compound Document Files.

	     compress  Checks for, and looks inside, compressed files.

	     elf       Prints ELF file details, provided soft magic tests are
		       enabled and the elf magic is found.

	     soft      Consults magic files.

	     tar       Examines tar files.

     --extension
	     Print a slash-separated list of valid extensions for the file
	     type found.

     -F, --separator separator
	     Use the specified string as the separator between the filename
	     and the file result returned.  Defaults to `:'.

     -f, --files-from namefile
	     Read the names of the files to be examined from namefile (one per
	     line) before the argument list.  Either namefile or at least one
	     filename argument must be present; to test the standard input,
	     use `-' as a filename argument.  Please note that namefile is
	     unwrapped and the enclosed filenames are processed when this
	     option is encountered and before any further options processing
	     is done.  This allows one to process multiple lists of files with
	     different command line arguments on the same file invocation.
	     Thus if you want to set the delimiter, you need to do it before
	     you specify the list of files, like: ``-F @ -f namefile'',
	     instead of: ``-f namefile -F @''.

     -h, --no-dereference
	     option causes symlinks not to be followed (on systems that sup-
	     port symbolic links).

     -i      If the file is a regular file, do not classify its contents.

     -I, --mime
	     Causes the file command to output mime type strings rather than
	     the more traditional human readable ones.	Thus it may say
	     `text/plain; charset=us-ascii' rather than ``ASCII text''.

     --mime-type, --mime-encoding
	     Like -I, but print only the specified element(s).

     -k, --keep-going
	     Don't stop at the first match, keep going.  Subsequent matches
	     will be have the string `\012- ' prepended.  (If you want a new-
	     line, see the -r option.)	The magic pattern with the highest
	     strength (see the -l option) comes first.

     -l, --list
	     Shows a list of patterns and their strength sorted descending by
	     magic(4) strength which is used for the matching (see also the -k
	     option).

     -L, --dereference
	     option causes symlinks to be followed, as the like-named option
	     in ls(1) (on systems that support symbolic links).  This is the
	     default behavior.

     -m, --magic-file list
	     Specify an alternate list of files and directories containing
	     magic.  This can be a single item, or a colon-separated list.  If
	     a compiled magic file is found alongside a file or directory, it
	     will be used instead.

     -M list
	     Like -m, except that the default rules are not applied unless -d
	     is specified.

     -n, --no-buffer
	     Force stdout to be flushed after checking each file.  This is
	     only useful if checking a list of files.  It is intended to be
	     used by programs that want filetype output from a pipe.

     -p, --preserve-date
	     On systems that support utime(3) or utimes(2), attempt to pre-
	     serve the access time of files analyzed, to pretend that file
	     never read them.

     -P, --parameter name=value
	     Set various parameter limits.

		   Name 	Default    Explanation
		   indir	15	   recursion limit for indirect magic
		   name 	30	   use count limit for name/use magic
		   elf_notes	256	   max ELF notes processed
		   elf_phnum	128	   max ELF program sections processed
		   elf_shnum	32768	   max ELF sections processed
		   regex	8192	   length limit for regex searches

     -r, --raw
	     No operation, included for historical compatibility.

     -s, --special-files
	     Normally, file only attempts to read and determine the type of
	     argument files which stat(2) reports are ordinary files.  This
	     prevents problems, because reading special files may have pecu-
	     liar consequences.  Specifying the -s option causes file to also
	     read argument files which are block or character special files.
	     This is useful for determining the filesystem types of the data
	     in raw disk partitions, which are block special files.  This
	     option also causes file to disregard the file size as reported by
	     stat(2) since on some systems it reports a zero size for raw disk
	     partitions.

     -v, --version
	     Print the version of the program and exit.

     -z, --uncompress
	     Try to look inside compressed files.

     -Z, --uncompress-noreport
	     Try to look inside compressed files, but report information about
	     the contents only not the compression.

     -0, --print0
	     Output a null character `\0' after the end of the filename.  Nice
	     to cut(1) the output.  This does not affect the separator, which
	     is still printed.

     --help  Print a help message and exit.

FILES
     /usr/share/file/magic.mgc	Default compiled list of magic.
     /usr/share/file/magic	Directory containing default magic files.

ENVIRONMENT
     The environment variable MAGIC can be used to set the default magic file
     name.  file adds ``.mgc'' to the value of this variable as appropriate.
     However, file has to exist in order for file.mime to be considered.

LEGACY DESCRIPTION
     In legacy mode, the -D, -I, and -M options do not exist.

     The -d, -i, and -r options behave differently.  The -d option provides
     debugging information (same as -D in conformance mode).  The -i option
     displays mime type information (same as -I in conformance mode).  The -r
     option will disable the translation of unprintable characters (by
     default, this translation is already disabled in conformance mode).

     Furthermore, the -h option becomes the default symlink behavior (don't
     follow symlinks) unless POSIXLY_CORRECT is set.

     For more information about legacy mode, see compat(5).

SEE ALSO
     hexdump(1), od(1), strings(1), magic(5), otool(1), compat(5)

STANDARDS CONFORMANCE
     This program conforms to Version 3 of the Single UNIX Specification
     (``SUSv3'').  Its behavior is mostly compatible with the System V program
     of the same name.	This version knows more magic, however, so it will
     produce different (albeit more accurate) output in many cases.

     The one significant difference between this version and System V is that
     this version treats any white space as a delimiter, so that spaces in
     pattern strings must be escaped.  For example,

	   >10	   string  language impress	   (imPRESS data)

     in an existing magic file would have to be changed to

	   >10	   string  language\ impress	   (imPRESS data)

     In addition, in this version, if a pattern string contains a backslash,
     it must be escaped.  For example

	   0	   string	   \begindata	   Andrew Toolkit document

     in an existing magic file would have to be changed to

	   0	   string	   \\begindata	   Andrew Toolkit document

     SunOS releases 3.2 and later from Sun Microsystems include a file command
     derived from the System V one, but with some extensions.  This version
     differs from Sun's only in minor ways.  It includes the extension of the
     `&' operator, used as, for example,

	   >16	   long&0x7fffffff >0		   not stripped

MAGIC DIRECTORY
     The magic file entries have been collected from various sources, mainly
     USENET, and contributed by various authors.  Christos Zoulas (address
     below) will collect additional or corrected magic file entries.  A con-
     solidation of magic file entries will be distributed periodically.

     The order of entries in the magic file is significant.  Depending on what
     system you are using, the order that they are put together may be incor-
     rect.  If your old file command uses a magic file, keep the old magic
     file around for comparison purposes (rename it to
     /usr/share/file/magic.orig).

EXAMPLES
	   $ file file.c file /dev/{wd0a,hda}
	   file.c:   C program text
	   file:     ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV),
		     dynamically linked (uses shared libs), stripped
	   /dev/wd0a: block special (0/0)
	   /dev/hda: block special (3/0)

	   $ file -s /dev/wd0{b,d}
	   /dev/wd0b: data
	   /dev/wd0d: x86 boot sector

	   $ file -s /dev/hda{,1,2,3,4,5,6,7,8,9,10}
	   /dev/hda:   x86 boot sector
	   /dev/hda1:  Linux/i386 ext2 filesystem
	   /dev/hda2:  x86 boot sector
	   /dev/hda3:  x86 boot sector, extended partition table
	   /dev/hda4:  Linux/i386 ext2 filesystem
	   /dev/hda5:  Linux/i386 swap file
	   /dev/hda6:  Linux/i386 swap file
	   /dev/hda7:  Linux/i386 swap file
	   /dev/hda8:  Linux/i386 swap file
	   /dev/hda9:  empty
	   /dev/hda10: empty

	   $ file -i file.c file /dev/{wd0a,hda}
	   file.c:	text/x-c
	   file:	application/x-executable
	   /dev/hda:	application/x-not-regular-file
	   /dev/wd0a:	application/x-not-regular-file


HISTORY
     There has been a file command in every UNIX since at least Research
     Version 4 (man page dated November, 1973).  The System V version intro-
     duced one significant major change: the external list of magic types.
     This slowed the program down slightly but made it a lot more flexible.

     This program, based on the System V version, was written by Ian Darwin
     <ian@darwinsys.com> without looking at anybody else's source code.

     John Gilmore revised the code extensively, making it better than the
     first version.  Geoff Collyer found several inadequacies and provided
     some magic file entries.  Contributions of the `&' operator by Rob McMa-
     hon, <cudcv@warwick.ac.uk>, 1989.

     Guy Harris, <guy@netapp.com>, made many changes from 1993 to the present.

     Primary development and maintenance from 1990 to the present by Christos
     Zoulas <christos@astron.com>.

     Altered by Chris Lowth <chris@lowth.com>, 2000: handle the -I option to
     output mime type strings, using an alternative magic file and internal
     logic.

     Altered by Eric Fischer <enf@pobox.com>, July, 2000, to identify charac-
     ter codes and attempt to identify the languages of non-ASCII files.

     Altered by Reuben Thomas <rrt@sc3d.org>, 2007-2011, to improve MIME sup-
     port, merge MIME and non-MIME magic, support directories as well as files
     of magic, apply many bug fixes, update and fix a lot of magic, improve
     the build system, improve the documentation, and rewrite the Python bind-
     ings in pure Python.

     The list of contributors to the `magic' directory (magic files) is too
     long to include here.  You know who you are; thank you.  Many contribu-
     tors are listed in the source files.

LEGAL NOTICE
     Copyright (c) Ian F. Darwin, Toronto, Canada, 1986-1999.  Covered by the
     standard Berkeley Software Distribution copyright; see the file COPYING
     in the source distribution.

     The files tar.h and is_tar.c were written by John Gilmore from his pub-
     lic-domain tar(1) program, and are not covered by the above license.

RETURN CODE
     file returns 0 on success, and non-zero on error.

BUGS
     Please report bugs and send patches to the bug tracker at
     http://bugs.gw.com/ or the mailing list at <file@mx.gw.com> (visit
     http://mx.gw.com/mailman/listinfo/file first to subscribe).

TODO
     Fix output so that tests for MIME and APPLE flags are not needed all over
     the place, and actual output is only done in one place.  This needs a
     design.  Suggestion: push possible outputs on to a list, then pick the
     last-pushed (most specific, one hopes) value at the end, or use a default
     if the list is empty.  This should not slow down evaluation.

     The handling of MAGIC_CONTINUE and printing \012- between entries is
     clumsy and complicated; refactor and centralize.

     Some of the encoding logic is hard-coded in encoding.c and can be moved
     to the magic files if we had a !:charset annotation

     Continue to squash all magic bugs.  See Debian BTS for a good source.

     Store arbitrarily long strings, for example for %s patterns, so that they
     can be printed out.  Fixes Debian bug #271672.  This can be done by allo-
     cating strings in a string pool, storing the string pool at the end of
     the magic file and converting all the string pointers to relative offsets
     from the string pool.

     Add syntax for relative offsets after current level (Debian bug #466037).

     Make file -ki work, i.e. give multiple MIME types.

     Add a zip library so we can peek inside Office2007 documents to print
     more details about their contents.

     Add an option to print URLs for the sources of the file descriptions.

     Combine script searches and add a way to map executable names to MIME
     types (e.g. have a magic value for !:mime which causes the resulting
     string to be looked up in a table).  This would avoid adding the same
     magic repeatedly for each new hash-bang interpreter.

     When a file descriptor is available, we can skip and adjust the buffer
     instead of the hacky buffer management we do now.

     Fix ``name'' and ``use'' to check for consistency at compile time (dupli-
     cate ``name'', ``use'' pointing to undefined ``name'' ).  Make ``name'' /
     ``use'' more efficient by keeping a sorted list of names.	Special-case ^
     to flip endianness in the parser so that it does not have to be escaped,
     and document it.

     If the offsets specified internally in the file exceed the buffer size (
     HOWMANY variable in file.h), then we don't seek to that offset, but we
     give up.  It would be better if buffer managements was done when the file
     descriptor is available so move around the file.  One must be careful
     though because this has performance (and thus security considerations).

AVAILABILITY
     You can obtain the original author's latest version by anonymous FTP on
     ftp.astron.com in the directory /pub/file/file-X.YZ.tar.gz.

BSD			       October 19, 2016 			   BSD
","# file

> Determine file type.

- Give a description of the type of the specified file. Works fine for files with no file extension:

`file {{filename}}`

- Look inside a zipped file and determine the file type(s) inside:

`file -z {{foo.zip}}`

- Allow file to work with special or device files:

`file -s {{filename}}`

- Don't stop at first file type match; keep going until the end of the file:

`file -k {{filename}}`

- Determine the mime encoding type of a file:

`file -i {{filename}}`
"
mdadm,,,,"# mdadm

> RAID management utility.

- Create array:

`mdadm --create {{/path/to/raid_device_file}} --level {{raid_level}} --raid-devices {{number_of_disks}} {{/path/to/disk_device_file}}`

- Stop array:

`mdadm -S {{/path/to/raid_device_file}}`

- Mark disk as failed:

`mdadm {{/path/to/raid_device_file}} -f {{/path/to/disk_device_file}}`

- Remove disk:

`mdadm {{/path/to/raid_device_file}} -r {{/path/to/disk_device_file}}`

- Add disk to array:

`mdadm {{/path/to/raid_device_file}} -a {{/path/to/disk_device_file}}`

- Show RAID info:

`mdadm -D {{/path/to/raid_device_file}}`
"
nsenter,https://github.com/jpetazzo/nsenter/,"













GitHub - jpetazzo/nsenter








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            














    This repository has been archived by the owner. It is now read-only.
  






jpetazzo

/

nsenter

Archived






    Watch
 
      88
    




      Star


      2.4k
    




          Fork


        259
      







            Apache-2.0 License
        




2.4k
        stars
 

259
        forks
 




      Star





    Watch









Code

 



Pull requests
0
 



Actions

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Pull requests
 


                    Actions
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



0
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




jpetazzo

Update link + intro



…



93c0856

May 27, 2020





Update link + intro

The PaaS under the hood blog post was taken down, so I'm putting
a link to a conference talk about the same topic instead.

Also clarifying in the intro paragraph that this is not maintained
anymore.

93c0856



Git stats





82
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






Dockerfile


 


 







LICENSE


 


 







README.md


 


 







docker-enter


 


 







importenv.c


 


 







installer


 


 





        View code
      







        README.md
      


Looking to start a shell inside a Docker container?
Starting from Docker 1.3 you can use Docker exec to enter a Docker container. Example:
docker exec -it CONTAINER_NAME /bin/bash

There are differences between nsenter and docker exec; namely, nsenter doesn't enter the cgroups, and therefore evades resource limitations. The potential benefit of this would be debugging and external audit, but  for remote access, docker exec is the current recommended approach.
Important notice: this repository was useful in the early days of Docker, because nsenter was missing from major distributions back then. nsenter was written in early 2013, and included in util-linux release 2.23. If we look at Ubuntu LTS releases, trusty (14.04) shipped util-linux 2.20, and xenial (16.04) shipped 2.27. In other words, if you were using Ubuntu LTS, you had to wait until 2016 to get nsenter through the main, official packages. That being said, all modern distros now ship with nsenter, and this repository is no longer useful, except for historical or curiosity purposes. It is no longer maintained.
nsenter in a can
This is a small Docker recipe to build nsenter easily and install it in your
system.
What is nsenter?
It is a small tool allowing to enter into namespaces. Technically,
it can enter existing namespaces, or spawn a process into a new set of
namespaces. ""What are those namespaces you're blabbering about?""
We are talking about container namespaces.
nsenter can do many useful things, but the main reason why I'm so
excited about it is because it lets you enter into a Docker container.
Why build nsenter in a container?
This is because my preferred distros (Debian and Ubuntu) ship with an
outdated version of util-linux (the package that should contain nsenter).
Therefore, if you need nsenter on those distros, you have to juggle with
APT repository, or compile from source, or… Ain't nobody got time for that.
I'm going to make a very bold assumption: if you landed here, it's because
you want to enter a Docker container. Therefore, you won't mind if my
method to build nsenter uses Docker itself.
How do I install nsenter with this?
If you want to install nsenter into /usr/local/bin, just do this:
docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter

The jpetazzo/nsenter container will detect that /target is a
mountpoint, and it will copy the nsenter binary into it.
If you don't trust me, and prefer to extract the nsenter binary,
rather than allowing my container to potentially wreak havoc into
your system's $PATH, you can also do this:
docker run --rm jpetazzo/nsenter cat /nsenter > /tmp/nsenter && chmod +x /tmp/nsenter

Then do whatever you want with the binary in /tmp/nsenter.
How do I use nsenter?
First, figure out the PID of the container you want to enter:
PID=$(docker inspect --format {{.State.Pid}} <container_name_or_ID>)

Then enter the container:
nsenter --target $PID --mount --uts --ipc --net --pid

What's that docker-enter thing?
It's just a small shell script that wraps up the steps described above into
a tiny helper. It takes the name or ID of a container and optionally the name
of a program to execute inside the namespace. If no command is specified a
shell will be invoked instead.
# list the root filesystem
docker-enter my_awesome_container ls -la

Docker toolbox usage for OS X or Windows user
SSH to the Docker Toolbox virtual machine
docker-machine ssh default

Install nsenter, docker-enter, and importenv into the VM
docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter

You can also install nsenter to another folder. In that case, you will
need to specify the full path of nsenter to run it.
docker run --rm -v /tmp:/target jpetazzo/nsenter

Using nsenter
List running containers:
docker ps

Identify the ID of the container that you want to get into; and retrieve
its associated PID:
PID=$(docker inspect --format {{.State.Pid}} 08a2a025e05f)

Enter the container:
sudo nsenter --target $PID --mount --uts --ipc --net --pid

Remember to run those commands in the Docker Toolbox virtual machine; not
in your host environment.
Using docker-enter
With docker-enter, you don't need to lookup the container PID.
You can get a shell inside the container:
docker-enter 08a2a025e05f

Or run commands directly:
docker-enter 08a2a025e05f ls /var/log
docker-enter 08a2a025e05f df -h

docker-enter with boot2docker
If you are using boot2docker, you can use the function below, to:

install nsenter and docker-enter into boot2docker's /var/lib/boot2docker/ directory,
so they survive restarts.
execute docker-enter inside of boot2docker combined with ssh

docker-enter() {
  boot2docker ssh '[ -f /var/lib/boot2docker/nsenter ] || docker run --rm -v /var/lib/boot2docker/:/target jpetazzo/nsenter'
  boot2docker ssh -t sudo /var/lib/boot2docker/docker-enter ""$@""
}

You can use it directly from your host (OS X/Windows), no need to ssh into boot2docker.
Caveats

This only works on Intel 64 bits platforms. It should be relatively
easy to adapt to other architectures, though.
nsenter still needs to run from the host; it cannot run inside a
container (yet).









About

      No description, website, or topics provided.
    
Resources



      Readme
 
License



        Apache-2.0 License
    







    Releases

No releases published






    Packages 0


        No packages published 













    Contributors 25





 



 



 



 



 



 



 



 



 



 



 



      + 14 contributors





Languages










Shell
51.8%





C
31.1%





Dockerfile
17.1%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# nsenter

> Run a new command in a running process' namespace.
> Particularly useful for docker images or chroot jails.
> More information: <https://github.com/jpetazzo/nsenter/>.

- Run command in existing processes network namespace:

`nsenter -t {{pid}} -n {{command}} {{command_arguments}}`

- Run a new command in an existing processes ps-table namespace:

`nsenter -t {{pid}} -p {{command}} {{command_arguments}}`

- Run command in existing processes IPC namespace:

`nsenter -t {{pid}} -i {{command}} {{command_arguments}}`
"
ndctl,,,,"# ndctl

> Utility for managing Non-Volatile DIMMs.

- Create an 'fsdax' mode namespace:

`ndctl create-namespace --mode={{fsdax}}`

- Change the mode of a namespace to 'raw':

`ndctl create-namespace --reconfigure={{namespaceX.Y}} --mode={{raw}}`

- Check a sector mode namespace for consistency, and repair if needed:

`ndctl check-namespace --repair {{namespaceX.Y}}`

- List all namespaces, regions, and buses (including disabled ones):

`ndctl list --namespaces --regions --buses --idle`

- List a specific namespace and include lots of additional information:

`ndctl list -vvv --namespace={{namespaceX.Y}}`

- Run a monitor to watch for SMART health events for NVDIMMs on the 'ACPI.NFIT' bus:

`ndctl monitor --bus={{ACPI.NFIT}}`

- Remove a namespace (when applicable) or reset it to an initial state:

`ndctl destroy-namespace --force {{namespaceX.Y}}`
"
dpkg-query,,,,"# dpkg-query

> A tool that shows information about installed packages.

- List all installed packages:

`dpkg-query -l`

- List installed packages matching a pattern:

`dpkg-query -l '{{pattern}}'`

- List all files installed by a package:

`dpkg-query -L {{package_name}}`

- Show information about a package:

`dpkg-query -s {{package_name}}`
"
xsetwacom,,,,"# xsetwacom

> Command line tool to change settings for Wacom pen tablets at runtime.

- List all the available wacom devices. The device name is in the first column:

`xsetwacom list`

- Set Wacom area to specific screen. Get name of the screen with `xrandr`:

`xsetwacom set ""{{device_name}}"" MapToOutput {{screen}}`

- Set mode to relative (like a mouse) or absolute (like a pen) mode:

`xsetwacom set ""{{device_name}}"" Mode ""{{Relative|Absolute}}""`

- Rotate the input (useful for tablet-PC when rotating screen) by 0|90|180|270 degrees from ""natural"" rotation:

`xsetwacom set ""{{device_name}}"" Rotate {{none|half|cw|ccw}}`

- Set button to only work when the tip of the pen is touching the tablet:

`xsetwacom set ""{{device_name}}"" TabletPCButton ""on""`
"
setfacl,,,,"# setfacl

> Set file access control lists (ACL).

- Modify ACL of a file for user with read and write access:

`setfacl -m u:{{username}}:rw {{file}}`

- Modify default ACL of a file for all users:

`setfacl -d -m u::rw {{file}}`

- Remove ACL of a file for an user:

`setfacl -x u:{{username}} {{file}}`

- Remove all ACL entries of a file:

`setfacl -b {{file}}`
"
sshuttle,,,,"# sshuttle

> Transparent proxy server that tunnels traffic over an SSH connection.
> Doesn't require root or any special setup on the remote SSH server, though root access on the local machine is prompted for.

- Forward all IPv4 TCP traffic via a remote SSH server:

`sshuttle --remote={{username}}@{{sshserver}} {{0.0.0.0/0}}`

- Also forward all DNS traffic to the server's default DNS resolver:

`sshuttle --dns --remote={{username}}@{{sshserver}} {{0.0.0.0/0}}`

- Forward all traffic except that which is bound for a specific subnet:

`sshuttle --remote={{username}}@{{sshserver}} {{0.0.0.0/0}} --exclude {{192.168.0.1/24}}`

- Use the tproxy method to forward all IPv4 and IPv6 traffic:

`sshuttle --method=tproxy --remote={{username}}@{{sshserver}} {{0.0.0.0/0}} {{::/0}} --exclude={{your_local_ip_address}} --exclude={{ssh_server_ip_address}}`
"
eyeD3,https://eyed3.readthedocs.io/en/latest/," 



Welcome to eyeD3 — eyeD3 0.9.4 documentation




























 eyeD3
          

          
          

                latest
              










Installation


âeyeD3â Command Line Tool
Plugins
eyed3 module
Compliance
Contributing
Authors


Release History







eyeD3





Docs »
Welcome to eyeD3

 Edit on GitHub







Welcome to eyeD3Â¶

StatusÂ¶








AboutÂ¶
eyeD3 is a Python tool for working with audio files, specifically MP3 files
containing ID3 metadata (i.e. song info).
It provides a command-line tool (eyeD3) and a Python library
(import eyed3) that can be used to write your own applications or
plugins that are callable from the command-line tool.
For example, to set some song information in an mp3 file called
song.mp3:
$ eyeD3 -a Integrity -A ""Humanity Is The Devil"" -t ""Hollow"" -n 2 song.mp3


With this command weâve set the artist (-a/--artist), album
(-A/--album), title (-t/--title), and track number
(-n/--track-num) properties in the ID3 tag of the file. This is the
standard interface that eyeD3 has always had in the past, therefore it
is also the default plugin when no other is specified.
The results of this command can be seen by running the eyeD3 with no
options.
$ eyeD3 song.mp3
song.mp3      [ 3.06 MB ]
-------------------------------------------------------------------------
ID3 v2.4:
title: Hollow
artist: Integrity
album: Humanity Is The Devil
album artist: None
track: 2
-------------------------------------------------------------------------


The same can be accomplished using Python.
import eyed3

audiofile = eyed3.load(""song.mp3"")
audiofile.tag.artist = ""Token Entry""
audiofile.tag.album = ""Free For All Comp LP""
audiofile.tag.album_artist = ""Various Artists""
audiofile.tag.title = ""The Edge""
audiofile.tag.track_num = 3

audiofile.tag.save()


eyeD3 is written and maintained by Travis Shirk and is licensed under
version 3 of the GPL.


FeaturesÂ¶

Python package (import eyed3) for writing applications and plugins.
eyeD3 : Command-line tool driver script that supports plugins.
Easy ID3 editing/viewing of audio metadata from the command-line.
Plugins for: Tag to string formatting (display), album fixing (fixup),
cover art downloading (art), collection stats (stats),
and json/yaml/jabber/nfo output formats, and more included.
Support for ID3 versions 1.x, 2.2 (read-only), 2.3, and 2.4.
Support for the MP3 audio format exposing details such as play time, bit
rate, sampling frequency, etc.
Abstract design allowing future support for different audio formats and
metadata containers.



Get StartedÂ¶
Python >= 3.6 is required.
For installation instructions or more complete documentation see
http://eyeD3.nicfit.net/
Please post feedback and/or defects on the issue tracker, or mailing list.

InstallationÂ¶
Stable releases of eyeD3 are best installed via pip or easy_install;
or you may download TGZ or ZIP source archives from a couple of official
locations. Detailed instructions and links may be found on the
Installation page.
Otherwise, if you want to live on the edge, you can pull down the source code
from the Git repository at GitHub. The Installation page has
details for how to access the source code.




DocumentationÂ¶


âeyeD3â Command Line Tool
Plugins
Configuration Files
Custom Plugins


Plugins
art(work) plugin
classic - Tag Viewer/Editor
display - Display tag information by pattern
Extract Plugin
fixup - Music directory fixer
itunes-podcast - Convert files so iTunes recognizes them as podcasts
JSON Plugin
genres - ID3 Genre List
lameinfo (xing) - Lame (Xing) Header Information
Mime-types Plugin
nfo - (I)NFO File Generator
pymod - Use simple python modules as eyeD3 plugins
stats - Music Collection Statistics
xep-118 - Jabber (XMPP) Tune Format
YAML Plugin


eyed3 module
eyed3 package


Compliance
ID3


Contributing
Types of Contributions
Get Started!
Pull Request Guidelines


Authors






ChangeLogÂ¶
Changes made to eyeD3 and the projectâs release history can be found in the
Release History.


ReferencesÂ¶

ID3 v1.x Specification
ID3 v2.4 Structure and
Frames
ID3 v2.3 Specification
ID3 v2.2 Specification
ISO 8601 Date and Time
ISO 639-2 Language Codes
MusicBrainz Tag Mappings
MP3 Headers



Indices and tablesÂ¶

Index
Module Index
Search Page








Next 




        © Copyright 2002-2020, Travis Shirk
      
        
          Revision 3eaa919b.
        


  Built with Sphinx using a theme provided by Read the Docs. 








 Read the Docs
      v: latest
      



Versions
master
latest


Downloads
pdf
html
epub


On Read the Docs

Project Home


Builds



      Free document hosting provided by Read the Docs.

    



",,"# eyeD3

> Read and manipulate metadata of MP3 files.
> More information: <https://eyed3.readthedocs.io/en/latest/>.

- View information about an MP3 file:

`eyeD3 {{filename.mp3}}`

- Set the title of an MP3 file:

`eyeD3 --title {{""A Title""}} {{filename.mp3}}`

- Set the album of all the MP3 files in a directory:

`eyeD3 --album {{""Album Name""}} {{*.mp3}}`

- Set the front cover art for an MP3 file:

`eyeD3 --add-image {{front_cover.jpeg}}:FRONT_COVER: {{filename.mp3}}`
"
perl-rename,,,,"# rename

> Rename multiple files.
> NOTE: this page refers to the command from the `perl-rename` Arch Linux package.

- Rename files using a Perl Common Regular Expression (substitute 'foo' with 'bar' wherever found):

`rename {{'s/foo/bar/'}} {{*}}`

- Dry-run - display which renames would occur without performing them:

`rename -n {{'s/foo/bar/'}} {{*}}`

- Force renaming even if the operation would remove existing destination files:

`rename -f {{'s/foo/bar/'}} {{*}}`

- Convert filenames to lower case (use `-f` in case-insensitive filesystems to prevent ""already exists"" errors):

`rename 'y/A-Z/a-z/' {{*}}`

- Replace whitespace with underscores:

`rename 's/\s+/_/g' {{*}}`
"
xman,,,,"# xman

> Manual page viewer for X Window System.

- Start xman in three-button window:

`xman`

- Open the manual page output stored in a given file:

`xman -helpfile {{filename}}`

- Show both manual page and directory:

`xman -bothshown`
"
nologin,,,"
NOLOGIN(8)		  BSD System Manager's Manual		    NOLOGIN(8)

NAME
     nologin -- politely refuse a login

SYNOPSIS
     nologin

DESCRIPTION
     The nologin utility displays a message that an account is not available
     and exits non-zero.  It is intended as a replacement shell field for
     accounts that have been disabled.

     To disable all logins, investigate nologin(5).

SEE ALSO
     login(1), nologin(5)

HISTORY
     The nologin utility appeared in 4.4BSD.

BSD				 June 19, 1993				   BSD
","# nologin

> Alternative shell that prevents a user from logging in.

- Set a user's login shell to `nologin` to prevent the user from logging in:

`chsh -s {{user}} nologin`

- Customize message for users with the login shell of `nologin`:

`echo ""{{declined_login_message}}"" > /etc/nologin.txt`
"
apt-mark,,,,"# apt-mark

> Utility to change the status of installed packages.

- Mark a package as automatically installed:

`sudo apt-mark auto {{package_name}}`

- Hold a package at its current version and prevent updates to it:

`sudo apt-mark hold {{package_name}}`

- Allow a package to be updated again:

`sudo apt-mark unhold {{package_name}}`

- Show manually installed packages:

`apt-mark showmanual`

- Show held packages that aren't being updated:

`apt-mark showhold`
"
vmstat,https://linux.die.net/man/8/vmstat,"

vmstat(8): Report virtual memory statistics - Linux man page
















vmstat(8) - Linux man page
Name
vmstat - Report virtual memory statistics
Synopsis





vmstat [-a] [-n] [-t] [-S unit] [delay [ count]]
vmstat [-s] [-n] [-S unit]
vmstat [-m] [-n] [delay [ count]]
vmstat [-d] [-n] [delay [ count]]
vmstat [-p disk partition] [-n] [delay [ count]]
vmstat [-f]
vmstat [-V]
Description
vmstat reports information about processes, memory, paging, block IO, traps, and cpu activity.
The first report produced gives averages since the last reboot. Additional reports give information on a sampling period of length delay. The process
and memory reports are instantaneous in either case.

Options

The -a switch displays active/inactive memory, given a 2.5.41 kernel or better.
The -f switch displays the number of forks since boot. This includes the fork, vfork, and clone system calls, and is equivalent to the total number
of tasks created. Each process is represented by one or more tasks, depending on thread usage. This display does not repeat.
The -t switch adds timestamp to the output.
The -m switch displays slabinfo.
The -n switch causes the header to be displayed only once rather than periodically.
The -s switch displays a table of various event counters and memory statistics. This display does not repeat.
delay is the delay between updates in seconds. If no delay is specified, only one report is printed with the average values since boot.

count is the number of updates. If no count is specified and delay is defined, count defaults to infinity.
The -d reports disk statistics (2.5.70 or above required)
The -w enlarges field width for big memory sizes
The -p followed by some partition name for detailed statistics (2.5.70 or above required)
The -S followed by k or K or m or M switches outputs between 1000, 1024, 1000000, or 1048576 bytes
The -V switch results in displaying version information.

Field Description For Vm Mode
Procs


r: The number of processes waiting for run time.
b: The number of processes in uninterruptible sleep.

Memory


swpd: the amount of virtual memory used.
free: the amount of idle memory.
buff: the amount of memory used as buffers.
cache: the amount of memory used as cache.
inact: the amount of inactive memory. (-a option)
active: the amount of active memory. (-a option)

Swap


si: Amount of memory swapped in from disk (/s).
so: Amount of memory swapped to disk (/s).

IO


bi: Blocks received from a block device (blocks/s).
bo: Blocks sent to a block device (blocks/s).

System


in: The number of interrupts per second, including the clock.
cs: The number of context switches per second.

CPU

These are percentages of total CPU time.
us: Time spent running non-kernel code. (user time, including nice time)
sy: Time spent running kernel code. (system time)
id: Time spent idle. Prior to Linux 2.5.41, this includes IO-wait time.
wa: Time spent waiting for IO. Prior to Linux 2.5.41, included in idle.
st: Time stolen from a virtual machine. Prior to Linux 2.6.11, unknown.

Field Description For Disk Mode
Reads


total: Total reads completed successfully
merged: grouped reads (resulting in one I/O)
sectors: Sectors read successfully
ms: milliseconds spent reading

Writes


total: Total writes completed successfully
merged: grouped writes (resulting in one I/O)
sectors: Sectors written successfully
ms: milliseconds spent writing

IO


cur: I/O in progress
s: seconds spent for I/O

Field Description For Disk Partition Mode
reads: Total number of reads issued to this partition
read sectors: Total read sectors for partition
writes : Total number of writes issued to this partition
requested writes: Total number of write requests made for partition
Field Description For Slab Mode
cache: Cache name
num: Number of currently active objects
total: Total number of available objects
size: Size of each object
pages: Number of pages with at least one active object
totpages: Total number of allocated pages
pslab: Number of pages per slab
Notes
vmstat does not require special permissions.
These reports are intended to help identify system bottlenecks. Linux vmstat does not count itself as a running process.
All linux blocks are currently 1024 bytes. Old kernels may report blocks as 512 bytes, 2048 bytes, or 4096 bytes.
Since procps 3.1.9, vmstat lets you choose units (k, K, m, M) default is K (1024 bytes) in the default mode
vmstat uses slabinfo 1.1 FIXME
Files
/proc/meminfo
/proc/stat
/proc/*/stat
See Also
iostat(1), sar(1), mpstat(1), ps(1), top(1), free(1)
Bugs
Does not tabulate the block io per device or count the number of system calls.
Authors
Written by Henry Ware <al172@yfn.ysu.edu>.
Fabian FrÃ©dÃ©rick <ffrederick@users.sourceforge.net> (diskstat, slab, partitions...)

Referenced By
cifsiostat(1),
cpupower-monitor(1),
pidstat(1),
slabtop(1),
smem(8),
tcpstat(1),
vmtouch(8)








Site Search











Library
linux docs
linux man pages
page load time


Toys
world sunlight
moon phase
trace explorer







",,"# vmstat

> Report information about processes, memory, paging, block IO, traps, disks and CPU activity.
> More information: <https://linux.die.net/man/8/vmstat>.

- Display virtual memory statistics:

`vmstat`

- Display reports every 2 seconds for 5 times:

`vmstat {{2}} {{5}}`
"
findmnt,,,,"# findmnt

> Find your filesystem.

- List all mounted filesystems:

`findmnt`

- Search for a device:

`findmnt {{/dev/sdb1}}`

- Search for a mountpoint:

`findmnt {{/}}`

- Find filesystems in specific type:

`findmnt -t {{ext4}}`

- Find filesystems with specific label:

`findmnt LABEL={{BigStorage}}`
"
openrc,https://wiki.gentoo.org/wiki/OpenRC,"


OpenRC - Gentoo Wiki


















 
		Jump to:		content







 Get Gentoo!


 gentoo.org sites 


 gentoo.org
 Wiki
 Bugs
 Forums
 Packages

 Planet
 Archives
 Gitweb
 CVS sources

 Infra Status








Wiki









Toggle navigation







Main pageRecent changesHelp 
Gentoo 
Gentoo Projects 
 
Documentation 
Gentoo HandbookGentoo FAQFeatured DocumentsTopicsCore systemHardwareSoftwareDesktopServer & SecurityProject & Community 
 


 Tools 

What links hereRelated changesSpecial pagesPrintable versionPermanent linkPage informationBrowse properties 




				User				


Create accountLog in 










Toggle navigation







PageDiscussion 



 



View source
more 

History 












OpenRC


From Gentoo Wiki



								Jump to:								navigation, 								search


Resources
Project
Wikipedia
Package information
GitHub
Article status
This article has some todo items:
Busybox specific init.d files

OpenRC is a dependency-based init system that maintains compatibility with the system provided init program, normally located in /sbin/init. It does not function as a replacement for the /sbin/init file. OpenRC is 100% compatible with Gentoo init scripts, which means a solution can be found to run the dozens of daemons in the main Gentoo repository. OpenRC, however, is not designed to be exclusively used by Gentoo Linux and can be used on other distributions and BSD systems.

Contents

1 Features

1.1 OpenRC Busybox integration
1.2 Replacing init

1.2.1 busybox
1.2.2 openrc-init


1.3 Daemon supervision
1.4 Busybox specific init.d files
1.5 Replacing udev with mdev
1.6 Replacing udev with eudev


2 Configuration

2.1 Files
2.2 Network management
2.3 Dependency behavior
2.4 Selecting a specific runlevel at boot


3 Usage

3.1 Runlevels
3.2 Listing

3.2.1 Named runlevels
3.2.2 Stacked runlevels


3.3 Prefix
3.4 Hotplug
3.5 Manually recovering crashed services
3.6 Automatic respawning crashed services
3.7 CGroups support
3.8 Chroot support


4 systemd compatibility

4.1 logind
4.2 tmpfiles.d


5 See also


Features
OpenRC provides a number of features touted as innovative by recent init systems like systemd or upstart (wikipedia), such as:

cgroups support,
process supervision,
parallel startup of services, and
hardware initiated initscripts run.
It does this without requiring large layout changes to accommodate radically different designs and dependencies.

 TipSee the comparison of init systems article for more information on init systems.
OpenRC Busybox integration
Busybox can be used to replace most of the userspace utilities needed by OpenRC (init, shell, awk and other POSIX tools), by using a complete Busybox as shell for OpenRC all the calls that normally would cause a fork/exec would be spared, improving the overall speed. This process is not yet streamlined.
Please note that there are currently many Busybox applets that are incompatible with OpenRC. See bug #529086 for details.

Replacing init
In order to set a specific runlevel from the bootloader the variable softlevel= should be used.

busybox
The SysV-init /etc/inittab file provided by Gentoo is not compatible with the Busybox init.

FILE /etc/inittabExample inittab compatible with Busybox init::sysinit:/sbin/openrc sysinit
::wait:/sbin/openrc boot
::wait:/sbin/openrc
openrc-init
OpenRC has its own init system called openrc-init. See OpenRC/openrc-init for details.

Daemon supervision
OpenRC has its own process supervisor. See OpenRC/supervise-daemon for details. 
Alternatively Skarnet's S6 is also supported by OpenRC. See S6 for details.

Busybox specific init.d files
TODO: busybox provides a number of applets that could be used to replace third party software like acpid or dhcp/dhcpcd.

Replacing udev with mdev
See mdev.

Replacing udev with eudev
Older Gentoo installs were using udev as the main virtual/udev provider.  Based on bug #575718 it was changed to eudev. However, the rc service is still /etc/init.d/udev.

Configuration
Files
/etc/rc.conf
The global OpenRC configuration file.
Network management
OpenRC can be used with one of several network managers or even with none, see Network manager.

Dependency behavior
Changing the default dependencies of init scripts, might be needed to fit more complex setups. See /etc/rc.conf for how to change the default behavior; notice the rc_depend_strict option. In addition, next networking examples show how flexible OpenRC can be.

Multiple network interfaces (example)
The SSH service must come up with the internal network, for instance eth0 and never wlan0.
Overrule the ""net"" dependency from /etc/init.d/sshd, and refine it to depend on ""net.eth0"":

FILE /etc/conf.d/sshdrc_need=""!net net.eth0""

Multiple network interfaces in multiple runlevels (example)
The SSH service must start with eth0 (not wlan0) in ""default"" runlevel, but in ""office"" runlevel it must start with wlan0 (not eth0).
Keep the default:

FILE /etc/rc.conf#rc_depend_strict=""YES""

Make additional symlinks to sshd with the network interface names:

root #ln -s sshd /etc/init.d/sshd.eth0
root #ln -s sshd /etc/init.d/sshd.wlan0

Settings are read from /etc/conf.d/sshd.eth0 and /etc/conf.d/sshd.wlan0 now:

root #cp /etc/conf.d/sshd /etc/conf.d/sshd.eth0
root #cp /etc/conf.d/sshd /etc/conf.d/sshd.wlan0

Add the dependencies:

root #echo 'rc_need=""!net net.eth0""' >> /etc/conf.d/sshd.eth0
root #echo 'rc_need=""!net net.wlan0""' >> /etc/conf.d/sshd.wlan0

In this example net.eth0 and net.wlan0 read their settings from /etc/conf.d/net, or /etc/conf.d/net.office depending on the active runlevel. Add all runscripts to the different runlevels:

root #rc-update add sshd.eth0 default
root #rc-update add sshd.wlan0 office
root #rc-update add net.eth0 default office
root #rc-update add net.wlan0 default office

To switch between ""default"" runlevel and ""office"" runlevel without rebooting the computer, change to ""nonetwork"" runlevel in between. The network interfaces will be stopped this way, and re-read their runlevel specific configuration. This works best when ""nonetwork"" is a stacked runlevel in both the ""default"" and ""office"" runlevels, and the display manager and other non-network services are added to the ""nonetwork"" runlevel only.

default runlevel <---> nonetwork runlevel <---> office runlevel
root #rc nonetwork && rc office
root #rc nonetwork && rc default

Selecting a specific runlevel at boot
OpenRC reads the kernel command-line used at boot time, and will start the runlevel specified by the ""softlevel"" parameter if provided, instead of 'default'.
For instance, you can choose whether to boot into the 'default' or 'nonetwork' runlevels with the following example grub.conf configuration:

FILE /boot/grub/grub.confExample grub.conf (GRUB Legacy)title=Regular Start-up

kernel (hd0,0)/boot/kernel-3.7.10-gentoo-r1 root=/dev/sda3

title=Start without Networking

kernel (hd0,0)/boot/kernel-3.7.10-gentoo-r1 root=/dev/sda3 softlevel=nonetwork
Usage
Runlevels
OpenRC can be controlled and configured using openrc, rc-update and rc-status commands.
Delete a service from default runlevel, where <service> is the name of the service to be removed:

root #rc-update delete <service> default
Listing
Listing commands do not need to be ran as root.
Use rc-update show -v to display all available init scripts and their current runlevel (if they have been added to one):

user $rc-update show -v
Running rc-update or rc-update show will display only the init scripts that have been added to a runlevel.
Alternatively, the rc-status command can be used with the --servicelist (-s) option to view the state of all services:

user $rc-status --servicelist
Named runlevels
OpenRC runlevels are directories living in /etc/runlevels to create additional runlevels is enough to issue:

root #install -d /etc/runlevels/$runlevel
Stacked runlevels
Is possible manage variants using rc-update -s.
An usage example for using stacked runlevel on laptop to group networking services based on location is at OpenRC/StackedRunlevel.

Prefix
Gentoo Prefix installs Gentoo within an offset, known as a prefix, allowing users to install Gentoo in another location in the filesystem hierarchy, hence avoiding conflicts. Next to this offset, Gentoo Prefix runs unprivileged, meaning no root user or rights are required to use it.
By using an offset (the ""prefix"" location), it is possible for many ""alternative"" user groups to benefit from a large part of the packages in the Gentoo Linux Portage tree. Currently users of the following systems successfully run Gentoo Prefix: Mac OS X on PPC and x86, Linux on x86, x86_64 and ia64, Solaris 10 on Sparc, Sparc/64, x86 and x86_64, FreeBSD on x86, AIX on PPC, Interix on x86, Windows on x86 (with the help of Interix), HP-UX on PARISC and ia64. 
OpenRC runscript already support prefix-installed daemons, during the Summer of Code 2012 work will be done to implement full secondary/session daemon behavior to complete the overall feature set provided by Prefix.
OpenRC/Prefix, a tutorial for trying it out.

Hotplug
OpenRC can be triggered by external events, such as new hardware from udev. See OpenRC/Event Driven for details.

Manually recovering crashed services
If you have a process that crashes upon start you will see the following when you go to check it's status.

root #/etc/init.d/docker status
* status: crashed

root #/etc/init.d/docker start
* WARNING: docker has already been started

root #/etc/init.d/docker stop
* Caching service dependencies ...                                                                                                  [ ok ]
* Stopping docker ...
* Failed to stop docker                                                                                                             [ !! ]
* ERROR: docker failed to stop


To remedy this situation you will need to zap the process which in the following example is the docker service.

root #/etc/init.d/docker zap
Automatic respawning crashed services
OpenRC can return state of services to runlevel setting state, to provide stateful init scripts and automatic respawning. What you need is to run openrc (for default runlevel). Crashed services start and manual run services will stop. To prevent this you can run openrc -n (--not-stop)
By default openrc will attempt just to start crashed services, not restart. This сontrolled by rc_crashed_stop (default NO) and rc_crashed_start (default YES) options in /etc/rc.conf.

CGroups support
OpenRC starting with version 0.12 has extended cgroups support. See OpenRC/CGroups for details.

Chroot support
root #mkdir /lib64/rc/init.d
root #ln -s /lib64/rc/init.d /run/openrc
root #touch /run/openrc/softlevel
root #emerge --oneshot sys-apps/openrc

FILE /etc/rc.confOpenRC config filerc_sys=""prefix""
rc_controller_cgroups=""NO""
rc_depend_strict=""NO""
rc_need=""!net !dev !udev-mount !sysfs !checkfs !fsck !netmount !logger !clock !modules""

If you find that you are getting

 * WARNING: <service> is already starting
messages attempting to start a service, you may need to run

root #rc-update --update
systemd compatibility
logind
As some setups require systemd-logind. Elogind can be a suitable replacement as a standalone logind running with OpenRC.

tmpfiles.d
systemd has a special tmpfiles.d file syntax for managing temporary files. sys-apps/opentmpfiles provides a tmpfiles.d interpreter for OpenRC.
Both can also be used to manage volatile entries in /sys or /proc.

See also
Gentoo AMD64 Handbook - Initscript system
OpenRC/Baselayout 1 to 2 migration — provides instructions on migrating from baselayout-1 to baselayout-2 using OpenRC.





Retrieved from ""https://wiki.gentoo.org/index.php?title=OpenRC&oldid=884343""
Categories: Todo articlesOpenRC 










 This page was last edited on 19 July 2020, at 22:31.Privacy policyAbout Gentoo WikiDisclaimers 














© 2001–2020 Gentoo Foundation, Inc.

						Gentoo is a trademark of the Gentoo Foundation, Inc.
						The contents of this document, unless otherwise expressly stated, are licensed under the
						CC-BY-SA-3.0 license.
						The Gentoo Name and Logo Usage Guidelines apply.
					





",,"# openrc

> The OpenRC service manager.
> See also `rc-status`, `rc-update`, and `rc-service`.
> More information: <https://wiki.gentoo.org/wiki/OpenRC>.

- Change to a specific runlevel:

`sudo openrc {{runlevel_name}}`

- Change to a specific runlevel, but don't stop any existing services:

`sudo openrc --no-stop {{runlevel_name}}`
"
fc-pattern,,,"FC-PATTERN(1)							 FC-PATTERN(1)



NAME
       fc-pattern - parse and show pattern

SYNOPSIS
       fc-pattern  [ -cdVh ]  [ --config ]  [ --default ]  [  [ -f format ]  [
       --format format ]  ]  [ --version ]  [ --help ]

	[ pattern  [ element... ]   ]

DESCRIPTION
       fc-pattern parses pattern (empty pattern  by  default)  and  shows  the
       parsed  result.	If --config is given, config substitution is performed
       on the pattern before being displayed.  If --default is given,  default
       substitution is performed on the pattern before being displayed.

       If any elements are specified, only those are printed.

OPTIONS
       This  program  follows  the  usual  GNU	command line syntax, with long
       options starting with  two  dashes  (`-').  A  summary  of  options  is
       included below.

       -c     Perform config substitution on pattern.

       -d     Perform default substitution on pattern.

       -f     Format output according to the format specifier format.

       -V     Show version of the program and exit.

       -h     Show summary of options.

       pattern
	      Parses and displays pattern (uses empty pattern by default).

       element
	      If set, the element property is displayed for parsed pattern.

SEE ALSO
       FcNameParse(3)  FcConfigSubstitute(3) FcDefaultSubstitute(3) FcPattern-
       Print(3)  FcPatternFormat(3)  fc-cat(1)	fc-cache(1)   fc-list(1)   fc-
       match(1) fc-query(1) fc-scan(1)

       The  fontconfig	user's	guide, in HTML format: /usr/share/doc/fontcon-
       fig/fontconfig-user.html.

AUTHOR
       This manual page was updated by Behdad Esfahbod <behdad@behdad.org>.



				 Apr 20, 2010			 FC-PATTERN(1)
","# fc-pattern

> Shows information about a font matching a pattern.

- Display default information about a font:

`fc-pattern -d '{{DejaVu Serif}}'`
"
nmcli-connection,,,,"# nmcli connection

> Connection management with NetworkManager.

- List all NetworkManager connections (shows name, uuid, type and device):

`nmcli connection`

- Activate a connection by specifying an uuid:

`nmcli connection up uuid {{uuid}}`

- Deactivate a connection:

`nmcli connection down uuid {{uuid}}`

- Create an auto-configured dual stack connection:

`nmcli connection add ifname {{interface_name}} type {{ethernet}} ipv4.method {{auto}} ipv6.method {{auto}}`

- Create a static IPv6-only connection:

`nmcli connection add ifname {{interface_name}} type {{ethernet}} ip6 {{2001:db8::2/64}} gw6 {{2001:db8::1}} ipv6.dns {{2001:db8::1}} ipv4.method {{ignore}}`

- Create a static IPv4-only connection:

`nmcli connection add ifname {{interface_name}} type {{ethernet}} ip4 {{10.0.0.7/8}} gw4 {{10.0.0.1}} ipv4.dns {{10.0.0.1}} ipv6.method {{ignore}}`
"
blkid,,,,"# blkid

> Lists all recognized partitions and their Universally Unique Identifier (UUID).

- List all partitions:

`sudo blkid`

- List all partitions in a table, including current mountpoints:

`sudo blkid -o list`
"
swapoff,,,,"# swapoff

> Disables device or file for swapping.

- Disable a given swap partition:

`swapoff {{/dev/sdb7}}`

- Disable a given swap file:

`swapoff {{path/to/file}}`

- Disable all swap areas:

`swapoff -a`

- Disable swap by label of a device or file:

`swapoff -L {{swap1}}`
"
lastlog,,,"
UTMP(5) 		    BSD File Formats Manual		       UTMP(5)

NAME
     utmp, wtmp, lastlog -- login records (DEPRECATED)

SYNOPSIS
     #include <utmp.h>

DESCRIPTION
     The interfaces in file <utmp.h> are all DEPRECATED and are only provided
     for compatibility with previous releases of Mac OS X.  See pututxline(3)
     and utmpx(5) for the supported interfaces.

     <utmp.h> declares the structures used to record information about current
     users in the file utmp, logins and logouts in the file wtmp, and last
     logins in the file lastlog.  The time stamps of date changes, shutdowns
     and reboots are also logged in the wtmp file.

     These files can grow rapidly on busy systems, daily or weekly rotation is
     recommended.  If any of these files do not exist, it is not created.
     These files must be created manually and are normally maintained in
     either the script /etc/daily or the script /etc/weekly.  (See cron(8).)

	   #define _PATH_UTMP	   ""/var/run/utmp""
	   #define _PATH_WTMP	   ""/var/log/wtmp""
	   #define _PATH_LASTLOG   ""/var/log/lastlog""

	   #define UT_NAMESIZE	   8
	   #define UT_LINESIZE	   8
	   #define UT_HOSTSIZE	   16

	   struct lastlog {
		   time_t  ll_time;
		   char    ll_line[UT_LINESIZE];
		   char    ll_host[UT_HOSTSIZE];
	   };

	   struct utmp {
		   char    ut_line[UT_LINESIZE];
		   char    ut_name[UT_NAMESIZE];
		   char    ut_host[UT_HOSTSIZE];
		   time_t  ut_time;
	   };

     Each time a user logs in, the login program looks up the user's UID in
     the file lastlog. If it is found, the timestamp of the last time the user
     logged in, the terminal line and the hostname are written to the standard
     output. (Providing the login is not quiet, see login(1).)	The login pro-
     gram then records the new login time in the file lastlog.

     After the new lastlog record is written , the file utmp is opened and the
     utmp record for the user inserted.  This record remains there until the
     user logs out at which time it is deleted.  The utmp file is used by the
     programs rwho(1), users(1), w(1), and who(1).

     Next, the login program opens the file wtmp, and appends the user's utmp
     record.  The same utmp record, with an updated time stamp is later
     appended to the file when the user logs out. (See launchd(8).)  The wtmp
     file is used by the programs last(1) and ac(8).

     In the event of a date change, a shutdown or reboot, the following items
     are logged in the wtmp file.

     reboot
     shutdown	 A system reboot or shutdown has been initiated.  The charac-
		 ter `~' is placed in the field ut_line, and reboot or
		 shutdown in the field ut_name.  (See shutdown(8) and
		 reboot(8).)

     date	 The system time has been manually or automatically updated.
		 (See date(1).)  The command name date is recorded in the
		 field ut_name.  In the field ut_line, the character `|' indi-
		 cates the time prior to the change, and the character `{'
		 indicates the new time.

FILES
     (These files no longer exist in 10.5 or later.)

     /var/run/utmp     The utmp file.
     /var/log/wtmp     The wtmp file.
     /var/log/lastlog  The lastlog file.

SEE ALSO
     last(1), login(1), who(1), ac(8), launchd(8)

HISTORY
     A utmp and wtmp file format appeared in Version 6 AT&T UNIX.  The lastlog
     file format appeared in 3.0BSD.

4th Berkeley Distribution	March 17, 1994	     4th Berkeley Distribution
","# lastlog

> Show the most recent login of all users or of a given user.

- Display the most recent login of all users:

`lastlog`

- Display lastlog record of the specified user:

`lastlog -u {{username}}`

- Display records before than 7 days:

`lastlog -b {{7}}`

- Display records more recent than 3 days:

`lastlog -t {{3}}`
"
pvs,https://www.man7.org/linux/man-pages/man8/pvs.8.html,"




pvs(8) - Linux manual page









man7.org > Linux > man-pages



Linux/UNIX system programming training






pvs(8) — Linux manual page




NAME | SYNOPSIS | DESCRIPTION | USAGE | OPTIONS | VARIABLES | ENVIRONMENT VARIABLES | NOTES | SEE ALSO | COLOPHON













 



PVS(8)                     System Manager's Manual                    PVS(8)

NAME          top
       pvs - Display information about physical volumes

SYNOPSIS          top
       pvs
           [ option_args ]
           [ position_args ]

DESCRIPTION          top
       pvs produces formatted output about PVs.

USAGE          top
       pvs
           [ -a|--all ]
           [ -o|--options String ]
           [ -S|--select String ]
           [ -O|--sort String ]
           [    --segments ]
           [    --aligned ]
           [    --binary ]
           [    --configreport log|vg|lv|pv|pvseg|seg ]
           [    --foreign ]
           [    --ignorelockingfailure ]
           [    --logonly ]
           [    --nameprefixes ]
           [    --noheadings ]
           [    --nosuffix ]
           [    --readonly ]
           [    --reportformat basic|json ]
           [    --rows ]
           [    --separator String ]
           [    --shared ]
           [    --unbuffered ]
           [    --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E ]
           [    --unquoted ]
           [ COMMON_OPTIONS ]
           [ PV|Tag ... ]

       Common options for lvm:
           [ -d|--debug ]
           [ -h|--help ]
           [ -q|--quiet ]
           [ -t|--test ]
           [ -v|--verbose ]
           [ -y|--yes ]
           [    --commandprofile String ]
           [    --config String ]
           [    --driverloaded y|n ]
           [    --lockopt String ]
           [    --longhelp ]
           [    --nolocking ]
           [    --profile String ]
           [    --version ]

OPTIONS          top
       --aligned
              Use with --separator to align the output columns

       -a|--all
              Show information about devices that have not been initialized
              by LVM, i.e. they are not PVs.

       --binary
              Use binary values ""0"" or ""1"" instead of descriptive literal
              values for columns that have exactly two valid values to
              report (not counting the ""unknown"" value which denotes that
              the value could not be determined).

       --commandprofile String
              The command profile to use for command configuration.  See
              lvm.conf(5) for more information about profiles.

       --config String
              Config settings for the command. These override lvm.conf
              settings.  The String arg uses the same format as lvm.conf, or
              may use section/field syntax.  See lvm.conf(5) for more
              information about config.

       --configreport log|vg|lv|pv|pvseg|seg
              See lvmreport(7).

       -d|--debug ...
              Set debug level. Repeat from 1 to 6 times to increase the
              detail of messages sent to the log file and/or syslog (if
              configured).

       --driverloaded y|n
              If set to no, the command will not attempt to use device-
              mapper.  For testing and debugging.

       --foreign
              Report/display foreign VGs that would otherwise be skipped.
              See lvmsystemid(7) for more information about foreign VGs.

       -h|--help
              Display help text.

       --ignorelockingfailure
              Allows a command to continue with read-only metadata
              operations after locking failures.

       --lockopt String
              Used to pass options for special cases to lvmlockd.  See
              lvmlockd(8) for more information.

       --logonly
              Suppress command report and display only log report.

       --longhelp
              Display long help text.

       --nameprefixes
              Add an ""LVM2_"" prefix plus the field name to the output.
              Useful with --noheadings to produce a list of field=value
              pairs that can be used to set environment variables (for
              example, in udev rules).

       --noheadings
              Suppress the headings line that is normally the first line of
              output.  Useful if grepping the output.

       --nolocking
              Disable locking.

       --nosuffix
              Suppress the suffix on output sizes. Use with --units (except
              h and H) if processing the output.

       -o|--options String
              Comma-separated, ordered list of fields to display in columns.
              String arg syntax is: [+|-|#]Field1[,Field2 ...]  The prefix +
              will append the specified fields to the default fields, - will
              remove the specified fields from the default fields, and #
              will compact specified fields (removing them when empty for
              all rows.)  Use -o help to view the list of all available
              fields.  Use separate lists of fields to add, remove or
              compact by repeating the -o option: -o+field1,field2 -o-
              field3,field4 -o#field5.  These lists are evaluated from left
              to right.  Use field name lv_all to view all LV fields, vg_all
              all VG fields, pv_all all PV fields, pvseg_all all PV segment
              fields, seg_all all LV segment fields, and pvseg_all all PV
              segment columns.  See the lvm.conf report section for more
              config options.  See lvmreport(7) for more information about
              reporting.

       --profile String
              An alias for --commandprofile or --metadataprofile, depending
              on the command.

       -q|--quiet ...
              Suppress output and log messages. Overrides --debug and
              --verbose.  Repeat once to also suppress any prompts with
              answer 'no'.

       --readonly
              Run the command in a special read-only mode which will read
              on-disk metadata without needing to take any locks. This can
              be used to peek inside metadata used by a virtual machine
              image while the virtual machine is running. No attempt will be
              made to communicate with the device-mapper kernel driver, so
              this option is unable to report whether or not LVs are
              actually in use.

       --reportformat basic|json
              Overrides current output format for reports which is defined
              globally by the report/output_format setting in lvm.conf.
              basic is the original format with columns and rows.  If there
              is more than one report per command, each report is prefixed
              with the report name for identification. json produces report
              output in JSON format. See lvmreport(7) for more information.

       --rows
              Output columns as rows.

       --segments
              Produces one line of output for each contiguous allocation of
              space on each PV, showing the start (pvseg_start) and length
              (pvseg_size) in units of physical extents.

       -S|--select String
              Select objects for processing and reporting based on specified
              criteria.  The criteria syntax is described by --select help
              and lvmreport(7).  For reporting commands, one row is
              displayed for each object matching the criteria.  See
              --options help for selectable object fields.  Rows can be
              displayed with an additional ""selected"" field (-o selected)
              showing 1 if the row matches the selection and 0 otherwise.
              For non-reporting commands which process LVM entities, the
              selection is used to choose items to process.

       --separator String
              String to use to separate each column. Useful if grepping the
              output.

       --shared
              Report/display shared VGs that would otherwise be skipped when
              lvmlockd is not being used on the host.  See lvmlockd(8) for
              more information about shared VGs.

       -O|--sort String
              Comma-separated ordered list of columns to sort by. Replaces
              the default selection. Precede any column with - for a reverse
              sort on that column.

       -t|--test
              Run in test mode. Commands will not update metadata.  This is
              implemented by disabling all metadata writing but nevertheless
              returning success to the calling function. This may lead to
              unusual error messages in multi-stage operations if a tool
              relies on reading back metadata it believes has changed but
              hasn't.

       --unbuffered
              Produce output immediately without sorting or aligning the
              columns properly.

       --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E
              All sizes are output in these units: human-(r)eadable with '<'
              rounding indicator, (h)uman-readable, (b)ytes, (s)ectors,
              (k)ilobytes, (m)egabytes, (g)igabytes, (t)erabytes,
              (p)etabytes, (e)xabytes.  Capitalise to use multiples of 1000
              (S.I.) instead of 1024.  Custom units can be specified, e.g.
              --units 3M.

       --unquoted
              When used with --nameprefixes, output values in the
              field=value pairs are not quoted.

       -v|--verbose ...
              Set verbose level. Repeat from 1 to 4 times to increase the
              detail of messages sent to stdout and stderr.

       --version
              Display version information.

       -y|--yes
              Do not prompt for confirmation interactively but always assume
              the answer yes. Use with extreme caution.  (For automatic no,
              see -qq.)

VARIABLES          top
       PV
              Physical Volume name, a device path under /dev.  For commands
              managing physical extents, a PV positional arg generally
              accepts a suffix indicating a range (or multiple ranges) of
              physical extents (PEs). When the first PE is omitted, it
              defaults to the start of the device, and when the last PE is
              omitted it defaults to end.  Start and end range (inclusive):
              PV[:PE-PE]...  Start and length range (counting from 0):
              PV[:PE+PE]...

       Tag
              Tag name.  See lvm(8) for information about tag names and
              using tags in place of a VG, LV or PV.

       String
              See the option description for information about the string
              content.

       Size[UNIT]
              Size is an input number that accepts an optional unit.  Input
              units are always treated as base two values, regardless of
              capitalization, e.g. 'k' and 'K' both refer to 1024.  The
              default input unit is specified by letter, followed by |UNIT.
              UNIT represents other possible input units: bBsSkKmMgGtTpPeE.
              b|B is bytes, s|S is sectors of 512 bytes, k|K is kilobytes,
              m|M is megabytes, g|G is gigabytes, t|T is terabytes, p|P is
              petabytes, e|E is exabytes.  (This should not be confused with
              the output control --units, where capital letters mean
              multiple of 1000.)

ENVIRONMENT VARIABLES          top
       See lvm(8) for information about environment variables used by lvm.
       For example, LVM_VG_NAME can generally be substituted for a required
       VG parameter.

NOTES          top
       The pv_attr bits are:

       1  (d)uplicate, (a)llocatable, (u)sed

       2  e(x)ported

       3  (m)issing

SEE ALSO          top
       lvm(8) lvm.conf(5) lvmconfig(8)

       pvchange(8) pvck(8) pvcreate(8) pvdisplay(8) pvmove(8) pvremove(8)
       pvresize(8) pvs(8) pvscan(8)

       vgcfgbackup(8) vgcfgrestore(8) vgchange(8) vgck(8) vgcreate(8)
       vgconvert(8) vgdisplay(8) vgexport(8) vgextend(8) vgimport(8)
       vgimportclone(8) vgmerge(8) vgmknodes(8) vgreduce(8) vgremove(8)
       vgrename(8) vgs(8) vgscan(8) vgsplit(8)

       lvcreate(8) lvchange(8) lvconvert(8) lvdisplay(8) lvextend(8)
       lvreduce(8) lvremove(8) lvrename(8) lvresize(8) lvs(8) lvscan(8)

       lvm-fullreport(8) lvm-lvpoll(8) lvm2-activation-generator(8)
       blkdeactivate(8) lvmdump(8)

       dmeventd(8) lvmpolld(8) lvmlockd(8) lvmlockctl(8) cmirrord(8)
       lvmdbusd(8)

       lvmsystemid(7) lvmreport(7) lvmraid(7) lvmthin(7) lvmcache(7)

COLOPHON          top
       This page is part of the lvm2 (Logical Volume Manager 2) project.
       Information about the project can be found at 
       â¨http://www.sourceware.org/lvm2/â©.  If you have a bug report for this
       manual page, see â¨https://github.com/lvmteam/lvm2/issuesâ©.  This page
       was obtained from the tarball
       https://github.com/lvmteam/lvm2/archive/v2_03_10.tar.gz fetched from
       â¨https://github.com/lvmteam/lvm2/releasesâ© on 2020-08-13.  If you
       discover any rendering problems in this HTML version of the page, or
       you believe there is a better or more up-to-date source for the page,
       or you have corrections or improvements to the information in this
       COLOPHON (which is not part of the original manual page), send a mail
       to man-pages@man7.org

Red Hat, Inc.         LVM TOOLS 2.03.10(2) (2020-08-09)               PVS(8)


Pages that refer to this page: 
    lvmreport(7),  
    fullreport(8),  
    lvchange(8),  
    lvconvert(8),  
    lvcreate(8),  
    lvdisplay(8),  
    lvextend(8),  
    lvm(8),  
    lvm-config(8),  
    lvmconfig(8),  
    lvmdiskscan(8),  
    lvm-dumpconfig(8),  
    lvm-fullreport(8),  
    lvm-lvpoll(8),  
    lvpoll(8),  
    lvreduce(8),  
    lvremove(8),  
    lvrename(8),  
    lvresize(8),  
    lvs(8),  
    lvscan(8),  
    pvchange(8),  
    pvck(8),  
    pvcreate(8),  
    pvdisplay(8),  
    pvmove(8),  
    pvremove(8),  
    pvresize(8),  
    pvs(8),  
    pvscan(8),  
    vgcfgbackup(8),  
    vgcfgrestore(8),  
    vgchange(8),  
    vgck(8),  
    vgconvert(8),  
    vgcreate(8),  
    vgdisplay(8),  
    vgexport(8),  
    vgextend(8),  
    vgimport(8),  
    vgimportclone(8),  
    vgmerge(8),  
    vgmknodes(8),  
    vgreduce(8),  
    vgremove(8),  
    vgrename(8),  
    vgs(8),  
    vgscan(8),  
    vgsplit(8)








            HTML rendering created 2020-08-13
            by Michael Kerrisk, 
            author of 
            The Linux Programming Interface, 
            maintainer of the 
            Linux man-pages project.
        

            For details of in-depth
            Linux/UNIX system programming training courses
            that I teach, look here.
        

            Hosting by jambit GmbH.
        



























",,"# pvs

> Display information about LVM physical volumes.
> More information: <https://www.man7.org/linux/man-pages/man8/pvs.8.html>.

- Display information about physical volumes:

`pvs`

- Display non-physical volumes:

`pvs -a`

- Change default display to show more details:

`pvs -v`

- Display only specific fields:

`pvs -o {{field_name_1}},{{field_name_2}}`

- Append field to default display:

`pvs -o +{{field_name}}`

- Suppress heading line:

`pvs --noheadings`

- Use separator to separate fields:

`pvs --separator {{special_character}}`
"
lslocks,,,,"# lslocks

> List local system locks.

- List all local system locks:

`lslocks`

- List locks with defined column headers:

`lslocks --output {{PID}},{{COMMAND}},{{PATH}}`

- List locks producing a raw output (no columns), and without column headers:

`lslocks --raw --noheadings`

- List locks by PID input:

`lslocks --pid {{PID}}`

- List locks with json output to `stdout`:

`lslocks --json`
"
pasuspender,,,,"# pasuspender

> Temporarily suspends `pulseaudio` while another command is running to allow access to alsa.

- Suspend pulseaudio while running `jackd`:

`pasuspender -- {{jackd -d alsa --device hw:0}}`
"
timeshift,https://github.com/teejee2008/timeshift,"













GitHub - teejee2008/timeshift: System restore tool for Linux. Creates filesystem snapshots using rsync+hardlinks, or BTRFS snapshots. Supports scheduled snapshots, multiple backup levels, and exclude filters. Snapshots can be restored while system is running or from Live CD/USB.








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















teejee2008

/

timeshift







    Watch
 
      72
    




      Star


      2.3k
    




          Fork


        194
      





        System restore tool for Linux. Creates filesystem snapshots using rsync+hardlinks, or BTRFS snapshots. Supports scheduled snapshots, multiple backup levels, and exclude filters. Snapshots can be restored while system is running or from Live CD/USB.
      



            View license
        




2.3k
        stars
 

194
        forks
 




      Star





    Watch









Code

 



Issues
305
 



Pull requests
17
 



Actions

 



Projects
0
 



Wiki

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Wiki
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



15
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




teejee2008

Merge remote-tracking branch 'origin/master'



…



2e2a291

Sep 8, 2020





Merge remote-tracking branch 'origin/master'


2e2a291



Git stats





884
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.github/ISSUE_TEMPLATE



Update issue templates



Sep 8, 2020







debian



v20.03



Mar 5, 2020







files



Include default config file in package; Install to /etc/timeshift.json;



Sep 24, 2017







icons



Installer: Fixed libgee dependency for arch; Updated main icon; Added…



Oct 7, 2016







images



Updated README; Added section on supported system types;



Nov 5, 2017







man



Fix build error



Aug 11, 2019







po



Merge pull request #601 from marcuscf/master



May 13, 2020







release



Fedora: Added 'psmisc' dependency for installer



Apr 7, 2018







src



v20.03



Mar 5, 2020







.bzrignore



Added and updated translations



Nov 5, 2017







.gitignore



Minor changes



Feb 9, 2020







AUTHORS



Initial release



Oct 5, 2013







BUILD_CONFIG



Update build scripts; Use the new Sanity installer;



Sep 17, 2017







COPYING



Initial release



Oct 5, 2013







INSTALL



Updated build scripts



Oct 15, 2017







LICENSE.md



Updated build scripts



Oct 15, 2017







NOTES



Updated build scripts



Oct 15, 2017







README.md



Updated support message



Sep 8, 2020







_config.yml



Set theme jekyll-theme-cayman



Oct 6, 2017







build-deb.sh



Check existence necessary executables



Mar 26, 2018







build-installers.sh



Check existence necessary executables



Mar 26, 2018







build-source.sh



Check existence necessary executables



Mar 26, 2018







makefile



Fix build error



Aug 11, 2019







makepot



update translation template & complete German translation



Nov 13, 2018







merge-launchpad-translations.sh



Added a script for merging launchpad translations



Feb 3, 2018







timeshift.geany



Update support section in README



Sep 8, 2020







timeshift.pot



Minor changes



Feb 9, 2020





        View code
      






        README.md
      


Timeshift
Timeshift for Linux is an application that provides functionality similar to the System Restore feature in Windows and the Time Machine tool in Mac OS. Timeshift protects your system by taking incremental snapshots of the file system at regular intervals. These snapshots can be restored at a later date to undo all changes to the system.
In RSYNC mode, snapshots are taken using rsync and hard-links. Common files are shared between snapshots which saves disk space. Each snapshot is a full system backup that can be browsed with a file manager.
In BTRFS mode, snapshots are taken using the in-built features of the BTRFS filesystem. BTRFS snapshots are supported only on BTRFS systems having an Ubuntu-type subvolume layout (with @ and @home subvolumes).
Timeshift is similar to applications like rsnapshot, BackInTime and TimeVault but with different goals. It is designed to protect only system files and settings. User files such as documents, pictures and music are excluded. This ensures that your files remains unchanged when you restore your system to an earlier date. If you need a tool to backup your documents and files please take a look at the excellent BackInTime application which is more configurable and provides options for saving user files.

Features
Minimal Setup


Timeshift requires very little setup. Just install it, run it for the first time and take the first snapshot. Cron job can be enabled for taking automatic snapshots of the system at regular intervals. The backup levels can be selected from the Settings window.


Snapshots are saved by default on the system (root) partition in path /timeshift. Other linux partitions can also be selected. For best results the snapshots should be saved to an external (non-system) partition.



Multiple Snapshot Levels


Multiple levels of snapshots can be enabled - Hourly, Daily, Weekly, Monthly and Boot


Number of snapshots to retain can be specified for each level


Boot snapshots provide an additional level of backup and are created every time the system starts. Boot snapshots are created with a delay of 10 mins so that system startup is not affected.



Rsync & BTRFS Snapshots


Supports rsync snapshots on all systems


Supports BTRFS snapshots on BTRFS systems


It is strongly recommended to use BTRFS snapshots on systems that are installed on BTRFS partition. BTRFS snapshots are perfect byte-for-byte copies of the system. Nothing is excluded. BTRFS snapshots can be created and restored in seconds, and have very low overhead in terms of disk space.


User Data is Excluded by Default
Timeshift is designed to protect system files and settings. It is NOT a backup tool and is not meant to protect user data. Entire contents of users' home directories are excluded by default. This has two advantages:

You don't need to worry about your documents getting overwritten when you restore a previous snapshot to recover the system.
Your music and video collection in your home directory will not waste space on the backup device.

You can selectively include items for backup from the Settings window. Selecting the option ""Include hidden items"" from the Users tab will backup and restore the .hidden files and directories in your home folder. These folders contain user-specific config files and can be included in snapshots if required.
Note: It is not recommended to include user data in backups as it will be overwritten when you restore the snapshot.


Better Snapshots & Rotation

Unlike similar tools that are scheduled to take backups at a fixed time of the day, Timeshift is designed to run once every hour and take snapshots only when a snapshot is due. This is more suitable for desktop users who keep their laptops and desktops switched on for few hours daily. Scheduling snapshots at a fixed time on such users will result in missed backups since the system may not be running when the snapshot is scheduled to run. By running once every hour and creating snapshots when due, Timeshift ensures that backups are not missed.
Applications like rsnapshot rotate a snapshot to the next level by creating a hard-linked copy. Creating a hard-linked copy may seem like a good idea but it is still a waste of disk space, since only files can be hard-linked and not directories. The duplicated directory structure can take up as much as 100 MB of space. Timeshift avoids this wastage by using tags for maintaining backup levels. Each snapshot will have only one copy on disk and is tagged as ""daily"", ""monthly"", etc. The snapshot location will have a set of folders for each backup level (""Monthly"", ""Daily"", etc) with symbolic links pointing to the actual snapshots tagged with the level.

System Restore


Snapshots can be restored by selecting a snapshot from the main window and clicking Restore button on the toolbar.


Snapshots can be restored either from the running system (online restore) or from another system that has Timeshift installed on it (offline restore).


If the main system is not bootable, then it is possible to boot from an Ubuntu Live CD, install Timeshift on the live system, and restore a snapshot on the main system.


Restoring backups from the running system requires a reboot to complete the restore process.



Cross-Distribution Restore

You can also Timeshift across distributions. Let's say you are currently using Xubuntu and decide to try out Linux Mint. You install Linux Mint on your system and try it out for a week before deciding to go back to Xubuntu. Using Timeshift you can simply restore the last week's snapshot to get your Xubuntu system back. Timeshift will take care of things like reinstalling the bootloader and other details.
Since installing a new linux distribution also formats your root partition you need to save your snapshots on a separate linux partition for this to work.
It is recommended to include hidden items in home directory by selecting the option ""Include  Hidden Items"" from Settings > Users.

Supported System Configurations


Normal - OS installed on non-encrypted partitions


LUKS Encrypted - OS installed on LUKS-encrypted partitions


LVM2 - OS installed on LVM2 volumes (with or without LUKS)


BTRFS - OS installed on BTRFS volumes (with or without LUKS)

Only Ubuntu-type layouts with @ and @home subvolumes are supported
@ and @home subvolumes may be on same or different BTRFS volumes
@ may be on BTRFS volume and /home may be mounted on non-BTRFS partition
Other layouts are not supported



GRUB2 - Bootloader must be GRUB2. GRUB legacy and other bootloaders are not supported.


EFI - EFI systems are supported. Make sure that /boot/efi partition is selected for mounting before restoring snapshots (application will do it automatically).


Encrypted Home - For users with encrypted home, files in /home/.ecryptfs/$USER will be backed-up and restored. The decrypted contents in $HOME will be excluded. This avoids the security risk of decrypted contents becoming available outside the user's home directory.


Encrypted Private Directory - For users with encrypted Private directory, the encrypted files in $HOME/.Private, as well as the decrypted files in $HOME/Private, will be excluded (as it contains user data). Filters added by user to include files from $HOME/.Private or $HOME/Private will be ignored.


Docker & Containers - Docker and containerized systems are not supported. Running Timeshift on such systems will have unpredictable results.


Installation
Ubuntu-based Distributions
Ubuntu, Linux Mint, Elementary OS, etc.
Packages are available in the Launchpad PPA for supported Ubuntu releases.
Run the following commands in a terminal window:
sudo add-apt-repository -y ppa:teejee2008/timeshift
sudo apt-get update
sudo apt-get install timeshift
DEB packages are available on Releases page for older Ubuntu releases which have reached end-of-life.
Fedora
sudo dnf update
sudo dnf install timeshift
Installer can be used on the following distribution types:

Debian based - Debian, Ubuntu, Linux Mint, Elementary OS, etc (supports apt)
Arch based - Arch Linux, Manjaro, etc (supports pacman)

UnInstall
Run the following command in a terminal window:
sudo apt-get remove timeshift

or
sudo timeshift-uninstall

Remember to delete all snapshots before un-installing. Otherwise the snapshots continue to occupy space on your system.  To delete all snapshots, run the application, select all snapshots from the list (CTRL+A) and click the Delete button on the toolbar. This will delete all snapshots and remove the /timeshift folder in the root directory.
If you used the installer to install Timeshift, you can remove the installed files with following command:
sudo timeshift-uninstall

Known Issues & Limitations
BTRFS volumes
BTRFS volumes must have an Ubuntu-type layout with @ and @home subvolumes. Other layouts are not supported. Systems having the @ subvolume and having /home on a non-BTRFS partition are also supported.
Disk Space
Timeshift requires a lot of disk space to keep snapshot data. The device selected as snapshot device must have sufficient free space to store the snapshots that will be created.
If the backup device is running out of space, try the following steps:

Reduce the number of backup levels - Uncheck the backup levels and keep only one selected
Reduce the number of snapshots that are kept - In the Schedule tab set the number of snapshots to 5 or less.
You can also disable scheduled snapshots completely and create snapshots manually when required

Bootloader & EFI

Only those systems are supported which use GRUB2 bootloader. Trying to create and restore snapshots on a system using older versions of GRUB will result in a non-bootable system.
EFI systems are fully supported. Ensure that the /boot/efi partition is mapped while restoring a snapshot. It will be mapped automatically if detected.
If you are restoring from Live CD/USB, and your installed system uses EFI mode, then you must boot from Live CD/USB in EFI mode.

Support
If you use Linux Mint and need support for an issue please use the Linux Mint support forums
Issues reported on the Issue Tracker will be fixed during the next update. Please do not expect a response as the tracker is checked once a year when the app is being updated.
Disclaimer
This program is free for personal and commercial use and comes with absolutely no warranty. You use this program entirely at your own risk. The author will not be liable for any damages arising from the use of this program. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
Contribute
You can contribute to this project in various ways:

Submitting ideas, and reporting issues in the tracker
Translating this application to other languages
Contributing code changes by fixing issues and submitting a pull request
Making a donation via PayPal or bitcoin

Donate
Timeshift is a non-commercial application. I work on it during my free time based on my requirements and interest. If you wish to support this project, you can make a donation for $10 or more via PayPal. Your contributions will help keep the project alive.
PayPal

Bitcoin ~ You can send bitcoins at this address or by scanning the QR code below:
1KdEyJjkuEW8aZWjenf4x5uEeHo9VTYqio









About

      System restore tool for Linux. Creates filesystem snapshots using rsync+hardlinks, or BTRFS snapshots. Supports scheduled snapshots, multiple backup levels, and exclude filters. Snapshots can be restored while system is running or from Live CD/USB.
    
Resources



      Readme
 
License



        View license
    







    Releases
      15





v20.03

          Latest
 
Mar 5, 2020

 

        + 14 releases







    Packages 0


        No packages published 













    Contributors 45





 



 



 



 



 



 



 



 



 



 



 



      + 34 contributors





Languages










Vala
98.0%





Shell
1.2%





Makefile
0.8%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# timeshift

> System restore utility.
> More information: <https://github.com/teejee2008/timeshift>.

- List snapshots:

`sudo timeshift --list`

- Create a new snapshot (if scheduled):

`sudo timeshift --check`

- Create a new snapshot (even if not scheduled):

`sudo timeshift --create`

- Restore a snapshot (selecting which snapshot to restore interactively):

`sudo timeshift --restore`

- Restore a specific snapshot:

`sudo timeshift --restore --snapshot '{{snapshot}}'`

- Delete a specific snapshot:

`sudo timeshift --delete --snapshot '{{snapshot}}'`
"
add-apt-repository,,,,"# add-apt-repository

> Manages apt repository definitions.

- Add a new apt repository:

`add-apt-repository {{repository_spec}}`

- Remove an apt repository:

`add-apt-repository --remove {{repository_spec}}`

- Update the package cache after adding a repository:

`add-apt-repository --update {{repository_spec}}`

- Enable source packages:

`add-apt-repository --enable-source {{repository_spec}}`
"
guix-package,,,,"# guix package

> Install, upgrade and remove Guix packages, or rollback to previous configurations.

- Install a new package:

`guix package -i {{package_name}}`

- Remove a package:

`guix package -r {{package_name}}`

- Search the package database for a regular expression:

`guix package -s ""{{search_pattern}}""`

- List installed packages:

`guix package -I`

- List generations:

`guix package -l`

- Roll back to the previous generation:

`guix package --roll-back`
"
playerctl,https://github.com/altdesktop/playerctl,"













GitHub - altdesktop/playerctl: 🎧 mpris command-line controller and library for vlc, audacious, bmp, cmus, spotify and others.








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















altdesktop

/

playerctl







    Watch
 
      25
    




      Star


      1.1k
    




          Fork


        57
      





🎧 mpris command-line controller and library for vlc, audacious, bmp, cmus, spotify and others.
      



dubstepdish.com/index.php/2018/10/21/playerctl-at-version-2-0/





            LGPL-3.0 License
        




1.1k
        stars
 

57
        forks
 




      Star





    Watch









Code

 



Issues
15
 



Pull requests
0
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














3
branches



16
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




acrisci

Merge pull request #185 from erzoe/master



…



9b49fd7

Aug 17, 2020





Merge pull request #185 from erzoe/master

readme: required plugin in Quod Libet

9b49fd7



Git stats





404
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.github/ISSUE_TEMPLATE



Update issue templates



Jun 14, 2019







data



fix invalid free in listing system players



May 15, 2020







doc



update man page for emoji function



Jan 29, 2020







examples



format the project



Jan 15, 2020







playerctl



add tests for playerctld shift error conditions



Jun 4, 2020







test



add tests for playerctld shift error conditions



Jun 4, 2020







.clang-format



clang-format the project



Sep 26, 2018







.dockerignore



fix dockerignore format



Jun 22, 2019







.flake8



refactor tests



Jan 25, 2020







.gitignore



Add a basic test suit



May 1, 2019







.travis.yml



Add a basic test suit



May 1, 2019







CHANGELOG.md



bump to version 2.2.1



Aug 8, 2020







CONTRIBUTORS



CONTRIBUTORS: add myself



May 22, 2018







COPYING



Relicense under LGPL



Apr 27, 2014







Dockerfile



fix invalid free in listing system players



May 15, 2020







Makefile



refactor tests



Jan 25, 2020







README.md



readme: required plugin in Quod Libet



Aug 16, 2020







fpm-packages.sh



create dist packages is post release script



Aug 9, 2020







letter-to-spotify-support.md



add letter to spotify customer support



May 20, 2020







meson.build



bump to version 2.2.1



Aug 8, 2020







meson_options.txt



dont install bash completions by default



Jan 31, 2020







pytest.ini



Add a basic test suit



May 1, 2019







requirements.txt



test: update to dbus-next 0.1.1



Jun 2, 2019





        View code
      






        README.md
      








Playerctl
For true players only: vlc, audacious, bmp, xmms2, spotify and others.
About
Playerctl is a command-line utility and library for controlling media players that implement the MPRIS D-Bus Interface Specification. Playerctl makes it easy to bind player actions, such as play and pause, to media keys. You can also get metadata about the playing track such as the artist and title for integration into statusline generators or other command-line tools.
For more advanced users, Playerctl provides an introspectable library available in your favorite scripting language that allows more detailed control like the ability to subscribe to media player events or get metadata such as artist and title for the playing track.
Chat
Using the CLI
playerctl [--version] [--list-all] [--all-players] [--player=NAME] [--ignore-player=IGNORE] [--format=FORMAT] COMMAND

Here is a list of available commands:



Command
Description




play
Command the player to play.


pause
Command the player to pause


play-pause
Command the player to toggle between play/pause.


stop
Command the player to stop.


next
Command the player to skip to the next track.


previous
Command the player to skip to the previous track.


position [OFFSET][+/-]
Command the player to go to the position or seek forward or backward OFFSET in seconds.


volume [LEVEL][+/-]
Print or set the volume to LEVEL from 0.0 to 1.0.


status
Get the play status of the player. Either ""Playing"", ""Paused"", or ""Stopped"".


metadata [KEY...]
Print the metadata for the current track. If KEY is passed, print only those values from the metadata.


open [URI]
Command for the player to open a given URI. Can be either a file path or a remote URL.


loop [STATUS]
Print or set the loop status. Either ""None"", ""Track"", or ""Playlist"".


shuffle [STATUS]
Print or set the shuffle status. Either ""On"", ""Off"".



Selecting Players to Control
Without specifying any players to control, Playerctl will act on the first player it can find.
You can list the names of players that are available to control that are running on the system with playerctl --list-all.
If you'd only like to control certain players, you can pass the names of those players separated by commas with the --player flag. Playerctl will select the first instance of a player in that list that supports the command. To control all players in the list, you can use the --all-players flag.
Similarly, you can ignore players by passing their names with the --ignore-player flag.
The special player name %any can be used in the list of selected players once to match any player not in the list. This can be used to prioritize or deprioritize players.
Examples:
# Command the first instance of VLC to play
playerctl --player=vlc play

# Command all players to stop
playerctl --all-players stop

# Command VLC to go to the next track if it's running. If it's not, send the
# command to Spotify.
playerctl --player=vlc,spotify next

# Get the status of the first player that is not Gwenview.
playerctl --ignore-player=Gwenview status

# Command any player to play, but select Chromium last
playerctl --player=%any,chromium play

# Command any player to play, but select VLC first
playerctl --player=vlc,%any play
Selecting the Most Recent Player
Playerctl comes with a service called playerctld you can use that monitors the activity of media players to select the one with the most recent activity. To use it, simply pass playerctld as the selected player to Playerctl and the service should start automatically (if it doesn't, see the troubleshooting section).
# Command the most recent player to play
playerctl --player=playerctld play

Printing Properties and Metadata
You can pass a format string with the --format argument to print properties in a specific format. Pass the variable you want to print in the format string between double braces like {{ VARIABLE }}. The variables available are either the name of the query command, or anything in the metadata map which can be viewed with playerctl metadata. You can use this to integrate playerctl into a statusline generator.
For a simple ""now playing"" banner:
playerctl metadata --format ""Now playing: {{ artist }} - {{ album }} - {{ title }}""
# prints 'Now playing: Lana Del Rey - Born To Die - Video Games'
Included in the template language are some built-in variables and helper functions for common formatting that you can call on template variables.
# Prints 'Total length: 3:23'
playerctl metadata --format ""Total length: {{ duration(mpris:length) }}""

# Prints 'At position: 1:16'
playerctl position --format ""At position: {{ duration(position) }}""

# Prints 'Artist in lowercase: lana del rey'
playerctl metadata --format ""Artist in lowercase: {{ lc(artist) }}""

# Prints 'STATUS: PLAYING'
playerctl status --format ""STATUS: {{ uc(status) }}""



Function
Argument
Description




lc
string
Convert the string to lowercase.


uc
string
Convert the string to uppercase.


duration
int
Convert the duration to hh:mm:ss format.


markup_escape
string
Escape XML markup characters in the string.


default
any, any
Print the first value if it is present, or else print the second.


emoji
status or volume
Try to convert the variable to an emoji representation.






Variable
Description




playerName
The name of the current player.


position
The position of the current track in microseconds


status
The playback status of the current player


volume
The volume from 0.0 to 1.0


album
The album of the current track.


artist
The artist of the current track.


title
The title of the current track.



Following changes
You can pass the --follow flag to query commands to block, wait for players to connect, and print the query whenever it changes. If players are passed with --player, players earlier in the list will be preferred in the order they appear unless --all-players is passed. When no player can support the query, such as when all the players exit, a newline will be printed. For example, to be notified of information about the latest currently playing track for your media players, use:
playerctl metadata --format '{{ playerName }}: {{ artist }} - {{ title }} {{ duration(position) }}|{{ duration(mpris:length) }}' --follow
Using the Library
To use a scripting library, find your favorite language from this list and install the bindings library. Documentation for the library is hosted here. For examples on how to use the library, see the examples folder.
Example Python Script
This example uses the Python bindings.
#!/usr/bin/env python3

from gi.repository import Playerctl, GLib

player = Playerctl.Player('vlc')


def on_metadata(player, metadata):
    if 'xesam:artist' in metadata.keys() and 'xesam:title' in metadata.keys():
        print('Now playing:')
        print('{artist} - {title}'.format(
            artist=metadata['xesam:artist'][0], title=metadata['xesam:title']))


def on_play(player, status):
    print('Playing at volume {}'.format(player.props.volume))


def on_pause(player, status):
    print('Paused the song: {}'.format(player.get_title()))


player.connect('status::playing', on_play)
player.connect('status::paused', on_pause)
player.connect('metadata', on_metadata)

# start playing some music
player.play()

if player.get_artist() == 'Lana Del Rey':
    # I meant some good music!
    player.next()

# wait for events
main = GLib.MainLoop()
main.run()
For a more complete example which is capable of listening to when players start and exit, see player-manager.py from the official examples.
Troubleshooting
Debug Logging
To enable debug logging, set the environment variable G_MESSAGES_DEBUG=playerctl. It's helpful to include a debug log when you report issues.
No Players Found
If you are using Quod Libet as your music player you need to install/activate a plugin for it.
In Quod Libet open the window File -> Plugins and select the plugin called MPRIS D-Bus Support.
Some players like Spotify require certain DBus environment variables to be set which are normally set within the session manager. If you're not using a session manager or it does not set these variables automatically (like xinit), launch your desktop environment wrapped in a dbus-launch command. For example, in your .xinitrc file, use this to start your WM:
exec dbus-launch --autolaunch=$(cat /var/lib/dbus/machine-id) i3

Playerctld Autostart Issues
If playerctld does not autostart and you use xinit and systemd, you might need this fix to enable DBus activation to work correctly:
systemctl --user import-environment DISPLAY XAUTHORITY

if which dbus-update-activation-environment >/dev/null 2>&1; then
        dbus-update-activation-environment DISPLAY XAUTHORITY
fi

Installing
First, check and see if Playerctl is available from your package manager (if it is not, get someone to host a package for you) and also check the releases page on github.
Fedora
playerctl is available for Fedora 28 or later:
sudo dnf install playerctl

Mageia, openSUSE
playerctl is available for Mageia and openSUSE via this COPR repository. First, install the repository file for your distribution from COPR. Then, install playerctl with your package manager of choice.
Guix
playerctl is available as a Guix package which can be installed on any Linux distribution after installing Guix:
guix install playerctl

Compile from source
Using the cli and library requires GLib (which is a dependency of almost all of these players as well, so you probably already have it). You can use the library in almost any programming language with the associated introspection binding library.
Additionally, you also need the following build dependencies:
gobject-introspection for building introspection data (configurable with the introspection meson option)
gtk-doc for building documentation (configurable with the gtk-doc meson option)
Fedora users also need to install redhat-rpm-config
To generate and build the project to contribute to development and install playerctl to /:
meson mesonbuild
sudo ninja -C mesonbuild install

Note that you need meson >= 0.50.0 installed. In case your distro only has an older version of meson in its repository you can install the newest version via pip:
pip3 install meson

Also keep in mind that gtk-doc and gobject-introspection are enabled by default, you can disable them with -Dintrospection=false and -Dgtk-doc=false.
If you don't want to install playerctl to / you can install it elsewhere by exporting DESTDIR before invoking ninja, e.g.:
export PREFIX=""/usr/local""
meson --prefix=""${PREFIX}"" --libdir=""${PREFIX}/lib"" mesonbuild
export DESTDIR=""$(pwd)/install""
ninja -C mesonbuild install

You can use it later on by exporting the following variables:
export LD_LIBRARY_PATH=""$DESTDIR/${PREFIX}/lib/:$LD_LIBRARY_PATH""
export GI_TYPELIB_PATH=""$DESTDIR/${PREFIX}/lib/:$GI_TYPELIB_PATH""
export PATH=""$DESTDIR/${PREFIX}/bin:$PATH""

Resources
Check out the following articles about Playerctl:

2 new apps for music tweakers on Fedora Workstation - Fedora Magazine
Playerctl at Version 2.0

Related projects from the maker of Playerctl:

altdesktop/python-dbus-next - The DBus library used in the Playerctl test suite.
altdesktop/playerbm - A CLI bookmark utility for audiobooks and podcasts.
dbusjs/mpris-service - MPRIS implementation for JavaScript targeting Electron apps.

License
This work is available under the GNU Lesser General Public License (See COPYING).
Copyright © 2014, Tony Crisci








About

🎧 mpris command-line controller and library for vlc, audacious, bmp, cmus, spotify and others.
    



dubstepdish.com/index.php/2018/10/21/playerctl-at-version-2-0/


Topics



  mpris


  cli


  vlc


  mediaplayer


  c


  cmus


  mopidy


  audacious


  rhythmbox


  mpd



Resources



      Readme
 
License



        LGPL-3.0 License
    







    Releases
      16





Version 2.2.1

          Latest
 
Aug 8, 2020

 

        + 15 releases







    Packages 0


        No packages published 













    Contributors 24





 



 



 



 



 



 



 



 



 



 



 



      + 13 contributors





Languages












C
83.7%





Python
12.4%





Meson
2.1%





Shell
1.2%





Other
0.6%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# playerctl

> Utility to control different media players.
> More information: <https://github.com/altdesktop/playerctl>.

- Toggle play:

`playerctl play-pause`

- Next media:

`playerctl next`

- Previous media:

`playerctl previous`

- List all players:

`playerctl --list-all`

- Send a command to a specific player:

`playerctl --player={{player_name}} {{command}}`

- Send a command to all players:

`playerctl --all-players {{command}}`

- Show now playing:

`playerctl metadata --format ""Now playing: {{artist}} - {{album}} - {{title}}""`
"
lsb_release,,,,"# lsb_release

> Provides certain LSB (Linux Standard Base) and distribution-specific information.

- Print all available information:

`lsb_release -a`

- Print a description (usually the full name) of the operating system:

`lsb_release -d`

- Print only the operating system name (ID), suppressing the field name:

`lsb_release -i -s`

- Print the release number and codename of the distribution, suppressing the field names:

`lsb_release -rcs`
"
opkg,,,,"# opkg

> A lightweight package manager used to install OpenWrt packages.

- Install a package:

`opkg install {{package}}`

- Remove a package:

`opkg remove {{package}}`

- Update the list of available packages:

`opkg update`

- Upgrade all the installed packages:

`opkg upgrade`

- Upgrade one or more specific package(s):

`opkg upgrade {{package(s)}}`

- Display informations for a specific package:

`opkg info {{package}}`

- List all the available packages:

`opkg list`
"
usermod,,,,"# usermod

> Modifies a user account.

- Change a user's name:

`usermod -l {{newname}} {{user}}`

- Add user to supplementary groups (mind the whitespace):

`usermod -a -G {{group1,group2}} {{user}}`

- Create a new home directory for a user and move their files to it:

`usermod -m -d {{/path/to/home}} {{user}}`
"
run-mailcap,,,,"# run-mailcap

> Run MailCap Programs.
> Run mailcap view, see, edit, compose, print - execute programs via entries in the mailcap file (or any of its aliases) will use the given action to process each mime-type/file.

- Individual actions/programs on run-mailcap can be invoked with action flag:

`run-mailcap --action=ACTION [--option[=value]]`

- In simple language:

`run-mailcap --action=ACTION {{filename}}`

- Turn on extra information:

`run-mailcap --action=ACTION --debug {{filename}}`

- Ignore any ""copiousoutput"" directive and forward output to standard output:

`run-mailcap --action=ACTION --nopager {{filename}}`

- Display the found command without actually executing it:

`run-mailcap --action=ACTION --norun {{filename}}`
"
lynis,https://cisofy.com/documentation/lynis/,"Lynis Installation and Usage Guide - CISOfySolutionsDemoPricingSupportAboutHomeSupportLynis documentationLynis DocumentationInstallation and Usage
First time user of Lynis? Get Started
Want to read this document offline, or as a PDF? Use the printer icon in the right corner for easy access.Table of ContentsLynis Installation and UsageIntroductionInstallationUsing LynisBasicsCommands, Options, and ArgumentsSuggestions and WarningsBehind the scenesProfilesHostIDsLynis ConfigurationLynis PluginsLynis EnterpriseLynis Enterprise APILynis Enterprise (self-hosted)Lynis CollectorLynisIntroductionLynis is an open source security tool. It helps with auditing systems running UNIX-alike systems (Linux, macOS, BSD), and providing guidance for system hardening and compliance testing. This document contains the basics to use the software.InstallationThe installation of Lynis is explained in the Get Started guide.Using LynisBasicsBy running 'lynis' the program is started and will provide the basic parameters available. If you manually extracted Lynis (or used Git), then use './lynis' to start the program from the local directory.The most common command to start Lynis is using audit system command. This still start the security scan.
To run Lynis you should meet one requirement: have write access to /tmp (temporary files)Commands, Options, and ArgumentsIntroductionThe behavior of programs can influenced with commands, arguments, and options. These terms are often mixed up, so we start with a quick introduction.Commands tell the program what to do. An option tells the program how to do it. If an argument is used, it tell on what it applies. Arguments usually follow an option, like a filename, or a target.Example$ ./lynis audit system --quick --auditor ""The Auditor""In this example we tell Lynis to audit (command), with the target system (argument). By using the --quick (option), we tell it not to wait. We used --auditor (option) and defined it as ""The Auditor"" (argument).Lynis CommandsThe Lynis tool requires a minimum amount of parameters to run. If you are using it for the first time, just run lynis and see what output it provides.$ ./lynisWithout any commands, Lynis will display its status, together with suggestions on how to start.AuditThe audit command tells Lynis to perform an audit.Targets include:system - audit the host systemdockerfile - audit a dockerfileShowThe show command informs Lynis to share information, like help or the value of something.Examples:help - show help and tipsprofiles - show discovered audit profilessettings - show active settingsversion - show Lynis versionParametersIn the table below, the most commonly used parameters are listed.ParameterAbbreviatedDescription--auditor ""Name"" Assign an auditor name to the audit (report)--checkall-cStart the check--check-update Check if Lynis is up-to-date--cronjob Run Lynis as cronjob (includes -c -Q)--help-hShows valid parameters--manpage View man page--nocolors Do not use any colors--pentest Perform a penetration test scan (non-privileged)--quick-QDon't wait for user input, except on errors--quiet Only show warnings (includes --quick, but doesn't wait)--reverse-colors Use a different color scheme for light backgrounds--version-VCheck program version (and quit)TipsIf Lynis is not installed as package (with included man page), use --man or nroff -man ./lynis.8For systems where the shell background is light, use --nocolors or --reverse-colorsUse lynis show options to see all available parameters of LynisProfilesLynis uses profiles to have a set of predefined options for your operating system and preferences. If you don't provide a profile (--profile <name>), the default profile (default.prf) will be used. You are advised to copy the default.prf and adjust it to your needs.With the usage of profiles, you can make a template/baseline for different types of systems.Examples:Profile per operating system (Debian Linux, RedHat Linux, OpenBSD)Profile per system roles (mail server, web server)Profile per security level (low, medium, high level)HostIDsDuring the security audit, Lynis attempts to assign two identifiers to the system. They can be compared as fingerprints and can be used in other tools and to link data to an existing system.Identifiers: hostid and hostid2The first identifier is named hostid and has a length of 40 characters. The MAC address of the system is typically used its data input. The second identifier is hostid2. It is 64 characters long and typically uses a public SSH key a data input.lynis show hostidsOverriding the identifiersIn case your system can not generate the host identifiers automatically, then you can specify them in your custom profile (custom.prf). This can also be useful when systems are short-lived, yet you want to link the same data to such instance.lynis configure settings hostid=$(head -c 64 /dev/random | sha1sum | awk '{print $1}'):hostid2=$(head -c 64 /dev/random | sha256sum | awk '{print $1}')One-liner to generate both IDs and add them to the configurationImportant notesOnly override the host identifiers when really neededMake sure that the identifiers are unique for every individual systemWhen using this option, both values for hostid and hostid2 need to be set in the profileScreen output
While Lynis scans a system it will perform single target tests and output the result of every (performed) test to the screen. Every
scan result has to be interpreted by the auditor and (re)checked what it means.
Behind most tests, it will output [OK] or [WARNING], where the first one is considered an expected (good) result, the second
one unexpected. However, keep in mind that a result saying ""[OK]"" does NOT always mean the scanned target is correctly configured, safe (security wise) or a best practice.
On the opposite, every ""[WARNING]"" doesn't have to be 'bad', since systems (and their requirements) are different. However, as auditor you are adviced to pay attention to them and check what influence the test has on your system or policy. 

Actions you can take after getting a warning:
- Fix the problem
Read the log file about the technical background (often it contains a suggestion at the test), consult internet sources
and documentation about what the impact of the change can be.
- Disable the test (whitelisting)
Within the scan profile, tests can be completely disabled (option test_skip_always).
When you have a test which gives a warning and you are not interested in the result of that particular test, you can ingore it.For example:
You have only one DNS server configured on your workstation. A test
shows a warning and reveals that it expects at least two working name servers. In
such case you can choose not to get informed about it and disable the test. Extend the option test_skip_always
in your scanning profile with the test number (which can be found in the log file or at the end of the Lynis screen output).
 After every scan, the auditor should consult the log file (/var/log/lynis.log) and interpreter the results. If tests are displayed as a ""[WARNING]"",
the log file will  give the reason why a warning was displayed. In most cases a ""Suggestion:"" line will be present, to assist in resolving the issue or give more information what was tested (or expected).Suggestions and WarningsThe screen output, as outlined in previous section, will provide the status of most tests on screen. During the audit proces, Lynis will gather
any possible suggestion or warning. These results will be grouped and displayed at the bottom of screen output. Usually warnings are events which really need
an action.Suggestions on the other hand could indicate room for improvement. It's common to find much more suggestions than warnings. This does not imply
that because there are many suggestions (and no warnings) that a system is properly secured!To determine what has been checked together with the related suggestion/warning, the test identifier is displayed on the same line (between brackets). Open
the lynis log file (/var/log/lynis.log) and search for this identifier.Plugins
Lynis plugins are extensions to the Lynis core. Where normal Lynis controls perform individual tests and share the outcome, plugins will usually just gather information. This information is
then collected and processed in bulk. The big benefit is that is quicker and more powerful. For example security intelligence can be applied by collecting data and correlating it on the central
node.Plugin phases
Lynis has modular support to extend basic functionality by using plugins. Plugins are executed in several phases:Plugins: Phase 1
Plugins which do use hooks into existing tests, or gather data for later processing, will use phase 1 to initialize. Some tests which are part of the plugin will then finish in phase 2.Plugins: Phase 2
After running all tests, plugins get a last chance to do their job. For example parse discovered elements on the system, like a virtual host within Apache.

Plugins which can be used standalone (e.g. no hooks, no input from existing tests), can be executed in phase 1. No need for a phase 2 component.Enabling plugins:
Plugins can be enabled by using the plugin option within the profile.
Example: plugin=<custom_myplugin>Plugin directory
The directory in which plugins can be stored is determined by Lynis. By default it tries a few paths (/usr/local/lynis/plugins /usr/local/share/lynis/plugins /usr/share/lynis/plugins and /etc/lynis/plugins). If these directories
are not found, then the local work directory is being used. To use a different directory, use the --plugin-dir parameter, followed by the directory name.Custom plugins
When creating personal plugins, you are adviced to add a personal prefix and making the file name unique (ie. custom_myplugin). This prevents the file
being overwritten at a new release. If you just want an invidual test, you are advised to use the custom_test file instead, as plugins have a different goal.
If you consider writing a plugin, we ask you to contact us to determine the possibilities.5. Reporting and Logging
Lynis supports one report format, which can be used to gather results and display them in a custom or (more) friendly
presentation. The report file can also be used to compare scan results from the past with a current scan. Lynis Enterprise on the other hand has much more possibilities
to display data, including extended reports in several formats.
Contents of report file:
- Remarks: #<remark>
- Section: [<section name>]
- Option/value: <option name>=<value of option>
When an option may have multiple values (like installed packages for example), brackets ([]) are added. Example: installed_package[]=Package-1.0.0Logging
When a system is scanned and results are displayed, additional debugging information will be added to the log file (default: /var/log/lynis.log). For advanced testers
this information will be useful to see what the program did in the background or where anomalies showed up (and often why).
Information in the log file:
- Time of an action/event
- Reason(s) why a test failed or will be skipped
- Output of (internal) tests and sub tests
- Suggestions about configuration options or how to fix/improve things
- Threat/impact scoreRemark: the log file
will be purged every scan. If you need debugging or logging information for previous scans, schedule log rotation or make a backup before running Lynis again.6. Integration with Lynis EnterpriseLynis data can be uploaded via the --upload option. For companies using multiple systems, the Lynis Collector is usually the preferred option. This
specific tool has more capabilities and features to deal with batches of data. Both the --upload parameter and Lynis Collector, are meant to upload data to the central node.Upload via LynisAdd the license key in in the scan profile (default.prf or your customized profile). After adjusting, use the --upload parameter to upload the data after scanning.For data uploads, the cURL utility is being used. For environments which require a proxy, the profile allows you to define any options given to cURL, like --proxy.
In case a self-signed certificate is being used on the central node, you can disable full certificate checking with the --insecure option.Upload via Lynis CollectorAn alternative option is to use Lynis Collector. This tool allows uploads from a central machine with an internet connection available. This way other machines within the network don't need direct access.
Lynis Collector is available for customers in the downloads section. See part II for more details about this component.Part II: Lynis CollectorIntroductionThe Collector component within the Lynis suite, is a supporting tool. It collects reports from many systems and uploads it in one batch. It is available to users
of the Enterprise solution. Only one Collector is usually needed within the network.See the Lynis Collector documentation for full details.Part III: Lynis EnterpriseIntroductionRequirementsTo use Lynis Enterprise, you need a license key and an active user account. An account can be created during the ordering process or before.
Management happens with a web based solution. No external plugins have to be installed to work with our solution.For auditing purposes, Lynis needs to be configured on the systems that are to be audited. Optionally the Lynis Collector can be used
to collect data, then upload it to the central system.Please refer to Section I and Section II to install and configure these components.14. Account ManagementAn account on the Lynis Enterprise service provides access to the systems and configuration of a company. Each account can be linked only
to one company.15. Management of systemsAdding new systemDuring the life cycle of a system, it can be easily added by uploading the data to Lynis Enterprise. If the unique ID of the system is not known
yet, the system will be added to the pool of machines.RemovingWhen a system is being decommissioned, the absence of new scan data will be noticed and a related event will be raised. If the system is to
be removed altogether, select the system and use the delete icon (  ).16. Security hardening
One of the main components of Lynis and Lynis Enterprise is to provide guidance in security hardening of systems. Per system the related
security controls are listed. The Enterprise edition includes an implementation plan, customized to your environment. This way help
is provided to select which controls.17. Compliance and Baselines
Baselines provide a means to check for a defined policy and report about the compliance with the policy. Each system can be linked
to a baseline of choice.18. Change managementMore details will follow later19. Event handling
Events within the Lynis Enterprise solution are used to inform the administrator(s) about a specific activity. This includes exceeding
a warning threshold or for example missing data. Usually an event is a call to action and check the related component.20. Software upgrades
Since Lynis will be often updated to support new tests and software, performing regular updates is advised. Depending on the installation
method there are two options to stay up-to-date:Option 1. Using software packages
If the platform(s) used provides an up-to-date Lynis package, it could be used as part of your software upgrade strategy.In case the
vendor maintains only ""stable"" releases, they will usually not release newer versions of Lynis, until the next OS release. Then you
might consider creating a Lynis package yourself. See the Tips section on how to create a package.Option 2. No install
Instead of installing Lynis at all, a cronjob could be used to fetch the latest Lynis package from an internal server (e.g. HTTP/FTP/SCP/NFS). The cronjob
first extracts the tarball into a temporary directory. Then it runs Lynis from there, and before cleaning up, it sends the data to the Lynis Collector.Updating to a new release would mean the administrator will test the new version first on a few systems and then upload it to the central location. From that very moment
all systems will be using the latest version.Tips and SuggestionsStaying up-to-date
Staying up-to-date with software is important to have access to the latest functionality and make sure that known bugs have been
solved. Since Lynis is an auditing tool, it's possibly even more important to keep up with the latest version. Right now we
don't provie auto-updating yet. We believe strongly that people should test software releases before applying them into production.
To get notified when new releases are available, the following options are available:Notification list
At our Downloads page you can subscribe to the notification list. When a new release is available, you get an email with the changes.
Twitter
Follow founder Michael Boelen (@mboelen) and our company @cisofy_isLynis --check-update
For monitoring purposes or to notify yourself, it's possible to parse the output of Lynis while it checks for the latest version. If the output is ""Outdated"", a new version is available.
Background information: Lynis uses DNS to check for the latest version by using a TXT record query.Building your own packages
For companies or individuals who prefer their own packages, there is a lynis.spec file available. Building a RPM is very easy due to the low number of dependencies
of Lynis and consists of the following steps:Package creation:
To create a custom package for installation on your machine(s):
- Download lynis.spec file (see project page)
- Adjust version number and if needed, paths
- Run 'rpmbuild -ta lynis-version.tar.gz' to build the RPM package
- Install package by running: rpm -ivh <filename>Error: You have to be root (or equivalent) to perform an audit. Please su(do) and try again.Lynis needs to be executed as root for a full audit. Change to the root and execute Lynis again. Sudo might work as well. If you don't have root permissions, use the --pentest option.Error: Change ownership of ./include/const and ./include/functions to 'root'To protect alteration of the files, Lynis perform a few security checks. If the related files are not owned by root, or their permissions are not strict enough, Lynis will
show this on screen, including the commands to fix it. Usually it is caused because files were untarred by a user other than root.Part V: Support
Lynis is tested on the most common operating systems. The documentation (README, FAQ) and the debugging information in the log file usually provides
the answer to most questions (or problems). Bugs can be reported by contacting us. Commercial support is available.Part VI: Frequently Asked QuestionsIs Lynis really free?
Yes, Lynis is open source and free to use. By default it comes without warranties or support, as described in the Lynis package. If you prefer support,
then integration with Lynis Enterprise is better suitable for your needs.Is Lynis restricted in functionality, compared to Enterprise version?
There are no limitations regarding functionality. Lynis is also part of the Enterprise version, therefore it has full functionality.
Companies benefit from using the Enterprise version, as it includes additional plugins.What systems are supported?
All common systems based on Unix/Linux are supported. Examples include Linux, AIX, *BSD, HP-UX, macOS and Solaris.

For package management are the following tools supported:
- dpkg/apt, pacman, pkg_info, RPM, YUM, zypperWhat is the difference between Lynis and Lynis Enterprise?Lynis is an open source auditing tool, focused on auditing single Linux or Unix based systems.Lynis Enterprise is a centralized auditing system, with additional reporting, ready-to-use hardening scripts, monitoring and dashboards. Primary benefits is saving time by automation and always having up-to-date reports at hand.Product comparisonCan I create my own tests?
Sure you can! Lynis has a test category named ""custom"" (filename tests_custom). If this file exists, it will execute your own defined tests.
While creating your own tests is totally fine, please consider if others could benefit from them as well by sharing them with us. We accept most
tests and give you the appropriate credit (or keep it anonymous if preferred).The colors used are hard to read with my white background, how can I solve this?Disable color usage or use the --reverse-colors optionWhat is the difference between a normal test and a plugin?
While both are similiar in what they can do, a test has the main goal of performing a check and directly form a conclusion (something is present or not, the outcome is good or bad etc). The
purpose of plugins is to collect data for later use. In particular the Lynis Enterprise solution will use plugins to collect extra data which will be later analyzed. One example would be
to determine exceptions or outliers. It would not make sense to have everyone build up databases of data, while all information is already centrally stored.Is it possible to become reseller of Lynis?Yes. Please contact us for the possibilites.How can I verify the downloadsAfter downloading, test the file to confirm the integrity of the download. The related SHA1 and SHA256 hash are provided on the website as well. Depending on your OS, this
can be performed with the command sha1, sha1sum or with openssl.
 $ sha1sum lynis-version.tar.gz
 $ sha256sum lynis-version.tar.gz
 $ sha1 lynis-version.tar.gz
 $ sha256 lynis-version.tar.gz
 $ openssl sha1 lynis-version.tar.gz
 $ openssl sha256 lynis-version.tar.gz
The resulting hash displayed should be the same as on the website. If not, try downloading it on another machine or via a browser, to confirm the download
was not corrupted. If the hash still shows a different value, please contact us.4. Verification - SignatureIf you have GnuPG installed on your system, you can download our public key (https://cisofy.com/files/cisofy-software.pub) and the related signature of the download itself. The signature itself
is a file with the extension .asc.
$ wget https://cisofy.com/files/cisofy-software.pub
$ gpg --import cisofy-software.pub
$ gpg --list-keys --fingerprint
/home/user/.gnupg/pubring.gpg
------------------------
pub   4096R/D5B79251 2014-11-04 [expires: 2030-10-31]
      Key fingerprint = 73AC 9FC5 5848 E977 024D  1A61 429A 566F D5B7 9251
uid                  CISOfy (Software Signing Key) <security@cisofy.com>
sub   4096R/6E8847E1 2014-11-04 [expires: 2030-10-31]
Verify that the results are the same as listed above. Next step is verifying the download:
$ gpg --verify lynis-version.tar.gz.asc lynis-version.tar.gz
gpg: Signature made Wed 05 Nov 2014 12:39:26 AM CET using RSA key ID D5B79251
gpg: Good signature from ""CISOfy (Software Signing Key) <security@cisofy.com>""
gpg: WARNING: This key is not certified with a trusted signature!
gpg:          There is no indication that the signature belongs to the owner.
Primary key fingerprint: 73AC 9FC5 5848 E977 024D  1A61 429A 566F D5B7 9251
Note: The warning is displayed as the system simply does not not know if it is trusted. As there is no central authority to validate, you can mark the key as trusted yourself.
Before doing so, we have some tips to make sure you are using the right key:Compare the key output you get, with the results on this pageCheck DNS entry cisofy-software-key.cisofy.com, it should give the same fingerprint.
$ host -t txt cisofy-software-key.cisofy.com
cisofy-software-key.cisofy.com descriptive text ""Key fingerprint =
73AC 9FC5 5848 E977 024D  1A61 429A 566F D5B7 9251""

$ gpg --edit-key security@cisofy.com
gpg (GnuPG) 1.4.16; Copyright (C) 2013 Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

pub  4096R/D5B79251  created: 2014-11-04  expires: 2030-10-31  usage: SC
                     trust: unknown       validity: unknown
sub  4096R/6E8847E1  created: 2014-11-04  expires: 2030-10-31  usage: E
[ unknown] (1). CISOfy (Software Signing Key) <security@cisofy.com>

gpg> trust
pub  4096R/D5B79251  created: 2014-11-04  expires: 2030-10-31  usage: SC
                     trust: unknown       validity: unknown
sub  4096R/6E8847E1  created: 2014-11-04  expires: 2030-10-31  usage: E
[ unknown] (1). CISOfy (Software Signing Key) <security@cisofy.com>

Please decide how far you trust this user to correctly verify other users' keys
(by looking at passports, checking fingerprints from different sources, etc.)

  1 = I don't know or won't say
  2 = I do NOT trust
  3 = I trust marginally
  4 = I trust fully
  5 = I trust ultimately
  m = back to the main menu

Your decision? 5
Do you really want to set this key to ultimate trust? (y/N) y

pub  4096R/D5B79251  created: 2014-11-04  expires: 2030-10-31  usage: SC
                     trust: ultimate      validity: unknown
sub  4096R/6E8847E1  created: 2014-11-04  expires: 2030-10-31  usage: E
[ unknown] (1). CISOfy (Software Signing Key) <security@cisofy.com>
Please note that the shown key validity is not necessarily correct
unless you restart the program.

gpg> quitNow the key has be marked as being trusted and the related warning will be gone when verifying our downloads.Note: ultimate trust is the most extensive type of trust in a key. You may also use option 4 (I trust fully).Lynis is copyrighted by Michael Boelen, CISOfy, and licensed under the GPLv3 license.SolutionsSoftwareLynisDownloadsDocumentationLynis EnterpriseFeaturesDemoTopicsComplianceCommunityLynis on GitHubSoftware packagesLinux Audit BlogDocumentation and QuestionsSupportFrequently Asked Questions@cisofy_isAbout CISOfyCISOfy is an independent software company with solutions in the field of information security. Bootstrapped since 2013 and a focus on the long term.About UsContactLegalPrivacySecuritySitemapOur privacy promises:No tracking code on our websiteLimited external scriptsReduced data collection",,"# lynis

> System and security auditing tool.
> More information: <https://cisofy.com/documentation/lynis/>.

- Check that Lynis is up-to-date:

`sudo lynis update info`

- Run a security audit of the system:

`sudo lynis audit system`

- Run a security audit of a Dockerfile:

`sudo lynis audit dockerfile {{path/to/dockerfile}}`
"
update-rc.d,,,,"# update-rc.d

> Install and remove services which are System-V style init script links.
> Init scripts are in the /etc/init.d/.

- Install a service:

`update-rc.d {{mysql}} defaults`

- Enable a service:

`update-rc.d {{mysql}} enable`

- Disable a service:

`update-rc.d {{mysql}} disable`

- Forcibly remove a service:

`update-rc.d -f {{mysql}} remove`
"
vmware-checkvm,,,,"# vmware-checkvm

> Checks to see if the current host is a VMWare VM or not.

- Return the current VMWare software version (exit status determines whether the system is a VM or not):

`vmware-checkvm`

- Return the VMWare hardware version:

`vmware-checkvm -h`
"
smbpasswd,,,,"# smbpasswd

> Change a user's SMB password.
> Samba users must also have a local Unix account.

- Change the current user's SMB password:

`smbpasswd`

- Add a specified user to Samba and set password(user should already exist in system):

`smbpasswd -a {{username}}`

- Modify an existing Samba user's password:

`smbpasswd {{username}}`

- Delete a Samba user:

`smbpasswd -x {{username}}`
"
do-release-upgrade,,,,"# do-release-upgrade

> The Ubuntu release upgrader.

- Upgrade to the latest release:

`sudo do-release-upgrade`

- Upgrade to the latest development release:

`sudo do-release-upgrade --devel-release`

- Upgrade to the latest proposed release:

`sudo do-release-upgrade --proposed`
"
archey,,,,"# archey

> Simple tool for stylishly displaying system information.

- Show system information:

`archey`
"
nixos-rebuild,https://nixos.org/nixos/manual/#sec-changing-config,"

NixOS - NixOS 20.03 manual













NixOS







 Features
 Download
 Learn
 Community
 Governance
 Donate 




NixOS ManualVersion 20.03
  Appendix A. Configuration Options →Table of ContentsPrefaceI. Installation1. Obtaining NixOS2. Installing NixOS3. Changing the Configuration4. Upgrading NixOSII. Configuration5. Configuration Syntax6. Package Management7. User Management8. File Systems9. X Window System10. Xfce Desktop Environment11. Networking12. Linux Kernel13. Pantheon Desktop14. Matomo15. Nextcloud16. Grocy17. Prometheus exporters18. WeeChat19. Taskserver20. Matrix21. Gitlab22. Trezor23. Emacs24. Flatpak25. PostgreSQL26. FoundationDB27. Hiding process information28. SSL/TLS Certificates with ACME29. Oh my ZSH30. Plotinus31. Digital Bitbox32. Input Methods33. Profiles34. KubernetesIII. Administration35. Service Management36. Rebooting and Shutting Down37. User Sessions38. Control Groups39. Logging40. Cleaning the Nix Store41. Container Management42. TroubleshootingIV. Development43. Getting the Sources44. Writing NixOS Modules45. Building Specific Parts of NixOS46. Writing NixOS Documentation47. Building Your Own NixOS CD48. NixOS Tests49. Testing the Installer50. ReleasesA. Configuration OptionsB. Release NotesPreface
  This manual describes how to install, use and extend NixOS, a Linux
  distribution based on the purely functional package management system
  Nix, that is composed
  using modules and packages defined in the
  Nixpkgs project.
 
  Additional information regarding the Nix package manager and the Nixpkgs
  project can be found in respectively the
  Nix manual and the
  Nixpkgs manual.
 
  If you encounter problems, please report them on the
  Discourse or
  on the 
#nixos channel on Freenode. Bugs should be
  reported in
  NixOS’
  GitHub issue tracker.
 Note: 
   Commands prefixed with # have to be run as root, either
   requiring to login as root user or temporarily switching to it using
   sudo for example.
  Part I. Installation
   This section describes how to obtain, install, and configure NixOS for
   first-time use.
  Table of Contents1. Obtaining NixOS2. Installing NixOS3. Changing the Configuration4. Upgrading NixOSChapter 1. Obtaining NixOS
  NixOS ISO images can be downloaded from the
  NixOS download
  page. There are a number of installation options. If you happen to
  have an optical drive and a spare CD, burning the image to CD and booting
  from that is probably the easiest option. Most people will need to prepare a
  USB stick to boot from. Section 2.5.1, “Booting from a USB Drive” describes the
  preferred method to prepare a USB stick. A number of alternative methods are
  presented in the
  NixOS
  Wiki.
 
  As an alternative to installing NixOS yourself, you can get a running NixOS
  system through several other means:
  
     Using virtual appliances in Open Virtualization Format (OVF) that can be
     imported into VirtualBox. These are available from the
     NixOS download
     page.
    
     Using AMIs for Amazon’s EC2. To find one for your region and instance
     type, please refer to the
     list
     of most recent AMIs.
    
     Using NixOps, the NixOS-based cloud deployment tool, which allows you to
     provision VirtualBox and EC2 NixOS instances from declarative
     specifications. Check out the
     NixOps homepage for
     details.
    
Chapter 2. Installing NixOSTable of Contents2.1. Booting the system2.2. Partitioning and formatting2.3. Installing2.4. Installation summary2.5. Additional installation notes2.1. Booting the system
   NixOS can be installed on BIOS or UEFI systems. The procedure for a UEFI
   installation is by and large the same as a BIOS installation. The
   differences are mentioned in the steps that follow.
  
   The installation media can be burned to a CD, or now more commonly, ""burned""
   to a USB drive (see Section 2.5.1, “Booting from a USB Drive”).
  
   The installation media contains a basic NixOS installation. When it’s
   finished booting, it should have detected most of your hardware.
  
   The NixOS manual is available on virtual console 8 (press Alt+F8 to access)
   or by running nixos-help.
  
   You are logged-in automatically as nixos.
   The nixos user account has an empty password so you
   can use sudo without a password.
  
   If you downloaded the graphical ISO image, you can run systemctl
   start display-manager to start the desktop environment. If you want to continue on the
   terminal, you can use loadkeys to switch to your
   preferred keyboard layout. (We even provide neo2 via loadkeys de
   neo!)
  2.1.1. Networking in the installer
    The boot process should have brought up networking (check ip
    a). Networking is necessary for the installer, since it will
    download lots of stuff (such as source tarballs or Nixpkgs channel
    binaries). It’s best if you have a DHCP server on your network. Otherwise
    configure networking manually using ifconfig.
   
    To manually configure the network on the graphical installer, first disable
    network-manager with systemctl stop NetworkManager.
   
    To manually configure the wifi on the minimal installer, run
    wpa_supplicant -B -i interface -c <(wpa_passphrase 'SSID'
    'key').
   
    If you would like to continue the installation from a different machine you
    need to activate the SSH daemon via systemctl start
    sshd. You then must set a password for either root or
    nixos with passwd to be able to login.
   2.2. Partitioning and formatting
   The NixOS installer doesn’t do any partitioning or formatting, so you need
   to do that yourself.
  
   The NixOS installer ships with multiple partitioning tools. The examples
   below use parted, but also provides
   fdisk, gdisk,
   cfdisk, and cgdisk.
  
   The recommended partition scheme differs depending if the computer uses
   Legacy Boot or UEFI.
  2.2.1. UEFI (GPT)
    Here's an example partition scheme for UEFI, using
    /dev/sda as the device.
    Note: 
      You can safely ignore parted's informational message
      about needing to update /etc/fstab.
     


       Create a GPT partition table.
# parted /dev/sda -- mklabel gpt

       Add the root partition. This will fill the disk
       except for the end part, where the swap will live, and the space left in
       front (512MiB) which will be used by the boot partition.
# parted /dev/sda -- mkpart primary 512MiB -8GiB

       Next, add a swap partition. The size required will
       vary according to needs, here a 8GiB one is created.
# parted /dev/sda -- mkpart primary linux-swap -8GiB 100%
Note: 
         The swap partition size rules are no different than for other Linux
         distributions.
        

       Finally, the boot partition. NixOS by default uses
       the ESP (EFI system partition) as its /boot
       partition. It uses the initially reserved 512MiB at the start of the
       disk.
# parted /dev/sda -- mkpart ESP fat32 1MiB 512MiB
# parted /dev/sda -- set 3 boot on


    Once complete, you can follow with
    Section 2.2.3, “Formatting”.
   2.2.2. Legacy Boot (MBR)
    Here's an example partition scheme for Legacy Boot, using
    /dev/sda as the device.
    Note: 
      You can safely ignore parted's informational message
      about needing to update /etc/fstab.
     


       Create a MBR partition table.
# parted /dev/sda -- mklabel msdos

       Add the root partition. This will fill the the disk
       except for the end part, where the swap will live.
# parted /dev/sda -- mkpart primary 1MiB -8GiB

       Finally, add a swap partition. The size required
       will vary according to needs, here a 8GiB one is created.
# parted /dev/sda -- mkpart primary linux-swap -8GiB 100%
Note: 
         The swap partition size rules are no different than for other Linux
         distributions.
        


    Once complete, you can follow with
    Section 2.2.3, “Formatting”.
   2.2.3. Formatting
    Use the following commands:
    
       For initialising Ext4 partitions: mkfs.ext4. It is
       recommended that you assign a unique symbolic label to the file system
       using the option -L label,
       since this makes the file system configuration independent from device
       changes. For example:

# mkfs.ext4 -L nixos /dev/sda1

       For creating swap partitions: mkswap. Again it’s
       recommended to assign a label to the swap partition: -L
       label. For example:

# mkswap -L swap /dev/sda2

         UEFI systems
        
          For creating boot partitions: mkfs.fat. Again
          it’s recommended to assign a label to the boot partition:
          -n label. For example:

# mkfs.fat -F 32 -n boot /dev/sda3

       For creating LVM volumes, the LVM commands, e.g.,
       pvcreate, vgcreate, and
       lvcreate.
      
       For creating software RAID devices, use mdadm.
      
2.3. Installing
     Mount the target file system on which NixOS should be installed on
     /mnt, e.g.

# mount /dev/disk/by-label/nixos /mnt


       UEFI systems
      
        Mount the boot file system on /mnt/boot, e.g.

# mkdir -p /mnt/boot
# mount /dev/disk/by-label/boot /mnt/boot


     If your machine has a limited amount of memory, you may want to activate
     swap devices now (swapon
     device). The installer (or rather,
     the build actions that it may spawn) may need quite a bit of RAM,
     depending on your configuration.

# swapon /dev/sda2

     You now need to create a file
     /mnt/etc/nixos/configuration.nix that specifies the
     intended configuration of the system. This is because NixOS has a
     declarative configuration model: you create or edit a
     description of the desired configuration of your system, and then NixOS
     takes care of making it happen. The syntax of the NixOS configuration file
     is described in Chapter 5, Configuration Syntax, while a list
     of available configuration options appears in
     Appendix A, Configuration Options. A minimal example is shown in
     Example 2.4, “NixOS Configuration”.
    
     The command nixos-generate-config can generate an
     initial configuration file for you:

# nixos-generate-config --root /mnt
     You should then edit /mnt/etc/nixos/configuration.nix
     to suit your needs:

# nano /mnt/etc/nixos/configuration.nix

     If you’re using the graphical ISO image, other editors may be available
     (such as vim). If you have network access, you can also
     install other editors — for instance, you can install Emacs by running
     nix-env -f '<nixpkgs>' -iA emacs.
    
       BIOS systems
      
        You must set the option
        boot.loader.grub.device to specify on which disk
        the GRUB boot loader is to be installed. Without it, NixOS cannot boot.
       
       UEFI systems
      
        You must set the option
        boot.loader.systemd-boot.enable to
        true. nixos-generate-config
        should do this automatically for new configurations when booted in UEFI
        mode.
       
        You may want to look at the options starting with
        boot.loader.efi
        and
        boot.loader.systemd
        as well.
       
     If there are other operating systems running on the machine before
     installing NixOS, the boot.loader.grub.useOSProber
     option can be set to true to automatically add them to
     the grub menu.
    
     If you need to configure networking for your machine the configuration
     options are described in Chapter 11, Networking. In particular,
     while wifi is supported on the installation image, it is not enabled by
     default in the configuration generated by
     nixos-generate-config.
    
     Another critical option is fileSystems, specifying the
     file systems that need to be mounted by NixOS. However, you typically
     don’t need to set it yourself, because
     nixos-generate-config sets it automatically in
     /mnt/etc/nixos/hardware-configuration.nix from your
     currently mounted file systems. (The configuration file
     hardware-configuration.nix is included from
     configuration.nix and will be overwritten by future
     invocations of nixos-generate-config; thus, you
     generally should not modify it.) Additionally, you may want to look at
     Hardware
     configuration for known-hardware at this point or after
     installation.

    Note: 
      Depending on your hardware configuration or type of file system, you may
      need to set the option boot.initrd.kernelModules to
      include the kernel modules that are necessary for mounting the root file
      system, otherwise the installed system will not be able to boot. (If this
      happens, boot from the installation media again, mount the target file
      system on /mnt, fix
      /mnt/etc/nixos/configuration.nix and rerun
      nixos-install.) In most cases,
      nixos-generate-config will figure out the required
      modules.
     
     Do the installation:

# nixos-install
     This will install your system based on the configuration you provided.
     If anything fails due to a configuration problem or any other issue
     (such as a network outage while downloading binaries from the NixOS
     binary cache), you can re-run nixos-install after
     fixing your configuration.nix.
    
     As the last step, nixos-install will ask you to set the
     password for the root user, e.g.

setting root password...
Enter new UNIX password: ***
Retype new UNIX password: ***
Note: 
       For unattended installations, it is possible to use
       nixos-install --no-root-passwd in order to disable
       the password prompt entirely.
      

     If everything went well:

# reboot

     You should now be able to boot into the installed NixOS. The GRUB boot
     menu shows a list of available configurations
     (initially just one). Every time you change the NixOS configuration (see
     Changing Configuration
     ), a new item is added to the menu. This allows you to easily roll back to
     a previous configuration if something goes wrong.
    
     You should log in and change the root password with
     passwd.
    
     You’ll probably want to create some user accounts as well, which can be
     done with useradd:

$ useradd -c 'Eelco Dolstra' -m eelco
$ passwd eelco

     You may also want to install some software. For instance,

$ nix-env -qaP \*
     shows what packages are available, and

$ nix-env -f '<nixpkgs>' -iA w3m
     installs the w3m browser.
    2.4. Installation summary
   To summarise, Example 2.3, “Commands for Installing NixOS on /dev/sda” shows a typical
   sequence of commands for installing NixOS on an empty hard drive (here
   /dev/sda). Example 2.4, “NixOS Configuration” shows a
   corresponding configuration Nix expression.
  Example 2.1. Example partition schemes for NixOS on /dev/sda (MBR)
# parted /dev/sda -- mklabel msdos
# parted /dev/sda -- mkpart primary 1MiB -8GiB
# parted /dev/sda -- mkpart primary linux-swap -8GiB 100%Example 2.2. Example partition schemes for NixOS on /dev/sda (UEFI)
# parted /dev/sda -- mklabel gpt
# parted /dev/sda -- mkpart primary 512MiB -8GiB
# parted /dev/sda -- mkpart primary linux-swap -8GiB 100%
# parted /dev/sda -- mkpart ESP fat32 1MiB 512MiB
# parted /dev/sda -- set 3 boot onExample 2.3. Commands for Installing NixOS on /dev/sda
    With a partitioned disk.

# mkfs.ext4 -L nixos /dev/sda1
# mkswap -L swap /dev/sda2
# swapon /dev/sda2
# mkfs.fat -F 32 -n boot /dev/sda3        # (for UEFI systems only)
# mount /dev/disk/by-label/nixos /mnt
# mkdir -p /mnt/boot                      # (for UEFI systems only)
# mount /dev/disk/by-label/boot /mnt/boot # (for UEFI systems only)
# nixos-generate-config --root /mnt
# nano /mnt/etc/nixos/configuration.nix
# nixos-install
# reboot
Example 2.4. NixOS Configuration
{ config, pkgs, ... }: {
  imports = [
    # Include the results of the hardware scan.
    ./hardware-configuration.nix
  ];

  boot.loader.grub.device = ""/dev/sda"";   # (for BIOS systems only)
  boot.loader.systemd-boot.enable = true; # (for UEFI systems only)

  # Note: setting fileSystems is generally not
  # necessary, since nixos-generate-config figures them out
  # automatically in hardware-configuration.nix.
  #fileSystems.""/"".device = ""/dev/disk/by-label/nixos"";

  # Enable the OpenSSH server.
  services.sshd.enable = true;
}
2.5. Additional installation notes2.5.1. Booting from a USB Drive
  For systems without CD drive, the NixOS live CD can be booted from a USB
  stick. You can use the dd utility to write the image:
  dd if=path-to-image
  of=/dev/sdX. Be careful about specifying
  the correct drive; you can use the lsblk command to get a
  list of block devices.
  On macOS

$ diskutil list
[..]
/dev/diskN (external, physical):
   #:                       TYPE NAME                    SIZE       IDENTIFIER
[..]
$ diskutil unmountDisk diskN
Unmount of all volumes on diskN was successful
$ sudo dd if=nix.iso of=/dev/rdiskN

    Using the 'raw' rdiskN device instead of
    diskN completes in minutes instead of hours. After
    dd completes, a GUI dialog ""The disk you inserted was
    not readable by this computer"" will pop up, which can be ignored.
   

  The dd utility will write the image verbatim to the drive,
  making it the recommended option for both UEFI and non-UEFI installations.
 2.5.2. Booting from the “netboot” media (PXE)
  Advanced users may wish to install NixOS using an existing PXE or iPXE setup.
 
  These instructions assume that you have an existing PXE or iPXE
  infrastructure and simply want to add the NixOS installer as another option.
  To build the necessary files from a recent version of nixpkgs, you can run:
 
nix-build -A netboot nixos/release.nix

  This will create a result directory containing: *
  bzImage – the Linux kernel * initrd
  – the initrd file * netboot.ipxe – an example ipxe
  script demonstrating the appropriate kernel command line arguments for this
  image
 
  If you’re using plain PXE, configure your boot loader to use the
  bzImage and initrd files and have it
  provide the same kernel command line arguments found in
  netboot.ipxe.
 
  If you’re using iPXE, depending on how your HTTP/FTP/etc. server is
  configured you may be able to use netboot.ipxe unmodified,
  or you may need to update the paths to the files to match your server’s
  directory layout
 
  In the future we may begin making these files available as build products
  from hydra at which point we will update this documentation with instructions
  on how to obtain them either for placing on a dedicated TFTP server or to
  boot them directly over the internet.
 2.5.3. Installing in a VirtualBox guest
  Installing NixOS into a VirtualBox guest is convenient for users who want to
  try NixOS without installing it on bare metal. If you want to use a pre-made
  VirtualBox appliance, it is available at
  the downloads
  page. If you want to set up a VirtualBox guest manually, follow these
  instructions:
 
    Add a New Machine in VirtualBox with OS Type ""Linux / Other Linux""
   
    Base Memory Size: 768 MB or higher.
   
    New Hard Disk of 8 GB or higher.
   
    Mount the CD-ROM with the NixOS ISO (by clicking on CD/DVD-ROM)
   
    Click on Settings / System / Processor and enable PAE/NX
   
    Click on Settings / System / Acceleration and enable ""VT-x/AMD-V""
    acceleration
   
    Click on Settings / Display / Screen and select VBoxVGA as Graphics Controller
   
    Save the settings, start the virtual machine, and continue installation
    like normal
   
  There are a few modifications you should make in configuration.nix. Enable
  booting:
 
boot.loader.grub.device = ""/dev/sda"";

  Also remove the fsck that runs at startup. It will always fail to run,
  stopping your boot until you press *.
 
boot.initrd.checkJournalingFS = false;

  Shared folders can be given a name and a path in the host system in the
  VirtualBox settings (Machine / Settings / Shared Folders, then click on the
  ""Add"" icon). Add the following to the
  /etc/nixos/configuration.nix to auto-mount them. If you do
  not add ""nofail"", the system will no boot properly. The
  same goes for disabling rngd which is normally used to get
  randomness but this does not work in virtual machines.
 
{ config, pkgs, ...} :
{
  security.rngd.enable = false; // otherwise vm will not boot
  ...

  fileSystems.""/virtualboxshare"" = {
    fsType = ""vboxsf"";
    device = ""nameofthesharedfolder"";
    options = [ ""rw"" ""nofail"" ];
  };
}

  The folder will be available directly under the root directory.
 2.5.4. Installing from another Linux distribution
  Because Nix (the package manager) & Nixpkgs (the Nix packages collection)
  can both be installed on any (most?) Linux distributions, they can be used to
  install NixOS in various creative ways. You can, for instance:
 
    Install NixOS on another partition, from your existing Linux distribution
    (without the use of a USB or optical device!)
   
    Install NixOS on the same partition (in place!), from your existing
    non-NixOS Linux distribution using NIXOS_LUSTRATE.
   
    Install NixOS on your hard drive from the Live CD of any Linux
    distribution.
   
  The first steps to all these are the same:
 
    Install the Nix package manager:
   
    Short version:
   
$ curl https://nixos.org/nix/install | sh
$ . $HOME/.nix-profile/etc/profile.d/nix.sh # …or open a fresh shell
    More details in the
    
    Nix manual

    Switch to the NixOS channel:
   
    If you've just installed Nix on a non-NixOS distribution, you will be on
    the nixpkgs channel by default.
   
$ nix-channel --list
nixpkgs https://nixos.org/channels/nixpkgs-unstable
    As that channel gets released without running the NixOS tests, it will be
    safer to use the nixos-* channels instead:
   
$ nix-channel --add https://nixos.org/channels/nixos-version nixpkgs
    You may want to throw in a nix-channel --update for good
    measure.
   
    Install the NixOS installation tools:
   
    You'll need nixos-generate-config and
    nixos-install and we'll throw in some man pages and
    nixos-enter just in case you want to chroot into your
    NixOS partition. They are installed by default on NixOS, but you don't have
    NixOS yet..
   $ nix-env -iE ""_: with import <nixpkgs/nixos> { configuration = {}; }; with config.system.build; [ nixos-generate-config nixos-install nixos-enter manual.manpages ]""Note: 
     The following 5 steps are only for installing NixOS to another partition.
     For installing NixOS in place using NIXOS_LUSTRATE,
     skip ahead.
    
    Prepare your target partition:
   
    At this point it is time to prepare your target partition. Please refer to
    the partitioning, file-system creation, and mounting steps of
    Chapter 2, Installing NixOS

    If you're about to install NixOS in place using
    NIXOS_LUSTRATE there is nothing to do for this step.
   
    Generate your NixOS configuration:
   $ sudo `which nixos-generate-config` --root /mnt
    You'll probably want to edit the configuration files. Refer to the
    nixos-generate-config step in
    Chapter 2, Installing NixOS for more
    information.
   
    Consider setting up the NixOS bootloader to give you the ability to boot on
    your existing Linux partition. For instance, if you're using GRUB and your
    existing distribution is running Ubuntu, you may want to add something like
    this to your configuration.nix:
   
boot.loader.grub.extraEntries = ''
  menuentry ""Ubuntu"" {
    search --set=ubuntu --fs-uuid 3cc3e652-0c1f-4800-8451-033754f68e6e
    configfile ""($ubuntu)/boot/grub/grub.cfg""
  }
'';
    (You can find the appropriate UUID for your partition in
    /dev/disk/by-uuid)
   
    Create the nixbld group and user on your original
    distribution:
   
$ sudo groupadd -g 30000 nixbld
$ sudo useradd -u 30000 -g nixbld -G nixbld nixbld
    Download/build/install NixOS:
   Warning: 
     Once you complete this step, you might no longer be able to boot on
     existing systems without the help of a rescue USB drive or similar.
    $ sudo PATH=""$PATH"" NIX_PATH=""$NIX_PATH"" `which nixos-install` --root /mnt
    Again, please refer to the nixos-install step in
    Chapter 2, Installing NixOS for more information.
   
    That should be it for installation to another partition!
   
    Optionally, you may want to clean up your non-NixOS distribution:
   
$ sudo userdel nixbld
$ sudo groupdel nixbld
    If you do not wish to keep the Nix package manager installed either, run
    something like sudo rm -rv ~/.nix-* /nix and remove the
    line that the Nix installer added to your ~/.profile.
   Note: 
     The following steps are only for installing NixOS in place using
     NIXOS_LUSTRATE:
    
    Generate your NixOS configuration:
   $ sudo `which nixos-generate-config` --root /
    Note that this will place the generated configuration files in
    /etc/nixos. You'll probably want to edit the
    configuration files. Refer to the nixos-generate-config
    step in Chapter 2, Installing NixOS for more
    information.
   
    You'll likely want to set a root password for your first boot using the
    configuration files because you won't have a chance to enter a password
    until after you reboot. You can initalize the root password to an empty one
    with this line: (and of course don't forget to set one once you've rebooted
    or to lock the account with sudo passwd -l root if you
    use sudo)
   
users.users.root.initialHashedPassword = """";

    Build the NixOS closure and install it in the system
    profile:
   $ nix-env -p /nix/var/nix/profiles/system -f '<nixpkgs/nixos>' -I nixos-config=/etc/nixos/configuration.nix -iA system
    Change ownership of the /nix tree to root (since your
    Nix install was probably single user):
   $ sudo chown -R 0.0 /nix
    Set up the /etc/NIXOS and
    /etc/NIXOS_LUSTRATE files:
   
/etc/NIXOS officializes that this is now a NixOS
    partition (the bootup scripts require its presence).
   
/etc/NIXOS_LUSTRATE tells the NixOS bootup scripts to
    move everything that's in the root partition to
    /old-root. This will move your existing distribution out
    of the way in the very early stages of the NixOS bootup. There are
    exceptions (we do need to keep NixOS there after all), so the NixOS
    lustrate process will not touch:
   
      The /nix directory
     
      The /boot directory
     
      Any file or directory listed in /etc/NIXOS_LUSTRATE
      (one per line)
     Note
     Support for NIXOS_LUSTRATE was added in NixOS 16.09.
     The act of ""lustrating"" refers to the wiping of the existing distribution.
     Creating /etc/NIXOS_LUSTRATE can also be used on NixOS
     to remove all mutable files from your root partition (anything that's not
     in /nix or /boot gets ""lustrated"" on
     the next boot.
    
     lustrate /ˈlʌstreɪt/ verb.
    
     purify by expiatory sacrifice, ceremonial washing, or some other ritual
     action.
    
    Let's create the files:
   
$ sudo touch /etc/NIXOS
$ sudo touch /etc/NIXOS_LUSTRATE

    Let's also make sure the NixOS configuration files are kept once we reboot
    on NixOS:
   
$ echo etc/nixos | sudo tee -a /etc/NIXOS_LUSTRATE

    Finally, move the /boot directory of your current
    distribution out of the way (the lustrate process will take care of the
    rest once you reboot, but this one must be moved out now because NixOS
    needs to install its own boot files:
   Warning: 
     Once you complete this step, your current distribution will no longer be
     bootable! If you didn't get all the NixOS configuration right, especially
     those settings pertaining to boot loading and root partition, NixOS may
     not be bootable either. Have a USB rescue device ready in case this
     happens.
    
$ sudo mv -v /boot /boot.bak &&
sudo /nix/var/nix/profiles/system/bin/switch-to-configuration boot

    Cross your fingers, reboot, hopefully you should get a NixOS prompt!
   
    If for some reason you want to revert to the old distribution, you'll need
    to boot on a USB rescue disk and do something along these lines:
   
# mkdir root
# mount /dev/sdaX root
# mkdir root/nixos-root
# mv -v root/* root/nixos-root/
# mv -v root/nixos-root/old-root/* root/
# mv -v root/boot.bak root/boot  # We had renamed this by hand earlier
# umount root
# reboot
    This may work as is or you might also need to reinstall the boot loader
   
    And of course, if you're happy with NixOS and no longer need the old
    distribution:
   sudo rm -rf /old-root
    It's also worth noting that this whole process can be automated. This is
    especially useful for Cloud VMs, where provider do not provide NixOS. For
    instance,
    nixos-infect
    uses the lustrate process to convert Digital Ocean droplets to NixOS from
    other distributions automatically.
   2.5.5. Installing behind a proxy
  To install NixOS behind a proxy, do the following before running
  nixos-install.
 
    Update proxy configuration in
    /mnt/etc/nixos/configuration.nix to keep the internet
    accessible after reboot.
   
networking.proxy.default = ""http://user:password@proxy:port/"";
networking.proxy.noProxy = ""127.0.0.1,localhost,internal.domain"";

    Setup the proxy environment variables in the shell where you are running
    nixos-install.
   
# proxy_url=""http://user:password@proxy:port/""
# export http_proxy=""$proxy_url""
# export HTTP_PROXY=""$proxy_url""
# export https_proxy=""$proxy_url""
# export HTTPS_PROXY=""$proxy_url""
Note: 
   If you are switching networks with different proxy configurations, use the
   nesting.clone option in
   configuration.nix to switch proxies at runtime. Refer to
   Appendix A, Configuration Options for more information.
  Chapter 3. Changing the Configuration
  The file /etc/nixos/configuration.nix contains the
  current configuration of your machine. Whenever you’ve
  changed something in that file, you
  should do

# nixos-rebuild switch

  to build the new configuration, make it the default configuration for
  booting, and try to realise the configuration in the running system (e.g., by
  restarting system services).
  Warning: 
    This command doesn't start/stop user
    services automatically. nixos-rebuild only runs a
    daemon-reload for each user with running user services.
   
Warning: 
   These commands must be executed as root, so you should either run them from
   a root shell or by prefixing them with sudo -i.
  
  You can also do

# nixos-rebuild test

  to build the configuration and switch the running system to it, but without
  making it the boot default. So if (say) the configuration locks up your
  machine, you can just reboot to get back to a working configuration.
 
  There is also

# nixos-rebuild boot

  to build the configuration and make it the boot default, but not switch to it
  now (so it will only take effect after the next reboot).
 
  You can make your configuration show up in a different submenu of the GRUB 2
  boot screen by giving it a different profile name, e.g.

# nixos-rebuild switch -p test

  which causes the new configuration (and previous ones created using
  -p test) to show up in the GRUB submenu “NixOS - Profile
  'test'”. This can be useful to separate test configurations from
  “stable” configurations.
 
  Finally, you can do

$ nixos-rebuild build

  to build the configuration but nothing more. This is useful to see whether
  everything compiles cleanly.
 
  If you have a machine that supports hardware virtualisation, you can also
  test the new configuration in a sandbox by building and running a QEMU
  virtual machine that contains the desired configuration.
  Just do

$ nixos-rebuild build-vm
$ ./result/bin/run-*-vm

  The VM does not have any data from your host system, so your existing user
  accounts and home directories will not be available unless you have set
  mutableUsers = false. Another way is to temporarily add
  the following to your configuration:

users.users.your-user.initialHashedPassword = ""test"";

Important: delete the $hostname.qcow2 file if you have
  started the virtual machine at least once without the right users, otherwise
  the changes will not get picked up. You can forward ports on the host to the
  guest. For instance, the following will forward host port 2222 to guest port
  22 (SSH):

$ QEMU_NET_OPTS=""hostfwd=tcp::2222-:22"" ./result/bin/run-*-vm

  allowing you to log in via SSH (assuming you have set the appropriate
  passwords or SSH authorized keys):

$ ssh -p 2222 localhost

Chapter 4. Upgrading NixOSTable of Contents4.1. Automatic Upgrades
  The best way to keep your NixOS installation up to date is to use one of the
  NixOS channels. A channel is a Nix mechanism for
  distributing Nix expressions and associated binaries. The NixOS channels are
  updated automatically from NixOS’s Git repository after certain tests have
  passed and all packages have been built. These channels are:
  
Stable channels, such as
     nixos-20.03.
     These only get conservative bug fixes and package upgrades. For instance,
     a channel update may cause the Linux kernel on your system to be upgraded
     from 4.19.34 to 4.19.38 (a minor bug fix), but not from
     4.19.x to 4.20.x (a
     major change that has the potential to break things). Stable channels are
     generally maintained until the next stable branch is created.
    
     The unstable channel,
     nixos-unstable.
     This corresponds to NixOS’s main development branch, and may thus see
     radical changes between channel updates. It’s not recommended for
     production systems.
    
Small channels, such as
     nixos-20.03-small
     or
     nixos-unstable-small.
     These are identical to the stable and unstable channels described above,
     except that they contain fewer binary packages. This means they get
     updated faster than the regular channels (for instance, when a critical
     security patch is committed to NixOS’s source tree), but may require
     more packages to be built from source than usual. They’re mostly
     intended for server environments and as such contain few GUI applications.
    
  To see what channels are available, go to
  https://nixos.org/channels. (Note that the URIs of the
  various channels redirect to a directory that contains the channel’s latest
  version and includes ISO images and VirtualBox appliances.) Please note that
  during the release process, channels that are not yet released will be
  present here as well. See the Getting NixOS page
  https://nixos.org/nixos/download.html to find the newest
  supported stable release.
 
  When you first install NixOS, you’re automatically subscribed to the NixOS
  channel that corresponds to your installation source. For instance, if you
  installed from a 20.03 ISO, you will be subscribed to the
  nixos-20.03 channel. To see which NixOS channel you’re
  subscribed to, run the following as root:

# nix-channel --list | grep nixos
nixos https://nixos.org/channels/nixos-unstable

  To switch to a different NixOS channel, do

# nix-channel --add https://nixos.org/channels/channel-name nixos

  (Be sure to include the nixos parameter at the end.) For
  instance, to use the NixOS 20.03 stable channel:

# nix-channel --add https://nixos.org/channels/nixos-20.03 nixos

  If you have a server, you may want to use the “small” channel instead:

# nix-channel --add https://nixos.org/channels/nixos-20.03-small nixos

  And if you want to live on the bleeding edge:

# nix-channel --add https://nixos.org/channels/nixos-unstable nixos


  You can then upgrade NixOS to the latest version in your chosen channel by
  running

# nixos-rebuild switch --upgrade

  which is equivalent to the more verbose nix-channel --update nixos;
  nixos-rebuild switch.
 Note: 
   Channels are set per user. This means that running  nix-channel
   --add as a non root user (or without sudo) will not affect
   configuration in /etc/nixos/configuration.nix
Warning: 
   It is generally safe to switch back and forth between channels. The only
   exception is that a newer NixOS may also have a newer Nix version, which may
   involve an upgrade of Nix’s database schema. This cannot be undone easily,
   so in that case you will not be able to go back to your original channel.
  4.1. Automatic Upgrades
   You can keep a NixOS system up-to-date automatically by adding the following
   to configuration.nix:

system.autoUpgrade.enable = true;
system.autoUpgrade.allowReboot = true;

   This enables a periodically executed systemd service named
   nixos-upgrade.service. If the allowReboot
   option is false, it runs nixos-rebuild switch
   --upgrade to upgrade NixOS to the latest version in the current
   channel. (To see when the service runs, see systemctl list-timers.)
   If allowReboot is true, then the
   system will automatically reboot if the new generation contains a different
   kernel, initrd or kernel modules.
   You can also specify a channel explicitly, e.g.

system.autoUpgrade.channel = https://nixos.org/channels/nixos-20.03;

Part II. Configuration
   This chapter describes how to configure various aspects of a NixOS machine
   through the configuration file
   /etc/nixos/configuration.nix. As described in
   Chapter 3, Changing the Configuration, changes to this file only take
   effect after you run nixos-rebuild.
  Table of Contents5. Configuration Syntax6. Package Management7. User Management8. File Systems9. X Window System10. Xfce Desktop Environment11. Networking12. Linux Kernel13. Pantheon Desktop14. Matomo15. Nextcloud16. Grocy17. Prometheus exporters18. WeeChat19. Taskserver20. Matrix21. Gitlab22. Trezor23. Emacs24. Flatpak25. PostgreSQL26. FoundationDB27. Hiding process information28. SSL/TLS Certificates with ACME29. Oh my ZSH30. Plotinus31. Digital Bitbox32. Input Methods33. Profiles34. KubernetesChapter 5. Configuration SyntaxTable of Contents5.1. NixOS Configuration File5.2. Abstractions5.3. Modularity5.4. Syntax Summary
  The NixOS configuration file
  /etc/nixos/configuration.nix is actually a Nix
  expression, which is the Nix package manager’s purely functional
  language for describing how to build packages and configurations. This means
  you have all the expressive power of that language at your disposal,
  including the ability to abstract over common patterns, which is very useful
  when managing complex systems. The syntax and semantics of the Nix language
  are fully described in the
  Nix
  manual, but here we give a short overview of the most important
  constructs useful in NixOS configuration files.
 5.1. NixOS Configuration File
  The NixOS configuration file generally looks like this:

{ config, pkgs, ... }:

{ option definitions
}

  The first line ({ config, pkgs, ... }:) denotes that this
  is actually a function that takes at least the two arguments
  config and pkgs. (These are explained
  later.) The function returns a set of option definitions
  ({ ... }). These definitions
  have the form name =
  value, where
  name is the name of an option and
  value is its value. For example,

{ config, pkgs, ... }:

{ services.httpd.enable = true;
  services.httpd.adminAddr = ""alice@example.org"";
  services.httpd.virtualHosts.localhost.documentRoot = ""/webroot"";
}

  defines a configuration with three option definitions that together enable
  the Apache HTTP Server with /webroot as the document
  root.
 
  Sets can be nested, and in fact dots in option names are shorthand for
  defining a set containing another set. For instance,
  services.httpd.enable defines a set named
  services that contains a set named
  httpd, which in turn contains an option definition named
  enable with value true. This means that
  the example above can also be written as:

{ config, pkgs, ... }:

{ services = {
    httpd = {
      enable = true;
      adminAddr = ""alice@example.org"";
      virtualHosts = {
        localhost = {
          documentRoot = ""/webroot"";
        };
      };
    };
  };
}

  which may be more convenient if you have lots of option definitions that
  share the same prefix (such as services.httpd).
 
  NixOS checks your option definitions for correctness. For instance, if you
  try to define an option that doesn’t exist (that is, doesn’t have a
  corresponding option declaration),
  nixos-rebuild will give an error like:

The option `services.httpd.enable' defined in `/etc/nixos/configuration.nix' does not exist.

  Likewise, values in option definitions must have a correct type. For
  instance, services.httpd.enable must be a Boolean
  (true or false). Trying to give it a
  value of another type, such as a string, will cause an error:

The option value `services.httpd.enable' in `/etc/nixos/configuration.nix' is not a boolean.


  Options have various types of values. The most important are:
  
     Strings
    
      Strings are enclosed in double quotes, e.g.

networking.hostName = ""dexter"";

      Special characters can be escaped by prefixing them with a backslash
      (e.g. \"").
     
      Multi-line strings can be enclosed in double single
      quotes, e.g.

networking.extraHosts =
  ''
    127.0.0.2 other-localhost
    10.0.0.1 server
  '';

      The main difference is that it strips from each line a number of spaces
      equal to the minimal indentation of the string as a whole (disregarding
      the indentation of empty lines), and that characters like
      "" and \ are not special (making it
      more convenient for including things like shell code). See more info
      about this in the Nix manual
      here.
     
     Booleans
    
      These can be true or false, e.g.

networking.firewall.enable = true;
networking.firewall.allowPing = false;


     Integers
    
      For example,

boot.kernel.sysctl.""net.ipv4.tcp_keepalive_time"" = 60;

      (Note that here the attribute name
      net.ipv4.tcp_keepalive_time is enclosed in quotes to
      prevent it from being interpreted as a set named net
      containing a set named ipv4, and so on. This is
      because it’s not a NixOS option but the literal name of a Linux kernel
      setting.)
     
     Sets
    
      Sets were introduced above. They are name/value pairs enclosed in braces,
      as in the option definition

fileSystems.""/boot"" =
  { device = ""/dev/sda1"";
    fsType = ""ext4"";
    options = [ ""rw"" ""data=ordered"" ""relatime"" ];
  };


     Lists
    
      The important thing to note about lists is that list elements are
      separated by whitespace, like this:

boot.kernelModules = [ ""fuse"" ""kvm-intel"" ""coretemp"" ];

      List elements can be any other type, e.g. sets:

swapDevices = [ { device = ""/dev/disk/by-label/swap""; } ];


     Packages
    
      Usually, the packages you need are already part of the Nix Packages
      collection, which is a set that can be accessed through the function
      argument pkgs. Typical uses:

environment.systemPackages =
  [ pkgs.thunderbird
    pkgs.emacs
  ];

services.postgresql.package = pkgs.postgresql_10;

      The latter option definition changes the default PostgreSQL package used
      by NixOS’s PostgreSQL service to 10.x. For more information on
      packages, including how to add new ones, see
      Section 6.1.2, “Adding Custom Packages”.
     
5.2. Abstractions
  If you find yourself repeating yourself over and over, it’s time to
  abstract. Take, for instance, this Apache HTTP Server configuration:

{
  services.httpd.virtualHosts =
    { ""blog.example.org"" = {
        documentRoot = ""/webroot/blog.example.org"";
        adminAddr = ""alice@example.org"";
        forceSSL = true;
        enableACME = true;
        enablePHP = true;
      };
      ""wiki.example.org"" = {
        documentRoot = ""/webroot/wiki.example.org"";
        adminAddr = ""alice@example.org"";
        forceSSL = true;
        enableACME = true;
        enablePHP = true;
      };
    };
}

  It defines two virtual hosts with nearly identical configuration; the only
  difference is the document root directories. To prevent this
  duplication, we can use a let:

let
  commonConfig =
    { adminAddr = ""alice@example.org"";
      forceSSL = true;
      enableACME = true;
    };
in
{
  services.httpd.virtualHosts =
    { ""blog.example.org"" = (commonConfig // { documentRoot = ""/webroot/blog.example.org""; });
      ""wiki.example.org"" = (commonConfig // { documentRoot = ""/webroot/wiki.example.com""; });
    };
}

  The let commonConfig = ...
  defines a variable named commonConfig. The
  // operator merges two attribute sets, so the
  configuration of the second virtual host is the set
  commonConfig extended with the document root option.
 
  You can write a let wherever an expression is allowed.
  Thus, you also could have written:

{
  services.httpd.virtualHosts =
    let commonConfig = ...; in
    { ""blog.example.org"" = (commonConfig // { ... })
      ""wiki.example.org"" = (commonConfig // { ... })
    };
}

  but not { let commonConfig = ...; in
  ...; } since attributes (as opposed to
  attribute values) are not expressions.
 
Functions provide another method of abstraction. For
  instance, suppose that we want to generate lots of different virtual hosts,
  all with identical configuration except for the document root. This can be done
  as follows:

{
  services.httpd.virtualHosts =
    let
      makeVirtualHost = webroot:
        { documentRoot = webroot;
          adminAddr = ""alice@example.org"";
          forceSSL = true;
          enableACME = true;
        };
    in
      { ""example.org"" = (makeVirtualHost ""/webroot/example.org"");
        ""example.com"" = (makeVirtualHost ""/webroot/example.com"");
        ""example.gov"" = (makeVirtualHost ""/webroot/example.gov"");
        ""example.nl"" = (makeVirtualHost ""/webroot/example.nl"");
      };
}

  Here, makeVirtualHost is a function that takes a single
  argument webroot and returns the configuration for a virtual
  host. That function is then called for several names to produce the list of
  virtual host configurations.
 5.3. Modularity
  The NixOS configuration mechanism is modular. If your
  configuration.nix becomes too big, you can split it into
  multiple files. Likewise, if you have multiple NixOS configurations (e.g. for
  different computers) with some commonality, you can move the common
  configuration into a shared file.
 
  Modules have exactly the same syntax as
  configuration.nix. In fact,
  configuration.nix is itself a module. You can use other
  modules by including them from configuration.nix, e.g.:

{ config, pkgs, ... }:

{ imports = [ ./vpn.nix ./kde.nix ];
  services.httpd.enable = true;
  environment.systemPackages = [ pkgs.emacs ];
  ...
}

  Here, we include two modules from the same directory,
  vpn.nix and kde.nix. The latter
  might look like this:

{ config, pkgs, ... }:

{ services.xserver.enable = true;
  services.xserver.displayManager.sddm.enable = true;
  services.xserver.desktopManager.plasma5.enable = true;
}

  Note that both configuration.nix and
  kde.nix define the option
  environment.systemPackages. When multiple modules
  define an option, NixOS will try to merge the
  definitions. In the case of environment.systemPackages,
  that’s easy: the lists of packages can simply be concatenated. The value in
  configuration.nix is merged last, so for list-type
  options, it will appear at the end of the merged list. If you want it to
  appear first, you can use mkBefore:

boot.kernelModules = mkBefore [ ""kvm-intel"" ];

  This causes the kvm-intel kernel module to be loaded
  before any other kernel modules.
 
  For other types of options, a merge may not be possible. For instance, if two
  modules define services.httpd.adminAddr,
  nixos-rebuild will give an error:

The unique option `services.httpd.adminAddr' is defined multiple times, in `/etc/nixos/httpd.nix' and `/etc/nixos/configuration.nix'.

  When that happens, it’s possible to force one definition take precedence
  over the others:

services.httpd.adminAddr = pkgs.lib.mkForce ""bob@example.org"";


  When using multiple modules, you may need to access configuration values
  defined in other modules. This is what the config function
  argument is for: it contains the complete, merged system configuration. That
  is, config is the result of combining the configurations
  returned by every module
  [1]
  . For example, here is a module that adds some packages to
  environment.systemPackages only if
  services.xserver.enable is set to
  true somewhere else:

{ config, pkgs, ... }:

{ environment.systemPackages =
    if config.services.xserver.enable then
      [ pkgs.firefox
        pkgs.thunderbird
      ]
    else
      [ ];
}


  With multiple modules, it may not be obvious what the final value of a
  configuration option is. The command nixos-option allows you
  to find out:

$ nixos-option services.xserver.enable
true

$ nixos-option boot.kernelModules
[ ""tun"" ""ipv6"" ""loop"" ... ]

  Interactive exploration of the configuration is possible using nix
  repl, a read-eval-print loop for Nix expressions. A typical use:

$ nix repl '<nixpkgs/nixos>'

nix-repl> config.networking.hostName
""mandark""

nix-repl> map (x: x.hostName) config.services.httpd.virtualHosts
[ ""example.org"" ""example.gov"" ]


  While abstracting your configuration, you may find it useful to generate
  modules using code, instead of writing files. The example below would have
  the same effect as importing a file which sets those options.

{ config, pkgs, ... }:

let netConfig = { hostName }: {
  networking.hostName = hostName;
  networking.useDHCP = false;
};

in

{ imports = [ (netConfig ""nixos.localdomain"") ]; }

5.4. Syntax Summary
  Below is a summary of the most important syntactic constructs in the Nix
  expression language. It’s not complete. In particular, there are many other
  built-in functions. See the
  Nix
  manual for the rest.
 ExampleDescriptionBasic values
""Hello world""
A string""${pkgs.bash}/bin/sh""
A string containing an expression (expands to ""/nix/store/hash-bash-version/bin/sh"")true, false
Booleans123
An integer./foo.png
A path (relative to the containing Nix expression)Compound values
{ x = 1; y = 2; }
A set with attributes named x and y
{ foo.bar = 1; }
A nested set, equivalent to { foo = { bar = 1; }; }
rec { x = ""foo""; y = x + ""bar""; }
A recursive set, equivalent to { x = ""foo""; y = ""foobar""; }
[ ""foo"" ""bar"" ]
A list with two elementsOperators
""foo"" + ""bar""
String concatenation1 + 2
Integer addition""foo"" == ""f"" + ""oo""
Equality test (evaluates to true)""foo"" != ""bar""
Inequality test (evaluates to true)!true
Boolean negation{ x = 1; y = 2; }.x
Attribute selection (evaluates to 1){ x = 1; y = 2; }.z or 3
Attribute selection with default (evaluates to 3){ x = 1; y = 2; } // { z = 3; }
Merge two sets (attributes in the right-hand set taking precedence)Control structures
if 1 + 1 == 2 then ""yes!"" else ""no!""
Conditional expressionassert 1 + 1 == 2; ""yes!""
Assertion check (evaluates to ""yes!""). See Section 44.4, “Warnings and Assertions” for using assertions in moduleslet x = ""foo""; y = ""bar""; in x + y
Variable definitionwith pkgs.lib; head [ 1 2 3 ]
Add all attributes from the given set to the scope
        (evaluates to 1)Functions (lambdas)
x: x + 1
A function that expects an integer and returns it increased by 1(x: x + 1) 100
A function call (evaluates to 101)let inc = x: x + 1; in inc (inc (inc 100))
A function bound to a variable and subsequently called by name (evaluates to 103){ x, y }: x + y
A function that expects a set with required attributes
        x and y and concatenates
        them{ x, y ? ""bar"" }: x + y
A function that expects a set with required attribute
        x and optional y, using
        ""bar"" as default value for
        y
{ x, y, ... }: x + y
A function that expects a set with required attributes
        x and y and ignores any
        other attributes{ x, y } @ args: x + y
A function that expects a set with required attributes
        x and y, and binds the
        whole set to args
Built-in functions
import ./foo.nix
Load and return Nix expression in given filemap (x: x + x) [ 1 2 3 ]
Apply a function to every element of a list (evaluates to [ 2 4 6 ])[1] 
    If you’re wondering how it’s possible that the (indirect)
    result of a function is passed as an
    input to that same function: that’s because Nix is a
    “lazy” language — it only computes values when they are needed. This
    works as long as no individual configuration value depends on itself.
   Chapter 6. Package ManagementTable of Contents6.1. Declarative Package Management6.2. Ad-Hoc Package Management
  This section describes how to add additional packages to your system. NixOS
  has two distinct styles of package management:
  
Declarative, where you declare what packages you want
     in your configuration.nix. Every time you run
     nixos-rebuild, NixOS will ensure that you get a
     consistent set of binaries corresponding to your specification.
    
Ad hoc, where you install, upgrade and uninstall
     packages via the nix-env command. This style allows
     mixing packages from different Nixpkgs versions. It’s the only choice
     for non-root users.
    
6.1. Declarative Package Management
  With declarative package management, you specify which packages you want on
  your system by setting the option
  environment.systemPackages. For instance, adding the
  following line to configuration.nix enables the Mozilla
  Thunderbird email application:

environment.systemPackages = [ pkgs.thunderbird ];

  The effect of this specification is that the Thunderbird package from Nixpkgs
  will be built or downloaded as part of the system when you run
  nixos-rebuild switch.
 Note: 
   Some packages require additional global configuration such as D-Bus or systemd service registration so adding them to environment.systemPackages might not be sufficient. You are advised to check the list of options whether a NixOS module for the package does not exist.
  
  You can get a list of the available packages as follows:

$ nix-env -qaP '*' --description
nixos.firefox   firefox-23.0   Mozilla Firefox - the browser, reloaded
...

  The first column in the output is the attribute name,
  such as nixos.thunderbird.
 
  Note: the nixos prefix tells us that we want to get the
  package from the nixos channel and works only in CLI tools.

  In declarative configuration use pkgs prefix (variable).
 
  To “uninstall” a package, simply remove it from
  environment.systemPackages and run
  nixos-rebuild switch.
 6.1.1. Customising Packages
  Some packages in Nixpkgs have options to enable or disable optional
  functionality or change other aspects of the package. For instance, the
  Firefox wrapper package (which provides Firefox with a set of plugins such as
  the Adobe Flash player) has an option to enable the Google Talk plugin. It
  can be set in configuration.nix as follows: 
  nixpkgs.config.firefox.enableGoogleTalkPlugin = true; 
Warning: 
   Unfortunately, Nixpkgs currently lacks a way to query available
   configuration options.
  
  Apart from high-level options, it’s possible to tweak a package in almost
  arbitrary ways, such as changing or disabling dependencies of a package. For
  instance, the Emacs package in Nixpkgs by default has a dependency on GTK 2.
  If you want to build it against GTK 3, you can specify that as follows:

environment.systemPackages = [ (pkgs.emacs.override { gtk = pkgs.gtk3; }) ];

  The function override performs the call to the Nix
  function that produces Emacs, with the original arguments amended by the set
  of arguments specified by you. So here the function argument
  gtk gets the value pkgs.gtk3, causing
  Emacs to depend on GTK 3. (The parentheses are necessary because in Nix,
  function application binds more weakly than list construction, so without
  them, environment.systemPackages would be a list with
  two elements.)
 
  Even greater customisation is possible using the function
  overrideAttrs. While the override
  mechanism above overrides the arguments of a package function,
  overrideAttrs allows changing the
  attributes passed to mkDerivation.
  This permits changing any aspect of the package, such as the source code. For
  instance, if you want to override the source code of Emacs, you can say:

environment.systemPackages = [
  (pkgs.emacs.overrideAttrs (oldAttrs: {
    name = ""emacs-25.0-pre"";
    src = /path/to/my/emacs/tree;
  }))
];

  Here, overrideAttrs takes the Nix derivation specified by
  pkgs.emacs and produces a new derivation in which the
  original’s name and src attribute
  have been replaced by the given values by re-calling
  stdenv.mkDerivation. The original attributes are
  accessible via the function argument, which is conventionally named
  oldAttrs.
 
  The overrides shown above are not global. They do not affect the original
  package; other packages in Nixpkgs continue to depend on the original rather
  than the customised package. This means that if another package in your
  system depends on the original package, you end up with two instances of the
  package. If you want to have everything depend on your customised instance,
  you can apply a global override as follows:

nixpkgs.config.packageOverrides = pkgs:
  { emacs = pkgs.emacs.override { gtk = pkgs.gtk3; };
  };

  The effect of this definition is essentially equivalent to modifying the
  emacs attribute in the Nixpkgs source tree. Any package in
  Nixpkgs that depends on emacs will be passed your
  customised instance. (However, the value pkgs.emacs in
  nixpkgs.config.packageOverrides refers to the original
  rather than overridden instance, to prevent an infinite recursion.)
 6.1.2. Adding Custom Packages
  It’s possible that a package you need is not available in NixOS. In that
  case, you can do two things. First, you can clone the Nixpkgs repository, add
  the package to your clone, and (optionally) submit a patch or pull request to
  have it accepted into the main Nixpkgs repository. This is described in
  detail in the Nixpkgs
  manual. In short, you clone Nixpkgs:

$ git clone https://github.com/NixOS/nixpkgs
$ cd nixpkgs

  Then you write and test the package as described in the Nixpkgs manual.
  Finally, you add it to environment.systemPackages, e.g.

environment.systemPackages = [ pkgs.my-package ];

  and you run nixos-rebuild, specifying your own Nixpkgs
  tree:

# nixos-rebuild switch -I nixpkgs=/path/to/my/nixpkgs

  The second possibility is to add the package outside of the Nixpkgs tree. For
  instance, here is how you specify a build of the
  GNU Hello
  package directly in configuration.nix:

environment.systemPackages =
  let
    my-hello = with pkgs; stdenv.mkDerivation rec {
      name = ""hello-2.8"";
      src = fetchurl {
        url = ""mirror://gnu/hello/${name}.tar.gz"";
        sha256 = ""0wqd8sjmxfskrflaxywc7gqw7sfawrfvdxd9skxawzfgyy0pzdz6"";
      };
    };
  in
  [ my-hello ];

  Of course, you can also move the definition of my-hello
  into a separate Nix expression, e.g.

environment.systemPackages = [ (import ./my-hello.nix) ];

  where my-hello.nix contains:

with import <nixpkgs> {}; # bring all of Nixpkgs into scope

stdenv.mkDerivation rec {
  name = ""hello-2.8"";
  src = fetchurl {
    url = ""mirror://gnu/hello/${name}.tar.gz"";
    sha256 = ""0wqd8sjmxfskrflaxywc7gqw7sfawrfvdxd9skxawzfgyy0pzdz6"";
  };
}

  This allows testing the package easily:

$ nix-build my-hello.nix
$ ./result/bin/hello
Hello, world!

6.2. Ad-Hoc Package Management
  With the command nix-env, you can install and uninstall
  packages from the command line. For instance, to install Mozilla Thunderbird:

$ nix-env -iA nixos.thunderbird
  If you invoke this as root, the package is installed in the Nix profile
  /nix/var/nix/profiles/default and visible to all users
  of the system; otherwise, the package ends up in
  /nix/var/nix/profiles/per-user/username/profile
  and is not visible to other users. The -A flag specifies the
  package by its attribute name; without it, the package is installed by
  matching against its package name (e.g. thunderbird). The
  latter is slower because it requires matching against all available Nix
  packages, and is ambiguous if there are multiple matching packages.
 
  Packages come from the NixOS channel. You typically upgrade a package by
  updating to the latest version of the NixOS channel:

$ nix-channel --update nixos

  and then running nix-env -i again. Other packages in the
  profile are not affected; this is the crucial difference
  with the declarative style of package management, where running
  nixos-rebuild switch causes all packages to be updated to
  their current versions in the NixOS channel. You can however upgrade all
  packages for which there is a newer version by doing:

$ nix-env -u '*'


  A package can be uninstalled using the -e flag:

$ nix-env -e thunderbird


  Finally, you can roll back an undesirable nix-env action:

$ nix-env --rollback


nix-env has many more flags. For details, see the
  nix-env(1) manpage or the Nix manual.
 Chapter 7. User Management
  NixOS supports both declarative and imperative styles of user management. In
  the declarative style, users are specified in
  configuration.nix. For instance, the following states
  that a user account named alice shall exist:

users.users.alice = {
  isNormalUser = true;
  home = ""/home/alice"";
  description = ""Alice Foobar"";
  extraGroups = [ ""wheel"" ""networkmanager"" ];
  openssh.authorizedKeys.keys = [ ""ssh-dss AAAAB3Nza... alice@foobar"" ];
};

  Note that alice is a member of the
  wheel and networkmanager groups, which
  allows her to use sudo to execute commands as
  root and to configure the network, respectively. Also note
  the SSH public key that allows remote logins with the corresponding private
  key. Users created in this way do not have a password by default, so they
  cannot log in via mechanisms that require a password. However, you can use
  the passwd program to set a password, which is retained
  across invocations of nixos-rebuild.
 
  If you set users.mutableUsers to false, then the
  contents of /etc/passwd and /etc/group
  will be congruent to your NixOS configuration. For instance, if you remove a
  user from users.users and run nixos-rebuild, the user
  account will cease to exist. Also, imperative commands for managing users and
  groups, such as useradd, are no longer available. Passwords may still be
  assigned by setting the user's
  hashedPassword
  option. A hashed password can be generated using mkpasswd -m
  sha-512 after installing the mkpasswd package.
 
  A user ID (uid) is assigned automatically. You can also specify a uid
  manually by adding

uid = 1000;

  to the user specification.
 
  Groups can be specified similarly. The following states that a group named
  students shall exist:

users.groups.students.gid = 1000;

  As with users, the group ID (gid) is optional and will be assigned
  automatically if it’s missing.
 
  In the imperative style, users and groups are managed by commands such as
  useradd, groupmod and so on. For
  instance, to create a user account named alice:

# useradd -m alice
  To make all nix tools available to this new user use `su - USER` which opens
  a login shell (==shell that loads the profile) for given user. This will
  create the ~/.nix-defexpr symlink. So run:

# su - alice -c ""true""
  The flag -m causes the creation of a home directory for the
  new user, which is generally what you want. The user does not have an initial
  password and therefore cannot log in. A password can be set using the
  passwd utility:

# passwd alice
Enter new UNIX password: ***
Retype new UNIX password: ***

  A user can be deleted using userdel:

# userdel -r alice
  The flag -r deletes the user’s home directory. Accounts
  can be modified using usermod. Unix groups can be managed
  using groupadd, groupmod and
  groupdel.
 Chapter 8. File SystemsTable of Contents8.1. LUKS-Encrypted File Systems
  You can define file systems using the fileSystems
  configuration option. For instance, the following definition causes NixOS to
  mount the Ext4 file system on device
  /dev/disk/by-label/data onto the mount point
  /data:

fileSystems.""/data"" =
  { device = ""/dev/disk/by-label/data"";
    fsType = ""ext4"";
  };

  Mount points are created automatically if they don’t already exist. For
  device,
  it’s best to use the topology-independent device aliases in
  /dev/disk/by-label and
  /dev/disk/by-uuid, as these don’t change if the
  topology changes (e.g. if a disk is moved to another IDE controller).
 
  You can usually omit the file system type
  (fsType),
  since mount can usually detect the type and load the
  necessary kernel module automatically. However, if the file system is needed
  at early boot (in the initial ramdisk) and is not ext2,
  ext3 or ext4, then it’s best to
  specify fsType to ensure that the kernel module is
  available.
 Note: 
   System startup will fail if any of the filesystems fails to mount, dropping
   you to the emergency shell. You can make a mount asynchronous and
   non-critical by adding
   options = [
   ""nofail"" ];.
  8.1. LUKS-Encrypted File Systems
  NixOS supports file systems that are encrypted using
  LUKS (Linux Unified Key Setup). For example, here is how
  you create an encrypted Ext4 file system on the device
  /dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d:

# cryptsetup luksFormat /dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d

WARNING!
========
This will overwrite data on /dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d irrevocably.

Are you sure? (Type uppercase yes): YES
Enter LUKS passphrase: ***
Verify passphrase: ***

# cryptsetup luksOpen /dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d crypted
Enter passphrase for /dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d: ***

# mkfs.ext4 /dev/mapper/crypted

  To ensure that this file system is automatically mounted at boot time as
  /, add the following to
  configuration.nix:

boot.initrd.luks.devices.crypted.device = ""/dev/disk/by-uuid/3f6b0024-3a44-4fde-a43a-767b872abe5d"";
fileSystems.""/"".device = ""/dev/mapper/crypted"";

  Should grub be used as bootloader, and /boot is located
  on an encrypted partition, it is necessary to add the following grub option:
boot.loader.grub.enableCryptodisk = true;
8.1.1. FIDO2
   NixOS also supports unlocking your LUKS-Encrypted file system using a FIDO2 compatible token. In the following example, we will create a new FIDO2 credential
   and add it as a new key to our existing device /dev/sda2:

   
# export FIDO2_LABEL=""/dev/sda2 @ $HOSTNAME""
# fido2luks credential ""$FIDO2_LABEL""
f1d00200108b9d6e849a8b388da457688e3dd653b4e53770012d8f28e5d3b269865038c346802f36f3da7278b13ad6a3bb6a1452e24ebeeaa24ba40eef559b1b287d2a2f80b7

# fido2luks -i add-key /dev/sda2 f1d00200108b9d6e849a8b388da457688e3dd653b4e53770012d8f28e5d3b269865038c346802f36f3da7278b13ad6a3bb6a1452e24ebeeaa24ba40eef559b1b287d2a2f80b7
Password:
Password (again):
Old password:
Old password (again):
Added to key to device /dev/sda2, slot: 2


  To ensure that this file system is decrypted using the FIDO2 compatible key, add the following to configuration.nix:

boot.initrd.luks.fido2Support = true;
boot.initrd.luks.devices.""/dev/sda2"".fido2.credential = ""f1d00200108b9d6e849a8b388da457688e3dd653b4e53770012d8f28e5d3b269865038c346802f36f3da7278b13ad6a3bb6a1452e24ebeeaa24ba40eef559b1b287d2a2f80b7"";


  You can also use the FIDO2 passwordless setup, but for security reasons, you might want to enable it only when your device is PIN protected, such as Trezor.


boot.initrd.luks.devices.""/dev/sda2"".fido2.passwordLess = true;

Chapter 9. X Window System
  The X Window System (X11) provides the basis of NixOS’ graphical user
  interface. It can be enabled as follows:

services.xserver.enable = true;

  The X server will automatically detect and use the appropriate video driver
  from a set of X.org drivers (such as vesa and
  intel). You can also specify a driver manually, e.g.

services.xserver.videoDrivers = [ ""r128"" ];

  to enable X.org’s xf86-video-r128 driver.
 
  You also need to enable at least one desktop or window manager. Otherwise,
  you can only log into a plain undecorated xterm window.
  Thus you should pick one or more of the following lines:

services.xserver.desktopManager.plasma5.enable = true;
services.xserver.desktopManager.xfce.enable = true;
services.xserver.desktopManager.gnome3.enable = true;
services.xserver.desktopManager.mate.enable = true;
services.xserver.windowManager.xmonad.enable = true;
services.xserver.windowManager.twm.enable = true;
services.xserver.windowManager.icewm.enable = true;
services.xserver.windowManager.i3.enable = true;


  NixOS’s default display manager (the program that
  provides a graphical login prompt and manages the X server) is LightDM. You
  can select an alternative one by picking one of the following lines:

services.xserver.displayManager.sddm.enable = true;
services.xserver.displayManager.gdm.enable = true;


  You can set the keyboard layout (and optionally the layout variant):

services.xserver.layout = ""de"";
services.xserver.xkbVariant = ""neo"";


  The X server is started automatically at boot time. If you don’t want this
  to happen, you can set:

services.xserver.autorun = false;

  The X server can then be started manually:

# systemctl start display-manager.service


  On 64-bit systems, if you want OpenGL for 32-bit programs such as in Wine,
  you should also set the following:

hardware.opengl.driSupport32Bit = true;

Auto-login
  The x11 login screen can be skipped entirely, automatically logging you into
  your window manager and desktop environment when you boot your computer.
  
  This is especially helpful if you have disk encryption enabled. Since you
  already have to provide a password to decrypt your disk, entering a second
  password to login can be redundant.
  
  To enable auto-login, you need to define your default window manager and
  desktop environment. If you wanted no desktop environment and i3 as your your
  window manager, you'd define:

services.xserver.displayManager.defaultSession = ""none+i3"";

  Every display manager in NixOS supports auto-login, here is an example
  using lightdm for a user alice:

services.xserver.displayManager.lightdm.enable = true;
services.xserver.displayManager.lightdm.autoLogin.enable = true;
services.xserver.displayManager.lightdm.autoLogin.user = ""alice"";

  The options are named identically for all other display managers.
  Proprietary NVIDIA drivers
   NVIDIA provides a proprietary driver for its graphics cards that has better
   3D performance than the X.org drivers. It is not enabled by default because
   it’s not free software. You can enable it as follows:

services.xserver.videoDrivers = [ ""nvidia"" ];

   Or if you have an older card, you may have to use one of the legacy drivers:

services.xserver.videoDrivers = [ ""nvidiaLegacy390"" ];
services.xserver.videoDrivers = [ ""nvidiaLegacy340"" ];
services.xserver.videoDrivers = [ ""nvidiaLegacy304"" ];
services.xserver.videoDrivers = [ ""nvidiaLegacy173"" ];

   You may need to reboot after enabling this driver to prevent a clash with
   other kernel modules.
  Proprietary AMD drivers
   AMD provides a proprietary driver for its graphics cards that has better 3D
   performance than the X.org drivers. It is not enabled by default because
   it’s not free software. You can enable it as follows:

services.xserver.videoDrivers = [ ""ati_unfree"" ];

   You will need to reboot after enabling this driver to prevent a clash with
   other kernel modules.
  Note: 
   For recent AMD GPUs you most likely want to keep either the defaults
   or ""amdgpu"" (both free).
  Touchpads
   Support for Synaptics touchpads (found in many laptops such as the Dell
   Latitude series) can be enabled as follows:

services.xserver.libinput.enable = true;

   The driver has many options (see Appendix A, Configuration Options). For
   instance, the following disables tap-to-click behavior:

services.xserver.libinput.tapping = false;

   Note: the use of services.xserver.synaptics is deprecated
   since NixOS 17.09.
  GTK/Qt themes
   GTK themes can be installed either to user profile or system-wide (via
   environment.systemPackages). To make Qt 5 applications
   look similar to GTK2 ones, you can install qt5.qtbase.gtk
   package into your system environment. It should work for all Qt 5 library
   versions.
  Custom XKB layouts
   It is possible to install custom
   
    XKB
   
   keyboard layouts using the option
   

     services.xserver.extraLayouts
    
.
   As a first example, we are going to create a layout based on the basic US
   layout, with an additional layer to type some greek symbols by pressing the
   right-alt key.
  
   To do this we are going to create a us-greek file
   with a xkb_symbols section.
  
xkb_symbols ""us-greek""
{
  include ""us(basic)""            // includes the base US keys
  include ""level3(ralt_switch)""  // configures right alt as a third level switch

  key <LatA> { [ a, A, Greek_alpha ] };
  key <LatB> { [ b, B, Greek_beta  ] };
  key <LatG> { [ g, G, Greek_gamma ] };
  key <LatD> { [ d, D, Greek_delta ] };
  key <LatZ> { [ z, Z, Greek_zeta  ] };
};

   To install the layout, the filepath, a description and the list of
   languages must be given:
  
services.xserver.extraLayouts.us-greek = {
  description = ""US layout with alt-gr greek"";
  languages   = [ ""eng"" ];
  symbolsFile = /path/to/us-greek;
}
Note: 
   The name should match the one given to the
   xkb_symbols block.
  
   The layout should now be installed and ready to use: try it by
   running setxkbmap us-greek and type
   <alt>+a. To change the default the usual
   

     services.xserver.layout
    

   option can still be used.
  
   A layout can have several other components besides
   xkb_symbols, for example we will define new
   keycodes for some multimedia key and bind these to some symbol.
  
   Use the xev utility from
   pkgs.xorg.xev to find the codes of the keys of
   interest, then create a media-key file to hold
   the keycodes definitions
  
xkb_keycodes ""media""
{
 <volUp>   = 123;
 <volDown> = 456;
}

    Now use the newly define keycodes in media-sym:
  
xkb_symbols ""media""
{
 key.type = ""ONE_LEVEL"";
 key <volUp>   { [ XF86AudioLowerVolume ] };
 key <volDown> { [ XF86AudioRaiseVolume ] };
}

    As before, to install the layout do
  
services.xserver.extraLayouts.media = {
  description  = ""Multimedia keys remapping"";
  languages    = [ ""eng"" ];
  symbolsFile  = /path/to/media-key;
  keycodesFile = /path/to/media-sym;
};
Note: 
   The function pkgs.writeText <filename> <content>
    can be useful if you prefer to keep the layout definitions
   inside the NixOS configuration.
  
    Unfortunately, the Xorg server does not (currently) support setting a
    keymap directly but relies instead on XKB rules to select the matching
    components (keycodes, types, ...) of a layout. This means that components
    other than symbols won't be loaded by default. As a workaround, you
    can set the keymap using setxkbmap at the start of the
    session with:
  
services.xserver.displayManager.sessionCommands = ""setxkbmap -keycodes media"";

    If you are manually starting the X server, you should set the argument
    -xkbdir /etc/X11/xkb, otherwise X won't find your layout files.
    For example with xinit run
    $ xinit -- -xkbdir /etc/X11/xkb

   To learn how to write layouts take a look at the XKB
  
   documentation
  . More example layouts can also be found
  
   here
  .
  Chapter 10. Xfce Desktop Environment
  To enable the Xfce Desktop Environment, set

services.xserver.desktopManager.xfce.enable = true;
services.xserver.displayManager.defaultSession = ""xfce"";


  Optionally, picom can be enabled for nice graphical
  effects, some example settings:

services.picom = {
  enable          = true;
  fade            = true;
  inactiveOpacity = ""0.9"";
  shadow          = true;
  fadeDelta       = 4;
};


  Some Xfce programs are not installed automatically. To install them manually
  (system wide), put them into your
  environment.systemPackages from pkgs.xfce.
 Thunar Plugins
    If you'd like to add extra plugins to Thunar, add them to
    services.xserver.desktopManager.xfce.thunarPlugins.
    You shouldn't just add them to environment.systemPackages.
  Troubleshooting
   Even after enabling udisks2, volume management might not work. Thunar and/or
   the desktop takes time to show up. Thunar will spit out this kind of message
   on start (look at journalctl --user -b).

Thunar:2410): GVFS-RemoteVolumeMonitor-WARNING **: remote volume monitor with dbus name org.gtk.Private.UDisks2VolumeMonitor is not supported

   This is caused by some needed GNOME services not running. This is all fixed
   by enabling ""Launch GNOME services on startup"" in the Advanced tab of the
   Session and Startup settings panel. Alternatively, you can run this command
   to do the same thing.

$ xfconf-query -c xfce4-session -p /compat/LaunchGNOME -s true

   A log-out and re-log will be needed for this to take effect.
  Chapter 11. NetworkingTable of Contents11.1. NetworkManager11.2. Secure Shell Access11.3. IPv4 Configuration11.4. IPv6 Configuration11.5. Firewall11.6. Wireless Networks11.7. Ad-Hoc Configuration
  This section describes how to configure networking components on your NixOS
  machine.
 11.1. NetworkManager
  To facilitate network configuration, some desktop environments use
  NetworkManager. You can enable NetworkManager by setting:

networking.networkmanager.enable = true;

  some desktop managers (e.g., GNOME) enable NetworkManager automatically for
  you.
 
  All users that should have permission to change network settings must belong
  to the networkmanager group:

users.users.alice.extraGroups = [ ""networkmanager"" ];


  NetworkManager is controlled using either nmcli or
  nmtui (curses-based terminal user interface). See their
  manual pages for details on their usage. Some desktop environments (GNOME,
  KDE) have their own configuration tools for NetworkManager. On XFCE, there is
  no configuration tool for NetworkManager by default: by enabling programs.nm-applet.enable, the
  graphical applet will be installed and will launch automatically when the graphical session is started.
 Note
networking.networkmanager and networking.wireless
   (WPA Supplicant) can be used together if desired. To do this you need to instruct
   NetworkManager to ignore those interfaces like:

networking.networkmanager.unmanaged = [
   ""*"" ""except:type:wwan"" ""except:type:gsm""
];

   Refer to the option description for the exact syntax and references to external documentation.
  11.2. Secure Shell Access
  Secure shell (SSH) access to your machine can be enabled by setting:

services.openssh.enable = true;

  By default, root logins using a password are disallowed. They can be disabled
  entirely by setting services.openssh.permitRootLogin to
  ""no"".
 
  You can declaratively specify authorised RSA/DSA public keys for a user as
  follows:


users.users.alice.openssh.authorizedKeys.keys =
  [ ""ssh-dss AAAAB3NzaC1kc3MAAACBAPIkGWVEt4..."" ];

11.3. IPv4 Configuration
  By default, NixOS uses DHCP (specifically, dhcpcd) to
  automatically configure network interfaces. However, you can configure an
  interface manually as follows:

networking.interfaces.eth0.ipv4.addresses = [ {
  address = ""192.168.1.2"";
  prefixLength = 24;
} ];

  Typically you’ll also want to set a default gateway and set of name
  servers:

networking.defaultGateway = ""192.168.1.1"";
networking.nameservers = [ ""8.8.8.8"" ];

Note: 
   Statically configured interfaces are set up by the systemd service
   interface-name-cfg.service.
   The default gateway and name server configuration is performed by
   network-setup.service.
  
  The host name is set using networking.hostName:

networking.hostName = ""cartman"";

  The default host name is nixos. Set it to the empty string
  ("""") to allow the DHCP server to provide the host name.
 11.4. IPv6 Configuration
  IPv6 is enabled by default. Stateless address autoconfiguration is used to
  automatically assign IPv6 addresses to all interfaces. You can disable IPv6
  support globally by setting:

networking.enableIPv6 = false;


  You can disable IPv6 on a single interface using a normal sysctl (in this
  example, we use interface eth0):

boot.kernel.sysctl.""net.ipv6.conf.eth0.disable_ipv6"" = true;


  As with IPv4 networking interfaces are automatically configured via DHCPv6.
  You can configure an interface manually:

networking.interfaces.eth0.ipv6.addresses = [ {
  address = ""fe00:aa:bb:cc::2"";
  prefixLength = 64;
} ];


  For configuring a gateway, optionally with explicitly specified interface:

networking.defaultGateway6 = {
  address = ""fe00::1"";
  interface = ""enp0s3"";
};


  See Section 11.3, “IPv4 Configuration” for similar examples and additional
  information.
 11.5. Firewall
  NixOS has a simple stateful firewall that blocks incoming connections and
  other unexpected packets. The firewall applies to both IPv4 and IPv6 traffic.
  It is enabled by default. It can be disabled as follows:

networking.firewall.enable = false;

  If the firewall is enabled, you can open specific TCP ports to the outside
  world:

networking.firewall.allowedTCPPorts = [ 80 443 ];

  Note that TCP port 22 (ssh) is opened automatically if the SSH daemon is
  enabled (services.openssh.enable =
  true). UDP ports can be opened through
  networking.firewall.allowedUDPPorts.
 
  To open ranges of TCP ports:

networking.firewall.allowedTCPPortRanges = [
  { from = 4000; to = 4007; }
  { from = 8000; to = 8010; }
];

  Similarly, UDP port ranges can be opened through
  networking.firewall.allowedUDPPortRanges.
 11.6. Wireless Networks
  For a desktop installation using NetworkManager (e.g., GNOME), you just have
  to make sure the user is in the networkmanager group and you can
  skip the rest of this section on wireless networks.
 
  NixOS will start wpa_supplicant for you if you enable this setting:

networking.wireless.enable = true;

  NixOS lets you specify networks for wpa_supplicant declaratively:

networking.wireless.networks = {
  echelon = {                # SSID with no spaces or special characters
    psk = ""abcdefgh"";
  };
  ""echelon's AP"" = {         # SSID with spaces and/or special characters
    psk = ""ijklmnop"";
  };
  echelon = {                # Hidden SSID
    hidden = true;
    psk = ""qrstuvwx"";
  };
  free.wifi = {};            # Public wireless network
};

  Be aware that keys will be written to the nix store in plaintext! When no
  networks are set, it will default to using a configuration file at
  /etc/wpa_supplicant.conf. You should edit this file
  yourself to define wireless networks, WPA keys and so on (see wpa_supplicant.conf(5)).
 
  If you are using WPA2 you can generate pskRaw key using
  wpa_passphrase:

$ wpa_passphrase ESSID PSK
network={
        ssid=""echelon""
        #psk=""abcdefgh""
        psk=dca6d6ed41f4ab5a984c9f55f6f66d4efdc720ebf66959810f4329bb391c5435
}


networking.wireless.networks = {
  echelon = {
    pskRaw = ""dca6d6ed41f4ab5a984c9f55f6f66d4efdc720ebf66959810f4329bb391c5435"";
  };
}

  or you can use it to directly generate the
  wpa_supplicant.conf:

# wpa_passphrase ESSID PSK > /etc/wpa_supplicant.conf
  After you have edited the wpa_supplicant.conf, you need to
  restart the wpa_supplicant service.

# systemctl restart wpa_supplicant.service
11.7. Ad-Hoc Configuration
  You can use networking.localCommands to specify shell
  commands to be run at the end of network-setup.service.
  This is useful for doing network configuration not covered by the existing
  NixOS modules. For instance, to statically configure an IPv6 address:

networking.localCommands =
  ''
    ip -6 addr add 2001:610:685:1::1/64 dev eth0
  '';

Chapter 12. Linux KernelTable of Contents12.1. Customize your kernel12.2. Developing kernel modules
  You can override the Linux kernel and associated packages using the option
  boot.kernelPackages. For instance, this selects the Linux
  3.10 kernel:

boot.kernelPackages = pkgs.linuxPackages_3_10;

  Note that this not only replaces the kernel, but also packages that are
  specific to the kernel version, such as the NVIDIA video drivers. This
  ensures that driver packages are consistent with the kernel.
 
  The default Linux kernel configuration should be fine for most users. You can
  see the configuration of your current kernel with the following command:

zcat /proc/config.gz

  If you want to change the kernel configuration, you can use the
  packageOverrides feature (see
  Section 6.1.1, “Customising Packages”). For instance, to enable support
  for the kernel debugger KGDB:

nixpkgs.config.packageOverrides = pkgs:
  { linux_3_4 = pkgs.linux_3_4.override {
      extraConfig =
        ''
          KGDB y
        '';
    };
  };

extraConfig takes a list of Linux kernel configuration
  options, one per line. The name of the option should not include the prefix
  CONFIG_. The option value is typically
  y, n or m (to build
  something as a kernel module).
 
  Kernel modules for hardware devices are generally loaded automatically by
  udev. You can force a module to be loaded via
  boot.kernelModules, e.g.

boot.kernelModules = [ ""fuse"" ""kvm-intel"" ""coretemp"" ];

  If the module is required early during the boot (e.g. to mount the root file
  system), you can use boot.initrd.kernelModules:

boot.initrd.kernelModules = [ ""cifs"" ];

  This causes the specified modules and their dependencies to be added to the
  initial ramdisk.
 
  Kernel runtime parameters can be set through
  boot.kernel.sysctl, e.g.

boot.kernel.sysctl.""net.ipv4.tcp_keepalive_time"" = 120;

  sets the kernel’s TCP keepalive time to 120 seconds. To see the available
  parameters, run sysctl -a.
 12.1. Customize your kernel
   The first step before compiling the kernel is to generate an appropriate
   .config configuration. Either you pass your own config
   via the configfile setting of
   linuxManualConfig:

  custom-kernel = super.linuxManualConfig {
    inherit (super) stdenv hostPlatform;
    inherit (linux_4_9) src;
    version = ""${linux_4_9.version}-custom"";

    configfile = /home/me/my_kernel_config;
    allowImportFromDerivation = true;
  };
  
   You can edit the config with this snippet (by default make
   menuconfig won't work out of the box on nixos):

      nix-shell -E 'with import <nixpkgs> {}; kernelToOverride.overrideAttrs (o: {nativeBuildInputs=o.nativeBuildInputs ++ [ pkgconfig ncurses ];})'
  
   or you can let nixpkgs generate the configuration. Nixpkgs generates it via
   answering the interactive kernel utility make config. The
   answers depend on parameters passed to
   pkgs/os-specific/linux/kernel/generic.nix (which you
   can influence by overriding extraConfig, autoModules,
   modDirVersion, preferBuiltin, extraConfig).


  mptcp93.override ({
      name=""mptcp-local"";

      ignoreConfigErrors = true;
      autoModules = false;
      kernelPreferBuiltin = true;

      enableParallelBuilding = true;

      extraConfig = ''
        DEBUG_KERNEL y
        FRAME_POINTER y
        KGDB y
        KGDB_SERIAL_CONSOLE y
        DEBUG_INFO y
      '';
    });
  
12.2. Developing kernel modules
   When developing kernel modules it's often convenient to run edit-compile-run
   loop as quickly as possible. See below snippet as an example of developing
   mellanox drivers.
  
$ nix-build '<nixpkgs>' -A linuxPackages.kernel.dev
$ nix-shell '<nixpkgs>' -A linuxPackages.kernel
$ unpackPhase
$ cd linux-*
$ make -C $dev/lib/modules/*/build M=$(pwd)/drivers/net/ethernet/mellanox modules
# insmod ./drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.ko
Chapter 13. Pantheon DesktopTable of Contents13.1. Enabling Pantheon13.2. Wingpanel and Switchboard plugins13.3. FAQ
  Pantheon is the desktop environment created for the elementary OS distribution. It is written from scratch in Vala, utilizing GNOME technologies with GTK 3 and Granite.
 13.1. Enabling Pantheon
   All of Pantheon is working in NixOS and the applications should be available, aside from a few exceptions. To enable Pantheon, set

services.xserver.desktopManager.pantheon.enable = true;

   This automatically enables LightDM and Pantheon's LightDM greeter. If you'd like to disable this, set

services.xserver.displayManager.lightdm.greeters.pantheon.enable = false;
services.xserver.displayManager.lightdm.enable = false;

   but please be aware using Pantheon without LightDM as a display manager will break screenlocking from the UI. The NixOS module for Pantheon installs all of Pantheon's default applications. If you'd like to not install Pantheon's apps, set

services.pantheon.apps.enable = false;

   You can also use environment.pantheon.excludePackages to remove any other app (like geary).
  13.2. Wingpanel and Switchboard plugins
   Wingpanel and Switchboard work differently than they do in other distributions, as far as using plugins. You cannot install a plugin globally (like with environment.systemPackages) to start using it. You should instead be using the following options:
   
services.xserver.desktopManager.pantheon.extraWingpanelIndicators

services.xserver.desktopManager.pantheon.extraSwitchboardPlugs

   to configure the programs with plugs or indicators.
  
   The difference in NixOS is both these programs are patched to load plugins from a directory that is the value of an environment variable. All of which is controlled in Nix. If you need to configure the particular packages manually you can override the packages like:

wingpanel-with-indicators.override {
  indicators = [
    pkgs.some-special-indicator
  ];
};

switchboard-with-plugs.override {
  plugs = [
    pkgs.some-special-plug
  ];
};

   please note that, like how the NixOS options describe these as extra plugins, this would only add to the default plugins included with the programs. If for some reason you'd like to configure which plugins to use exactly, both packages have an argument for this:

wingpanel-with-indicators.override {
  useDefaultIndicators = false;
  indicators = specialListOfIndicators;
};

switchboard-with-plugs.override {
  useDefaultPlugs = false;
  plugs = specialListOfPlugs;
};

   this could be most useful for testing a particular plug-in in isolation.
  13.3. FAQ
     I have switched from a different desktop and Pantheon’s theming looks messed up.
    
      Open Switchboard and go to: Administration → About → Restore Default Settings → Restore Settings. This will reset any dconf settings to their Pantheon defaults. Note this could reset certain GNOME specific preferences if that desktop was used prior.
     
     I cannot enable both GNOME 3 and Pantheon.
    
      This is a known issue and there is no known workaround.
     
     Does AppCenter work, or is it available?
    
      AppCenter has been available since 20.03, but it is of little use. This is because there is no functioning PackageKit backend for Nix 2.0. In the near future you will be able to install Flatpak applications from AppCenter on NixOS. See this issue.
     Chapter 14. MatomoTable of Contents14.1. Database Setup14.2. Archive Processing14.3. Backup14.4. Issues14.5. Using other Web Servers than nginx
  Matomo is a real-time web analytics application. This module configures
  php-fpm as backend for Matomo, optionally configuring an nginx vhost as well.
 
  An automatic setup is not suported by Matomo, so you need to configure Matomo
  itself in the browser-based Matomo setup.
 14.1. Database Setup
   You also need to configure a MariaDB or MySQL database and -user for Matomo
   yourself, and enter those credentials in your browser. You can use
   passwordless database authentication via the UNIX_SOCKET authentication
   plugin with the following SQL commands:

# For MariaDB
INSTALL PLUGIN unix_socket SONAME 'auth_socket';
CREATE DATABASE matomo;
CREATE USER 'matomo'@'localhost' IDENTIFIED WITH unix_socket;
GRANT ALL PRIVILEGES ON matomo.* TO 'matomo'@'localhost';

# For MySQL
INSTALL PLUGIN auth_socket SONAME 'auth_socket.so';
CREATE DATABASE matomo;
CREATE USER 'matomo'@'localhost' IDENTIFIED WITH auth_socket;
GRANT ALL PRIVILEGES ON matomo.* TO 'matomo'@'localhost';

   Then fill in matomo as database user and database name,
   and leave the password field blank. This authentication works by allowing
   only the matomo unix user to authenticate as the
   matomo database user (without needing a password), but no
   other users. For more information on passwordless login, see
   https://mariadb.com/kb/en/mariadb/unix_socket-authentication-plugin/.
  
   Of course, you can use password based authentication as well, e.g. when the
   database is not on the same host.
  14.2. Archive Processing
   This module comes with the systemd service
   matomo-archive-processing.service and a timer that
   automatically triggers archive processing every hour. This means that you
   can safely
   
   disable browser triggers for Matomo archiving  at
   Administration > System > General Settings.
  
   With automatic archive processing, you can now also enable to
   
   delete old visitor logs  at Administration > System >
   Privacy, but make sure that you run systemctl start
   matomo-archive-processing.service at least once without errors if
   you have already collected data before, so that the reports get archived
   before the source data gets deleted.
  14.3. Backup
   You only need to take backups of your MySQL database and the
   /var/lib/matomo/config/config.ini.php file. Use a user
   in the matomo group or root to access the file. For more
   information, see
   https://matomo.org/faq/how-to-install/faq_138/.
  14.4. Issues
     Matomo will warn you that the JavaScript tracker is not writable. This is
     because it's located in the read-only nix store. You can safely ignore
     this, unless you need a plugin that needs JavaScript tracker access.
    14.5. Using other Web Servers than nginx
   You can use other web servers by forwarding calls for
   index.php and piwik.php to the
   services.phpfpm.pools.<name>.socket fastcgi unix socket. You can use
   the nginx configuration in the module code as a reference to what else
   should be configured.
  Chapter 15. NextcloudTable of Contents15.1. Basic usage15.2. Pitfalls15.3. Maintainer information
Nextcloud is an open-source,
  self-hostable cloud platform. The server setup can be automated using
  services.nextcloud. A
  desktop client is packaged at pkgs.nextcloud-client.
 15.1. Basic usage
   Nextcloud is a PHP-based application which requires an HTTP server
   (services.nextcloud
   optionally supports
   services.nginx)
   and a database (it's recommended to use
   services.postgresql).
  
   A very basic configuration may look like this:
{ pkgs, ... }:
{
  services.nextcloud = {
    enable = true;
    hostName = ""nextcloud.tld"";
    nginx.enable = true;
    config = {
      dbtype = ""pgsql"";
      dbuser = ""nextcloud"";
      dbhost = ""/run/postgresql""; # nextcloud will add /.s.PGSQL.5432 by itself
      dbname = ""nextcloud"";
      adminpassFile = ""/path/to/admin-pass-file"";
      adminuser = ""root"";
    };
  };

  services.postgresql = {
    enable = true;
    ensureDatabases = [ ""nextcloud"" ];
    ensureUsers = [
     { name = ""nextcloud"";
       ensurePermissions.""DATABASE nextcloud"" = ""ALL PRIVILEGES"";
     }
    ];
  };

  # ensure that postgres is running *before* running the setup
  systemd.services.""nextcloud-setup"" = {
    requires = [""postgresql.service""];
    after = [""postgresql.service""];
  };

  networking.firewall.allowedTCPPorts = [ 80 443 ];
}

   The options hostName and nginx.enable
   are used internally to configure an HTTP server using
   PHP-FPM
   and nginx. The config attribute set is
   used by the imperative installer and all values are written to an additional file
   to ensure that changes can be applied by changing the module's options.
  
   In case the application serves multiple domains (those are checked with
   $_SERVER['HTTP_HOST'])
   it's needed to add them to
   services.nextcloud.config.extraTrustedDomains.
  
   Auto updates for Nextcloud apps can be enabled using
   services.nextcloud.autoUpdateApps.
15.2. Pitfalls
   Unfortunately Nextcloud appears to be very stateful when it comes to
   managing its own configuration. The config file lives in the home directory
   of the nextcloud user (by default
   /var/lib/nextcloud/config/config.php) and is also used to
   track several states of the application (e.g. whether installed or not).
  
   All configuration parameters are also stored in
   /var/lib/nextcloud/config/override.config.php which is generated by
   the module and linked from the store to ensure that all values from config.php
   can be modified by the module.
   However config.php manages the application's state and shouldn't be touched
   manually because of that.
  Warning: Don't delete config.php! This file
   tracks the application's state and a deletion can cause unwanted
   side-effects!Warning: Don't rerun nextcloud-occ
   maintenance:install! This command tries to install the application
   and can cause unwanted side-effects!
   Nextcloud doesn't allow to move more than one major-version forward. If you're e.g. on
   v16, you cannot upgrade to v18, you need to upgrade to
   v17 first. This is ensured automatically as long as the
   stateVersion is declared properly. In that case
   the oldest version available (one major behind the one from the previous NixOS
   release) will be selected by default and the module will generate a warning that reminds
   the user to upgrade to latest Nextcloud after that deploy.
  15.3. Maintainer information
   As stated in the previous paragraph, we must provide a clean upgrade-path for Nextcloud
   since it cannot move more than one major version forward on a single upgrade. This chapter
   adds some notes how Nextcloud updates should be rolled out in the future.
  
   While minor and patch-level updates are no problem and can be done directly in the
   package-expression (and should be backported to supported stable branches after that),
   major-releases should be added in a new attribute (e.g. Nextcloud v19.0.0
   should be available in nixpkgs as pkgs.nextcloud19).
   To provide simple upgrade paths it's generally useful to backport those as well to stable
   branches. As long as the package-default isn't altered, this won't break existing setups.
   After that, the versioning-warning in the nextcloud-module should be
   updated to make sure that the
   package-option selects the latest version
   on fresh setups.
  
   If major-releases will be abandoned by upstream, we should check first if those are needed
   in NixOS for a safe upgrade-path before removing those. In that case we shold keep those
   packages, but mark them as insecure in an expression like this (in
   <nixpkgs/pkgs/servers/nextcloud/default.nix>):
/* ... */
{
  nextcloud17 = generic {
    version = ""17.0.x"";
    sha256 = ""0000000000000000000000000000000000000000000000000000"";
    insecure = true;
  };
}
Chapter 16. GrocyTable of Contents16.1. Basic usage16.2. Settings
Grocy is a web-based self-hosted groceries
    & household management solution for your home.
  16.1. Basic usage
    A very basic configuration may look like this:
{ pkgs, ... }:
{
  services.grocy = {
    enable = true;
    hostName = ""grocy.tld"";
  };
}
    This configures a simple vhost using nginx
    which listens to grocy.tld with fully configured ACME/LE (this can be
    disabled by setting services.grocy.nginx.enableSSL
    to false). After the initial setup the credentials admin:admin
    can be used to login.
   
    The application's state is persisted at /var/lib/grocy/grocy.db in a
    sqlite3 database. The migration is applied when requesting the /-route
    of the application.
   16.2. Settings
    The configuration for grocy is located at /etc/grocy/config.php.
    By default, the following settings can be defined in the NixOS-configuration:
{ pkgs, ... }:
{
  services.grocy.settings = {
    # The default currency in the system for invoices etc.
    # Please note that exchange rates aren't taken into account, this
    # is just the setting for what's shown in the frontend.
    currency = ""EUR"";

    # The display language (and locale configuration) for grocy.
    culture = ""de"";

    calendar = {
      # Whether or not to show the week-numbers
      # in the calendar.
      showWeekNumber = true;

      # Index of the first day to be shown in the calendar (0=Sunday, 1=Monday,
      # 2=Tuesday and so on).
      firstDayOfWeek = 2;
    };
  };
}

    If you want to alter the configuration file on your own, you can do this manually with
    an expression like this:
{ lib, ... }:
{
  environment.etc.""grocy/config.php"".text = lib.mkAfter ''
    // Arbitrary PHP code in grocy's configuration file
  '';
}
Chapter 17. Prometheus exportersTable of Contents17.1. Configuration17.2. Adding a new exporter17.3. Updating an exporter module
  Prometheus exporters provide metrics for the
  prometheus monitoring system.
 17.1. Configuration
   One of the most common exporters is the
   node
   exporter, it provides hardware and OS metrics from the host it's
   running on. The exporter could be configured as follows:

  services.prometheus.exporters.node = {
    enable = true;
    enabledCollectors = [
      ""logind""
      ""systemd""
    ];
    disabledCollectors = [
      ""textfile""
    ];
    openFirewall = true;
    firewallFilter = ""-i br0 -p tcp -m tcp --dport 9100"";
  };

   It should now serve all metrics from the collectors that are explicitly
   enabled and the ones that are
   enabled
   by default, via http under /metrics. In this
   example the firewall should just allow incoming connections to the
   exporter's port on the bridge interface br0 (this would
   have to be configured seperately of course). For more information about
   configuration see man configuration.nix or search through
   the
   available
   options.
  17.2. Adding a new exporter
   To add a new exporter, it has to be packaged first (see
   nixpkgs/pkgs/servers/monitoring/prometheus/ for
   examples), then a module can be added. The postfix exporter is used in this
   example:
  
     Some default options for all exporters are provided by
     nixpkgs/nixos/modules/services/monitoring/prometheus/exporters.nix:
    
enable

port

listenAddress

extraFlags

openFirewall

firewallFilter

user

group

     As there is already a package available, the module can now be added. This
     is accomplished by adding a new file to the
     nixos/modules/services/monitoring/prometheus/exporters/
     directory, which will be called postfix.nix and contains all exporter
     specific options and configuration:

# nixpgs/nixos/modules/services/prometheus/exporters/postfix.nix
{ config, lib, pkgs, options }:

with lib;

let
  # for convenience we define cfg here
  cfg = config.services.prometheus.exporters.postfix;
in
{
  port = 9154; # The postfix exporter listens on this port by default

  # `extraOpts` is an attribute set which contains additional options
  # (and optional overrides for default options).
  # Note that this attribute is optional.
  extraOpts = {
    telemetryPath = mkOption {
      type = types.str;
      default = ""/metrics"";
      description = ''
        Path under which to expose metrics.
      '';
    };
    logfilePath = mkOption {
      type = types.path;
      default = /var/log/postfix_exporter_input.log;
      example = /var/log/mail.log;
      description = ''
        Path where Postfix writes log entries.
        This file will be truncated by this exporter!
      '';
    };
    showqPath = mkOption {
      type = types.path;
      default = /var/spool/postfix/public/showq;
      example = /var/lib/postfix/queue/public/showq;
      description = ''
        Path at which Postfix places its showq socket.
      '';
    };
  };

  # `serviceOpts` is an attribute set which contains configuration
  # for the exporter's systemd service. One of
  # `serviceOpts.script` and `serviceOpts.serviceConfig.ExecStart`
  # has to be specified here. This will be merged with the default
  # service confiuration.
  # Note that by default 'DynamicUser' is 'true'.
  serviceOpts = {
    serviceConfig = {
      DynamicUser = false;
      ExecStart = ''
        ${pkgs.prometheus-postfix-exporter}/bin/postfix_exporter \
          --web.listen-address ${cfg.listenAddress}:${toString cfg.port} \
          --web.telemetry-path ${cfg.telemetryPath} \
          ${concatStringsSep "" \\\n  "" cfg.extraFlags}
      '';
    };
  };
}


     This should already be enough for the postfix exporter. Additionally one
     could now add assertions and conditional default values. This can be done
     in the 'meta-module' that combines all exporter definitions and generates
     the submodules:
     nixpkgs/nixos/modules/services/prometheus/exporters.nix
17.3. Updating an exporter module
     Should an exporter option change at some point, it is possible to add
     information about the change to the exporter definition similar to
     nixpkgs/nixos/modules/rename.nix:

{ config, lib, pkgs, options }:

with lib;

let
  cfg = config.services.prometheus.exporters.nginx;
in
{
  port = 9113;
  extraOpts = {
    # additional module options
    # ...
  };
  serviceOpts = {
    # service configuration
    # ...
  };
  imports = [
    # 'services.prometheus.exporters.nginx.telemetryEndpoint' -> 'services.prometheus.exporters.nginx.telemetryPath'
    (mkRenamedOptionModule [ ""telemetryEndpoint"" ] [ ""telemetryPath"" ])

    # removed option 'services.prometheus.exporters.nginx.insecure'
    (mkRemovedOptionModule [ ""insecure"" ] ''
      This option was replaced by 'prometheus.exporters.nginx.sslVerify' which defaults to true.
    '')
    ({ options.warnings = options.warnings; })
  ];
}

Chapter 18. WeeChatTable of Contents18.1. Basic Usage18.2. Re-attaching to WeeChat
WeeChat is a fast and
  extensible IRC client.
 18.1. Basic Usage
   By default, the module creates a
   systemd
   unit which runs the chat client in a detached
   screen
   session.
  
   This can be done by enabling the weechat service:

{ ... }:

{
  services.weechat.enable = true;
}


   The service is managed by a dedicated user named weechat
   in the state directory /var/lib/weechat.
  18.2. Re-attaching to WeeChat
   WeeChat runs in a screen session owned by a dedicated user. To explicitly
   allow your another user to attach to this session, the
   screenrc needs to be tweaked by adding
   multiuser
   support:

{
  programs.screen.screenrc = ''
    multiuser on
    acladd normal_user
  '';
}

   Now, the session can be re-attached like this:

screen -x weechat/weechat-screen


The session name can be changed using
   services.weechat.sessionName.
Chapter 19. TaskserverTable of Contents19.1. Configuration19.2. The nixos-taskserver tool19.3. Declarative/automatic CA management19.4. Manual CA management
  Taskserver is the server component of
  Taskwarrior, a free and
  open source todo list application.
 
Upstream documentation:
https://taskwarrior.org/docs/#taskd
19.1. Configuration
   Taskserver does all of its authentication via TLS using client certificates,
   so you either need to roll your own CA or purchase a certificate from a
   known CA, which allows creation of client certificates. These certificates
   are usually advertised as “server certificates”.
  
   So in order to make it easier to handle your own CA, there is a helper tool
   called nixos-taskserver which manages the custom CA along
   with Taskserver organisations, users and groups.
  
   While the client certificates in Taskserver only authenticate whether a user
   is allowed to connect, every user has its own UUID which identifies it as an
   entity.
  
   With nixos-taskserver the client certificate is created
   along with the UUID of the user, so it handles all of the credentials needed
   in order to setup the Taskwarrior client to work with a Taskserver.
  19.2. The nixos-taskserver tool
   Because Taskserver by default only provides scripts to setup users
   imperatively, the nixos-taskserver tool is used for
   addition and deletion of organisations along with users and groups defined
   by services.taskserver.organisations and as well for
   imperative set up.
  
   The tool is designed to not interfere if the command is used to manually set
   up some organisations, users or groups.
  
   For example if you add a new organisation using nixos-taskserver
   org add foo, the organisation is not modified and deleted no
   matter what you define in
   services.taskserver.organisations, even if you're adding
   the same organisation in that option.
  
   The tool is modelled to imitate the official taskd
   command, documentation for each subcommand can be shown by using the
   --help switch.
  19.3. Declarative/automatic CA management
   Everything is done according to what you specify in the module options,
   however in order to set up a Taskwarrior client for synchronisation with a
   Taskserver instance, you have to transfer the keys and certificates to the
   client machine.
  
   This is done using nixos-taskserver user export $orgname
   $username which is printing a shell script fragment to stdout
   which can either be used verbatim or adjusted to import the user on the
   client machine.
  
   For example, let's say you have the following configuration:

{
  services.taskserver.enable = true;
  services.taskserver.fqdn = ""server"";
  services.taskserver.listenHost = ""::"";
  services.taskserver.organisations.my-company.users = [ ""alice"" ];
}

   This creates an organisation called my-company with the
   user alice.
  
   Now in order to import the alice user to another machine
   alicebox, all we need to do is something like this:

$ ssh server nixos-taskserver user export my-company alice | sh

   Of course, if no SSH daemon is available on the server you can also copy
   & paste it directly into a shell.
  
   After this step the user should be set up and you can start synchronising
   your tasks for the first time with task sync init on
   alicebox.
  
   Subsequent synchronisation requests merely require the command task
   sync after that stage.
  19.4. Manual CA management
   If you set any options within
   service.taskserver.pki.manual.*,
   nixos-taskserver won't issue certificates, but you can
   still use it for adding or removing user accounts.
  Chapter 20. MatrixTable of Contents20.1. Synapse Homeserver20.2. Element (formerly known as Riot) Web Client
Matrix is an open standard for
  interoperable, decentralised, real-time communication over IP. It can be used
  to power Instant Messaging, VoIP/WebRTC signalling, Internet of Things
  communication - or anywhere you need a standard HTTP API for publishing and
  subscribing to data whilst tracking the conversation history.
 
  This chapter will show you how to set up your own, self-hosted Matrix
  homeserver using the Synapse reference homeserver, and how to serve your own
  copy of the Element web client. See the
  Try
  Matrix Now! overview page for links to Element Apps for Android and iOS,
  desktop clients, as well as bridges to other networks and other projects
  around Matrix.
 20.1. Synapse Homeserver
Synapse is
   the reference homeserver implementation of Matrix from the core development
   team at matrix.org. The following configuration example will set up a
   synapse server for the example.org domain, served from
   the host myhostname.example.org. For more information,
   please refer to the
   
   installation instructions of Synapse .

{ pkgs, ... }:
let
  fqdn =
    let
      join = hostName: domain: hostName + optionalString (domain != null) "".${domain}"";
    in join config.networking.hostName config.networking.domain;
in {
  networking = {
    hostName = ""myhostname"";
    domain = ""example.org"";
  };
  networking.firewall.allowedTCPPorts = [ 80 443 ];

  services.postgresql.enable = true;
  services.postgresql.initialScript = pkgs.writeText ""synapse-init.sql"" ''
    CREATE ROLE ""matrix-synapse"" WITH LOGIN PASSWORD 'synapse';
    CREATE DATABASE ""matrix-synapse"" WITH OWNER ""matrix-synapse""
      TEMPLATE template0
      LC_COLLATE = ""C""
      LC_CTYPE = ""C"";
  '';

  services.nginx = {
    enable = true;
    # only recommendedProxySettings and recommendedGzipSettings are strictly required,
    # but the rest make sense as well
    recommendedTlsSettings = true;
    recommendedOptimisation = true;
    recommendedGzipSettings = true;
    recommendedProxySettings = true;

    virtualHosts = {
      # This host section can be placed on a different host than the rest,
      # i.e. to delegate from the host being accessible as ${config.networking.domain}
      # to another host actually running the Matrix homeserver.
      ""${config.networking.domain}"" = {
        locations.""= /.well-known/matrix/server"".extraConfig =
          let
            # use 443 instead of the default 8448 port to unite
            # the client-server and server-server port for simplicity
            server = { ""m.server"" = ""${fqdn}:443""; };
          in ''
            add_header Content-Type application/json;
            return 200 '${builtins.toJSON server}';
          '';
        locations.""= /.well-known/matrix/client"".extraConfig =
          let
            client = {
              ""m.homeserver"" =  { ""base_url"" = ""https://${fqdn}""; };
              ""m.identity_server"" =  { ""base_url"" = ""https://vector.im""; };
            };
          # ACAO required to allow element-web on any URL to request this json file
          in ''
            add_header Content-Type application/json;
            add_header Access-Control-Allow-Origin *;
            return 200 '${builtins.toJSON client}';
          '';
      };

      # Reverse proxy for Matrix client-server and server-server communication
      ${fqdn} = {
        enableACME = true;
        forceSSL = true;

        # Or do a redirect instead of the 404, or whatever is appropriate for you.
        # But do not put a Matrix Web client here! See the Element web section below.
        locations.""/"".extraConfig = ''
          return 404;
        '';

        # forward all Matrix API calls to the synapse Matrix homeserver
        locations.""/_matrix"" = {
          proxyPass = ""http://[::1]:8008""; # without a trailing /
        };
      };
    };
  };
  services.matrix-synapse = {
    enable = true;
    server_name = config.networking.domain;
    listeners = [
      {
        port = 8008;
        bind_address = ""::1"";
        type = ""http"";
        tls = false;
        x_forwarded = true;
        resources = [
          {
            names = [ ""client"" ""federation"" ];
            compress = false;
          }
        ];
      }
    ];
  };
};


   If the A and AAAA DNS records on
   example.org do not point on the same host as the records
   for myhostname.example.org, you can easily move the
   /.well-known virtualHost section of the code to the host that
   is serving example.org, while the rest stays on
   myhostname.example.org with no other changes required.
   This pattern also allows to seamlessly move the homeserver from
   myhostname.example.org to
   myotherhost.example.org by only changing the
   /.well-known redirection target.
  
   If you want to run a server with public registration by anybody, you can
   then enable services.matrix-synapse.enable_registration =
   true;. Otherwise, or you can generate a registration secret with
   pwgen -s 64 1 and set it with
   services.matrix-synapse.registration_shared_secret. To
   create a new user or admin, run the following after you have set the secret
   and have rebuilt NixOS:

$ nix run nixpkgs.matrix-synapse
$ register_new_matrix_user -k your-registration-shared-secret http://localhost:8008
New user localpart: your-username
Password:
Confirm password:
Make admin [no]:
Success!

   In the example, this would create a user with the Matrix Identifier
   @your-username:example.org. Note that the registration
   secret ends up in the nix store and therefore is world-readable by any user
   on your machine, so it makes sense to only temporarily activate the
   registration_shared_secret
   option until a better solution for NixOS is in place.
  20.2. Element (formerly known as Riot) Web Client
Element Web is
   the reference web client for Matrix and developed by the core team at
   matrix.org. Element was formerly known as Riot.im, see the
   Element introductory blog post
   for more information. The following snippet can be optionally added to the code before
   to complete the synapse installation with a web client served at
   https://element.myhostname.example.org and
   https://element.example.org. Alternatively, you can use the hosted
   copy at https://app.element.io/,
   or use other web clients or native client applications. Due to the
   /.well-known urls set up done above, many clients should
   fill in the required connection details automatically when you enter your
   Matrix Identifier. See
   Try
   Matrix Now! for a list of existing clients and their supported
   featureset.

{
  services.nginx.virtualHosts.""element.${fqdn}"" = {
    enableACME = true;
    forceSSL = true;
    serverAliases = [
      ""element.${config.networking.domain}""
    ];

    root = pkgs.element-web.override {
      conf = {
        default_server_config.""m.homeserver"" = {
          ""base_url"" = ""${config.networking.domain}"";
          ""server_name"" = ""${fqdn}"";
        };
      };
    };
  };
}


   Note that the Element developers do not recommend running Element and your Matrix
   homeserver on the same fully-qualified domain name for security reasons. In
   the example, this means that you should not reuse the
   myhostname.example.org virtualHost to also serve Element,
   but instead serve it on a different subdomain, like
   element.example.org in the example. See the
   Element
   Important Security Notes for more information on this subject.
  Chapter 21. GitlabTable of Contents21.1. Prerequisites21.2. Configuring21.3. Maintenance
  Gitlab is a feature-rich git hosting service.
 21.1. Prerequisites
   The gitlab service exposes only an Unix socket at
   /run/gitlab/gitlab-workhorse.socket. You need to
   configure a webserver to proxy HTTP requests to the socket.
  
   For instance, the following configuration could be used to use nginx as
   frontend proxy:

services.nginx = {
  enable = true;
  recommendedGzipSettings = true;
  recommendedOptimisation = true;
  recommendedProxySettings = true;
  recommendedTlsSettings = true;
  virtualHosts.""git.example.com"" = {
    enableACME = true;
    forceSSL = true;
    locations.""/"".proxyPass = ""http://unix:/run/gitlab/gitlab-workhorse.socket"";
  };
};

21.2. Configuring
   Gitlab depends on both PostgreSQL and Redis and will automatically enable
   both services. In the case of PostgreSQL, a database and a role will be
   created.
  
   The default state dir is /var/gitlab/state. This is where
   all data like the repositories and uploads will be stored.
  
   A basic configuration with some custom settings could look like this:

services.gitlab = {
  enable = true;
  databasePasswordFile = ""/var/keys/gitlab/db_password"";
  initialRootPasswordFile = ""/var/keys/gitlab/root_password"";
  https = true;
  host = ""git.example.com"";
  port = 443;
  user = ""git"";
  group = ""git"";
  smtp = {
    enable = true;
    address = ""localhost"";
    port = 25;
  };
  secrets = {
    dbFile = ""/var/keys/gitlab/db"";
    secretFile = ""/var/keys/gitlab/secret"";
    otpFile = ""/var/keys/gitlab/otp"";
    jwsFile = ""/var/keys/gitlab/jws"";
  };
  extraConfig = {
    gitlab = {
      email_from = ""gitlab-no-reply@example.com"";
      email_display_name = ""Example GitLab"";
      email_reply_to = ""gitlab-no-reply@example.com"";
      default_projects_features = { builds = false; };
    };
  };
};


   If you're setting up a new Gitlab instance, generate new
   secrets. You for instance use tr -dc A-Za-z0-9 <
   /dev/urandom | head -c 128 > /var/keys/gitlab/db to
   generate a new db secret. Make sure the files can be read by, and
   only by, the user specified by services.gitlab.user. Gitlab
   encrypts sensitive data stored in the database. If you're restoring
   an existing Gitlab instance, you must specify the secrets secret
   from config/secrets.yml located in your Gitlab
   state folder.
  
   Refer to Appendix A, Configuration Options for all available configuration
   options for the
   services.gitlab module.
  21.3. Maintenance
   You can run Gitlab's rake tasks with gitlab-rake which
   will be available on the system when gitlab is enabled. You will have to run
   the command as the user that you configured to run gitlab with.
  
   For example, to backup a Gitlab instance:

$ sudo -u git -H gitlab-rake gitlab:backup:create

   A list of all availabe rake tasks can be obtained by running:

$ sudo -u git -H gitlab-rake -T

Chapter 22. Trezor
  Trezor is an open-source cryptocurrency hardware wallet and security token
  allowing secure storage of private keys.
 
  It offers advanced features such U2F two-factor authorization, SSH login
  through
  Trezor SSH agent,
  GPG and a
  password manager.
  For more information, guides and documentation, see https://wiki.trezor.io.
 
  To enable Trezor support, add the following to your configuration.nix:

services.trezord.enable = true;

  This will add all necessary udev rules and start Trezor Bridge.
 Chapter 23. EmacsTable of Contents23.1. Installing Emacs23.2. Running Emacs as a Service23.3. Configuring Emacs
Emacs is an
  extensible, customizable, self-documenting real-time display editor — and
  more. At its core is an interpreter for Emacs Lisp, a dialect of the Lisp
  programming language with extensions to support text editing.
 
  Emacs runs within a graphical desktop environment using the X Window System,
  but works equally well on a text terminal. Under
  macOS, a ""Mac port"" edition is available, which
  uses Apple's native GUI frameworks.
 
Nixpkgs provides a superior environment for
  running Emacs. It's simple to create custom builds
  by overriding the default packages. Chaotic collections of Emacs Lisp code
  and extensions can be brought under control using declarative package
  management. NixOS even provides a
  systemd user service for automatically starting the Emacs
  daemon.
 23.1. Installing Emacs
   Emacs can be installed in the normal way for Nix (see
   Chapter 6, Package Management). In addition, a NixOS
   service can be enabled.
  23.1.1. The Different Releases of Emacs
Nixpkgs defines several basic Emacs packages.
    The following are attributes belonging to the pkgs set:
    
emacs
      , 
emacs25

        The latest stable version of Emacs 25 using the
        GTK 2
        widget toolkit.
       
emacs25-nox

        Emacs 25 built without any dependency on X11 libraries.
       
emacsMacport
      , 
emacs25Macport

        Emacs 25 with the ""Mac port"" patches, providing a more native look and
        feel under macOS.
       

    If those aren't suitable, then the following imitation Emacs editors are
    also available in Nixpkgs:
    Zile,
    mg,
    Yi,
    jmacs.
   23.1.2. Adding Packages to Emacs
    Emacs includes an entire ecosystem of functionality beyond text editing,
    including a project planner, mail and news reader, debugger interface,
    calendar, and more.
   
    Most extensions are gotten with the Emacs packaging system
    (package.el) from
    Emacs Lisp Package Archive
    (ELPA),
    MELPA,
    MELPA Stable, and
    Org ELPA. Nixpkgs is
    regularly updated to mirror all these archives.
   
    Under NixOS, you can continue to use
    package-list-packages and
    package-install to install packages. You can also
    declare the set of Emacs packages you need using the derivations from
    Nixpkgs. The rest of this section discusses declarative installation of
    Emacs packages through nixpkgs.
   
    The first step to declare the list of packages you want in your Emacs
    installation is to create a dedicated derivation. This can be done in a
    dedicated emacs.nix file such as:
    Example 23.1. Nix expression to build Emacs with packages (emacs.nix)
/*
This is a nix expression to build Emacs and some Emacs packages I like
from source on any distribution where Nix is installed. This will install
all the dependencies from the nixpkgs repository and build the binary files
without interfering with the host distribution.

To build the project, type the following from the current directory:

$ nix-build emacs.nix

To run the newly compiled executable:

$ ./result/bin/emacs
*/
{ pkgs ? import <nixpkgs> {} }: 

let
  myEmacs = pkgs.emacs; 
  emacsWithPackages = (pkgs.emacsPackagesGen myEmacs).emacsWithPackages; 
in
  emacsWithPackages (epkgs: (with epkgs.melpaStablePackages; [ 
    magit          # ; Integrate git <C-x g>
    zerodark-theme # ; Nicolas' theme
  ]) ++ (with epkgs.melpaPackages; [ 
    undo-tree      # ; <C-x u> to show the undo tree
    zoom-frm       # ; increase/decrease font size for all buffers %lt;C-x C-+>
  ]) ++ (with epkgs.elpaPackages; [ 
    auctex         # ; LaTeX mode
    beacon         # ; highlight my cursor when scrolling
    nameless       # ; hide current package name everywhere in elisp code
  ]) ++ [
    pkgs.notmuch   # From main packages set 
  ])

 
       The first non-comment line in this file ({ pkgs ? ...
       }) indicates that the whole file represents a function.
       
       The let expression below defines a
       myEmacs binding pointing to the current stable
       version of Emacs. This binding is here to separate the choice of the
       Emacs binary from the specification of the required packages.
       
       This generates an emacsWithPackages function. It
       takes a single argument: a function from a package set to a list of
       packages (the packages that will be available in Emacs).
       
       The rest of the file specifies the list of packages to install. In the
       example, two packages (magit and
       zerodark-theme) are taken from MELPA stable.
       
       Two packages (undo-tree and
       zoom-frm) are taken from MELPA.
       
       Three packages are taken from GNU ELPA.
       
notmuch is taken from a nixpkgs derivation which
       contains an Emacs mode.
      

    The result of this configuration will be an emacs
    command which launches Emacs with all of your chosen packages in the
    load-path.
   
    You can check that it works by executing this in a terminal:

$ nix-build emacs.nix
$ ./result/bin/emacs -q

    and then typing M-x package-initialize. Check that you
    can use all the packages you want in this Emacs instance. For example, try
    switching to the zerodark theme through M-x load-theme <RET>
    zerodark <RET> y.
   Tip
     A few popular extensions worth checking out are: auctex, company,
     edit-server, flycheck, helm, iedit, magit, multiple-cursors, projectile,
     and yasnippet.
    
    The list of available packages in the various ELPA repositories can be seen
    with the following commands:
    Example 23.2. Querying Emacs packages
nix-env -f ""<nixpkgs>"" -qaP -A emacsPackages.elpaPackages
nix-env -f ""<nixpkgs>"" -qaP -A emacsPackages.melpaPackages
nix-env -f ""<nixpkgs>"" -qaP -A emacsPackages.melpaStablePackages
nix-env -f ""<nixpkgs>"" -qaP -A emacsPackages.orgPackages


    If you are on NixOS, you can install this particular Emacs for all users by
    adding it to the list of system packages (see
    Section 6.1, “Declarative Package Management”). Simply modify your file
    configuration.nix to make it contain:
    Example 23.3. Custom Emacs in configuration.nix
{
 environment.systemPackages = [
   # [...]
   (import /path/to/emacs.nix { inherit pkgs; })
  ];
}


    In this case, the next nixos-rebuild switch will take
    care of adding your emacs to the PATH
    environment variable (see Chapter 3, Changing the Configuration).
   
    If you are not on NixOS or want to install this particular Emacs only for
    yourself, you can do so by adding it to your
    ~/.config/nixpkgs/config.nix (see
    Nixpkgs
    manual):
    Example 23.4. Custom Emacs in ~/.config/nixpkgs/config.nix
{
  packageOverrides = super: let self = super.pkgs; in {
    myemacs = import /path/to/emacs.nix { pkgs = self; };
  };
}


    In this case, the next nix-env -f '<nixpkgs>' -iA
    myemacs will take care of adding your emacs to the
    PATH environment variable.
   23.1.3. Advanced Emacs Configuration
    If you want, you can tweak the Emacs package itself from your
    emacs.nix. For example, if you want to have a
    GTK 3-based Emacs instead of the default GTK 2-based binary and remove the
    automatically generated emacs.desktop (useful is you
    only use emacsclient), you can change your file
    emacs.nix in this way:
   Example 23.5. Custom Emacs build
{ pkgs ? import <nixpkgs> {} }:
let
  myEmacs = (pkgs.emacs.override {
    # Use gtk3 instead of the default gtk2
    withGTK3 = true;
    withGTK2 = false;
  }).overrideAttrs (attrs: {
    # I don't want emacs.desktop file because I only use
    # emacsclient.
    postInstall = (attrs.postInstall or """") + ''
      rm $out/share/applications/emacs.desktop
    '';
  });
in [...]

    After building this file as shown in Example 23.1, “Nix expression to build Emacs with packages (emacs.nix)”, you
    will get an GTK 3-based Emacs binary pre-loaded with your favorite packages.
   23.2. Running Emacs as a Service
NixOS provides an optional
   systemd service which launches
   
   Emacs daemon  with the user's login session.
  
Source:
modules/services/editors/emacs.nix
23.2.1. Enabling the Service
    To install and enable the systemd user service for Emacs
    daemon, add the following to your configuration.nix:

services.emacs.enable = true;
services.emacs.package = import /home/cassou/.emacs.d { pkgs = pkgs; };


    The services.emacs.package option allows a custom
    derivation to be used, for example, one created by
    emacsWithPackages.
   
    Ensure that the Emacs server is enabled for your user's Emacs
    configuration, either by customizing the server-mode
    variable, or by adding (server-start) to
    ~/.emacs.d/init.el.
   
    To start the daemon, execute the following:

$ nixos-rebuild switch  # to activate the new configuration.nix
$ systemctl --user daemon-reload        # to force systemd reload
$ systemctl --user start emacs.service  # to start the Emacs daemon

    The server should now be ready to serve Emacs clients.
   23.2.2. Starting the client
    Ensure that the emacs server is enabled, either by customizing the
    server-mode variable, or by adding
    (server-start) to ~/.emacs.
   
    To connect to the emacs daemon, run one of the following:

emacsclient FILENAME
emacsclient --create-frame  # opens a new frame (window)
emacsclient --create-frame --tty  # opens a new frame on the current terminal

23.2.3. Configuring the EDITOR variable
    If services.emacs.defaultEditor is
    true, the EDITOR variable will be set
    to a wrapper script which launches emacsclient.
   
    Any setting of EDITOR in the shell config files will
    override services.emacs.defaultEditor. To make sure
    EDITOR refers to the Emacs wrapper script, remove any
    existing EDITOR assignment from
    .profile, .bashrc,
    .zshenv or any other shell config file.
   
    If you have formed certain bad habits when editing files, these can be
    corrected with a shell alias to the wrapper script:
alias vi=$EDITOR
23.2.4. Per-User Enabling of the Service
    In general, systemd user services are globally enabled
    by symlinks in /etc/systemd/user. In the case where
    Emacs daemon is not wanted for all users, it is possible to install the
    service but not globally enable it:

services.emacs.enable = false;
services.emacs.install = true;


    To enable the systemd user service for just the
    currently logged in user, run:
systemctl --user enable emacs
    This will add the symlink
    ~/.config/systemd/user/emacs.service.
   23.3. Configuring Emacs
   The Emacs init file should be changed to load the extension packages at
   startup:
   Example 23.6. Package initialization in .emacs
(require 'package)

;; optional. makes unpure packages archives unavailable
(setq package-archives nil)

(setq package-enable-at-startup nil)
(package-initialize)


   After the declarative emacs package configuration has been tested,
   previously downloaded packages can be cleaned up by removing
   ~/.emacs.d/elpa (do make a backup first, in case you
   forgot a package).
  23.3.1. A Major Mode for Nix Expressions
    Of interest may be melpaPackages.nix-mode, which
    provides syntax highlighting for the Nix language. This is particularly
    convenient if you regularly edit Nix files.
   23.3.2. Accessing man pages
    You can use woman to get completion of all available
    man pages. For example, type M-x woman <RET> nixos-rebuild
    <RET>.
23.3.3. Editing DocBook 5 XML Documents
    Emacs includes
    nXML,
    a major-mode for validating and editing XML documents. When editing DocBook
    5.0 documents, such as this one,
    nXML needs to be configured with the relevant schema, which is not
    included.
   
    To install the DocBook 5.0 schemas, either add
    pkgs.docbook5 to
    environment.systemPackages
    (NixOS), or run
    nix-env -f '<nixpkgs>' -iA docbook5
    (Nix).
   
    Then customize the variable rng-schema-locating-files to
    include ~/.emacs.d/schemas.xml and put the following
    text into that file:
    Example 23.7. nXML Schema Configuration (~/.emacs.d/schemas.xml)
<?xml version=""1.0""?>
<!--
  To let emacs find this file, evaluate:
  (add-to-list 'rng-schema-locating-files ""~/.emacs.d/schemas.xml"")
-->
<locatingRules xmlns=""http://thaiopensource.com/ns/locating-rules/1.0"">
  <!--
    Use this variation if pkgs.docbook5 is added to environment.systemPackages
  -->
  <namespace ns=""http://docbook.org/ns/docbook""
             uri=""/run/current-system/sw/share/xml/docbook-5.0/rng/docbookxi.rnc""/>
  <!--
    Use this variation if installing schema with ""nix-env -iA pkgs.docbook5"".
  <namespace ns=""http://docbook.org/ns/docbook""
             uri=""../.nix-profile/share/xml/docbook-5.0/rng/docbookxi.rnc""/>
  -->
</locatingRules>

Chapter 24. Flatpak
Source:
modules/services/desktop/flatpak.nix

Upstream documentation:
https://github.com/flatpak/flatpak/wiki

  Flatpak is a system for building, distributing, and running sandboxed desktop
  applications on Linux.
 
  To enable Flatpak, add the following to your
  configuration.nix:

  services.flatpak.enable = true;


  For the sandboxed apps to work correctly, desktop integration portals need to
  be installed. If you run GNOME, this will be handled automatically for you;
  in other cases, you will need to add something like the following to your
  configuration.nix:

  xdg.portal.extraPortals = [ pkgs.xdg-desktop-portal-gtk ];


  Then, you will need to add a repository, for example,
  Flathub,
  either using the following commands:

$ flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo
$ flatpak update

  or by opening the
  repository
  file in GNOME Software.
 
  Finally, you can search and install programs:

$ flatpak search bustle
$ flatpak install flathub org.freedesktop.Bustle
$ flatpak run org.freedesktop.Bustle

  Again, GNOME Software offers graphical interface for these tasks.
 Chapter 25. PostgreSQLTable of Contents25.1. Configuring25.2. Upgrading25.3. Options25.4. Plugins
Source: modules/services/databases/postgresql.nix

Upstream documentation: http://www.postgresql.org/docs/

  PostgreSQL is an advanced, free relational database.

 25.1. Configuring
   To enable PostgreSQL, add the following to your configuration.nix:

services.postgresql.enable = true;
services.postgresql.package = pkgs.postgresql_11;

   Note that you are required to specify the desired version of PostgreSQL (e.g. pkgs.postgresql_11). Since upgrading your PostgreSQL version requires a database dump and reload (see below), NixOS cannot provide a default value for services.postgresql.package such as the most recent release of PostgreSQL.
  
   By default, PostgreSQL stores its databases in /var/lib/postgresql/$psqlSchema. You can override this using services.postgresql.dataDir, e.g.

services.postgresql.dataDir = ""/data/postgresql"";

25.2. Upgrading
   Major PostgreSQL upgrade requires PostgreSQL downtime and a few imperative steps to be called. To simplify this process, use the following NixOS module:

  containers.temp-pg.config.services.postgresql = {
    enable = true;
    package = pkgs.postgresql_12;
    ## set a custom new dataDir
    # dataDir = ""/some/data/dir"";
  };
  environment.systemPackages =
    let newpg = config.containers.temp-pg.config.services.postgresql;
    in [
      (pkgs.writeScriptBin ""upgrade-pg-cluster"" ''
        set -x
        export OLDDATA=""${config.services.postgresql.dataDir}""
        export NEWDATA=""${newpg.dataDir}""
        export OLDBIN=""${config.services.postgresql.package}/bin""
        export NEWBIN=""${newpg.package}/bin""

        install -d -m 0700 -o postgres -g postgres ""$NEWDATA""
        cd ""$NEWDATA""
        sudo -u postgres $NEWBIN/initdb -D ""$NEWDATA""

        systemctl stop postgresql    # old one

        sudo -u postgres $NEWBIN/pg_upgrade \
          --old-datadir ""$OLDDATA"" --new-datadir ""$NEWDATA"" \
          --old-bindir $OLDBIN --new-bindir $NEWBIN \
          ""$@""
      '')
    ];


   The upgrade process is:
  
     Rebuild nixos configuration with the configuration above added to your configuration.nix. Alternatively, add that into separate file and reference it in imports list.
    
     Login as root (sudo su -)
    
     Run upgrade-pg-cluster. It will stop old postgresql, initialize new one and migrate old one to new one. You may supply arguments like --jobs 4 and --link to speedup migration process. See https://www.postgresql.org/docs/current/pgupgrade.html for details.
    
     Change postgresql package in NixOS configuration to the one you were upgrading to, and change dataDir to the one you have migrated to. Rebuild NixOS. This should start new postgres using upgraded data directory.
    
     After upgrade you may want to ANALYZE new db.
    25.3. Options
   A complete list of options for the PostgreSQL module may be found here.
  25.4. Plugins
   Plugins collection for each PostgreSQL version can be accessed with .pkgs. For example, for pkgs.postgresql_11 package, its plugin collection is accessed by pkgs.postgresql_11.pkgs:

$ nix repl '<nixpkgs>'

Loading '<nixpkgs>'...
Added 10574 variables.

nix-repl> postgresql_11.pkgs.<TAB><TAB>
postgresql_11.pkgs.cstore_fdw        postgresql_11.pkgs.pg_repack
postgresql_11.pkgs.pg_auto_failover  postgresql_11.pkgs.pg_safeupdate
postgresql_11.pkgs.pg_bigm           postgresql_11.pkgs.pg_similarity
postgresql_11.pkgs.pg_cron           postgresql_11.pkgs.pg_topn
postgresql_11.pkgs.pg_hll            postgresql_11.pkgs.pgjwt
postgresql_11.pkgs.pg_partman        postgresql_11.pkgs.pgroonga
...


   To add plugins via NixOS configuration, set services.postgresql.extraPlugins:

services.postgresql.package = pkgs.postgresql_11;
services.postgresql.extraPlugins = with pkgs.postgresql_11.pkgs; [
  pg_repack
  postgis
];


   You can build custom PostgreSQL-with-plugins (to be used outside of NixOS) using function .withPackages. For example, creating a custom PostgreSQL package in an overlay can look like:

self: super: {
  postgresql_custom = self.postgresql_11.withPackages (ps: [
    ps.pg_repack
    ps.postgis
  ]);
}


   Here's a recipe on how to override a particular plugin through an overlay:

self: super: {
  postgresql_11 = super.postgresql_11.override { this = self.postgresql_11; } // {
    pkgs = super.postgresql_11.pkgs // {
      pg_repack = super.postgresql_11.pkgs.pg_repack.overrideAttrs (_: {
        name = ""pg_repack-v20181024"";
        src = self.fetchzip {
          url = ""https://github.com/reorg/pg_repack/archive/923fa2f3c709a506e111cc963034bf2fd127aa00.tar.gz"";
          sha256 = ""17k6hq9xaax87yz79j773qyigm4fwk8z4zh5cyp6z0sxnwfqxxw5"";
        };
      });
    };
  };
}

Chapter 26. FoundationDBTable of Contents26.1. Configuring and basic setup26.2. Scaling processes and backup agents26.3. Clustering26.4. Client connectivity26.5. Client authorization and TLS26.6. Backups and Disaster Recovery26.7. Known limitations26.8. Options26.9. Full documentation
Source:
modules/services/databases/foundationdb.nix

Upstream documentation:
https://apple.github.io/foundationdb/

Maintainer: Austin Seipp
 
Available version(s): 5.1.x, 5.2.x, 6.0.x
 
  FoundationDB (or ""FDB"") is an open source, distributed, transactional
  key-value store.
 26.1. Configuring and basic setup
   To enable FoundationDB, add the following to your
   configuration.nix:

services.foundationdb.enable = true;
services.foundationdb.package = pkgs.foundationdb52; # FoundationDB 5.2.x


   The services.foundationdb.package option is required, and
   must always be specified. Due to the fact FoundationDB network protocols and
   on-disk storage formats may change between (major) versions, and upgrades
   must be explicitly handled by the user, you must always manually specify
   this yourself so that the NixOS module will use the proper version. Note
   that minor, bugfix releases are always compatible.
  
   After running nixos-rebuild, you can verify whether
   FoundationDB is running by executing fdbcli (which is
   added to environment.systemPackages):

$ sudo -u foundationdb fdbcli
Using cluster file `/etc/foundationdb/fdb.cluster'.

The database is available.

Welcome to the fdbcli. For help, type `help'.
fdb> status

Using cluster file `/etc/foundationdb/fdb.cluster'.

Configuration:
  Redundancy mode        - single
  Storage engine         - memory
  Coordinators           - 1

Cluster:
  FoundationDB processes - 1
  Machines               - 1
  Memory availability    - 5.4 GB per process on machine with least available
  Fault Tolerance        - 0 machines
  Server time            - 04/20/18 15:21:14

...

fdb>


   You can also write programs using the available client libraries. For
   example, the following Python program can be run in order to grab the
   cluster status, as a quick example. (This example uses
   nix-shell shebang support to automatically supply the
   necessary Python modules).

a@link> cat fdb-status.py
#! /usr/bin/env nix-shell
#! nix-shell -i python -p python pythonPackages.foundationdb52

import fdb
import json

def main():
    fdb.api_version(520)
    db = fdb.open()

    @fdb.transactional
    def get_status(tr):
        return str(tr['\xff\xff/status/json'])

    obj = json.loads(get_status(db))
    print('FoundationDB available: %s' % obj['client']['database_status']['available'])

if __name__ == ""__main__"":
    main()
a@link> chmod +x fdb-status.py
a@link> ./fdb-status.py
FoundationDB available: True
a@link>


   FoundationDB is run under the foundationdb user and group
   by default, but this may be changed in the NixOS configuration. The systemd
   unit foundationdb.service controls the
   fdbmonitor process.
  
   By default, the NixOS module for FoundationDB creates a single SSD-storage
   based database for development and basic usage. This storage engine is
   designed for SSDs and will perform poorly on HDDs; however it can handle far
   more data than the alternative ""memory"" engine and is a better default
   choice for most deployments. (Note that you can change the storage backend
   on-the-fly for a given FoundationDB cluster using
   fdbcli.)
  
   Furthermore, only 1 server process and 1 backup agent are started in the
   default configuration. See below for more on scaling to increase this.
  
   FoundationDB stores all data for all server processes under
   /var/lib/foundationdb. You can override this using
   services.foundationdb.dataDir, e.g.

services.foundationdb.dataDir = ""/data/fdb"";


   Similarly, logs are stored under /var/log/foundationdb
   by default, and there is a corresponding
   services.foundationdb.logDir as well.
  26.2. Scaling processes and backup agents
   Scaling the number of server processes is quite easy; simply specify
   services.foundationdb.serverProcesses to be the number of
   FoundationDB worker processes that should be started on the machine.
  
   FoundationDB worker processes typically require 4GB of RAM per-process at
   minimum for good performance, so this option is set to 1 by default since
   the maximum amount of RAM is unknown. You're advised to abide by this
   restriction, so pick a number of processes so that each has 4GB or more.
  
   A similar option exists in order to scale backup agent processes,
   services.foundationdb.backupProcesses. Backup agents are
   not as performance/RAM sensitive, so feel free to experiment with the number
   of available backup processes.
  26.3. Clustering
   FoundationDB on NixOS works similarly to other Linux systems, so this
   section will be brief. Please refer to the full FoundationDB documentation
   for more on clustering.
  
   FoundationDB organizes clusters using a set of
   coordinators, which are just specially-designated
   worker processes. By default, every installation of FoundationDB on NixOS
   will start as its own individual cluster, with a single coordinator: the
   first worker process on localhost.
  
   Coordinators are specified globally using the
   /etc/foundationdb/fdb.cluster file, which all servers and
   client applications will use to find and join coordinators. Note that this
   file can not be managed by NixOS so easily:
   FoundationDB is designed so that it will rewrite the file at runtime for all
   clients and nodes when cluster coordinators change, with clients
   transparently handling this without intervention. It is fundamentally a
   mutable file, and you should not try to manage it in any way in NixOS.
  
   When dealing with a cluster, there are two main things you want to do:
  
     Add a node to the cluster for storage/compute.
    
     Promote an ordinary worker to a coordinator.
    
   A node must already be a member of the cluster in order to properly be
   promoted to a coordinator, so you must always add it first if you wish to
   promote it.
  
   To add a machine to a FoundationDB cluster:
  
     Choose one of the servers to start as the initial coordinator.
    
     Copy the /etc/foundationdb/fdb.cluster file from this
     server to all the other servers. Restart FoundationDB on all of these
     other servers, so they join the cluster.
    
     All of these servers are now connected and working together in the
     cluster, under the chosen coordinator.
    
   At this point, you can add as many nodes as you want by just repeating the
   above steps. By default there will still be a single coordinator: you can
   use fdbcli to change this and add new coordinators.
  
   As a convenience, FoundationDB can automatically assign coordinators based
   on the redundancy mode you wish to achieve for the cluster. Once all the
   nodes have been joined, simply set the replication policy, and then issue
   the coordinators auto command
  
   For example, assuming we have 3 nodes available, we can enable double
   redundancy mode, then auto-select coordinators. For double redundancy, 3
   coordinators is ideal: therefore FoundationDB will make
   every node a coordinator automatically:
  
fdbcli> configure double ssd
fdbcli> coordinators auto

   This will transparently update all the servers within seconds, and
   appropriately rewrite the fdb.cluster file, as well as
   informing all client processes to do the same.
  26.4. Client connectivity
   By default, all clients must use the current fdb.cluster
   file to access a given FoundationDB cluster. This file is located by default
   in /etc/foundationdb/fdb.cluster on all machines with the
   FoundationDB service enabled, so you may copy the active one from your
   cluster to a new node in order to connect, if it is not part of the cluster.
  26.5. Client authorization and TLS
   By default, any user who can connect to a FoundationDB process with the
   correct cluster configuration can access anything. FoundationDB uses a
   pluggable design to transport security, and out of the box it supports a
   LibreSSL-based plugin for TLS support. This plugin not only does in-flight
   encryption, but also performs client authorization based on the given
   endpoint's certificate chain. For example, a FoundationDB server may be
   configured to only accept client connections over TLS, where the client TLS
   certificate is from organization Acme Co in the
   Research and Development unit.
  
   Configuring TLS with FoundationDB is done using the
   services.foundationdb.tls options in order to control the
   peer verification string, as well as the certificate and its private key.
  
   Note that the certificate and its private key must be accessible to the
   FoundationDB user account that the server runs under. These files are also
   NOT managed by NixOS, as putting them into the store may reveal private
   information.
  
   After you have a key and certificate file in place, it is not enough to
   simply set the NixOS module options -- you must also configure the
   fdb.cluster file to specify that a given set of
   coordinators use TLS. This is as simple as adding the suffix
   :tls to your cluster coordinator configuration, after the
   port number. For example, assuming you have a coordinator on localhost with
   the default configuration, simply specifying:
  
XXXXXX:XXXXXX@127.0.0.1:4500:tls

   will configure all clients and server processes to use TLS from now on.
  26.6. Backups and Disaster Recovery
   The usual rules for doing FoundationDB backups apply on NixOS as written in
   the FoundationDB manual. However, one important difference is the security
   profile for NixOS: by default, the foundationdb systemd
   unit uses Linux namespaces to restrict write access to
   the system, except for the log directory, data directory, and the
   /etc/foundationdb/ directory. This is enforced by default
   and cannot be disabled.
  
   However, a side effect of this is that the fdbbackup
   command doesn't work properly for local filesystem backups: FoundationDB
   uses a server process alongside the database processes to perform backups
   and copy the backups to the filesystem. As a result, this process is put
   under the restricted namespaces above: the backup process can only write to
   a limited number of paths.
  
   In order to allow flexible backup locations on local disks, the FoundationDB
   NixOS module supports a
   services.foundationdb.extraReadWritePaths option. This
   option takes a list of paths, and adds them to the systemd unit, allowing
   the processes inside the service to write (and read) the specified
   directories.
  
   For example, to create backups in /opt/fdb-backups, first
   set up the paths in the module options:
  
services.foundationdb.extraReadWritePaths = [ ""/opt/fdb-backups"" ];

   Restart the FoundationDB service, and it will now be able to write to this
   directory (even if it does not yet exist.) Note: this path
   must exist before restarting the unit. Otherwise,
   systemd will not include it in the private FoundationDB namespace (and it
   will not add it dynamically at runtime).
  
   You can now perform a backup:
  
$ sudo -u foundationdb fdbbackup start  -t default -d file:///opt/fdb-backups
$ sudo -u foundationdb fdbbackup status -t default
26.7. Known limitations
   The FoundationDB setup for NixOS should currently be considered beta.
   FoundationDB is not new software, but the NixOS compilation and integration
   has only undergone fairly basic testing of all the available functionality.
  
     There is no way to specify individual parameters for individual
     fdbserver processes. Currently, all server processes
     inherit all the global fdbmonitor settings.
    
     Ruby bindings are not currently installed.
    
     Go bindings are not currently installed.
    26.8. Options
   NixOS's FoundationDB module allows you to configure all of the most relevant
   configuration options for fdbmonitor, matching it quite
   closely. A complete list of options for the FoundationDB module may be found
   here. You should
   also read the FoundationDB documentation as well.
  26.9. Full documentation
   FoundationDB is a complex piece of software, and requires careful
   administration to properly use. Full documentation for administration can be
   found here: https://apple.github.io/foundationdb/.
  Chapter 27. Hiding process information
  Setting

security.hideProcessInformation = true;

  ensures that access to process information is restricted to the owning user.
  This implies, among other things, that command-line arguments remain private.
  Unless your deployment relies on unprivileged users being able to inspect the
  process information of other users, this option should be safe to enable.
 
  Members of the proc group are exempt from process
  information hiding.
 
  To allow a service foo to run without process
  information hiding, set

systemd.services.foo.serviceConfig.SupplementaryGroups = [ ""proc"" ];

Chapter 28. SSL/TLS Certificates with ACMETable of Contents28.1. Prerequisites28.2. Using ACME certificates in Nginx28.3. Using ACME certificates in Apache/httpd28.4. Manual configuration of HTTP-01 validation28.5. Configuring ACME for DNS validation
  NixOS supports automatic domain validation & certificate retrieval and
  renewal using the ACME protocol. Any provider can be used, but by default
  NixOS uses Let's Encrypt. The alternative ACME client lego
  is used under the hood.
 
  Automatic cert validation and configuration for Apache and Nginx virtual
  hosts is included in NixOS, however if you would like to generate a wildcard
  cert or you are not using a web server you will have to configure DNS
  based validation.
 28.1. Prerequisites
   To use the ACME module, you must accept the provider's terms of service
   by setting security.acme.acceptTerms
   to true. The Let's Encrypt ToS can be found
   here.
  
   You must also set an email address to be used when creating accounts with
   Let's Encrypt. You can set this for all certs with
   security.acme.email
   and/or on a per-cert basis with
   security.acme.certs.<name>.email.
   This address is only used for registration and renewal reminders,
   and cannot be used to administer the certificates in any way.
  
   Alternatively, you can use a different ACME server by changing the
   security.acme.server option
   to a provider of your choosing, or just change the server for one cert with
   security.acme.certs.<name>.server.
  
   You will need an HTTP server or DNS server for verification. For HTTP,
   the server must have a webroot defined that can serve
   .well-known/acme-challenge. This directory must be
   writeable by the user that will run the ACME client. For DNS, you must
   set up credentials with your provider/server for use with lego.
  28.2. Using ACME certificates in Nginx
   NixOS supports fetching ACME certificates for you by setting
   enableACME
   = true; in a virtualHost config. We first create self-signed
   placeholder certificates in place of the real ACME certs. The placeholder
   certs are overwritten when the ACME certs arrive. For
   foo.example.com the config would look like.
  
security.acme.acceptTerms = true;
security.acme.email = ""admin+acme@example.com"";
services.nginx = {
  enable = true;
  virtualHosts = {
    ""foo.example.com"" = {
      forceSSL = true;
      enableACME = true;
      # All serverAliases will be added as extra domains on the certificate.
      serverAliases = [ ""bar.example.com"" ];
      locations.""/"" = {
        root = ""/var/www"";
      };
    };

    # We can also add a different vhost and reuse the same certificate
    # but we have to append extraDomains manually.
    security.acme.certs.""foo.example.com"".extraDomains.""baz.example.com"" = null;
    ""baz.example.com"" = {
      forceSSL = true;
      useACMEHost = ""foo.example.com"";
      locations.""/"" = {
        root = ""/var/www"";
      };
    };
  };
}
28.3. Using ACME certificates in Apache/httpd
   Using ACME certificates with Apache virtual hosts is identical
   to using them with Nginx. The attribute names are all the same, just replace
   ""nginx"" with ""httpd"" where appropriate.
  28.4. Manual configuration of HTTP-01 validation
   First off you will need to set up a virtual host to serve the challenges.
   This example uses a vhost called certs.example.com, with
   the intent that you will generate certs for all your vhosts and redirect
   everyone to HTTPS.
  
security.acme.acceptTerms = true;
security.acme.email = ""admin+acme@example.com"";
services.nginx = {
  enable = true;
  virtualHosts = {
    ""acmechallenge.example.com"" = {
      # Catchall vhost, will redirect users to HTTPS for all vhosts
      serverAliases = [ ""*.example.com"" ];
      # /var/lib/acme/.challenges must be writable by the ACME user
      # and readable by the Nginx user.
      # By default, this is the case.
      locations.""/.well-known/acme-challenge"" = {
        root = ""/var/lib/acme/.challenges"";
      };
      locations.""/"" = {
        return = ""301 https://$host$request_uri"";
      };
    };
  };
}
# Alternative config for Apache
services.httpd = {
  enable = true;
  virtualHosts = {
    ""acmechallenge.example.com"" = {
      # Catchall vhost, will redirect users to HTTPS for all vhosts
      serverAliases = [ ""*.example.com"" ];
      # /var/lib/acme/.challenges must be writable by the ACME user and readable by the Apache user.
      # By default, this is the case.
      documentRoot = ""/var/lib/acme/.challenges"";
      extraConfig = ''
        RewriteEngine On
        RewriteCond %{HTTPS} off
        RewriteCond %{REQUEST_URI} !^/\.well-known/acme-challenge [NC]
        RewriteRule (.*) https://%{HTTP_HOST}%{REQUEST_URI} [R=301]
      '';
    };
  };
}

   Now you need to configure ACME to generate a certificate.
  
security.acme.certs.""foo.example.com"" = {
  webroot = ""/var/lib/acme/.challenges"";
  email = ""foo@example.com"";
  # Since we have a wildcard vhost to handle port 80,
  # we can generate certs for anything!
  # Just make sure your DNS resolves them.
  extraDomains = [ ""mail.example.com"" ];
};

   The private key key.pem and certificate
   fullchain.pem will be put into
   /var/lib/acme/foo.example.com.
  
   Refer to Appendix A, Configuration Options for all available configuration
   options for the security.acme
   module.
  28.5. Configuring ACME for DNS validation
   This is useful if you want to generate a wildcard certificate, since
   ACME servers will only hand out wildcard certs over DNS validation.
   There a number of supported DNS providers and servers you can utilise,
   see the lego docs
   for provider/server specific configuration values. For the sake of these
   docs, we will provide a fully self-hosted example using bind.
  
services.bind = {
  enable = true;
  extraConfig = ''
    include ""/var/lib/secrets/dnskeys.conf"";
  '';
  zones = [
    rec {
      name = ""example.com"";
      file = ""/var/db/bind/${name}"";
      master = true;
      extraConfig = ""allow-update { key rfc2136key.example.com.; };"";
    }
  ];
}

# Now we can configure ACME
security.acme.acceptTerms = true;
security.acme.email = ""admin+acme@example.com"";
security.acme.certs.""example.com"" = {
  domain = ""*.example.com"";
  dnsProvider = ""rfc2136"";
  credentialsFile = ""/var/lib/secrets/certs.secret"";
  # We don't need to wait for propagation since this is a local DNS server
  dnsPropagationCheck = false;
};

   The dnskeys.conf and certs.secret
   must be kept secure and thus you should not keep their contents in your
   Nix config. Instead, generate them one time with these commands:
  
mkdir -p /var/lib/secrets
tsig-keygen rfc2136key.example.com > /var/lib/secrets/dnskeys.conf
chown named:root /var/lib/secrets/dnskeys.conf
chmod 400 /var/lib/secrets/dnskeys.conf

# Copy the secret value from the dnskeys.conf, and put it in
# RFC2136_TSIG_SECRET below

cat > /var/lib/secrets/certs.secret << EOF
RFC2136_NAMESERVER='127.0.0.1:53'
RFC2136_TSIG_ALGORITHM='hmac-sha256.'
RFC2136_TSIG_KEY='rfc2136key.example.com'
RFC2136_TSIG_SECRET='your secret key'
EOF
chmod 400 /var/lib/secrets/certs.secret

   Now you're all set to generate certs! You should monitor the first invokation
   by running systemctl start acme-example.com.service &
   journalctl -fu acme-example.com.service and watching its log output.
  Chapter 29. Oh my ZSHTable of Contents29.1. Basic usage29.2. Custom additions29.3. Custom environments29.4. Package your own customizations
oh-my-zsh is a
  framework to manage your ZSH
  configuration including completion scripts for several CLI tools or custom
  prompt themes.
 29.1. Basic usage
   The module uses the oh-my-zsh package with all available
   features. The initial setup using Nix expressions is fairly similar to the
   configuration format of oh-my-zsh.

{
  programs.zsh.ohMyZsh = {
    enable = true;
    plugins = [ ""git"" ""python"" ""man"" ];
    theme = ""agnoster"";
  };
}

   For a detailed explanation of these arguments please refer to the
   oh-my-zsh
   docs.
  
   The expression generates the needed configuration and writes it into your
   /etc/zshrc.
  29.2. Custom additions
   Sometimes third-party or custom scripts such as a modified theme may be
   needed. oh-my-zsh provides the
   ZSH_CUSTOM
   environment variable for this which points to a directory with additional
   scripts.
  
   The module can do this as well:

{
  programs.zsh.ohMyZsh.custom = ""~/path/to/custom/scripts"";
}

29.3. Custom environments
   There are several extensions for oh-my-zsh packaged in
   nixpkgs. One of them is
   nix-zsh-completions
   which bundles completion scripts and a plugin for
   oh-my-zsh.
  
   Rather than using a single mutable path for ZSH_CUSTOM,
   it's also possible to generate this path from a list of Nix packages:

{ pkgs, ... }:
{
  programs.zsh.ohMyZsh.customPkgs = with pkgs; [
    pkgs.nix-zsh-completions
    # and even more...
  ];
}

   Internally a single store path will be created using
   buildEnv. Please refer to the docs of
   buildEnv
   for further reference.
  
Please keep in mind that this is not compatible with
   programs.zsh.ohMyZsh.custom as it requires an immutable
   store path while custom shall remain mutable! An
   evaluation failure will be thrown if both custom and
   customPkgs are set.
29.4. Package your own customizations
   If third-party customizations (e.g. new themes) are supposed to be added to
   oh-my-zsh there are several pitfalls to keep in mind:
  
     To comply with the default structure of ZSH the entire
     output needs to be written to $out/share/zsh.

     Completion scripts are supposed to be stored at
     $out/share/zsh/site-functions. This directory is part
     of the
     fpath
     and the package should be compatible with pure ZSH
     setups. The module will automatically link the contents of
     site-functions to completions directory in the proper
     store path.
    
     The plugins directory needs the structure
     pluginname/pluginname.plugin.zsh as structured in the
     upstream
     repo.

   A derivation for oh-my-zsh may look like this:

{ stdenv, fetchFromGitHub }:

stdenv.mkDerivation rec {
  name = ""exemplary-zsh-customization-${version}"";
  version = ""1.0.0"";
  src = fetchFromGitHub {
    # path to the upstream repository
  };

  dontBuild = true;
  installPhase = ''
    mkdir -p $out/share/zsh/site-functions
    cp {themes,plugins} $out/share/zsh
    cp completions $out/share/zsh/site-functions
  '';
}

Chapter 30. Plotinus
Source:
modules/programs/plotinus.nix

Upstream documentation:
https://github.com/p-e-w/plotinus

  Plotinus is a searchable command palette in every modern GTK application.
 
  When in a GTK 3 application and Plotinus is enabled, you can press
  Ctrl+Shift+P to open the command palette. The command
  palette provides a searchable list of of all menu items in the application.
 
  To enable Plotinus, add the following to your
  configuration.nix:

programs.plotinus.enable = true;

Chapter 31. Digital BitboxTable of Contents31.1. Package31.2. Hardware
  Digital Bitbox is a hardware wallet and second-factor authenticator.
 
  The digitalbitbox programs module may be installed by
  setting programs.digitalbitbox to true
  in a manner similar to

programs.digitalbitbox.enable = true;

  and bundles the digitalbitbox package (see
  Section 31.1, “Package”), which contains the
  dbb-app and dbb-cli binaries, along
  with the hardware module (see
  Section 31.2, “Hardware”) which sets up the
  necessary udev rules to access the device.
 
  Enabling the digitalbitbox module is pretty much the easiest way to get a
  Digital Bitbox device working on your system.
 
  For more information, see
  https://digitalbitbox.com/start_linux.
 31.1. Package
   The binaries, dbb-app (a GUI tool) and
   dbb-cli (a CLI tool), are available through the
   digitalbitbox package which could be installed as
   follows:

environment.systemPackages = [
  pkgs.digitalbitbox
];

31.2. Hardware
   The digitalbitbox hardware package enables the udev rules for Digital Bitbox
   devices and may be installed as follows:

hardware.digitalbitbox.enable = true;


   In order to alter the udev rules, one may provide different values for the
   udevRule51 and udevRule52 attributes
   by means of overriding as follows:

programs.digitalbitbox = {
  enable = true;
  package = pkgs.digitalbitbox.override {
    udevRule51 = ""something else"";
  };
};

Chapter 32. Input MethodsTable of Contents32.1. IBus32.2. Fcitx32.3. Nabi32.4. Uim
  Input methods are an operating system component that allows any data, such as
  keyboard strokes or mouse movements, to be received as input. In this way
  users can enter characters and symbols not found on their input devices.
  Using an input method is obligatory for any language that has more graphemes
  than there are keys on the keyboard.
 
  The following input methods are available in NixOS:
 
    IBus: The intelligent input bus.
   
    Fcitx: A customizable lightweight input method.
   
    Nabi: A Korean input method based on XIM.
   
    Uim: The universal input method, is a library with a XIM bridge.
   32.1. IBus
   IBus is an Intelligent Input Bus. It provides full featured and user
   friendly input method user interface.
  
   The following snippet can be used to configure IBus:
  
i18n.inputMethod = {
  enabled = ""ibus"";
  ibus.engines = with pkgs.ibus-engines; [ anthy hangul mozc ];
};

i18n.inputMethod.ibus.engines is optional and can be used
   to add extra IBus engines.
  
   Available extra IBus engines are:
  
     Anthy (ibus-engines.anthy): Anthy is a system for
     Japanese input method. It converts Hiragana text to Kana Kanji mixed text.
    
     Hangul (ibus-engines.hangul): Korean input method.
    
     m17n (ibus-engines.m17n): m17n is an input method that
     uses input methods and corresponding icons in the m17n database.
    
     mozc (ibus-engines.mozc): A Japanese input method from
     Google.
    
     Table (ibus-engines.table): An input method that load
     tables of input methods.
    
     table-others (ibus-engines.table-others): Various
     table-based input methods. To use this, and any other table-based input
     methods, it must appear in the list of engines along with
     table. For example:

ibus.engines = with pkgs.ibus-engines; [ table table-others ];


   To use any input method, the package must be added in the configuration, as
   shown above, and also (after running nixos-rebuild) the
   input method must be added from IBus' preference dialog.
  Troubleshooting
    If IBus works in some applications but not others, a likely cause of this
    is that IBus is depending on a different version of glib
    to what the applications are depending on. This can be checked by running
    nix-store -q --requisites <path> | grep glib,
    where <path> is the path of either IBus or an
    application in the Nix store. The glib packages must
    match exactly. If they do not, uninstalling and reinstalling the
    application is a likely fix.
   32.2. Fcitx
   Fcitx is an input method framework with extension support. It has three
   built-in Input Method Engine, Pinyin, QuWei and Table-based input methods.
  
   The following snippet can be used to configure Fcitx:
  
i18n.inputMethod = {
  enabled = ""fcitx"";
  fcitx.engines = with pkgs.fcitx-engines; [ mozc hangul m17n ];
};

i18n.inputMethod.fcitx.engines is optional and can be
   used to add extra Fcitx engines.
  
   Available extra Fcitx engines are:
  
     Anthy (fcitx-engines.anthy): Anthy is a system for
     Japanese input method. It converts Hiragana text to Kana Kanji mixed text.
    
     Chewing (fcitx-engines.chewing): Chewing is an
     intelligent Zhuyin input method. It is one of the most popular input
     methods among Traditional Chinese Unix users.
    
     Hangul (fcitx-engines.hangul): Korean input method.
    
     Unikey (fcitx-engines.unikey): Vietnamese input method.
    
     m17n (fcitx-engines.m17n): m17n is an input method that
     uses input methods and corresponding icons in the m17n database.
    
     mozc (fcitx-engines.mozc): A Japanese input method from
     Google.
    
     table-others (fcitx-engines.table-others): Various
     table-based input methods.
    32.3. Nabi
   Nabi is an easy to use Korean X input method. It allows you to enter
   phonetic Korean characters (hangul) and pictographic Korean characters
   (hanja).
  
   The following snippet can be used to configure Nabi:
  
i18n.inputMethod = {
  enabled = ""nabi"";
};
32.4. Uim
   Uim (short for ""universal input method"") is a multilingual input method
   framework. Applications can use it through so-called bridges.
  
   The following snippet can be used to configure uim:
  
i18n.inputMethod = {
  enabled = ""uim"";
};

   Note: The i18n.inputMethod.uim.toolbar option can be
   used to choose uim toolbar.
  Chapter 33. ProfilesTable of Contents33.1. All Hardware33.2. Base33.3. Clone Config33.4. Demo33.5. Docker Container33.6. Graphical33.7. Hardened33.8. Headless33.9. Installation Device33.10. Minimal33.11. QEMU Guest
  In some cases, it may be desirable to take advantage of commonly-used,
  predefined configurations provided by nixpkgs, but different from those that
  come as default. This is a role fulfilled by NixOS's Profiles, which come as
  files living in <nixpkgs/nixos/modules/profiles>.
  That is to say, expected usage is to add them to the imports list of your
  /etc/configuration.nix as such:
 
  imports = [
   <nixpkgs/nixos/modules/profiles/profile-name.nix>
  ];

  Even if some of these profiles seem only useful in the context of install
  media, many are actually intended to be used in real installs.
 
  What follows is a brief explanation on the purpose and use-case for each
  profile. Detailing each option configured by each one is out of scope.
 33.1. All Hardware
  Enables all hardware supported by NixOS: i.e., all firmware is included, and
  all devices from which one may boot are enabled in the initrd. Its primary
  use is in the NixOS installation CDs.
 
  The enabled kernel modules include support for SATA and PATA, SCSI
  (partially), USB, Firewire (untested), Virtio (QEMU, KVM, etc.), VMware, and
  Hyper-V. Additionally, hardware.enableAllFirmware is
  enabled, and the firmware for the ZyDAS ZD1211 chipset is specifically
  installed.
 33.2. Base
  Defines the software packages included in the ""minimal"" installation CD. It
  installs several utilities useful in a simple recovery or install media, such
  as a text-mode web browser, and tools for manipulating block devices,
  networking, hardware diagnostics, and filesystems (with their respective
  kernel modules).
 33.3. Clone Config
  This profile is used in installer images. It provides an editable
  configuration.nix that imports all the modules that were also used when
  creating the image in the first place. As a result it allows users to edit
  and rebuild the live-system.
 
  On images where the installation media also becomes an installation target,
  copying over configuration.nix should be disabled by
  setting installer.cloneConfig to false.
  For example, this is done in sd-image-aarch64.nix.
 33.4. Demo
  This profile just enables a demo
  user, with password demo, uid 1000,
  wheel group and
   autologin
  in the SDDM display manager.
 33.5. Docker Container
  This is the profile from which the Docker images are generated. It prepares a
  working system by importing the
  Minimal and
  Clone Config profiles, and
  setting appropriate configuration options that are useful inside a container
  context, like boot.isContainer.
 33.6. Graphical
  Defines a NixOS configuration with the Plasma 5 desktop. It's used by the
  graphical installation CD.
 
  It sets services.xserver.enable,
  services.xserver.displayManager.sddm.enable,
  services.xserver.desktopManager.plasma5.enable, and
  services.xserver.libinput.enable to true. It also
  includes glxinfo and firefox in the system packages list.
 33.7. Hardened
  A profile with most (vanilla) hardening options enabled by default,
  potentially at the cost of features and performance.
 
  This includes a hardened kernel, and limiting the system information
  available to processes through the /sys and
  /proc filesystems. It also disables the User Namespaces
  feature of the kernel, which stops Nix from being able to build anything
  (this particular setting can be overriden via
  security.allowUserNamespaces). See the
  
  profile source for further detail on which settings are altered.
 33.8. Headless
  Common configuration for headless machines (e.g., Amazon EC2 instances).
 
  Disables sound,
  vesa, serial consoles,
  emergency mode,
  grub splash images
  and configures the kernel to reboot automatically on panic.
 33.9. Installation Device
  Provides a basic configuration for installation devices like CDs.
  This enables redistributable firmware, includes the
  Clone Config profile
  and a copy of the Nixpkgs channel, so nixos-install
  works out of the box.
 
  Documentation for Nixpkgs
  and NixOS are
  forcefully enabled (to override the
  Minimal profile preference); the
  NixOS manual is shown automatically on TTY 8, udisks is disabled.
  Autologin is enabled as nixos user, while passwordless
  login as both root and nixos is possible.
  Passwordless sudo is enabled too.
  wpa_supplicant is
  enabled, but configured to not autostart.
 
  It is explained how to login, start the ssh server, and if available,
  how to start the display manager.
 
  Several settings are tweaked so that the installer has a better chance of
  succeeding under low-memory environments.
 33.10. Minimal
  This profile defines a small NixOS configuration. It does not contain any
  graphical stuff. It's a very short file that enables
  noXlibs, sets
  i18n.supportedLocales to
  only support the user-selected locale,
  disables packages' documentation
  , and disables sound.
 33.11. QEMU Guest
  This profile contains common configuration for virtual machines running under
  QEMU (using virtio).
 
  It makes virtio modules available on the initrd, sets the system time from
  the hardware clock to work around a bug in qemu-kvm, and
  enables rngd.
 Chapter 34. Kubernetes
  The NixOS Kubernetes module is a collective term for a handful of individual
  submodules implementing the Kubernetes cluster components.
 
  There are generally two ways of enabling Kubernetes on NixOS. One way is to
  enable and configure cluster components appropriately by hand:

services.kubernetes = {
  apiserver.enable = true;
  controllerManager.enable = true;
  scheduler.enable = true;
  addonManager.enable = true;
  proxy.enable = true;
  flannel.enable = true;
};

  Another way is to assign cluster roles (""master"" and/or ""node"") to the host.
  This enables apiserver, controllerManager, scheduler, addonManager,
  kube-proxy and etcd:

services.kubernetes.roles = [ ""master"" ];

  While this will enable the kubelet and kube-proxy only:

services.kubernetes.roles = [ ""node"" ];

  Assigning both the master and node roles is usable if you want a single node
  Kubernetes cluster for dev or testing purposes:

services.kubernetes.roles = [ ""master"" ""node"" ];

  Note: Assigning either role will also default both
  services.kubernetes.flannel.enable and
  services.kubernetes.easyCerts to true. This sets up
  flannel as CNI and activates automatic PKI bootstrapping.
 
  As of kubernetes 1.10.X it has been deprecated to open non-tls-enabled ports
  on kubernetes components. Thus, from NixOS 19.03 all plain HTTP ports have
  been disabled by default. While opening insecure ports is still possible, it
  is recommended not to bind these to other interfaces than loopback. To
  re-enable the insecure port on the apiserver, see options:
  services.kubernetes.apiserver.insecurePort and
  services.kubernetes.apiserver.insecureBindAddress
Note: 
   As of NixOS 19.03, it is mandatory to configure:
   services.kubernetes.masterAddress. The masterAddress
   must be resolveable and routeable by all cluster nodes. In single node
   clusters, this can be set to localhost.
  
  Role-based access control (RBAC) authorization mode is enabled by default.
  This means that anonymous requests to the apiserver secure port will
  expectedly cause a permission denied error. All cluster components must
  therefore be configured with x509 certificates for two-way tls communication.
  The x509 certificate subject section determines the roles and permissions
  granted by the apiserver to perform clusterwide or namespaced operations. See
  also:
  
  Using RBAC Authorization.
 
  The NixOS kubernetes module provides an option for automatic certificate
  bootstrapping and configuration,
  services.kubernetes.easyCerts. The PKI bootstrapping
  process involves setting up a certificate authority (CA) daemon (cfssl) on
  the kubernetes master node. cfssl generates a CA-cert for the cluster, and
  uses the CA-cert for signing subordinate certs issued to each of the cluster
  components. Subsequently, the certmgr daemon monitors active certificates and
  renews them when needed. For single node Kubernetes clusters, setting
  services.kubernetes.easyCerts = true is sufficient and
  no further action is required. For joining extra node machines to an existing
  cluster on the other hand, establishing initial trust is mandatory.
 
  To add new nodes to the cluster: On any (non-master) cluster node where
  services.kubernetes.easyCerts is enabled, the helper
  script nixos-kubernetes-node-join is available on PATH.
  Given a token on stdin, it will copy the token to the kubernetes secrets
  directory and restart the certmgr service. As requested certificates are
  issued, the script will restart kubernetes cluster components as needed for
  them to pick up new keypairs.
 Note: 
   Multi-master (HA) clusters are not supported by the easyCerts module.
  
  In order to interact with an RBAC-enabled cluster as an administrator, one
  needs to have cluster-admin privileges. By default, when easyCerts is
  enabled, a cluster-admin kubeconfig file is generated and linked into
  /etc/kubernetes/cluster-admin.kubeconfig as determined by
  services.kubernetes.pki.etcClusterAdminKubeconfig.
  export KUBECONFIG=/etc/kubernetes/cluster-admin.kubeconfig
  will make kubectl use this kubeconfig to access and authenticate the cluster.
  The cluster-admin kubeconfig references an auto-generated keypair owned by
  root. Thus, only root on the kubernetes master may obtain cluster-admin
  rights by means of this file.
 Part III. Administration
   This chapter describes various aspects of managing a running NixOS system,
   such as how to use the systemd service manager.
  Table of Contents35. Service Management36. Rebooting and Shutting Down37. User Sessions38. Control Groups39. Logging40. Cleaning the Nix Store41. Container Management42. TroubleshootingChapter 35. Service Management
  In NixOS, all system services are started and monitored using the systemd
  program. Systemd is the “init” process of the system (i.e. PID 1), the
  parent of all other processes. It manages a set of so-called “units”,
  which can be things like system services (programs), but also mount points,
  swap files, devices, targets (groups of units) and more. Units can have
  complex dependencies; for instance, one unit can require that another unit
  must be successfully started before the first unit can be started. When the
  system boots, it starts a unit named default.target; the
  dependencies of this unit cause all system services to be started, file
  systems to be mounted, swap files to be activated, and so on.
 
  The command systemctl is the main way to interact with
  systemd. Without any arguments, it shows the status of
  active units:

$ systemctl
-.mount          loaded active mounted   /
swapfile.swap    loaded active active    /swapfile
sshd.service     loaded active running   SSH Daemon
graphical.target loaded active active    Graphical Interface
...


  You can ask for detailed status information about a unit, for instance, the
  PostgreSQL database service:

$ systemctl status postgresql.service
postgresql.service - PostgreSQL Server
          Loaded: loaded (/nix/store/pn3q73mvh75gsrl8w7fdlfk3fq5qm5mw-unit/postgresql.service)
          Active: active (running) since Mon, 2013-01-07 15:55:57 CET; 9h ago
        Main PID: 2390 (postgres)
          CGroup: name=systemd:/system/postgresql.service
                  ├─2390 postgres
                  ├─2418 postgres: writer process
                  ├─2419 postgres: wal writer process
                  ├─2420 postgres: autovacuum launcher process
                  ├─2421 postgres: stats collector process
                  └─2498 postgres: zabbix zabbix [local] idle

Jan 07 15:55:55 hagbard postgres[2394]: [1-1] LOG:  database system was shut down at 2013-01-07 15:55:05 CET
Jan 07 15:55:57 hagbard postgres[2390]: [1-1] LOG:  database system is ready to accept connections
Jan 07 15:55:57 hagbard postgres[2420]: [1-1] LOG:  autovacuum launcher started
Jan 07 15:55:57 hagbard systemd[1]: Started PostgreSQL Server.

  Note that this shows the status of the unit (active and running), all the
  processes belonging to the service, as well as the most recent log messages
  from the service.
 
  Units can be stopped, started or restarted:

# systemctl stop postgresql.service
# systemctl start postgresql.service
# systemctl restart postgresql.service

  These operations are synchronous: they wait until the service has finished
  starting or stopping (or has failed). Starting a unit will cause the
  dependencies of that unit to be started as well (if necessary).
 Chapter 36. Rebooting and Shutting Down
  The system can be shut down (and automatically powered off) by doing:

# shutdown

  This is equivalent to running systemctl poweroff.
 
  To reboot the system, run

# reboot

  which is equivalent to systemctl reboot. Alternatively,
  you can quickly reboot the system using kexec, which
  bypasses the BIOS by directly loading the new kernel into memory:

# systemctl kexec


  The machine can be suspended to RAM (if supported) using systemctl
  suspend, and suspended to disk using systemctl
  hibernate.
 
  These commands can be run by any user who is logged in locally, i.e. on a
  virtual console or in X11; otherwise, the user is asked for authentication.
 Chapter 37. User Sessions
  Systemd keeps track of all users who are logged into the system (e.g. on a
  virtual console or remotely via SSH). The command loginctl
  allows querying and manipulating user sessions. For instance, to list all
  user sessions:

$ loginctl
   SESSION        UID USER             SEAT
        c1        500 eelco            seat0
        c3          0 root             seat0
        c4        500 alice

  This shows that two users are logged in locally, while another is logged in
  remotely. (“Seats” are essentially the combinations of displays and input
  devices attached to the system; usually, there is only one seat.) To get
  information about a session:

$ loginctl session-status c3
c3 - root (0)
           Since: Tue, 2013-01-08 01:17:56 CET; 4min 42s ago
          Leader: 2536 (login)
            Seat: seat0; vc3
             TTY: /dev/tty3
         Service: login; type tty; class user
           State: online
          CGroup: name=systemd:/user/root/c3
                  ├─ 2536 /nix/store/10mn4xip9n7y9bxqwnsx7xwx2v2g34xn-shadow-4.1.5.1/bin/login --
                  ├─10339 -bash
                  └─10355 w3m nixos.org

  This shows that the user is logged in on virtual console 3. It also lists the
  processes belonging to this session. Since systemd keeps track of this, you
  can terminate a session in a way that ensures that all the session’s
  processes are gone:

# loginctl terminate-session c3

Chapter 38. Control Groups
  To keep track of the processes in a running system, systemd uses
  control groups (cgroups). A control group is a set of
  processes used to allocate resources such as CPU, memory or I/O bandwidth.
  There can be multiple control group hierarchies, allowing each kind of
  resource to be managed independently.
 
  The command systemd-cgls lists all control groups in the
  systemd hierarchy, which is what systemd uses to keep
  track of the processes belonging to each service or user session:

$ systemd-cgls
├─user
│ └─eelco
│   └─c1
│     ├─ 2567 -:0
│     ├─ 2682 kdeinit4: kdeinit4 Running...
│     ├─ ...
│     └─10851 sh -c less -R
└─system
  ├─httpd.service
  │ ├─2444 httpd -f /nix/store/3pyacby5cpr55a03qwbnndizpciwq161-httpd.conf -DNO_DETACH
  │ └─...
  ├─dhcpcd.service
  │ └─2376 dhcpcd --config /nix/store/f8dif8dsi2yaa70n03xir8r653776ka6-dhcpcd.conf
  └─ ...

  Similarly, systemd-cgls cpu shows the cgroups in the CPU
  hierarchy, which allows per-cgroup CPU scheduling priorities. By default,
  every systemd service gets its own CPU cgroup, while all user sessions are in
  the top-level CPU cgroup. This ensures, for instance, that a thousand
  run-away processes in the httpd.service cgroup cannot
  starve the CPU for one process in the postgresql.service
  cgroup. (By contrast, it they were in the same cgroup, then the PostgreSQL
  process would get 1/1001 of the cgroup’s CPU time.) You can limit a
  service’s CPU share in configuration.nix:

systemd.services.httpd.serviceConfig.CPUShares = 512;

  By default, every cgroup has 1024 CPU shares, so this will halve the CPU
  allocation of the httpd.service cgroup.
 
  There also is a memory hierarchy that controls memory
  allocation limits; by default, all processes are in the top-level cgroup, so
  any service or session can exhaust all available memory. Per-cgroup memory
  limits can be specified in configuration.nix; for
  instance, to limit httpd.service to 512 MiB of RAM
  (excluding swap):

systemd.services.httpd.serviceConfig.MemoryLimit = ""512M"";


  The command systemd-cgtop shows a continuously updated
  list of all cgroups with their CPU and memory usage.
 Chapter 39. Logging
  System-wide logging is provided by systemd’s journal,
  which subsumes traditional logging daemons such as syslogd and klogd. Log
  entries are kept in binary files in /var/log/journal/.
  The command journalctl allows you to see the contents of
  the journal. For example,

$ journalctl -b

  shows all journal entries since the last reboot. (The output of
  journalctl is piped into less by
  default.) You can use various options and match operators to restrict output
  to messages of interest. For instance, to get all messages from PostgreSQL:

$ journalctl -u postgresql.service
-- Logs begin at Mon, 2013-01-07 13:28:01 CET, end at Tue, 2013-01-08 01:09:57 CET. --
...
Jan 07 15:44:14 hagbard postgres[2681]: [2-1] LOG:  database system is shut down
-- Reboot --
Jan 07 15:45:10 hagbard postgres[2532]: [1-1] LOG:  database system was shut down at 2013-01-07 15:44:14 CET
Jan 07 15:45:13 hagbard postgres[2500]: [1-1] LOG:  database system is ready to accept connections

  Or to get all messages since the last reboot that have at least a
  “critical” severity level:

$ journalctl -b -p crit
Dec 17 21:08:06 mandark sudo[3673]: pam_unix(sudo:auth): auth could not identify password for [alice]
Dec 29 01:30:22 mandark kernel[6131]: [1053513.909444] CPU6: Core temperature above threshold, cpu clock throttled (total events = 1)


  The system journal is readable by root and by users in the
  wheel and systemd-journal groups. All
  users have a private journal that can be read using
  journalctl.
 Chapter 40. Cleaning the Nix StoreTable of Contents40.1. NixOS Boot Entries
  Nix has a purely functional model, meaning that packages are never upgraded
  in place. Instead new versions of packages end up in a different location in
  the Nix store (/nix/store). You should periodically run
  Nix’s garbage collector to remove old, unreferenced
  packages. This is easy:

$ nix-collect-garbage

  Alternatively, you can use a systemd unit that does the same in the
  background:

# systemctl start nix-gc.service

  You can tell NixOS in configuration.nix to run this unit
  automatically at certain points in time, for instance, every night at 03:15:

nix.gc.automatic = true;
nix.gc.dates = ""03:15"";


  The commands above do not remove garbage collector roots, such as old system
  configurations. Thus they do not remove the ability to roll back to previous
  configurations. The following command deletes old roots, removing the ability
  to roll back to them:

$ nix-collect-garbage -d

  You can also do this for specific profiles, e.g.

$ nix-env -p /nix/var/nix/profiles/per-user/eelco/profile --delete-generations old

  Note that NixOS system configurations are stored in the profile
  /nix/var/nix/profiles/system.
 
  Another way to reclaim disk space (often as much as 40% of the size of the
  Nix store) is to run Nix’s store optimiser, which seeks out identical files
  in the store and replaces them with hard links to a single copy.

$ nix-store --optimise

  Since this command needs to read the entire Nix store, it can take quite a
  while to finish.
 40.1. NixOS Boot Entries
   If your /boot partition runs out of space, after
   clearing old profiles you must rebuild your system with
   nixos-rebuild to update the /boot
   partition and clear space.
  Chapter 41. Container ManagementTable of Contents41.1. Imperative Container Management41.2. Declarative Container Specification41.3. Container Networking
  NixOS allows you to easily run other NixOS instances as
  containers. Containers are a light-weight approach to
  virtualisation that runs software in the container at the same speed as in
  the host system. NixOS containers share the Nix store of the host, making
  container creation very efficient.
 Warning: 
   Currently, NixOS containers are not perfectly isolated from the host system.
   This means that a user with root access to the container can do things that
   affect the host. So you should not give container root access to untrusted
   users.
  
  NixOS containers can be created in two ways: imperatively, using the command
  nixos-container, and declaratively, by specifying them in
  your configuration.nix. The declarative approach implies
  that containers get upgraded along with your host system when you run
  nixos-rebuild, which is often not what you want. By
  contrast, in the imperative approach, containers are configured and updated
  independently from the host system.
 41.1. Imperative Container Management
  We’ll cover imperative container management using
  nixos-container first. Be aware that container management
  is currently only possible as root.
 
  You create a container with identifier foo as follows:

# nixos-container create foo

  This creates the container’s root directory in
  /var/lib/containers/foo and a small configuration file
  in /etc/containers/foo.conf. It also builds the
  container’s initial system configuration and stores it in
  /nix/var/nix/profiles/per-container/foo/system. You can
  modify the initial configuration of the container on the command line. For
  instance, to create a container that has sshd running,
  with the given public key for root:

# nixos-container create foo --config '
  services.openssh.enable = true;
  users.users.root.openssh.authorizedKeys.keys = [""ssh-dss AAAAB3N…""];
'

  By default the next free address in the 10.233.0.0/16 subnet will be chosen
  as container IP. This behavior can be altered by setting --host-address and
  --local-address:

# nixos-container create test --config-file test-container.nix \
    --local-address 10.235.1.2 --host-address 10.235.1.1


  Creating a container does not start it. To start the container, run:

# nixos-container start foo

  This command will return as soon as the container has booted and has reached
  multi-user.target. On the host, the container runs within
  a systemd unit called
  container@container-name.service.
  Thus, if something went wrong, you can get status info using
  systemctl:

# systemctl status container@foo


  If the container has started successfully, you can log in as root using the
  root-login operation:

# nixos-container root-login foo
[root@foo:~]#

  Note that only root on the host can do this (since there is no
  authentication). You can also get a regular login prompt using the
  login operation, which is available to all users on the
  host:

# nixos-container login foo
foo login: alice
Password: ***

  With nixos-container run, you can execute arbitrary
  commands in the container:

# nixos-container run foo -- uname -a
Linux foo 3.4.82 #1-NixOS SMP Thu Mar 20 14:44:05 UTC 2014 x86_64 GNU/Linux


  There are several ways to change the configuration of the container. First,
  on the host, you can edit
  /var/lib/container/name/etc/nixos/configuration.nix,
  and run

# nixos-container update foo

  This will build and activate the new configuration. You can also specify a
  new configuration on the command line:

# nixos-container update foo --config '
  services.httpd.enable = true;
  services.httpd.adminAddr = ""foo@example.org"";
  networking.firewall.allowedTCPPorts = [ 80 ];
'

# curl http://$(nixos-container show-ip foo)/
<!DOCTYPE HTML PUBLIC ""-//W3C//DTD HTML 3.2 Final//EN"">…

  However, note that this will overwrite the container’s
  /etc/nixos/configuration.nix.
 
  Alternatively, you can change the configuration from within the container
  itself by running nixos-rebuild switch inside the
  container. Note that the container by default does not have a copy of the
  NixOS channel, so you should run nix-channel --update
  first.
 
  Containers can be stopped and started using nixos-container
  stop and nixos-container start, respectively, or
  by using systemctl on the container’s service unit. To
  destroy a container, including its file system, do

# nixos-container destroy foo

41.2. Declarative Container Specification
  You can also specify containers and their configuration in the host’s
  configuration.nix. For example, the following specifies
  that there shall be a container named database running
  PostgreSQL:

containers.database =
  { config =
      { config, pkgs, ... }:
      { services.postgresql.enable = true;
      services.postgresql.package = pkgs.postgresql_9_6;
      };
  };

  If you run nixos-rebuild switch, the container will be
  built. If the container was already running, it will be updated in place,
  without rebooting. The container can be configured to start automatically by
  setting containers.database.autoStart = true in its
  configuration.
 
  By default, declarative containers share the network namespace of the host,
  meaning that they can listen on (privileged) ports. However, they cannot
  change the network configuration. You can give a container its own network as
  follows:

containers.database = {
  privateNetwork = true;
  hostAddress = ""192.168.100.10"";
  localAddress = ""192.168.100.11"";
};

  This gives the container a private virtual Ethernet interface with IP address
  192.168.100.11, which is hooked up to a virtual Ethernet
  interface on the host with IP address 192.168.100.10. (See
  the next section for details on container networking.)
 
  To disable the container, just remove it from
  configuration.nix and run nixos-rebuild
  switch. Note that this will not delete the root directory of the
  container in /var/lib/containers. Containers can be
  destroyed using the imperative method: nixos-container destroy
  foo.
 
  Declarative containers can be started and stopped using the corresponding
  systemd service, e.g. systemctl start container@database.
 41.3. Container Networking
  When you create a container using nixos-container create,
  it gets it own private IPv4 address in the range
  10.233.0.0/16. You can get the container’s IPv4 address
  as follows:

# nixos-container show-ip foo
10.233.4.2

$ ping -c1 10.233.4.2
64 bytes from 10.233.4.2: icmp_seq=1 ttl=64 time=0.106 ms


  Networking is implemented using a pair of virtual Ethernet devices. The
  network interface in the container is called eth0, while
  the matching interface in the host is called
  ve-container-name (e.g.,
  ve-foo). The container has its own network namespace and
  the CAP_NET_ADMIN capability, so it can perform arbitrary
  network configuration such as setting up firewall rules, without affecting or
  having access to the host’s network.
 
  By default, containers cannot talk to the outside network. If you want that,
  you should set up Network Address Translation (NAT) rules on the host to
  rewrite container traffic to use your external IP address. This can be
  accomplished using the following configuration on the host:

networking.nat.enable = true;
networking.nat.internalInterfaces = [""ve-+""];
networking.nat.externalInterface = ""eth0"";

  where eth0 should be replaced with the desired external
  interface. Note that ve-+ is a wildcard that matches all
  container interfaces.
 
  If you are using Network Manager, you need to explicitly prevent it from
  managing container interfaces:

networking.networkmanager.unmanaged = [ ""interface-name:ve-*"" ];


  You may need to restart your system for the changes to take effect.
 Chapter 42. TroubleshootingTable of Contents42.1. Boot Problems42.2. Maintenance Mode42.3. Rolling Back Configuration Changes42.4. Nix Store Corruption42.5. Network Problems
  This chapter describes solutions to common problems you might encounter when
  you manage your NixOS system.
 42.1. Boot Problems
  If NixOS fails to boot, there are a number of kernel command line parameters
  that may help you to identify or fix the issue. You can add these parameters
  in the GRUB boot menu by pressing “e” to modify the selected boot entry
  and editing the line starting with linux. The following
  are some useful kernel command line parameters that are recognised by the
  NixOS boot scripts or by systemd:
  
boot.shell_on_fail

      Start a root shell if something goes wrong in stage 1 of the boot process
      (the initial ramdisk). This is disabled by default because there is no
      authentication for the root shell.
     
boot.debug1

      Start an interactive shell in stage 1 before anything useful has been
      done. That is, no modules have been loaded and no file systems have been
      mounted, except for /proc and
      /sys.
     
boot.trace

      Print every shell command executed by the stage 1 and 2 boot scripts.
     
single

      Boot into rescue mode (a.k.a. single user mode). This will cause systemd
      to start nothing but the unit rescue.target, which
      runs sulogin to prompt for the root password and start
      a root login shell. Exiting the shell causes the system to continue with
      the normal boot process.
     
systemd.log_level=debug systemd.log_target=console

      Make systemd very verbose and send log messages to the console instead of
      the journal.
     
  For more parameters recognised by systemd, see systemd(1).
 
  If no login prompts or X11 login screens appear (e.g. due to hanging
  dependencies), you can press Alt+ArrowUp. If you’re lucky, this will start
  rescue mode (described above). (Also note that since most units have a
  90-second timeout before systemd gives up on them, the
  agetty login prompts should appear eventually unless
  something is very wrong.)
 42.2. Maintenance Mode
  You can enter rescue mode by running:

# systemctl rescue
  This will eventually give you a single-user root shell. Systemd will stop
  (almost) all system services. To get out of maintenance mode, just exit from
  the rescue shell.
 42.3. Rolling Back Configuration Changes
  After running nixos-rebuild to switch to a new
  configuration, you may find that the new configuration doesn’t work very
  well. In that case, there are several ways to return to a previous
  configuration.
 
  First, the GRUB boot manager allows you to boot into any previous
  configuration that hasn’t been garbage-collected. These configurations can
  be found under the GRUB submenu “NixOS - All configurations”. This is
  especially useful if the new configuration fails to boot. After the system
  has booted, you can make the selected configuration the default for
  subsequent boots:

# /run/current-system/bin/switch-to-configuration boot

  Second, you can switch to the previous configuration in a running system:

# nixos-rebuild switch --rollback
  This is equivalent to running:

# /nix/var/nix/profiles/system-N-link/bin/switch-to-configuration switch
  where N is the number of the NixOS system
  configuration. To get a list of the available configurations, do:

$ ls -l /nix/var/nix/profiles/system-*-link
...
lrwxrwxrwx 1 root root 78 Aug 12 13:54 /nix/var/nix/profiles/system-268-link -> /nix/store/202b...-nixos-13.07pre4932_5a676e4-4be1055

42.4. Nix Store Corruption
  After a system crash, it’s possible for files in the Nix store to become
  corrupted. (For instance, the Ext4 file system has the tendency to replace
  un-synced files with zero bytes.) NixOS tries hard to prevent this from
  happening: it performs a sync before switching to a new
  configuration, and Nix’s database is fully transactional. If corruption
  still occurs, you may be able to fix it automatically.
 
  If the corruption is in a path in the closure of the NixOS system
  configuration, you can fix it by doing

# nixos-rebuild switch --repair

  This will cause Nix to check every path in the closure, and if its
  cryptographic hash differs from the hash recorded in Nix’s database, the
  path is rebuilt or redownloaded.
 
  You can also scan the entire Nix store for corrupt paths:

# nix-store --verify --check-contents --repair

  Any corrupt paths will be redownloaded if they’re available in a binary
  cache; otherwise, they cannot be repaired.
 42.5. Network Problems
  Nix uses a so-called binary cache to optimise building a
  package from source into downloading it as a pre-built binary. That is,
  whenever a command like nixos-rebuild needs a path in the
  Nix store, Nix will try to download that path from the Internet rather than
  build it from source. The default binary cache is
  https://cache.nixos.org/. If this cache is unreachable, Nix
  operations may take a long time due to HTTP connection timeouts. You can
  disable the use of the binary cache by adding --option
  use-binary-caches false, e.g.

# nixos-rebuild switch --option use-binary-caches false

  If you have an alternative binary cache at your disposal, you can use it
  instead:

# nixos-rebuild switch --option binary-caches http://my-cache.example.org/

Part IV. Development
   This chapter describes how you can modify and extend NixOS.
  Table of Contents43. Getting the Sources44. Writing NixOS Modules45. Building Specific Parts of NixOS46. Writing NixOS Documentation47. Building Your Own NixOS CD48. NixOS Tests49. Testing the Installer50. ReleasesChapter 43. Getting the Sources
  By default, NixOS’s nixos-rebuild command uses the NixOS
  and Nixpkgs sources provided by the nixos channel (kept in
  /nix/var/nix/profiles/per-user/root/channels/nixos). To
  modify NixOS, however, you should check out the latest sources from Git. This
  is as follows:

$ git clone https://github.com/NixOS/nixpkgs
$ cd nixpkgs
$ git remote update origin

  This will check out the latest Nixpkgs sources to
  ./nixpkgs the NixOS sources to
  ./nixpkgs/nixos. (The NixOS source tree lives in a
  subdirectory of the Nixpkgs repository.) The
  nixpkgs repository has branches that correspond
  to each Nixpkgs/NixOS channel (see Chapter 4, Upgrading NixOS for more
  information about channels). Thus, the Git branch
  origin/nixos-17.03 will contain the latest built and
  tested version available in the nixos-17.03 channel.
 
  It’s often inconvenient to develop directly on the master branch, since if
  somebody has just committed (say) a change to GCC, then the binary cache may
  not have caught up yet and you’ll have to rebuild everything from source.
  So you may want to create a local branch based on your current NixOS version:

$ nixos-version
17.09pre104379.6e0b727 (Hummingbird)

$ git checkout -b local 6e0b727

  Or, to base your local branch on the latest version available in a NixOS
  channel:

$ git remote update origin
$ git checkout -b local origin/nixos-17.03

  (Replace nixos-17.03 with the name of the channel you want
  to use.) You can use git merge or git
  rebase to keep your local branch in sync with the channel, e.g.

$ git remote update origin
$ git merge origin/nixos-17.03

  You can use git cherry-pick to copy commits from your
  local branch to the upstream branch.
 
  If you want to rebuild your system using your (modified) sources, you need to
  tell nixos-rebuild about them using the
  -I flag:

# nixos-rebuild switch -I nixpkgs=/my/sources/nixpkgs


  If you want nix-env to use the expressions in
  /my/sources, use nix-env -f
  /my/sources/nixpkgs, or change the
  default by adding a symlink in ~/.nix-defexpr:

$ ln -s /my/sources/nixpkgs ~/.nix-defexpr/nixpkgs

  You may want to delete the symlink
  ~/.nix-defexpr/channels_root to prevent root’s NixOS
  channel from clashing with your own tree (this may break the
  command-not-found utility though). If you want to go back to the default
  state, you may just remove the ~/.nix-defexpr directory
  completely, log out and log in again and it should have been recreated with a
  link to the root channels.
 Chapter 44. Writing NixOS ModulesTable of Contents44.1. Option Declarations44.2. Options Types44.3. Option Definitions44.4. Warnings and Assertions44.5. Meta Attributes44.6. Importing Modules44.7. Replace Modules
  NixOS has a modular system for declarative configuration. This system
  combines multiple modules to produce the full system
  configuration. One of the modules that constitute the configuration is
  /etc/nixos/configuration.nix. Most of the others live in
  the
  nixos/modules
  subdirectory of the Nixpkgs tree.
 
  Each NixOS module is a file that handles one logical aspect of the
  configuration, such as a specific kind of hardware, a service, or network
  settings. A module configuration does not have to handle everything from
  scratch; it can use the functionality provided by other modules for its
  implementation. Thus a module can declare options that
  can be used by other modules, and conversely can define
  options provided by other modules in its own implementation. For example, the
  module
  pam.nix
  declares the option security.pam.services that allows other
  modules (e.g.
  sshd.nix)
  to define PAM services; and it defines the option
  environment.etc (declared by
  etc.nix)
  to cause files to be created in /etc/pam.d.
 
  In Chapter 5, Configuration Syntax, we saw the following structure
  of NixOS modules:

{ config, pkgs, ... }:

{ option definitions
}

  This is actually an abbreviated form of module that only
  defines options, but does not declare any. The structure of full NixOS
  modules is shown in Example 44.1, “Structure of NixOS Modules”.
 Example 44.1. Structure of NixOS Modules
{ config, pkgs, ... }: 

{
  imports =
    [ paths of other modules 
    ];

  options = {
    option declarations 
  };

  config = {
    option definitions 
  };
}
  The meaning of each part is as follows.
   
     This line makes the current Nix expression a function. The variable
     pkgs contains Nixpkgs, while config
     contains the full system configuration. This line can be omitted if there
     is no reference to pkgs and config
     inside the module.
     
     This list enumerates the paths to other NixOS modules that should be
     included in the evaluation of the system configuration. A default set of
     modules is defined in the file
     modules/module-list.nix. These don't need to be added
     in the import list.
     
     The attribute options is a nested set of
     option declarations (described below).
     
     The attribute config is a nested set of
     option definitions (also described below).
    

Example 44.2, “NixOS Module for the “locate” Service” shows a module that handles the regular
  update of the “locate” database, an index of all files in the file
  system. This module declares two options that can be defined by other modules
  (typically the user’s configuration.nix):
  services.locate.enable (whether the database should be
  updated) and services.locate.interval (when the update
  should be done). It implements its functionality by defining two options
  declared by other modules: systemd.services (the set of all
  systemd services) and systemd.timers (the list of commands
  to be executed periodically by systemd).
 Example 44.2. NixOS Module for the “locate” Service
{ config, lib, pkgs, ... }:

with lib;

let
  cfg = config.services.locate;
in {
  options.services.locate = {
    enable = mkOption {
      type = types.bool;
      default = false;
      description = ''
        If enabled, NixOS will periodically update the database of
        files used by the locate command.
      '';
    };

    interval = mkOption {
      type = types.str;
      default = ""02:15"";
      example = ""hourly"";
      description = ''
        Update the locate database at this interval. Updates by
        default at 2:15 AM every day.

        The format is described in
        systemd.time(7).
      '';
    };

    # Other options omitted for documentation
  };

  config = {
    systemd.services.update-locatedb =
      { description = ""Update Locate Database"";
        path  = [ pkgs.su ];
        script =
          ''
            mkdir -m 0755 -p $(dirname ${toString cfg.output})
            exec updatedb \
              --localuser=${cfg.localuser} \
              ${optionalString (!cfg.includeStore) ""--prunepaths='/nix/store'""} \
              --output=${toString cfg.output} ${concatStringsSep "" "" cfg.extraFlags}
          '';
      };

    systemd.timers.update-locatedb = mkIf cfg.enable
      { description = ""Update timer for locate database"";
        partOf      = [ ""update-locatedb.service"" ];
        wantedBy    = [ ""timers.target"" ];
        timerConfig.OnCalendar = cfg.interval;
      };
  };
}
44.1. Option Declarations
  An option declaration specifies the name, type and description of a NixOS
  configuration option. It is invalid to define an option that hasn’t been
  declared in any module. An option declaration generally looks like this:

options = {
  name = mkOption {
    type = type specification;
    default = default value;
    example = example value;
    description = ""Description for use in the NixOS manual."";
  };
};

  The attribute names within the name attribute path
  must be camel cased in general but should, as an exception, match the
  
  package attribute name when referencing a Nixpkgs package. For
  example, the option services.nix-serve.bindAddress
  references the nix-serve Nixpkgs package.
 
  The function mkOption accepts the following arguments.
  
type

      The type of the option (see Section 44.2, “Options Types”). It may
      be omitted, but that’s not advisable since it may lead to errors that
      are hard to diagnose.
     
default

      The default value used if no value is defined by any module. A default is
      not required; but if a default is not given, then users of the module
      will have to define the value of the option, otherwise an error will be
      thrown.
     
example

      An example value that will be shown in the NixOS manual.
     
description

      A textual description of the option, in DocBook format, that will be
      included in the NixOS manual.
     
44.1.1. Extensible Option Types
   Extensible option types is a feature that allow to extend certain types
   declaration through multiple module files. This feature only work with a
   restricted set of types, namely enum and
   submodules and any composed forms of them.
  
   Extensible option types can be used for enum options that
   affects multiple modules, or as an alternative to related
   enable options.
  
   As an example, we will take the case of display managers. There is a central
   display manager module for generic display manager options and a module file
   per display manager backend (sddm, gdm ...).
  
   There are two approach to this module structure:
   
      Managing the display managers independently by adding an enable option to
      every display manager module backend. (NixOS)
     
      Managing the display managers in the central module by adding an option
      to select which display manager backend to use.
     

   Both approaches have problems.
  
   Making backends independent can quickly become hard to manage. For display
   managers, there can be only one enabled at a time, but the type system can
   not enforce this restriction as there is no relation between each backend
   enable option. As a result, this restriction has to be
   done explicitely by adding assertions in each display manager backend
   module.
  
   On the other hand, managing the display managers backends in the central
   module will require to change the central module option every time a new
   backend is added or removed.
  
   By using extensible option types, it is possible to create a placeholder
   option in the central module
   (Example 44.3, “Extensible type placeholder in the service module”), and to extend
   it in each backend module
   (Example 44.4, “Extending services.xserver.displayManager.enable in the gdm module”,
   Example 44.5, “Extending services.xserver.displayManager.enable in the sddm module”).
  
   As a result, displayManager.enable option values can be
   added without changing the main service module file and the type system
   automatically enforce that there can only be a single display manager
   enabled.
  Example 44.3. Extensible type placeholder in the service module
services.xserver.displayManager.enable = mkOption {
  description = ""Display manager to use"";
  type = with types; nullOr (enum [ ]);
};Example 44.4. Extending services.xserver.displayManager.enable in the gdm module
services.xserver.displayManager.enable = mkOption {
  type = with types; nullOr (enum [ ""gdm"" ]);
};Example 44.5. Extending services.xserver.displayManager.enable in the sddm module
services.xserver.displayManager.enable = mkOption {
  type = with types; nullOr (enum [ ""sddm"" ]);
};
   The placeholder declaration is a standard mkOption
   declaration, but it is important that extensible option declarations only
   use the type argument.
  
   Extensible option types work with any of the composed variants of
   enum such as with types; nullOr (enum [ ""foo""
   ""bar"" ]) or with types; listOf (enum [ ""foo"" ""bar""
   ]).
  44.2. Options Types
  Option types are a way to put constraints on the values a module option can
  take. Types are also responsible of how values are merged in case of multiple
  value definitions.
 44.2.1. Basic Types
   Basic types are the simplest available types in the module system. Basic
   types include multiple string types that mainly differ in how definition
   merging is handled.
  
types.attrs

      A free-form attribute set.
     
types.bool

      A boolean, its values can be true or
      false.
     
types.path

      A filesystem path, defined as anything that when coerced to a string
      starts with a slash. Even if derivations can be considered as path, the
      more specific types.package should be preferred.
     
types.package

      A derivation or a store path.
     
   Integer-related types:
  
types.int

      A signed integer.
     
types.ints.{s8, s16, s32}

      Signed integers with a fixed length (8, 16 or 32 bits). They go from
      −2n/2 to 2n/2−1 respectively (e.g. −128 to
      127 for 8 bits).
     
types.ints.unsigned

      An unsigned integer (that is >= 0).
     
types.ints.{u8, u16, u32}

      Unsigned integers with a fixed length (8, 16 or 32 bits). They go from
      0 to
      2n−1 respectively (e.g. 0 to
      255 for 8 bits).
     
types.ints.positive

      A positive integer (that is > 0).
     
types.port

      A port number. This type is an alias to
      types.ints.u16.
     
   String-related types:
  
types.str

      A string. Multiple definitions cannot be merged.
     
types.lines

      A string. Multiple definitions are concatenated with a new line
      ""\n"".
     
types.commas

      A string. Multiple definitions are concatenated with a comma
      "","".
     
types.envVar

      A string. Multiple definitions are concatenated with a collon
      "":"".
     
types.strMatching

      A string matching a specific regular expression. Multiple definitions
      cannot be merged. The regular expression is processed using
      builtins.match.
     44.2.2. Value Types
   Value types are types that take a value parameter.
  
types.enum l

      One element of the list l, e.g.
      types.enum [ ""left"" ""right"" ]. Multiple definitions
      cannot be merged.
     
types.separatedString sep

      A string with a custom separator sep, e.g.
      types.separatedString ""|"".
     
types.ints.between lowest highest

      An integer between lowest and
      highest (both inclusive). Useful for creating
      types like types.port.
     
types.submodule o

      A set of sub options o.
      o can be an attribute set, a function
      returning an attribute set, or a path to a file containing such a value. Submodules are used in
      composed types to create modular options. This is equivalent to
      types.submoduleWith { modules = toList o; shorthandOnlyDefinesConfig = true; }.
      Submodules are detailed in
      Section 44.2.4, “Submodule”.
     
types.submoduleWith {
        modules,
        specialArgs ? {},
        shorthandOnlyDefinesConfig ? false }
     
         Like types.submodule, but more flexible and with better defaults.
         It has parameters
         
modules
             A list of modules to use by default for this submodule type. This gets combined
             with all option definitions to build the final list of modules that will be included.
             Note: 
               Only options defined with this argument are included in rendered documentation.
             

specialArgs
             An attribute set of extra arguments to be passed to the module functions.
             The option _module.args should be used instead
             for most arguments since it allows overriding. specialArgs should only be
             used for arguments that can't go through the module fixed-point, because of
             infinite recursion or other problems. An example is overriding the
             lib argument, because lib itself is used
             to define _module.args, which makes using
             _module.args to define it impossible.
           
shorthandOnlyDefinesConfig
             Whether definitions of this type should default to the config
             section of a module (see Example 44.1, “Structure of NixOS Modules”) if it is an attribute
             set. Enabling this only has a benefit when the submodule defines an option named
             config or options. In such a case it would
             allow the option to be set with the-submodule.config = ""value""
             instead of requiring the-submodule.config.config = ""value"".
             This is because only when modules don't set the
             config or options keys, all keys are interpreted
             as option definitions in the config section. Enabling this option
             implicitly puts all attributes in the config section.
           
             With this option enabled, defining a non-config section requires
             using a function: the-submodule = { ... }: { options = { ... }; }.
           
44.2.3. Composed Types
   Composed types are types that take a type as parameter. listOf
   int and either int str are examples of composed
   types.
  
types.listOf t

      A list of t type, e.g. types.listOf
      int. Multiple definitions are merged with list concatenation.
     
types.attrsOf t

      An attribute set of where all the values are of
      t type. Multiple definitions result in the
      joined attribute set.
      Note: 
       This type is strict in its values, which in turn
       means attributes cannot depend on other attributes. See 
       types.lazyAttrsOf for a lazy version.
      

types.lazyAttrsOf t

      An attribute set of where all the values are of
      t type. Multiple definitions result in the
      joined attribute set. This is the lazy version of types.attrsOf
      , allowing attributes to depend on each other.
      Warning: 
       This version does not fully support conditional definitions! With an
       option foo of this type and a definition
       foo.attr = lib.mkIf false 10, evaluating
       foo ? attr will return true
       even though it should be false. Accessing the value will then throw
       an error. For types t that have an
       emptyValue defined, that value will be returned
       instead of throwing an error. So if the type of foo.attr
       was lazyAttrsOf (nullOr int), null
       would be returned instead for the same mkIf false definition.
      

types.loaOf t

      An attribute set or a list of t type. Multiple
      definitions are merged according to the value.
     
types.nullOr t

null or type t. Multiple
      definitions are merged according to type t.
     
types.uniq t

      Ensures that type t cannot be merged. It is
      used to ensure option definitions are declared only once.
     
types.either t1 t2

      Type t1 or type t2,
      e.g. with types; either int str. Multiple definitions
      cannot be merged.
     
types.oneOf [ t1 t2 ... ]
    
      Type t1 or type t2 and so forth,
      e.g. with types; oneOf [ int str bool ]. Multiple definitions
      cannot be merged.
     
types.coercedTo from f to

      Type to or type
      from which will be coerced to type
      to using function f
      which takes an argument of type from and
      return a value of type to. Can be used to
      preserve backwards compatibility of an option if its type was changed.
     44.2.4. Submodule
submodule is a very powerful type that defines a set of
   sub-options that are handled like a separate module.
  
   It takes a parameter o, that should be a set, or
   a function returning a set with an options key defining
   the sub-options. Submodule option definitions are type-checked accordingly
   to the options declarations. Of course, you can nest
   submodule option definitons for even higher modularity.
  
   The option set can be defined directly
   (Example 44.6, “Directly defined submodule”) or as reference
   (Example 44.7, “Submodule defined as a reference”).
  Example 44.6. Directly defined submodule
options.mod = mkOption {
  description = ""submodule example"";
  type = with types; submodule {
    options = {
      foo = mkOption {
        type = int;
      };
      bar = mkOption {
        type = str;
      };
    };
  };
};Example 44.7. Submodule defined as a reference
let
  modOptions = {
    options = {
      foo = mkOption {
        type = int;
      };
      bar = mkOption {
        type = int;
      };
    };
  };
in
options.mod = mkOption {
  description = ""submodule example"";
  type = with types; submodule modOptions;
};
   The submodule type is especially interesting when used
   with composed types like attrsOf or
   listOf. When composed with listOf
   (Example 44.8, “Declaration of a list of submodules”),
   submodule allows multiple definitions of the submodule
   option set (Example 44.9, “Definition of a list of submodules”).
  Example 44.8. Declaration of a list of submodules
options.mod = mkOption {
  description = ""submodule example"";
  type = with types; listOf (submodule {
    options = {
      foo = mkOption {
        type = int;
      };
      bar = mkOption {
        type = str;
      };
    };
  });
};Example 44.9. Definition of a list of submodules
config.mod = [
  { foo = 1; bar = ""one""; }
  { foo = 2; bar = ""two""; }
];
   When composed with attrsOf
   (Example 44.10, “Declaration of attribute sets of submodules”),
   submodule allows multiple named definitions of the
   submodule option set (Example 44.11, “Declaration of attribute sets of submodules”).
  Example 44.10. Declaration of attribute sets of submodules
options.mod = mkOption {
  description = ""submodule example"";
  type = with types; attrsOf (submodule {
    options = {
      foo = mkOption {
        type = int;
      };
      bar = mkOption {
        type = str;
      };
    };
  });
};Example 44.11. Declaration of attribute sets of submodules
config.mod.one = { foo = 1; bar = ""one""; };
config.mod.two = { foo = 2; bar = ""two""; };44.2.5. Extending types
   Types are mainly characterized by their check and
   merge functions.
  
check

      The function to type check the value. Takes a value as parameter and
      return a boolean. It is possible to extend a type check with the
      addCheck function
      (Example 44.12, “Adding a type check”), or to fully
      override the check function
      (Example 44.13, “Overriding a type check”).
     Example 44.12. Adding a type check
byte = mkOption {
  description = ""An integer between 0 and 255."";
  type = types.addCheck types.int (x: x >= 0 && x <= 255);
};Example 44.13. Overriding a type check
nixThings = mkOption {
  description = ""words that start with 'nix'"";
  type = types.str // {
    check = (x: lib.hasPrefix ""nix"" x)
  };
};
merge

      Function to merge the options values when multiple values are set. The
      function takes two parameters, loc the option path as
      a list of strings, and defs the list of defined values
      as a list. It is possible to override a type merge function for custom
      needs.
     44.2.6. Custom Types
   Custom types can be created with the mkOptionType
   function. As type creation includes some more complex topics such as
   submodule handling, it is recommended to get familiar with
   types.nix
   code before creating a new type.
  
   The only required parameter is name.
  
name

      A string representation of the type function name.
     
definition

      Description of the type used in documentation. Give information of the
      type and any of its arguments.
     
check

      A function to type check the definition value. Takes the definition value
      as a parameter and returns a boolean indicating the type check result,
      true for success and false for
      failure.
     
merge

      A function to merge multiple definitions values. Takes two parameters:
     
loc

         The option path as a list of strings, e.g. [""boot"" ""loader
         ""grub"" ""enable""].
        
defs

         The list of sets of defined value and
         file where the value was defined, e.g. [ {
         file = ""/foo.nix""; value = 1; } { file = ""/bar.nix""; value = 2 }
         ]. The merge function should return the
         merged value or throw an error in case the values are impossible or
         not meant to be merged.
        
getSubOptions

      For composed types that can take a submodule as type parameter, this
      function generate sub-options documentation. It takes the current option
      prefix as a list and return the set of sub-options. Usually defined in a
      recursive manner by adding a term to the prefix, e.g. prefix:
      elemType.getSubOptions (prefix ++
      [""prefix""]) where
      ""prefix"" is the newly added prefix.
     
getSubModules

      For composed types that can take a submodule as type parameter, this
      function should return the type parameters submodules. If the type
      parameter is called elemType, the function should just
      recursively look into submodules by returning
      elemType.getSubModules;.
     
substSubModules

      For composed types that can take a submodule as type parameter, this
      function can be used to substitute the parameter of a submodule type. It
      takes a module as parameter and return the type with the submodule
      options substituted. It is usually defined as a type function call with a
      recursive call to substSubModules, e.g for a type
      composedType that take an elemtype
      type parameter, this function should be defined as m:
      composedType (elemType.substSubModules m).
     
typeMerge

      A function to merge multiple type declarations. Takes the type to merge
      functor as parameter. A null return
      value means that type cannot be merged.
     
f

         The type to merge functor.
        
      Note: There is a generic defaultTypeMerge that work
      with most of value and composed types.
     
functor

      An attribute set representing the type. It is used for type operations
      and has the following keys:
     
type

         The type function.
        
wrapped

         Holds the type parameter for composed types.
        
payload

         Holds the value parameter for value types. The types that have a
         payload are the enum,
         separatedString and submodule
         types.
        
binOp

         A binary operation that can merge the payloads of two same types.
         Defined as a function that take two payloads as parameters and return
         the payloads merged.
        44.3. Option Definitions
  Option definitions are generally straight-forward bindings of values to
  option names, like

config = {
  services.httpd.enable = true;
};

  However, sometimes you need to wrap an option definition or set of option
  definitions in a property to achieve certain effects:
 Delaying Conditionals
   If a set of option definitions is conditional on the value of another
   option, you may need to use mkIf. Consider, for instance:

config = if config.services.httpd.enable then {
  environment.systemPackages = [ ... ];
  ...
} else {};

   This definition will cause Nix to fail with an “infinite recursion”
   error. Why? Because the value of
   config.services.httpd.enable depends on the value being
   constructed here. After all, you could also write the clearly circular and
   contradictory:

config = if config.services.httpd.enable then {
  services.httpd.enable = false;
} else {
  services.httpd.enable = true;
};

   The solution is to write:

config = mkIf config.services.httpd.enable {
  environment.systemPackages = [ ... ];
  ...
};

   The special function mkIf causes the evaluation of the
   conditional to be “pushed down” into the individual definitions, as if
   you had written:

config = {
  environment.systemPackages = if config.services.httpd.enable then [ ... ] else [];
  ...
};

Setting Priorities
   A module can override the definitions of an option in other modules by
   setting a priority. All option definitions that do not
   have the lowest priority value are discarded. By default, option definitions
   have priority 1000. You can specify an explicit priority by using
   mkOverride, e.g.

services.openssh.enable = mkOverride 10 false;

   This definition causes all other definitions with priorities above 10 to be
   discarded. The function mkForce is equal to
   mkOverride 50.
  Merging Configurations
   In conjunction with mkIf, it is sometimes useful for a
   module to return multiple sets of option definitions, to be merged together
   as if they were declared in separate modules. This can be done using
   mkMerge:

config = mkMerge
  [ # Unconditional stuff.
    { environment.systemPackages = [ ... ];
    }
    # Conditional stuff.
    (mkIf config.services.bla.enable {
      environment.systemPackages = [ ... ];
    })
  ];

44.4. Warnings and Assertions
  When configuration problems are detectable in a module, it is a good idea to
  write an assertion or warning. Doing so provides clear feedback to the user
  and prevents errors after the build.
 
  Although Nix has the abort and
  builtins.trace
functions
  to perform such tasks, they are not ideally suited for NixOS modules. Instead
  of these functions, you can declare your warnings and assertions using the
  NixOS module system.
 44.4.1. Warnings
   This is an example of using warnings.
  

{ config, lib, ... }:
{
  config = lib.mkIf config.services.foo.enable {
    warnings =
      if config.services.foo.bar
      then [ ''You have enabled the bar feature of the foo service.
               This is known to cause some specific problems in certain situations.
               '' ]
      else [];
  }
}

44.4.2. Assertions
   This example, extracted from the
   
syslogd module  shows how to use
   assertions. Since there can only be one active syslog
   daemon at a time, an assertion is useful to prevent such a broken system
   from being built.
  

{ config, lib, ... }:
{
  config = lib.mkIf config.services.syslogd.enable {
    assertions =
      [ { assertion = !config.services.rsyslogd.enable;
          message = ""rsyslogd conflicts with syslogd"";
        }
      ];
  }
}

44.5. Meta Attributes
  Like Nix packages, NixOS modules can declare meta-attributes to provide extra
  information. Module meta attributes are defined in the
  meta.nix
  special module.
 
meta is a top level attribute like
  options and config. Available
  meta-attributes are maintainers and
  doc.
 
  Each of the meta-attributes must be defined at most once per module file.
 
{ config, lib, pkgs, ... }:
{
  options = {
    ...
  };

  config = {
    ...
  };

  meta = {
    maintainers = with lib.maintainers; [ ericsagnes ]; 
    doc = ./default.xml; 
  };
}
 
maintainers contains a list of the module maintainers.
    
doc points to a valid DocBook file containing the module
    documentation. Its contents is automatically added to
    Part II, “Configuration”. Changes to a module documentation
    have to be checked to not break building the NixOS manual:
   $ nix-build nixos/release.nix -A manual44.6. Importing Modules
  Sometimes NixOS modules need to be used in configuration but exist outside of
  Nixpkgs. These modules can be imported:
 
{ config, lib, pkgs, ... }:

{
  imports =
    [ # Use a locally-available module definition in
      # ./example-module/default.nix
        ./example-module
    ];

  services.exampleModule.enable = true;
}

  The environment variable NIXOS_EXTRA_MODULE_PATH is an
  absolute path to a NixOS module that is included alongside the Nixpkgs NixOS
  modules. Like any NixOS module, this module can import additional modules:
 
# ./module-list/default.nix
[
  ./example-module1
  ./example-module2
]

# ./extra-module/default.nix
{ imports = import ./module-list.nix; }

# NIXOS_EXTRA_MODULE_PATH=/absolute/path/to/extra-module
{ config, lib, pkgs, ... }:

{
  # No `imports` needed

  services.exampleModule1.enable = true;
}
44.7. Replace Modules
  Modules that are imported can also be disabled. The option declarations,
  config implementation and the imports of a disabled module will be ignored, allowing another
  to take it's place. This can be used to import a set of modules from another
  channel while keeping the rest of the system on a stable release.
 
disabledModules is a top level attribute like
  imports, options and
  config. It contains a list of modules that will be
  disabled. This can either be the full path to the module or a string with the
  filename relative to the modules path (eg. <nixpkgs/nixos/modules> for
  nixos).
 
  This example will replace the existing postgresql module with the version
  defined in the nixos-unstable channel while keeping the rest of the modules
  and packages from the original nixos channel. This only overrides the module
  definition, this won't use postgresql from nixos-unstable unless explicitly
  configured to do so.
 
{ config, lib, pkgs, ... }:

{
  disabledModules = [ ""services/databases/postgresql.nix"" ];

  imports =
    [ # Use postgresql service from nixos-unstable channel.
      # sudo nix-channel --add https://nixos.org/channels/nixos-unstable nixos-unstable
      <nixos-unstable/nixos/modules/services/databases/postgresql.nix>
    ];

  services.postgresql.enable = true;
}

  This example shows how to define a custom module as a replacement for an
  existing module. Importing this module will disable the original module
  without having to know it's implementation details.
 
{ config, lib, pkgs, ... }:

with lib;

let
  cfg = config.programs.man;
in

{
  disabledModules = [ ""services/programs/man.nix"" ];

  options = {
    programs.man.enable = mkOption {
      type = types.bool;
      default = true;
      description = ""Whether to enable manual pages."";
    };
  };

  config = mkIf cfg.enabled {
    warnings = [ ""disabled manpages for production deployments."" ];
  };
}
Chapter 45. Building Specific Parts of NixOS
  With the command nix-build, you can build specific parts
  of your NixOS configuration. This is done as follows:

$ cd /path/to/nixpkgs/nixos
$ nix-build -A config.option
  where option is a NixOS option with type
  “derivation” (i.e. something that can be built). Attributes of interest
  include:
  
system.build.toplevel

      The top-level option that builds the entire NixOS system. Everything else
      in your configuration is indirectly pulled in by this option. This is
      what nixos-rebuild builds and what
      /run/current-system points to afterwards.
     
      A shortcut to build this is:

$ nix-build -A system

system.build.manual.manualHTML

      The NixOS manual.
     
system.build.etc

      A tree of symlinks that form the static parts of
      /etc.
     
system.build.initialRamdisk
    , 
system.build.kernel

      The initial ramdisk and kernel of the system. This allows a quick way to
      test whether the kernel and the initial ramdisk boot correctly, by using
      QEMU’s -kernel and -initrd options:

$ nix-build -A config.system.build.initialRamdisk -o initrd
$ nix-build -A config.system.build.kernel -o kernel
$ qemu-system-x86_64 -kernel ./kernel/bzImage -initrd ./initrd/initrd -hda /dev/null


system.build.nixos-rebuild
    , 
system.build.nixos-install
    , 
system.build.nixos-generate-config

      These build the corresponding NixOS commands.
     
systemd.units.unit-name.unit

      This builds the unit with the specified name. Note that since unit names
      contain dots (e.g. httpd.service), you need to put
      them between quotes, like this:

$ nix-build -A 'config.systemd.units.""httpd.service"".unit'

      You can also test individual units, without rebuilding the whole system,
      by putting them in /run/systemd/system:

$ cp $(nix-build -A 'config.systemd.units.""httpd.service"".unit')/httpd.service \
    /run/systemd/system/tmp-httpd.service
# systemctl daemon-reload
# systemctl start tmp-httpd.service

      Note that the unit must not have the same name as any unit in
      /etc/systemd/system since those take precedence over
      /run/systemd/system. That’s why the unit is
      installed as tmp-httpd.service here.
     
Chapter 46. Writing NixOS DocumentationTable of Contents46.1. Building the Manual46.2. Editing DocBook XML46.3. Creating a Topic46.4. Adding a Topic to the Book
  As NixOS grows, so too does the need for a catalogue and explanation of its
  extensive functionality. Collecting pertinent information from disparate
  sources and presenting it in an accessible style would be a worthy
  contribution to the project.
 46.1. Building the Manual
   The DocBook sources of the NixOS Manual are in the
   nixos/doc/manual
   subdirectory of the Nixpkgs repository.
  
   You can quickly validate your edits with make:
  
  $ cd /path/to/nixpkgs/nixos/doc/manual
  $ make

   Once you are done making modifications to the manual, it's important to
   build it before committing. You can do that as follows:
  nix-build nixos/release.nix -A manual.x86_64-linux
   When this command successfully finishes, it will tell you where the manual
   got generated. The HTML will be accessible through the
   result symlink at
   ./result/share/doc/nixos/index.html.
  46.2. Editing DocBook XML
   For general information on how to write in DocBook, see
    DocBook
   5: The Definitive Guide.
  
   Emacs nXML Mode is very helpful for editing DocBook XML because it validates
   the document as you write, and precisely locates errors. To use it, see
   Section 23.3.3, “Editing DocBook 5 XML Documents”.
  
Pandoc can generate DocBook XML
   from a multitude of formats, which makes a good starting point.
   Example 46.1. Pandoc invocation to convert GitHub-Flavoured MarkDown to DocBook 5 XMLpandoc -f markdown_github -t docbook5 docs.md -o my-section.md
   Pandoc can also quickly convert a single section.xml to
   HTML, which is helpful when drafting.
  
   Sometimes writing valid DocBook is simply too difficult. In this case,
   submit your documentation updates in a
   GitHub
   Issue and someone will handle the conversion to XML for you.
  46.3. Creating a Topic
   You can use an existing topic as a basis for the new topic or create a topic
   from scratch.
  
   Keep the following guidelines in mind when you create and add a topic:
   
      The NixOS
      book
      element is in nixos/doc/manual/manual.xml. It
      includes several
      parts
      which are in subdirectories.
     
      Store the topic file in the same directory as the part to
      which it belongs. If your topic is about configuring a NixOS module, then
      the XML file can be stored alongside the module definition
      nix file.
     
      If you include multiple words in the file name, separate the words with a
      dash. For example: ipv6-config.xml.
     
      Make sure that the xml:id value is unique. You can use
      abbreviations if the ID is too long. For example:
      nixos-config.
     
      Determine whether your topic is a chapter or a section. If you are
      unsure, open an existing topic file and check whether the main element is
      chapter or section.
     
46.4. Adding a Topic to the Book
   Open the parent XML file and add an xi:include element to
   the list of chapters with the file name of the topic that you created. If
   you created a section, you add the file to the chapter
   file. If you created a chapter, you add the file to the
   part file.
  
   If the topic is about configuring a NixOS module, it can be automatically
   included in the manual by using the meta.doc attribute.
   See Section 44.5, “Meta Attributes” for an explanation.
  Chapter 47. Building Your Own NixOS CD
  Building a NixOS CD is as easy as configuring your own computer. The idea is
  to use another module which will replace your
  configuration.nix to configure the system that would be
  installed on the CD.
 
  Default CD/DVD configurations are available inside
  nixos/modules/installer/cd-dvd.

$ git clone https://github.com/NixOS/nixpkgs.git
$ cd nixpkgs/nixos
$ nix-build -A config.system.build.isoImage -I nixos-config=modules/installer/cd-dvd/installation-cd-minimal.nix default.nix

  Before burning your CD/DVD, you can check the content of the image by
  mounting anywhere like suggested by the following command:

# mount -o loop -t iso9660 ./result/iso/cd.iso /mnt/iso
Chapter 48. NixOS TestsTable of Contents48.1. Writing Tests48.2. Running Tests48.3. Running Tests interactively
  When you add some feature to NixOS, you should write a test for it. NixOS
  tests are kept in the directory
  nixos/tests,
  and are executed (using Nix) by a testing framework that automatically starts
  one or more virtual machines containing the NixOS system(s) required for the
  test.
 48.1. Writing Tests
  A NixOS test is a Nix expression that has the following structure:

import ./make-test-python.nix {

  # Either the configuration of a single machine:
  machine =
    { config, pkgs, ... }:
    { configuration…
    };

  # Or a set of machines:
  nodes =
    { machine1 =
        { config, pkgs, ... }: { … };
      machine2 =
        { config, pkgs, ... }: { … };
      …
    };

  testScript =
    ''
      Python code…
    '';
}

  The attribute testScript is a bit of Python code that
  executes the test (described below). During the test, it will start one or
  more virtual machines, the configuration of which is described by the
  attribute machine (if you need only one machine in your
  test) or by the attribute nodes (if you need multiple
  machines). For instance,
  login.nix
  only needs a single machine to test whether users can log in on the virtual
  console, whether device ownership is correctly maintained when switching
  between consoles, and so on. On the other hand,
  nfs.nix,
  which tests NFS client and server functionality in the Linux kernel
  (including whether locks are maintained across server crashes), requires
  three machines: a server and two clients.
 
  There are a few special NixOS configuration options for test VMs:

  
virtualisation.memorySize

      The memory of the VM in megabytes.
     
virtualisation.vlans

      The virtual networks to which the VM is connected. See
      nat.nix
      for an example.
     
virtualisation.writableStore

      By default, the Nix store in the VM is not writable. If you enable this
      option, a writable union file system is mounted on top of the Nix store
      to make it appear writable. This is necessary for tests that run Nix
      operations that modify the store.
     
  For more options, see the module
  qemu-vm.nix.
 
  The test script is a sequence of Python statements that perform various
  actions, such as starting VMs, executing commands in the VMs, and so on. Each
  virtual machine is represented as an object stored in the variable
  name if this is also the
  identifier of the machine in the declarative config.
  If you didn't specify multiple machines using the nodes
  attribute, it is just machine.
  The following example starts the machine, waits until it has finished booting,
  then executes a command and checks that the output is more-or-less correct:

machine.start()
machine.wait_for_unit(""default.target"")
if not ""Linux"" in machine.succeed(""uname""):
  raise Exception(""Wrong OS"")

  The first line is actually unnecessary; machines are implicitly started when
  you first execute an action on them (such as wait_for_unit
  or succeed). If you have multiple machines, you can speed
  up the test by starting them in parallel:

start_all()


  The following methods are available on machine objects:
  
start

      Start the virtual machine. This method is asynchronous — it does not
      wait for the machine to finish booting.
     
shutdown

      Shut down the machine, waiting for the VM to exit.
     
crash

      Simulate a sudden power failure, by telling the VM to exit immediately.
     
block

      Simulate unplugging the Ethernet cable that connects the machine to the
      other machines.
     
unblock

      Undo the effect of block.
     
screenshot

      Take a picture of the display of the virtual machine, in PNG format. The
      screenshot is linked from the HTML log.
     
get_screen_text

      Return a textual representation of what is currently visible on the
      machine's screen using optical character recognition.
     Note: 
       This requires passing enableOCR to the test attribute
       set.
      
send_monitor_command

      Send a command to the QEMU monitor. This is rarely used, but allows doing
      stuff such as attaching virtual USB disks to a running machine.
     
send_keys

      Simulate pressing keys on the virtual keyboard, e.g.,
      send_keys(""ctrl-alt-delete"").
     
send_chars

      Simulate typing a sequence of characters on the virtual keyboard, e.g.,
      send_keys(""foobar\n"") will type the string
      foobar followed by the Enter key.
     
execute

      Execute a shell command, returning a list
      (status,
      stdout).
     
succeed

      Execute a shell command, raising an exception if the exit status is not
      zero, otherwise returning the standard output.
     
fail

      Like succeed, but raising an exception if the
      command returns a zero status.
     
wait_until_succeeds

      Repeat a shell command with 1-second intervals until it succeeds.
     
wait_until_fails

      Repeat a shell command with 1-second intervals until it fails.
     
wait_for_unit

      Wait until the specified systemd unit has reached the “active” state.
     
wait_for_file

      Wait until the specified file exists.
     
wait_for_open_port

      Wait until a process is listening on the given TCP port (on
      localhost, at least).
     
wait_for_closed_port

      Wait until nobody is listening on the given TCP port.
     
wait_for_x

      Wait until the X11 server is accepting connections.
     
wait_for_text

      Wait until the supplied regular expressions matches the textual contents
      of the screen by using optical character recognition (see
      get_screen_text).
     Note: 
       This requires passing enableOCR to the test attribute
       set.
      
wait_for_window

      Wait until an X11 window has appeared whose name matches the given
      regular expression, e.g., wait_for_window(""Terminal"").
     
copy_file_from_host

      Copies a file from host to machine, e.g.,
      copy_file_from_host(""myfile"", ""/etc/my/important/file"").
     
      The first argument is the file on the host. The file needs to be
      accessible while building the nix derivation. The second argument is the
      location of the file on the machine.
     
systemctl

      Runs systemctl commands with optional support for
      systemctl --user


machine.systemctl(""list-jobs --no-pager"") # runs `systemctl list-jobs --no-pager`
machine.systemctl(""list-jobs --no-pager"", ""any-user"") # spawns a shell for `any-user` and runs `systemctl --user list-jobs --no-pager`



  To test user units declared by systemd.user.services the
  optional user argument can be used:

machine.start()
machine.wait_for_x()
machine.wait_for_unit(""xautolock.service"", ""x-session-user"")

  This applies to systemctl, get_unit_info,
  wait_for_unit, start_job and
  stop_job.
 
  For faster dev cycles it's also possible to disable the code-linters (this shouldn't
  be commited though):

import ./make-test-python.nix {
  skipLint = true;
  machine =
    { config, pkgs, ... }:
    { configuration…
    };

  testScript =
    ''
      Python code…
    '';
}

48.2. Running Tests
  You can run tests using nix-build. For example, to run the
  test
  login.nix,
  you just do:

$ nix-build '<nixpkgs/nixos/tests/login.nix>'

  or, if you don’t want to rely on NIX_PATH:

$ cd /my/nixpkgs/nixos/tests
$ nix-build login.nix
…
running the VM test script
machine: QEMU running (pid 8841)
…
6 out of 6 tests succeeded

  After building/downloading all required dependencies, this will perform a
  build that starts a QEMU/KVM virtual machine containing a NixOS system. The
  virtual machine mounts the Nix store of the host; this makes VM creation very
  fast, as no disk image needs to be created. Afterwards, you can view a
  pretty-printed log of the test:

$ firefox result/log.html

48.3. Running Tests interactively
  The test itself can be run interactively. This is particularly useful when
  developing or debugging a test:

$ nix-build nixos/tests/login.nix -A driver
$ ./result/bin/nixos-test-driver
starting VDE switch for network 1
>

  You can then take any Python statement, e.g.

> start_all()
> test_script()
> machine.succeed(""touch /tmp/foo"")
> print(machine.succeed(""pwd"")) # Show stdout of command

  The function test_script executes the entire test script
  and drops you back into the test driver command line upon its completion.
  This allows you to inspect the state of the VMs after the test (e.g. to debug
  the test script).
 
  To just start and experiment with the VMs, run:

$ nix-build nixos/tests/login.nix -A driver
$ ./result/bin/nixos-run-vms

  The script nixos-run-vms starts the virtual machines
  defined by test.
 
  The machine state is kept across VM restarts in
  /tmp/vm-state-machinename.
 Chapter 49. Testing the Installer
  Building, burning, and booting from an installation CD is rather tedious, so
  here is a quick way to see if the installer works properly:

# mount -t tmpfs none /mnt
# nixos-generate-config --root /mnt
$ nix-build '<nixpkgs/nixos>' -A config.system.build.nixos-install
# ./result/bin/nixos-install
  To start a login shell in the new NixOS installation in
  /mnt:

$ nix-build '<nixpkgs/nixos>' -A config.system.build.nixos-enter
# ./result/bin/nixos-enter

Chapter 50. ReleasesTable of Contents50.1. Release process50.2. Release Management Team50.3. Release schedule50.1. Release process
   Going through an example of releasing NixOS 17.09:
  50.1.1. One month before the beta
      Send an email to the nix-devel mailinglist as a warning about upcoming
      beta ""feature freeze"" in a month.
     
      Discuss with Eelco Dolstra and the community (via IRC, ML) about what
      will reach the deadline. Any issue or Pull Request targeting the release
      should be included in the release milestone.
     50.1.2. At beta release time
Create
      an issue for tracking Zero Hydra Failures progress. ZHF is an effort to
      get build failures down to zero.

git tag -a -s -m ""Release 17.09-beta"" 17.09-beta
      && git push origin 17.09-beta

      From the master branch run git checkout -b
      release-17.09.
     

      Make sure a channel is created at https://nixos.org/channels/. 


      Bump the system.defaultChannel attribute in
      nixos/modules/misc/version.nix 


      Update versionSuffix in
      nixos/release.nix, use git log
      --format=%an|wc -l to get the commit count
     
echo -n ""18.03"" > .version on master.
     

      Pick a new name for the unstable branch. 

      Create a new release notes file for the upcoming release + 1, in this
      case rl-1803.xml.
     
      Create two Hydra jobsets: release-17.09 and release-17.09-small with
      stableBranch set to false.
     
      Remove attributes that we know we will not be able to support,
      especially if there is a stable alternative. E.g. Check that our
      Linux kernels'
      
      projected end-of-life are after our release projected
      end-of-life
     
      Edit changelog at
      nixos/doc/manual/release-notes/rl-1709.xml (double
      check desktop versions are noted)
     
        Get all new NixOS modules git diff
        release-17.03..release-17.09 nixos/modules/module-list.nix|grep
        ^+

        Note systemd, kernel, glibc and Nix upgrades.
       50.1.3. During Beta
      Monitor the master branch for bugfixes and minor updates and cherry-pick
      them to the release branch.
     50.1.4. Before the final release
      Re-check that the release notes are complete.
     
      Release Nix (currently only Eelco Dolstra can do that).
      
      Make sure fallback is updated. 


      Update README.md with new stable NixOS version information. 

      Change stableBranch to true in Hydra and wait for
      the channel to update.
     50.1.5. At final release time
git tag -s -a -m ""Release 15.09"" 15.09

      Update ""Chapter 4. Upgrading NixOS"" section of the manual to match
      new stable release version.
     
      Update the
      NIXOS_SERIES
      in the
      nixos-homepage
      repository.
     
      Get number of commits for the release: git log
      release-14.04..release-14.12 --format=%an|wc -l

      Commits by contributor: git log release-14.04..release-14.12
      --format=%an|sort|uniq -c|sort -rn

      Create a new topic on the
      Discourse instance to announce the release with the above information.
      Best to check how previous email was formulated to see what needs to be
      included.
     50.2. Release Management Team
   For each release there are two release managers. After each release the
   release manager having managed two releases steps down and the release
   management team of the last release appoints a new release manager.
  
   This makes sure a release management team always consists of one release
   manager who already has managed one release and one release manager being
   introduced to their role, making it easier to pass on knowledge and
   experience.
  
   Release managers for the current NixOS release are tracked by GitHub team
   @NixOS/nixos-release-managers.
  
   A release manager's role and responsibilities are:
  manage the release processstart discussions about features and changes for a given releasecreate a roadmaprelease in cooperation with Eelco Dolstradecide which bug fixes, features, etc... get backported after a release50.3. Release schedule
            Date
          
            Event
          
            2016-07-25
          
            Send email to nix-dev about upcoming branch-off
          
            2016-09-01
          release-16.09 branch and corresponding jobsets are created,
            change freeze
          
            2016-09-30
          
            NixOS 16.09 released
          Appendix A. Configuration Options →





The project

Channel Status
Packages search
Options search
Security



Get in Touch

Forum
Chat
Commercial support



Contribute

Contributing Guide
Donate



Stay up to date

Announcements
Newsletter






NixOS


            Copyright © 2020 NixOS
          


              CC-BY-SA-4.0
            




Connect with us

Twitter
Youtube
GitHub




 



",,"# nixos-rebuild

> Reconfigure a NixOS machine.
> More information: <https://nixos.org/nixos/manual/#sec-changing-config>.

- Build and switch to the new configuration, making it the boot default:

`sudo nixos-rebuild switch`

- Build and switch to the new configuration, making it the boot default and naming the boot entry:

`sudo nixos-rebuild switch -p {{name}}`

- Build and switch to the new configuration, making it the boot default and installing updates:

`sudo nixos-rebuild switch --upgrade`

- Rollback changes to the configuration, switching to the previous generation:

`sudo nixos-rebuild switch --rollback`

- Build the new configuration and make it the boot default without switching to it:

`sudo nixos-rebuild boot`

- Build and activate the new configuration, but don't make a boot entry (for testing purposes):

`sudo nixos-rebuild test`

- Build the configuration and open it in a virtual machine:

`sudo nixos-rebuild build-vm`
"
acpi,,,,"# acpi

> Shows battery status or thermal information.

- Show battery information:

`acpi`

- Show thermal information:

`acpi -t`

- Show cooling device information:

`acpi -c`

- Show thermal information in Fahrenheit:

`acpi -tf`

- Show all information:

`acpi -V`
"
whiptail,,,,"# whiptail

> Display text-based dialog boxes from shell scripts.

- Display a simple message:

`whiptail --title ""{{title}}"" --msgbox ""{{message}}"" {{height_in_chars}} {{width_in_chars}}`

- Display a boolean choice, returning the result through the exit code:

`whiptail --title ""{{title}}"" --yesno ""{{message}}"" {{height_in_chars}} {{width_in_chars}}`

- Customise the text on the yes / no buttons:

`whiptail --title ""{{title}}"" --yes-button ""{{text}}"" --no-button ""{{text}}"" --yesno ""{{message}}"" {{height_in_chars}} {{width_in_chars}}`

- Display a text input box:

`{{result_variable_name}}=""$(whiptail --title ""{{title}}"" --inputbox ""{{message}}"" {{height_in_chars}} {{width_in_chars}} {{default_text}} 3>&1 1>&2 2>&3)""`

- Display a password input box:

`{{result_variable_name}}=""$(whiptail --title ""{{title}}"" --passwordbox ""{{message}}"" {{height_in_chars}} {{width_in_chars}} 3>&1 1>&2 2>&3)""`

- Display a multiple-choice menu:

`{{result_variable_name}}=$(whiptail --title ""{{title}}"" --menu ""{{message}}"" {{height_in_chars}} {{width_in_chars}} {{menu_display_height}} ""{{value_1}}"" ""{{display_text_1}}"" ""{{value_n}}"" ""{{display_text_n}}"" ..... 3>&1 1>&2 2>&3)`
"
runcon,,,,"# runcon

> Run a program in a different SELinux security context.
> With neither context nor command, print the current security context.

- Determine the current domain:

`runcon`

- Specify the domain to run a command in:

`runcon -t {{domain}}_t {{command}}`

- Specify the context role to run a command with:

`runcon -r {{role}}_r {{command}}`

- Specify the full context to run a command with:

`runcon {{user}}_u:{{role}}_r:{{domain}}_t {{command}}`
"
systemd-analyze,,,,"# systemd-analyze

> Show timing details about the boot process of units (services, mount points, devices, sockets).

- List time of each unit to start up:

`systemd-analyze blame`

- Print a tree of the time critical chain of units:

`systemd-analyze critical-chain`
"
gedit,,,,"# gedit

> Text editor of the GNOME Desktop project.

- Open a text file:

`gedit {{path/to/file}}`

- Open multiple text files:

`gedit {{file1 file2 ...}}`

- Open a text file with a specific encoding:

`gedit --encoding={{UTF-8}} {{path/to/file}}`

- Display a list of supported encodings:

`gedit --list-encodings`
"
zramctl,,,,"# zramctl

> Setup and control zram devices.
> Use `mkfs` or `mkswap` to format zram devices to partitions.

- Check if zram is enabled:

`lsmod | grep -i zram`

- Enable zram with a dynamic number of devices (use `zramctl` to configure devices further):

`sudo modprobe zram`

- Enable zram with exactly 2 devices:

`sudo modprobe zram num_devices={{2}}`

- Find and initialise the next free zram device to a 2GB virtual drive using LZ4 compression:

`sudo zramctl --find --size {{2GB}} --algorithm {{lz4}}`

- List currently initialised devices:

`zramctl`
"
repquota,,,"
REPQUOTA(8)		  BSD System Manager's Manual		   REPQUOTA(8)

NAME
     repquota -- summarize quotas for a file system

SYNOPSIS
     repquota [-g] [-u] [-v] filesystem ...
     repquota [-g] [-u] [-v] -a

DESCRIPTION
     Repquota prints a summary of the disk usage and quotas for the specified
     file systems.

     Available options:

     -a      Print the quotas of all the filesystems configured with a quota
	     mount option file at its root.

     -g      Print only group quotas (the default is to print both group and
	     user quotas if they exist).

     -u      Print only user quotas (the default is to print both group and
	     user quotas if they exist).

     -v      Print a header line before printing each filesystem quotas.

     For each user or group, the current number of files and amount of space
     (in kilobytes) is printed, along with any quotas created with edquota(8).

     Only members of the operator group or the super-user may use this com-
     mand.

FILES
     Each of the following quota files is located at the root of the mounted
     filesystem.  The mount option files are empty files whose existence indi-
     cates that quotas are to be enabled for that filesystem.

     .quota.user       data file containing user quotas
     .quota.group      data file containing group quotas
     .quota.ops.user   mount option file used to enable user quotas
     .quota.ops.group  mount option file used to enable group quotas

SEE ALSO
     quota(1), quotactl(2), edquota(8), quotacheck(8), quotaon(8)

DIAGNOSTICS
     Various messages about inaccessible files; self-explanatory.

HISTORY
     The repquota command appeared in 4.2BSD.

4.2 Berkeley Distribution	March 28, 2002	     4.2 Berkeley Distribution
","# repquota

> Display a summary of existing file quotas for a filesystem.

- Report stats for all quotas in use:

`sudo repquota -all`

- Report quota stats for all users, even those who aren't using any of their quota:

`sudo repquota -v {{filesystem}}`

- Report on quotas for users only:

`repquota --user {{filesystem}}`

- Report on quotas for groups only:

`sudo repquota --group {{filesystem}}`

- Report on used quota and limits in a human-readable format:

`sudo repquota --human-readable {{filesystem}}`

- Report on all quotas for users and groups in a human-readable format:

`sudo repquota -augs`
"
aspell,,,,"# aspell

> Interactive spell checker.

- Spell check a single file:

`aspell check {{path/to/file}}`

- List misspelled words from standard input:

`cat {{file}} | aspell list`

- Show available dictionary languages:

`aspell dicts`

- Run aspell with different language (takes two letter ISO 639 language code):

`aspell --lang={{cs}}`

- List misspelled words from standard input and ignore words from personal word list:

`cat {{file}} | aspell --personal={{personal-word-list.pws}} {{list}}`
"
xfce4-screenshooter,,,,"# xfce4-screenshooter

> The XFCE4 screenshot tool.

- Launch the screenshooter GUI:

`xfce4-screenshooter`

- Take a screenshot of the entire screen and launch the GUI to ask how to proceed:

`xfce4-screenshooter --fullscreen`

- Take a screenshot of the entire screen and save it in the specified directory:

`xfce4-screenshooter --fullscreen --save {{path/to/directory}}`

- Wait some time before taking the screenshot:

`xfce4-screenshooter --delay {{seconds}}`

- Take a screenshot of a region of the screen (select using the mouse):

`xfce4-screenshooter --region`

- Take a screenshot of the active window, and copy it to the clipboard:

`xfce4-screenshooter --window --clipboard`

- Take a screenshot of the active window, and open it with a chosen program:

`xfce4-screenshooter --window --open {{gimp}}`
"
groupadd,,,,"# groupadd

> Add user groups to the system.

- Create a new Linux group:

`groupadd {{group_name}}`

- Create new group with a specific groupid:

`groupadd {{group_name}} -g {{group_id}}`
"
lrunzip,,,,"# lrunzip

> A large file decompression program.
> See also `lrzip`, `lrztar`, `lrzuntar`.

- Decompress a file:

`lrunzip {{filename.lrz}}`

- Decompress a file using a specific number of processor threads:

`lrunzip -p {{8}} {{filename.lrz}}`

- Decompress a file and silently overwrite files if they exist:

`lrunzip -f {{filename.lrz}}`

- Keep broken or damaged files instead of deleting them when decompressing:

`lrunzip -K {{filename.lrz}}`

- Specify output file name and/or path:

`lrunzip -o {{outfilename}} {{filename.lrz}}`
"
pivpn,http://www.pivpn.io/,"

PIVPN: Simplest way to setup a VPN











The PiVPN Project

						Secure connectivity for the masses.
						Low cost, high security.
					



Install
About
Technical Information
Contribute!






Github




Reddit













PiVPN

								The simplest way to setup and manage a VPN,
								designed for Raspberry Pi.
							



::: INSTALLATION :::

curl -L https://install.pivpn.io | bash

::: Test (unstable) Branch :::

curl -L https://test.pivpn.io | TESTING= bash



SIMPLE ::: Yes, that's it!  It is *almost* that simple.
							To elaborate a little more, you will want to
							install Raspbian
							on a Raspberry pi, we strongly recommend using the latest
							Raspbian Lite
							image but the normal Raspbian image will work as well,
							preferably enable ssh access and then begin.
							After install, you may need to open a port on your router.
							There is a (now slightly outdated) guided walkthrough of the install available
							here.
							More information is also available on the PiVPN GitHub


FLEXIBLE ::: 
							Think if you can figure out how to do this yourself you'll have
							more options?
							
							This installer is no slouch! It'll allow you to customize your
							VPN port, key encryption strength, client DNS server, and more!
							Even if you are an expert, the options presented within are a
							perfect foundation for any openvpn server installation.
							Although this is geared toward running on a $35 Raspberry Pi,
							the installer will work just as well on an Ubuntu or Debian server.
						

MANAGEABLE ::: 
							Installation is finished, now what do you do? No worries,
							we've got you covered!
							
							Provided free of charge on your server is a new 'pivpn' command.
							Simply run pivpn and you are presented with all of the available options.
							Easily add client profiles (OVPN), revoke them, list the ones you created, etc.
							There is also an option to completely remove everything
							the installer did with the 'pivpn uninstall' command.
							So you can experiment with pivpn with no fear of irreversible
							changes to your server.
						

SECURE ::: 
						Even though this installer makes everything so trivial,
						it doesn't mean it gives you trivial security settings.
						
						Everything has been upgraded right out of the box beyond the default
						settings to harden the security of the server and client.
						Starting with offering you the ability to enable unattended-upgrades
						which will automatically patch your server with security updates.
						Next, the server configuration will only use the latest TLS protocol.
						Both the data and control channels use upgraded AES and SHA256 encryption and hash algorithms.
						Options are pre-configured to verify your server certificate to battle MITM attack vectors.
						All this and more are configured out of the box by the pivpn installer.
						This is a detailed level of hardening you'll have a difficult time finding elsewhere.
						





About
Origin

							There are quite a few various scripts that in some way install openvpn for you.
							This project, in particular, was started by 0-kaladin and began
							from the code by StarshipEngineer
							to help to install OpenVPN on a raspberry pi as simple as it can be.
							This is still the striving goal today (see Why This Is Important just below) however,
							even with the solid foundation provided by StarshipEngineer,
							0-kaladin came across the Pi-Hole
							project and saw just how easy the installation can be! He took the
							scripts from StarshipEngineer, the framework, and functions from
							the pi-hole project, and merged them into what you now see as PiVPN.
							Then added a ton of functionality, failsafe checks, hardened security, etc...
							
							Currently, community-maintained this should be bar none, the simplest
							and fastest way to set up an OpenVPN server on your raspberry pi
							that leaves you with an extremely secure configuration.
							
							We've made a few additions and tweaks as well to help make managing
							the OpenVPN server even easier after install.
							
							Everything can be managed by using a new 'pivpn' command on your system,
							this includes adding new client certs, revoking them,
							and completely uninstalling the pivpn.
							
							There is a lot more that can be added and we hope the suggestions
							and improvements can be contributed by the community at large.
						
Why This Is Important

							There are a few driving factors that make this very important to us,
							and we believe, the community at large. In this post-Snowden era
							where our privacy and security are infringed upon,
							not only by bad actors but potentially by those whom we thought
							should be protecting these very ideals, normal citizens must take
							matters into their own hands. The trouble with this, many times,
							is that if you are not very technical you may not know how to begin.
							I believe the EFF has helped lower a barrier of encrypted sites with their
							
								Let's Encrypt
							
							initiative.
							Allowing many to now have their sites on encrypted channels.
							To us, the next logical step here is also ensuring the pipe you are
							using is as secure as possible. This not only could include unknown
							networks at airports, Starbucks, generic public hot-spots;
							but also your ISP. To that end, We'd like to make sure these
							scripts also work on a Debian image from an Amazon free tier server.
							It is important that more and more people, have access to protecting
							their traffic online. Its clear others won't hand you this protection.
							PiVPN tries to make it easier for you to grab.
							
							Enjoy!
						





Technical Information & Features

Supports OpenVPN 2.4
Supports WireGuard
Elliptic curve encryption keys up to 512 bit
Integrates with Bitwarden
iOS keychain support
Supports multiple DNS providers
Supports Custom DNS Servers
Custom Search Domains (OpenVPN Only)
Runs with Pi-Hole®
Doesn't need to be a raspberry pi, It runs on any Debian VPS Server
Supports unattended installation for automated deployments

						For more information on PiVPN be sure to check the
						PiVPN Wiki

						It could also be helpful to browse closed Issues with the
						
							Information
						
						or
						
							Question
						
						tag.
						


Blogs / Video's About PiVPN

								The links below showcase some good write-ups and tutorials that use PiVPN.
								Some other decent information may also be contained regarding VPNs and security in general.
								If you find you have more questions on this area then read and/or watch some of them below!
							
Articles / Blogs



										Maintainer post about where to properly place a VPN
									


										Create your own VPN server with the Raspberry Pi
									



										PiVPN - Create your own VPN for your home network
									



										PiVPN, Easiest & Quickest Setup of OpenVPN
									


Video Guides



										How to Setup PiVPN on the Raspberry Pi Tutorial
									



										Raspberry Pi - OpenVPN Setup via PiVPN
									


FAQs & Support

									There are
									FAQs
									and a Wiki
									available on the Github page.
									
									Make sure you check the
									
										PiVPN Issues
									
									section and especially the closed ones as your question may
									already be answered!
									
									We also have our subreddit for support and discussion at
									
										r/PiVPN
									







Contribute!

							Contributions are Welcome and Encouraged!
						

							The PiVPN installation code is available on
							github.
							
							Plase Make sure you read the
							
								Contributors Guide
							

							After reading the
							
								Contributors Guide
							,
							checkout for any issues
							especially with the 'help wanted' label.
							








© The PiVPN Project. All rights reserved.













",,"# pivpn

> Easy security-hardened OpenVPN setup and manager.
> Originally designed for the Raspberry Pi, but works on other Linux devices too.
> More information: <http://www.pivpn.io/>.

- Add a new client device:

`sudo pivpn add`

- List all client devices:

`sudo pivpn list`

- List currently connected devices and their statistics:

`sudo pivpn clients`

- Revoke a previously authenticated device:

`sudo pivpn revoke`

- Uninstall PiVPN:

`sudo pivpn uninstall`
"
sa,,,"
SA(8)			  BSD System Manager's Manual			 SA(8)

NAME
     sa -- print system accounting statistics

SYNOPSIS
     sa [-abcdDfijkKlmnqrstu] [-P file] [-U file] [-v cutoff] [file ...]

DESCRIPTION
     The sa utility reports on, cleans up, and generally maintains system
     accounting files.

     The sa utility is able to condense the information in /var/account/acct
     into the summary files /var/account/savacct and /var/account/usracct,
     which contain system statistics according to command name and login id,
     respectively.  This condensation is desirable because on a large system,
     /var/account/acct can grow by hundreds of blocks per day.	The summary
     files are normally read before the accounting file, so that reports
     include all available information.

     If file names are supplied, they are read instead of /var/account/acct.
     After each file is read, if the summary files are being updated, an
     updated summary will be saved to disk.  Only one report is printed, after
     the last file is processed.

     The labels used in the output indicate the following, except where other-
     wise specified by individual options:

     avio   Average number of I/O operations per execution

     cp     Sum of user and system time, in minutes

     cpu    Same as cp

     k	    CPU-time averaged core usage, in 1k units

     k*sec  CPU storage integral, in 1k-core seconds

     re     Real time, in minutes

     s	    System time, in minutes

     tio    Total number of I/O operations

     u	    User time, in minutes

     The options to sa are:

     -a      List all command names, including those containing unprintable
	     characters and those used only once.  By default, sa places all
	     names containing unprintable characters and those used only once
	     under the name ``***other''.

     -b      If printing command statistics, sort output by the sum of user
	     and system time divided by number of calls.

     -c      In addition to the number of calls and the user, system and real
	     times for each command, print their percentage of the total over
	     all commands.

     -d      If printing command statistics, sort by the average number of
	     disk I/O operations.  If printing user statistics, print the
	     average number of disk I/O operations per user.

     -D      If printing command statistics, sort and print by the total num-
	     ber of disk I/O operations.

     -f      Force no interactive threshold comparison with the -v option.

     -i      Do not read in the summary files.

     -j      Instead of the total minutes per category, give seconds per call.

     -k      If printing command statistics, sort by the cpu-time average mem-
	     ory usage.  If printing user statistics, print the cpu-time aver-
	     age memory usage.

     -K      If printing command statistics, print and sort by the cpu-storage
	     integral.

     -l      Separate system and user time; normally they are combined.

     -m      Print per-user statistics rather than per-command statistics.

     -n      Sort by number of calls.

     -P file
	     Use the specified file for accessing the per-command accounting
	     summary database, instead of the default /var/account/savacct.

     -q      Create no output other than error messages.

     -r      Reverse order of sort.

     -s      Truncate the accounting files when done and merge their data into
	     the summary files.

     -t      For each command, report the ratio of real time to the sum of
	     user and system cpu times.  If the cpu time is too small to
	     report, ``*ignore*'' appears in this field.

     -U file
	     Use the specified file for accessing the per-user accounting sum-
	     mary database, instead of the default /var/account/usracct.

     -u      Superseding all other flags, for each entry in the accounting
	     file, print the user ID, total seconds of cpu usage, total memory
	     usage, number of I/O operations performed, and command name.

     -v cutoff
	     For each command used cutoff times or fewer, print the command
	     name and await a reply from the terminal.	If the reply begins
	     with ``y'', add the command to the category ``**junk**''.	This
	     flag is used to strip garbage from the report.

     By default, per-command statistics will be printed.  The number of calls,
     the total elapsed time in minutes, total cpu and user time in minutes,
     average number of I/O operations, and CPU-time averaged core usage will
     be printed.  If the -m option is specified, per-user statistics will be
     printed, including the user name, the number of commands invoked, total
     cpu time used (in minutes), total number of I/O operations, and CPU stor-
     age integral for each user.  If the -u option is specified, the uid, user
     and system time (in seconds), CPU storage integral, I/O usage, and com-
     mand name will be printed for each entry in the accounting data file.

     If the -u flag is specified, all flags other than -q are ignored.	If the
     -m flag is specified, only the -b, -d, -i, -k, -q, and -s flags are hon-
     ored.

FILES
     /var/account/acct	   raw accounting data file
     /var/account/savacct  per-command accounting summary database
     /var/account/usracct  per-user accounting summary database

EXIT STATUS
     The sa utility exits 0 on success, and >0 if an error occurs.

SEE ALSO
     lastcomm(1), acct(5), ac(8), accton(8)

CAVEATS
     While the behavior of the options in this version of sa was modeled after
     the original version, there are some intentional differences and undoubt-
     edly some unintentional ones as well.  In particular, the -q option has
     been added, and the -m option now understands more options than it used
     to.

     The formats of the summary files created by this version of sa are very
     different from the those used by the original version.  This is not con-
     sidered a problem, however, because the accounting record format has
     changed as well (since user ids are now 32 bits).

AUTHORS
     Chris G. Demetriou <cgd@postgres.berkeley.edu>

BUGS
     The number of options to this program is absurd, especially considering
     that there is not much logic behind their lettering.

     The field labels should be more consistent.

     The VM system does not record the CPU storage integral.

BSD				 May 18, 2007				   BSD
","# sa

> Summarizes accounting information. Part of the acct package.
> Shows commands called by users, including basic info on CPU time spent processing and I/O rates.

- Display executable invocations per user (username not displayed):

`sudo sa`

- Display executable invocations per user, showing responsible usernames:

`sudo sa --print-users`

- List resources used recently per user:

`sudo sa --user-summary`
"
hostname,,,"
HOSTNAME(1)		  BSD General Commands Manual		   HOSTNAME(1)

NAME
     hostname -- set or print name of current host system

SYNOPSIS
     hostname [-fs] [name-of-host]

DESCRIPTION
     The hostname utility prints the name of the current host.	The super-user
     can set the hostname by supplying an argument.  To keep the hostname
     between reboots, run `scutil --set HostName name-of-host'.

     Options:

     -f    Include domain information in the printed name.  This is the
	   default behavior.

     -s    Trim off any domain information from the printed name.

SEE ALSO
     gethostname(3), scutil(8)

HISTORY
     The hostname command appeared in 4.2BSD.

BSD			       December 7, 2006 			   BSD
","# hostname

> Show or set the system's host name.

- Show current host name:

`hostname`

- Show the network address of the host name:

`hostname -i`

- Show all network addresses of the host:

`hostname -I`

- Show the FQDN (Fully Qualified Domain Name):

`hostname --fqdn`

- Set current host name:

`hostname {{new_hostname}}`
"
apache2ctl,,,,"# apache2ctl

> The CLI tool to administrate HTTP web server Apache.
> This commmand comes with Debian based OSes, for RHEL based ones see `httpd`.

- Start the Apache daemon. Throw a message if it is already running:

`sudo apache2ctl start`

- Stop the Apache daemon:

`sudo apache2ctl stop`

- Restart the Apache daemon:

`sudo apache2ctl restart`

- Test syntax of the configuration file:

`sudo apache2ctl -t`

- List loaded modules:

`sudo apache2ctl -M`
"
ctrlaltdel,,,,"# ctrlaltdel

> Utility to control what happens when CTRL+ALT+DEL is pressed.

- Get current setting:

`ctrlaltdel`

- Set CRTL+ALT+DEL to reboot immediately, without any preparation:

`sudo ctrlaltdel hard`

- Set CTRL+ALT+DEL to reboot ""normally"", giving processes a chance to exit first (send SIGINT to PID1):

`sudo ctrlaltdel soft`
"
prt-get,,,,"# prt-get

> The CRUX package manager.

- Install a package:

`prt-get install {{package_name}}`

- Install a package with dependency handling:

`prt-get depinst {{package_name}}`

- Update a package manually:

`prt-get upgrade {{package_name}}`

- Remove a package:

`prt-get remove {{package_name}}`

- Upgrade the system from the local ports tree:

`prt-get sysup`

- Search the ports tree:

`prt-get search {{package_name}}`

- Search for a file in a package:

`prt-get fsearch {{file}}`
"
toilet,http://caca.zoy.org/wiki/toilet,"


      toilet – Caca Labs
    































         
      






Search:






LoginHelp/GuideAbout TracPreferences





HomeForumsDocTimelineBug ReportsBrowse SourceSearch




wiki:toilet
Tweet

Context Navigation

Start PageIndexHistory








TOIlet

The TOIlet project attempts to create a free replacement for the ​FIGlet utility. TOIlet stands for “The Other Implementation’s letters”, coined after FIGlet’s “Frank, Ian and Glen’s letters”.


TOIlet is in its very early development phase. It uses the powerful libcaca library to achieve various text-based effects. TOIlet implements or plans to implement the following features:

The ability to load FIGlet fonts
Support for Unicode input and output
Support for colour fonts
Support for colour output
Support for various output formats: HTML, IRC, ANSI...

TOIlet also aims for full FIGlet compatibility. It is currently able to load FIGlet fonts and perform horizontal smushing.

Live test

The live test is currently disabled.

Download

The latest TOIlet version is toilet-0.3.tar.gz (6 Apr 2012).

Screenshot



Development

Development happens in a centralised Subversion repository:

​svn://svn.zoy.org/caca/toilet/trunk
associated web interface

There is also a Git repository that mirrors the central one:

using the Git protocol: ​git://git.zoy.org/toilet.git
using HTTP: http://caca.zoy.org/git/toilet.git

If you want to discuss toilet or report bugs, you can write to me at ​sam@hocevar.net or join #libcaca on irc.freenode.net.



Last modified 8 years ago
Last modified on Apr 6, 2012, 11:05:20 PM



Attachments (3)



toilet-0.1.tar.gz​ (419.4 KB) - added by Sam Hocevar 12 years ago.
            
toilet-0.2.tar.gz​ (842.3 KB) - added by Sam Hocevar 11 years ago.
            
toilet-0.3.tar.gz​ (844.6 KB) - added by Sam Hocevar 8 years ago.
            





Download in other formats:


Plain Text






Powered by Trac 1.2.2
        By Edgewall Software.
Visit the Caca Labs athttp://caca.zoy.org/





",,"# toilet

> A tool to display ASCII-art fonts.
> More information: <http://caca.zoy.org/wiki/toilet>.

- Generate ASCII art for a given text:

`toilet {{input_text}}`

- Generate ASCII art using a custom font file:

`toilet {{input_text}} -f {{font_filename}}`

- Generate ASCII art using a filter:

`toilet {{input_text}} --filter {{filter_name}}`

- Show available toilet filters:

`toilet --filter list `
"
lftp,https://linux.die.net/man/1/lftp,"

lftp(1): Sophisticated file transfer program - Linux man page
















lftp(1) - Linux man page
Name
lftp - Sophisticated file transfer program
Syntax
lftp [-d] [-e cmd] [-p port] [-u user[,pass]] [site]
lftp -f script_file
lftp -c commands
lftp --version
lftp --help
Version
This man page documents lftp version 4.0.9.
Description





lftp is a file transfer program that allows sophisticated ftp, http and other connections to other hosts. If site is specified then lftp will
connect to that site otherwise a connection has to be established with the open command.
lftp can handle several file access methods - ftp, ftps, http, https, hftp, fish, sftp and file (https and ftps are only available when lftp is
compiled with GNU TLS or OpenSSL library). You can specify the method to use in 'open URL' command, e.g. 'open http://www.us.kernel.org/pub/linux'. hftp is
ftp-over-http-proxy protocol. It can be used automatically instead of ftp if ftp:proxy is set to 'http://proxy[:port]'. Fish is a protocol working over an ssh
connection to a unix account. SFtp is a protocol implemented in ssh2 as sftp subsystem.
Besides FTP-like protocols, lftp has support for BitTorrent protocol as 'torrent' command. Seeding is also supported.
Every operation in lftp is reliable, that is any not fatal error is ignored and the operation is repeated. So if downloading breaks, it will be
restarted from the point automatically. Even if ftp server does not support REST command, lftp will try to retrieve the file from the very beginning
until the file is transferred completely.
lftp has shell-like command syntax allowing you to launch several commands in parallel in background (&). It is also possible to group commands
within () and execute them in background. All background jobs are executed in the same single process. You can bring a foreground job to background with ^Z
(c-z) and back with command 'wait' (or 'fg' which is alias to 'wait'). To list running jobs, use command 'jobs'. Some commands allow redirecting their output
(cat, ls, ...) to file or via pipe to external command. Commands can be executed conditionally based on termination status of previous command (&&,
||).
If you exit lftp when some jobs are not finished yet, lftp will move itself to nohup mode in background. The same happens when you have a real
modem hangup or when you close an xterm.
lftp has builtin mirror which can download or update a whole directory tree. There is also reverse mirror (mirror -R) which uploads or updates a
directory tree on server. Mirror can also synchronize directories between two remote servers, using FXP if available.
There is command 'at' to launch a job at specified time in current context, command 'queue' to queue commands for sequential execution for current server,
and much more.
On startup, lftp executes /etc/lftp.conf and then ~/.lftprc and ~/.lftp/rc. You can place aliases and 'set' commands there. Some
people prefer to see full protocol debug, use 'debug' to turn the debug on. Use 'debug 3' to see only greeting messages and error messages.
lftp has a number of settable variables. You can use 'set -a' to see all variables and their values or 'set -d' to see list of defaults. Variable
names can be abbreviated and prefix can be omitted unless the rest becomes ambiguous.
If lftp was compiled with OpenSSL (configure --with-openssl), then it includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit.
(http://www.openssl.org/)

Commands

! shell command
Launch shell or shell command.

!ls
To do a directory listing of the local host.
alias [name [value]]
Define or undefine alias name. If value is omitted, the alias is undefined, else it takes the value value. If no argument is given the
current aliases are listed.

alias dir ls -lF
alias less zmore
anon
Sets the user to anonymous. This is the default.
at time [ -- command ]
Wait until the given time and execute given (optional) command. See also at(1).
bookmark [subcommand]
The bookmark command controls bookmarks.
add <name> [<loc>]

add current place or given location

to bookmarks and bind to given name

del <name>

remove bookmark with name

edit

start editor on bookmarks file

import <type>

import foreign bookmarks

list

list bookmarks (default)
cache [subcommand]
The cache command controls local memory cache. The following subcommands are recognized:
stat

print cache status (default)

on|off

turn on/off caching

flush

flush cache

size lim
set memory limit, -1 means unlimited

expire Nx
set cache expiration time to N seconds (x=s)

minutes (x=m) hours (x=h) or days (x=d)
cat files
cat outputs the remote file(s) to stdout. (See also more, zcat and zmore)
cd rdir
Change current remote directory. The previous remote directory is stored as '-'. You can do 'cd -' to change the directory back. The previous directory for
each site is also stored on disk, so you can do 'open site; cd -' even after lftp restart.
chmod mode files
Change permission mask on remote files. The mode must be an octal number.
close [-a]
Close idle connections. By default only with the current server, use -a to close all idle connections.
cls [OPTS] files...
'cls' tries to retrieve information about specified files or directories and outputs the information according to format options. The difference between
'ls' and 'cls' is that 'ls' requests the server to format file listing, and 'cls' formats it itself, after retrieving all the needed information. See 'help
cls' for options.
command cmd args...
execute given command ignoring aliases.
debug [-o file] level|off
Switch debugging to level or turn it off. Use -o to redirect the debug output to a file.
echo [-n] string
guess what it does.
eval [-f format ] args...
without -f it just executes given arguments as a command. With -f, arguments are transformed into a new command. The format can contain plain text and
placeholders $0...$9 and $@, corresponding to the arguments.
exit [bg] [top] [kill] [code]
exit will exit from lftp or move to background if there are active jobs. If no job is active, code is passed to operating system as lftp's
termination status. If code is omitted, the exit code of last command is used.
'exit bg' forces moving to background when cmd:move-background is false. 'exit top' makes top level 'shell' (internal lftp command executor) terminate.
'exit kill' kills all numbered jobs before exiting. The options can be combined, e.g. 'at 08:00 -- exit top kill &' kills all jobs and makes lftp exit at
specified time.
fg
Alias for 'wait'.
find [directory]
List files in the directory (current directory by default) recursively. This can help with servers lacking ls -R support. You can redirect output of this
command.
ftpcopy
Obsolete. Use one of the following instead:

get ftp://... -o ftp://...
get -O ftp://... file1 file2...
put ftp://...
mput ftp://.../*
mget -O ftp://... ftp://.../*
or other combinations to get FXP transfer (directly between two ftp servers). lftp would fallback to plain copy (via client) if FXP transfer cannot be
initiated or ftp:use-fxp is false.
get [-E] [-a] [-c] [-O base] rfile [-o lfile] ...
Retrieve the remote file rfile and store it as the local file lfile. If -o is omitted, the file is stored to local file named as base name of
rfile. You can get multiple files by specifying multiple instances of rfile (and -o lfile). Does not expand wildcards, use mget for
that.
-c

continue, reget

-E

delete source files after successful transfer

-a

use ascii mode (binary is the default)

-O <base>

specifies base directory or URL where files should be placed
Examples:

get README
get README -o debian.README
get README README.mirrors
get README -o debian.README README.mirrors -o debian.mirrors
get README -o ftp://some.host.org/debian.README
get README -o ftp://some.host.org/debian-dir/ (end slash is important)
get1 [OPTS] rfile
Transfer a single file. Options:
-o <lfile>

destination file name (default - basename of rfile)

-c

continue, reget

-E

delete source files after successful transfer

-a

use ascii mode (binary is the default)
--source-region=<from-to>
transfer specified region of source file
--target-position=<pos>
position in target file to write data at
glob [-d] [-a] [-f] command patterns
Glob given patterns containing metacharacters and pass result to given command. E.g. ''glob echo *''.
-f

plain files (default)

-d

directories

-a

all types
help [cmd]
Print help for cmd or if no cmd was specified print a list of available commands.
jobs [-v]
List running jobs. -v means verbose, several -v can be specified.
kill all|job_no
Delete specified job with job_no or all jobs. (For job_no see jobs)
lcd ldir
Change current local directory ldir. The previous local directory is stored as '-'. You can do 'lcd -' to change the directory back.

lpwd
Print current working directory on local machine.
ls params
List remote files. You can redirect output of this command to file or via pipe to external command. By default, ls output is cached, to see new listing use
rels or cache flush.
mget [-c] [-d] [-a] [-E] [-O base] files
Gets selected files with expanded wildcards.
-c

continue, reget.

-d

create directories the same as file names and get

the files into them instead of current directory.

-E

delete source files after successful transfer

-a

use ascii mode (binary is the default)

-O <base>

specifies base directory or URL where files should be placed
mirror [OPTS] [source [target]]
Mirror specified source directory to local target directory. If target directory ends with a slash, the source base name is appended to target directory
name. Source and/or target can be URLs pointing to directories.
-c, --continue

continue a mirror job if possible

-e, --delete

delete files not present at remote site

--delete-first

delete old files before transferring new ones

--depth-first

descend into subdirectories before transferring files

-s, --allow-suid

set suid/sgid bits according to remote site

--allow-chown

try to set owner and group on files

--ascii

use ascii mode transfers (implies --ignore-size)

--ignore-time

ignore time when deciding whether to download

--ignore-size

ignore size when deciding whether to download

--only-missing

download only missing files

--only-existing

download only files already existing at target

-n, --only-newer

download only newer files (-c won't work)

--no-empty-dirs

don't create empty directories (implies --depth-first)

-r, --no-recursion

don't go to subdirectories

--no-symlinks

don't create symbolic links

-p, --no-perms

don't set file permissions

--no-umask

don't apply umask to file modes

-R, --reverse

reverse mirror (put files)

-L, --dereference

download symbolic links as files

-N, --newer-than=SPEC

download only files newer than specified time

--on-change=CMD

execute the command if anything has been changed

--older-than=SPEC

download only files older than specified time

--size-range=RANGE

download only files with size in specified range

-P, --parallel[=N]

download N files in parallel

--use-pget[-n=N]

use pget to transfer every single file

--loop

loop until no changes found

-i RX, --include RX
include matching files

-x RX, --exclude RX
exclude matching files

-I GP, --include-glob GP
include matching files

-X GP, --exclude-glob GP
exclude matching files

-v, --verbose[=level]

verbose operation

--log=FILE

write lftp commands being executed to FILE

--script=FILE

write lftp commands to FILE, but don't execute them

--just-print, --dry-run

same as --script=-

--use-cache

use cached directory listings

--Remove-source-files

remove files after transfer (use with caution)

-a

same as --allow-chown --allow-suid --no-umask
When using -R, the first directory is local and the second is remote. If the second directory is omitted, base name of first directory is used. If both
directories are omitted, current local and remote directories are used. If target directory ends with a slash (except root directory) then base name of source
directory is appended.
RX is an extended regular expression, just like in egrep(1).
GP is a glob pattern, e.g. '*.zip'.
Include and exclude options can be specified multiple times. It means that a file or directory would be mirrored if it matches an include and does not match
to excludes after the include, or does not match anything and the first check is exclude. Directories are matched with a slash appended.
Note that symbolic links are not created when uploading to remote server, because ftp protocol cannot do it. To upload files the links refer to, use 'mirror
-RL' command (treat symbolic links as files).
For option --newer-than you can either specify a file or time specification like that used by at(1) command, e.g. 'now-7days' or 'week ago'. If you
specify a file, then modification time of that file will be used.
Verbosity level can be selected using --verbose=level option or by several -v options, e.g. -vvv. Levels are:

0 - no output (default)
1 - print actions
2 - +print not deleted file names (when -e is not specified)
3 - +print directory names which are mirrored
--only-newer turns off file size comparison and uploads/downloads only newer files even if size is different. By default older files are transferred and
replace newer ones.
You can mirror between two servers if you specify URLs instead of directories. FXP is used automatically for transfers between ftp servers, if possible.

Some ftp servers hide dot-files by default (e.g. .htaccess), and show them only when LIST command is used with -a option. In such case try to use
'set ftp:list-options -a'.
mkdir [-p] dir(s)
Make remote directories. If -p is used, make all components of paths.
module module [ args ]
Load given module using dlopen(3) function. If module name does not contain a slash, it is searched in directories specified by module:path variable.
Arguments are passed to module_init function. See README.modules for technical details.
more files
Same as 'cat files | more'. if PAGER is set, it is used as filter. (See also cat, zcat and zmore)
mput [-c] [-d] [-a] [-E] [-O base] files
Upload files with wildcard expansion. By default it uses the base name of local name as remote one. This can be changed by '-d' option.
-c

continue, reput

-d

create directories the same as in file names and put the

files into them instead of current directory

-E

delete source files after successful transfer (dangerous)

-a

use ascii mode (binary is the default)

-O <base>

specifies base directory or URL where files should be placed
mrm file(s)
Same as 'glob rm'. Removes specified file(s) with wildcard expansion.
mv file1 file2
Rename file1 to file2.
nlist [args]
List remote file names
open [-e cmd] [-u user[,pass]] [-p port] host|url
Select an ftp server.
pget [OPTS] rfile [-o lfile]
Gets the specified file using several connections. This can speed up transfer, but loads the net and server heavily impacting other users. Use only if you
really have to transfer the file ASAP. Options:
-c

continue transfer. Requires lfile.lftp-pget-status file.

-n maxconn
set maximum number of connections (default is taken from pget:default-n setting)
put [-E] [-a] [-c] [-O base] lfile [-o rfile]
Upload lfile with remote name rfile. If -o omitted, the base name of lfile is used as remote name. Does not expand wildcards, use
mput for that.
-o <rfile>

specifies remote file name (default - basename of lfile)

-c

continue, reput

it requires permission to overwrite remote files

-E

delete source files after successful transfer (dangerous)

-a

use ascii mode (binary is the default)

-O <base>

specifies base directory or URL where files should be placed
pwd [-p]
Print current remote URL. Use '-p' option to show password in the URL.
queue [-n num ] cmd
Add the given command to queue for sequential execution. Each site has its own queue. '-n' adds the command before the given item in the queue. Don't try to
queue 'cd' or 'lcd' commands, it may confuse lftp. Instead do the cd/lcd before 'queue' command, and it will remember the place in which the command is to be
done. It is possible to queue up an already running job by 'queue wait <jobno>', but the job will continue execution even if it is not the first in
queue.
'queue stop' will stop the queue, it will not execute any new commands, but already running jobs will continue to run. You can use 'queue stop' to create an
empty stopped queue. 'queue start' will resume queue execution. When you exit lftp, it will start all stopped queues automatically.
'queue' with no arguments will either create a stopped queue or print queue status.
queue --delete|-d [index or wildcard expression]
Delete one or more items from the queue. If no argument is given, the last entry in the queue is deleted.
queue --move|-m <index or wildcard expression> [index]
Move the given items before the given queue index, or to the end if no destination is given.
-q

Be quiet.

-v

Be verbose.

-Q

Output in a format that can be used to re-queue.

Useful with --delete.

> get file &
[1] get file
> queue wait 1
> queue get another_file
> cd a_directory
> queue get yet_another_file
queue -d 3

Delete the third item in the queue.

queue -m 6 4

Move the sixth item in the queue before the fourth.

queue -m ""get*zip"" 1

Move all commands matching ""get*zip"" to the beginning

of the queue. (The order of the items is preserved.)

queue -d ""get*zip""

Delete all commands matching ""get*zip"".
quote cmd
For FTP - send the command uninterpreted. Use with caution - it can lead to unknown remote state and thus will cause reconnect. You cannot be sure that any
change of remote state because of quoted command is solid - it can be reset by reconnect at any time.
For HTTP - specific to HTTP action. Syntax: ''quote <command> [<args>]''. Command may be ''set-cookie'' or ''post''.

open http://www.site.net
quote set-cookie ""variable=value; othervar=othervalue""
set http:post-content-type application/x-www-form-urlencoded
quote post /cgi-bin/script.cgi ""var=value&othervar=othervalue"" > local_file
For FISH - send the command uninterpreted. This can be used to execute arbitrary commands on server. The command must not take input or print ### at new
line beginning. If it does, the protocol will become out of sync.

open fish://server
quote find -name \*.zip
reget rfile [-o lfile]
Same as 'get -c'.
rels [args]
Same as 'ls', but ignores the cache.
renlist [args]
Same as 'nlist', but ignores the cache.
repeat [OPTS] [[-d] delay] [command]
Repeat specified command with a delay between iterations. Default delay is one second, default command is empty.
-c <count>

maximum number of iterations

-d <delay>

delay between iterations

--while-ok

stop when command exits with non-zero code

--until-ok

stop when command exits with zero code

--weak

stop when lftp moves to background.
Examples:

repeat at tomorrow -- mirror
repeat 1d mirror
reput lfile [-o rfile]
Same as 'put -c'.
rm [-r] [-f] files
Remove remote files. Does not expand wildcards, use mrm for that. -r is for recursive directory remove. Be careful, if something goes wrong you can
lose files. -f suppress error messages.
rmdir dir(s)
Remove remote directories.
scache [session]
List cached sessions or switch to specified session.
set [var [val]]
Set variable to given value. If the value is omitted, unset the variable. Variable name has format ''name/closure'', where closure can specify exact
application of the setting. See below for details. If set is called with no variable then only altered settings are listed. It can be changed by
options:
-a

list all settings, including default values

-d

list only default values, not necessary current ones
site site_cmd
Execute site command site_cmd and output the result. You can redirect its output.
sleep interval
Sleep given time interval and exit. Interval is in seconds by default, but can be suffixed with 'm', 'h', 'd' for minutes, hours and days respectively. See
also at.
slot [name]
Select specified slot or list all slots allocated. A slot is a connection to a server, somewhat like a virtual console. You can create multiple slots
connected to different servers and switch between them. You can also use slot:name as a pseudo-URL evaluating to that slot location.
Default readline binding allows quick switching between slots named 0-9 using Meta-0 - Meta-9 keys (often you can use Alt instead of Meta).

source file
source -e command
Execute commands recorded in file file or returned by specified external command.

source ~/.lftp/rc
source -e echo help
suspend
Stop lftp process. Note that transfers will be also stopped until you continue the process with shell's fg or bg commands.
torrent torrent-file [-O directory]
Start BitTorrent process for the given torrent-file, which can be a local file or URL. Existing files are first validated. Missing pieces are
downloaded. Files are stored in specified directory or current working directory by default. Seeding continues until ratio reachs
torrent:stop-on-ratio setting or time of torrent:seed-max-time outs.
user user [pass]
user URL [pass]
Use specified info for remote login. If you specify an URL with user name, the entered password will be cached so that future URL references can use it.

version
Print lftp version.
wait [jobno]
wait all
Wait for specified job to terminate. If jobno is omitted, wait for last backgrounded job.
'wait all' waits for all jobs termination.
zcat files
Same as cat, but filter each file through zcat. (See also cat, more and zmore)
zmore files
Same as more, but filter each file through zcat. (See also cat, zcat and more)

Settings

On startup, lftp executes ~/.lftprc and ~/.lftp/rc. You can place aliases and 'set' commands there. Some people prefer to see full protocol
debug, use 'debug' to turn the debug on.
There is also a system-wide startup file in /etc/lftp.conf. It can be in different directory, see FILES section.
lftp has the following settable variables (you can also use 'set -a' to see all variables and their values):
bmk:save-passwords (boolean)
save plain text passwords in ~/.lftp/bookmarks on 'bookmark add' command. Off by default.
cmd:at-exit (string)
the commands in string are executed before lftp exits.
cmd:csh-history (boolean)
enables csh-like history expansion.
cmd:default-protocol (string)
The value is used when 'open' is used with just host name without protocol. Default is 'ftp'.
cmd:fail-exit (boolean)
if true, exit when an unconditional (without || and && at begin) command fails.
cmd:long-running (seconds)
time of command execution, which is considered as 'long' and a beep is done before next prompt. 0 means off.
cmd:ls-default (string)
default ls argument
cmd:move-background (boolean)
when false, lftp refuses to go to background when exiting. To force it, use 'exit bg'.
cmd:move-background-detach (boolean)
when true (default), lftp detaches itself from the control terminal when moving to background, it is not possible to attach back; when false, lftp tricks
the shell to move lftp to background process group and continues to run, then fg shell command brings lftp back to foreground unless it has done all jobs and
terminated.
cmd:prompt (string)
The prompt. lftp recognizes the following backslash-escaped special characters that are decoded as follows:
\@
insert @ if current user is not default

\a
an ASCII bell character (07)

\e
an ASCII escape character (033)

\h
the hostname you are connected to

\n
newline

\s
the name of the client (lftp)

\S
current slot name

\u
the username of the user you are logged in as

\U
the URL of the remote site (e.g., ftp://g437.ub.gu.se/home/james/src/lftp)

\v
the version of lftp (e.g., 2.0.3)

\w
the current working directory at the remote site

\W
the base name of the current working directory at the remote site

\nnn
the character corresponding to the octal number nnn
\\
a backslash

\?
skips next character if previous substitution was empty.

\[
begin a sequence of non-printing characters, which could be used to embed a terminal control sequence into the prompt

\]
end a sequence of non-printing characters
cmd:parallel (number)
Number of jobs run in parallel in non-interactive mode. For example, this may be useful for scripts with multiple 'get' commands. Note that setting this to
a value greater than 1 changes conditional execution behaviour, basically makes it inconsistent.
cmd:queue-parallel (number)
Number of jobs run in parallel in a queue.
cmd:time-style (string)
This setting is the default value for cls --time-style option.
cmd:trace (boolean)
when true, lftp prints the commands it executes (like sh -x).
cache:cache-empty-listings (boolean)
When false, empty listings are not cached.
cache:enable (boolean)
When false, cache is disabled.
cache:expire (time interval)
Positive cache entries expire in this time interval.
cache:expire-negative (time interval)
Negative cache entries expire in this time interval.
cache:size (number)
Maximum cache size. When exceeded, oldest cache entries will be removed from cache.
cmd:remote-completion (boolean)
a boolean to control whether or not lftp uses remote completion.
cmd:verify-host (boolean)
if true, lftp resolves host name immediately in 'open' command. It is also possible to skip the check for a single 'open' command if '&' is given, or if
^Z is pressed during the check.
cmd:verify-path (boolean)
if true, lftp checks the path given in 'cd' command. It is also possible to skip the check for a single 'cd' command if '&' is given, or if ^Z is
pressed during the check. Examples:

set cmd:verify-path/hftp://* false
cd directory &
cmd:verify-path-cached (boolean)
When false, 'cd' to a directory known from cache as existent will succeed immediately. Otherwise the verification will depend on cmd:verify-path
setting.
color:use-color (boolean)
when true, cls command and completion output colored file listings according to color:dir-colors setting.
color:dir-colors (string)
file listing color description. By default the value of LS_COLORS environment variable is used. See dircolors(1).
dns:SRV-query (boolean)
query for SRV records and use them before gethostbyname. The SRV records are only used if port is not explicitly specified. See RFC2052 for details.
dns:cache-enable (boolean)
enable DNS cache. If it is off, lftp resolves host name each time it reconnects.
dns:cache-expire (time interval)
time to live for DNS cache entries. It has format <number><unit>+, e.g. 1d12h30m5s or just 36h. To disable expiration, set it to 'inf' or
'never'.
dns:cache-size (number)
maximum number of DNS cache entries.
dns:fatal-timeout (time interval)
limit the time for DNS queries. If DNS server is unavailable too long, lftp will fail to resolve a given host name. Set to 'never' to disable.
dns:order (list of protocol names)
sets the order of DNS queries. Default is ''inet6 inet'' which means first look up address in inet6 family, then inet and use them in that order. To disable
inet6 (AAAA) lookup, set this variable to ''inet''.
dns:use-fork (boolean)
if true, lftp will fork before resolving host address. Default is true.
dns:max-retries (number)
If zero, there is no limit on the number of times lftp will try to lookup an address. If > 0, lftp will try only this number of times to look up an
address of each address family in dns:order.
file:charset (string)
local character set. It is set from current locale initially.
fish:charset (string)
the character set used by fish server in requests, replies and file listings. Default is empty which means the same as local.
fish:connect-program (string)
the program to use for connecting to remote server. It should support '-l' option for user name, '-p' for port number. Default is 'ssh -a -x'. You can set
it to 'rsh', for example.
fish:shell (string)
use specified shell on server side. Default is /bin/sh. On some systems, /bin/sh exits when doing cd to a non-existent directory. lftp can handle that but
it has to reconnect. Set it to /bin/bash for such systems if bash is installed.
ftp:acct (string)
Send this string in ACCT command after login. The result is ignored. The closure for this setting has format user@host.
ftp:anon-pass (string)
sets the password used for anonymous ftp access authentication. Default is ""-name@"", where name is the username of the user running the program.
ftp:anon-user (string)
sets the user name used for anonymous ftp access authentication. Default is ""anonymous"".
ftp:auto-sync-mode (regex)
if first server message matches this regex, turn on sync mode for that host.
ftp:charset (string)
the character set used by ftp server in requests, replies and file listings. Default is empty which means the same as local. This setting is only used when
the server does not support UTF8.
ftp:client (string)
the name of ftp client to send with CLNT command, if supported by server. If it is empty, then no CLNT command will be sent.
ftp:bind-data-socket (boolean)
bind data socket to the interface of control connection (in passive mode). Default is true, exception is the loopback interface.
ftp:fix-pasv-address (boolean)
if true, lftp will try to correct address returned by server for PASV command in case when server address is in public network and PASV returns an address
from a private network. In this case lftp would substitute server address instead of the one returned by PASV command, port number would not be changed.
Default is true.
ftp:fxp-passive-source (boolean)
if true, lftp will try to set up source ftp server in passive mode first, otherwise destination one. If first attempt fails, lftp tries to set them up the
other way. If the other disposition fails too, lftp falls back to plain copy. See also ftp:use-fxp.
ftp:home (string)
Initial directory. Default is empty string which means auto. Set this to '/' if you don't like the look of %2F in ftp URLs. The closure for this setting has
format user@host.
ftp:ignore-pasv-address (boolean)
If true, lftp uses control connection address instead of the one returned in PASV reply for data connection. This can be useful for broken NATs. Default is
false.
ftp:list-empty-ok (boolean)
if set to false, empty lists from LIST command will be treated as incorrect, and another method (NLST) will be used.
ftp:list-options (string)
sets options which are always appended to LIST command. It can be useful to set this to '-a' if server does not show dot (hidden) files by default. Default
is empty.
ftp:nop-interval (seconds)
delay between NOOP commands when downloading tail of a file. This is useful for ftp servers which send ""Transfer complete"" message before flushing data
transfer. In such cases NOOP commands can prevent connection timeout.
ftp:passive-mode (boolean)
sets passive ftp mode. This can be useful if you are behind a firewall or a dumb masquerading router. In passive mode lftp uses PASV command, not the PORT
command which is used in active mode. In passive mode lftp itself makes the data connection to the server; in active mode the server connects to lftp for data
transfer. Passive mode is the default.
ftp:port-ipv4 (ipv4 address)
specifies an IPv4 address to send with PORT command. Default is empty which means to send the address of local end of control connection.
ftp:port-range (from-to)
allowed port range for active mode. Format is min-max, or 'full' or 'any' to indicate any port. Default is 'full'.
ftp:prefer-epsv (boolean)
use EPSV as preferred passive mode. Default is 'false'.
ftp:proxy (URL)
specifies ftp proxy to use. To disable proxy set this to empty string. Note that it is an ftp proxy which uses ftp protocol, not ftp over http. Default
value is taken from environment variable ftp_proxy if it starts with ''ftp://''. If your ftp proxy requires authentication, specify user name and
password in the URL. If ftp:proxy starts with http:// then hftp protocol (ftp over http proxy) is used instead of ftp automatically.
ftp:proxy-auth-type (string)
When set to ''joined'', lftp sends ''user@proxy_user@ftp.example.org'' as user name to proxy, and ''password@proxy_password'' as password.
When set to ''joined-acct'', lftp sends ''user@ftp.example.org proxy_user'' (with space) as user name to proxy. The site password is sent as usual and the
proxy password is expected in the following ACCT command.
When set to ''open'', lftp first sends proxy user and proxy password and then ''OPEN ftp.example.org'' followed by ''USER user''. The site password is then
sent as usual.
When set to ''user'' (default), lftp first sends proxy user and proxy password and then ''user@ftp.example.org'' as user name. The site password is then
sent as usual.
When set to ''proxy-user@host'', lftp first sends ''USER proxy_user@ftp.example.org'', then proxy password. The site user and password are then sent as
usual.
ftp:rest-list (boolean)
allow usage of REST command before LIST command. This might be useful for large directories, but some ftp servers silently ignore REST before LIST.
ftp:rest-stor (boolean)
if false, lftp will not try to use REST before STOR. This can be useful for some buggy servers which corrupt (fill with zeros) the file if REST followed by
STOR is used.
ftp:retry-530 (regex)
Retry on server reply 530 for PASS command if text matches this regular expression. This setting should be useful to distinguish between overloaded server
(temporary condition) and incorrect password (permanent condition).
ftp:retry-530-anonymous (regex)
Additional regular expression for anonymous login, like ftp:retry-530.
ftp:site-group (string)
Send this string in SITE GROUP command after login. The result is ignored. The closure for this setting has format user@host.
ftp:skey-allow (boolean)
allow sending skey/opie reply if server appears to support it. On by default.
ftp:skey-force (boolean)
do not send plain text password over the network, use skey/opie instead. If skey/opie is not available, assume failed login. Off by default.
ftp:ssl-allow (boolean)
if true, try to negotiate SSL connection with ftp server for non-anonymous access. Default is true. This and other ssl settings are only available if lftp
was compiled with an ssl/tls library.
ftp:ssl-data-use-keys (boolean)
if true, lftp loads ssl:key-file for protected data connection too. When false, it does not, and the server can match data and control connections by
session ID. Default is true.
ftp:ssl-force (boolean)
if true, refuse to send password in clear when server does not support SSL. Default is false.
ftp:ssl-protect-data (boolean)
if true, request ssl connection for data transfers. This is cpu-intensive but provides privacy. Default is false.
ftp:ssl-protect-fxp (boolean)
if true, request ssl connection for data transfer between two ftp servers in FXP mode. CPSV or SSCN command will be used in that case. If ssl connection
fails for some reason, lftp would try unprotected FXP transfer unless ftp:ssl-force is set for any of the two servers. Default is false.
ftp:ssl-protect-list (boolean)
if true, request ssl connection for file list transfers. Default is true.
ftp:ssl-use-ccc (boolean)
if true, lftp would issue CCC command after logon, thus disable ssl protection layer on control connection.
ftp:stat-interval (time interval)
interval between STAT commands. Default is 1 second.
ftp:sync-mode (boolean)
if true, lftp will send one command at a time and wait for response. This might be useful if you are using a buggy ftp server or router. When it is off,
lftp sends a pack of commands and waits for responses - it speeds up operation when round trip time is significant. Unfortunately it does not work with all ftp
servers and some routers have troubles with it, so it is on by default.
ftp:timezone (string)
Assume this timezone for time in listings returned by LIST command. This setting can be GMT offset [+|-]HH[:MM[:SS]] or any valid TZ value (e.g.
Europe/Moscow or MSK-3MSD,M3.5.0,M10.5.0/3). The default is GMT. Set it to an empty value to assume local timezone specified by environment variable
TZ.
ftp:trust-feat (string)
When true, assume that FEAT returned data are correct and don't use common protocol extensions like SIZE, MDTM, REST if they are not listed. Default is
false.
ftp:use-abor (boolean)
if false, lftp does not send ABOR command but closes data connection immediately.
ftp:use-allo (boolean)
when true (default), lftp sends ALLO command before uploading a file.
ftp:use-feat (boolean)
when true (default), lftp uses FEAT command to determine extended features of ftp server.
ftp:use-fxp (boolean)
if true, lftp will try to set up direct connection between two ftp servers.
ftp:use-hftp (boolean)
when ftp:proxy points to an http proxy, this setting selects hftp method (GET, HEAD) when true, and CONNECT method when false. Default is true.
ftp:lang (boolean)
the language selected with LANG command, if supported as indicated by FEAT response. Default is empty which means server default.
ftp:use-mdtm (boolean)
when true (default), lftp uses MDTM command to determine file modification time.
ftp:use-mdtm-overloaded (boolean)
when true, lftp uses two argument MDTM command to set file modification time on uploaded files. Default is false.
ftp:use-site-idle (boolean)
when true, lftp sends 'SITE IDLE' command with net:idle argument. Default is false.
ftp:use-site-utime (boolean)
when true, lftp sends 5-argument 'SITE UTIME' command to set file modification time on uploaded files. Default is true.
ftp:use-site-utime2 (boolean)
when true, lftp sends 2-argument 'SITE UTIME' command to set file modification time on uploaded files. Default is true. If 5-argument 'SITE UTIME' is also
enabled, 2-argument command is tried first.
ftp:use-size (boolean)
when true (default), lftp uses SIZE command to determine file size.
ftp:use-stat (boolean)
if true, lftp sends STAT command in FXP mode transfer to know how much data has been transferred. See also ftp:stat-interval. Default is true.
ftp:use-stat-for-list (boolean)
when true, lftp uses STAT instead of LIST command. By default '.' is used as STAT argument. Using STAT, lftp avoids creating data connection for directory
listing. Some servers require special options for STAT, use ftp:list-options to specify them (e.g. -la).
ftp:use-telnet-iac (boolean)
when true (default), lftp uses TELNET IAC command and follows TELNET protocol as specified in RFC959. When false, it does not follow TELNET protocol and
thus does not double 255 (0xFF, 0377) character and does not prefix ABOR and STAT commands with TELNET IP+SYNCH signal.
ftp:use-quit (boolean)
if true, lftp sends QUIT before disconnecting from ftp server. Default is true.
ftp:verify-address (boolean)
verify that data connection comes from the network address of control connection peer. This can possibly prevent data connection spoofing which can lead to
data corruption. Unfortunately, this can fail for certain ftp servers with several network interfaces, when they do not set outgoing address on data socket, so
it is disabled by default.
ftp:verify-port (boolean)
verify that data connection has port 20 (ftp-data) on its remote end. This can possibly prevent data connection spoofing by users of remote host.
Unfortunately, too many windows and even unix ftp servers forget to set proper port on data connection, thus this check is off by default.
ftp:web-mode (boolean)
disconnect after closing data connection. This can be useful for totally broken ftp servers. Default is false.
ftps:initial-prot (string)
specifies initial PROT setting for FTPS connections. Should be one of: C, S, E, P, or empty. Default is empty which means unknown, so that lftp will use
PROT command unconditionally. If PROT command turns out to be unsupported, then Clear mode would be assumed.
hftp:cache (boolean)
allow server/proxy side caching for ftp-over-http protocol.
hftp:cache-control (string)
specify corresponding HTTP request header.
hftp:proxy (URL)
specifies http proxy for ftp-over-http protocol (hftp). The protocol hftp cannot work without a http proxy, obviously. Default value is taken from
environment variable ftp_proxy if it starts with ''http://'', otherwise from environment variable http_proxy. If your ftp proxy requires
authentication, specify user name and password in the URL.
hftp:use-authorization (boolean)
if set to off, lftp will send password as part of URL to the proxy. This may be required for some proxies (e.g. M-soft). Default is on, and lftp will send
password as part of Authorization header.
hftp:use-head (boolean)
if set to off, lftp will try to use 'GET' instead of 'HEAD' for hftp protocol. While this is slower, it may allow lftp to work with some proxies which don't
understand or mishandle ''HEAD ftp://'' requests.
hftp:use-mkcol (boolean)
if set to off, lftp will try to use 'PUT' instead of 'MKCOL' to create directories with hftp protocol. Default is off.
hftp:use-propfind (boolean)
if set to off, lftp will not try to use 'PROPFIND' to get directory contents with hftp protocol and use 'GET' instead. Default is off.
hftp:use-type (boolean)
If set to off, lftp won't try to append ';type=' to URLs passed to proxy. Some broken proxies don't handle it correctly. Default is on.
http:accept, http:accept-charset, http:accept-language (string)
specify corresponding HTTP request headers.
http:authorization (string)
the authorization to use by default, when no user is specified. The format is ''user:password''. Default is empty which means no authorization.
http:cache (boolean)
allow server/proxy side caching.
http:cache-control (string)
specify corresponding HTTP request header.
http:cookie (string)
send this cookie to server. A closure is useful here: set cookie/www.somehost.com ""param=value""
http:post-content-type (string)
specifies value of Content-Type http request header for POST method. Default is ''application/x-www-form-urlencoded''.
http:proxy (URL)
specifies http proxy. It is used when lftp works over http protocol. Default value is taken from environment variable http_proxy. If your proxy
requires authentication, specify user name and password in the URL.
http:put-method (PUT or POST)
specifies which http method to use on put.
http:put-content-type (string)
specifies value of Content-Type http request header for PUT method.
http:referer (string)
specifies value for Referer http request header. Single dot '.' expands to current directory URL. Default is '.'. Set to empty string to disable Referer
header.
http:set-cookies (boolean)
if true, lftp modifies http:cookie variables when Set-Cookie header is received.
http:use-mkcol (boolean)
if set to off, lftp will try to use 'PUT' instead of 'MKCOL' to create directories with http protocol. Default is on.
http:use-propfind (boolean)
if set to off, lftp will not try to use 'PROPFIND' to get directory contents with http protocol and use 'GET' instead. Default is on.
http:user-agent (string)
the string lftp sends in User-Agent header of HTTP request.
https:proxy (string)
specifies https proxy. Default value is taken from environment variable https_proxy.
mirror:dereference (boolean)
when true, mirror will dereference symbolic links by default. You can override it by --no-dereference option. Default if false.
mirror:exclude-regex (regex)
specifies default exclusion pattern. You can override it by --include option.
mirror:include-regex (regex)
specifies default inclusion pattern. It is used just after mirror:exclude-regex is applied. It is never used if mirror:exclude-regex is empty.
mirror:order (list of patterns)
specifies order of file transfers. E.g. setting this to ""*.sfv *.sum"" makes mirror to transfer files matching *.sfv first, then ones matching *.sum and then
all other files. To process directories after other files, add ""*/"" to end of pattern list.
mirror:parallel-directories (boolean)
if true, mirror will start processing of several directories in parallel when it is in parallel mode. Otherwise, it will transfer files from a single
directory before moving to other directories.
mirror:parallel-transfer-count (number)
specifies number of parallel transfers mirror is allowed to start. Default is 1. You can override it with --parallel option.
mirror:set-permissions (boolean)
When set to off, mirror won't try to copy file and directory permissions. You can override it by --perms option. Default is on.
mirror:use-pget-n (number)
specifies -n option for pget command used to transfer every single file under mirror. Default is 1 which disables pget.
module:path (string)
colon separated list of directories to look for modules. Can be initialized by environment variable LFTP_MODULE_PATH. Default is
'PKGLIBDIR/VERSION:PKGLIBDIR'.
net:connection-limit (number)
maximum number of concurrent connections to the same site. 0 means unlimited.
net:connection-takeover (boolean)
if true, foreground connections have priority over background ones and can interrupt background transfers to complete a foreground operation.
net:idle (time interval)
disconnect from server after this idle time. Default is 3 minutes.
net:limit-rate (bytes per second)
limit transfer rate on data connection. 0 means unlimited. You can specify two numbers separated by colon to limit download and upload rate
separately.
net:limit-max (bytes)
limit accumulating of unused limit-rate. 0 means twice of limit-rate.
net:limit-total-rate (bytes per second)
limit transfer rate of all connections in sum. 0 means unlimited. You can specify two numbers separated by colon to limit download and upload rate
separately. Note that sockets have receive buffers on them, this can lead to network link load higher than this rate limit just after transfer beginning. You
can try to set net:socket-buffer to relatively small value to avoid this.
net:limit-total-max (bytes)
limit accumulating of unused limit-total-rate. 0 means twice of limit-total-rate.
net:max-retries (number)
the maximum number of sequential retries of an operation without success. 0 means unlimited.
net:no-proxy (string)
contains comma separated list of domains for which proxy should not be used. Default is taken from environment variable no_proxy.
net:persist-retries (number)
ignore this number of hard errors. Useful to login to buggy ftp servers which reply 5xx when there is too many users.
net:reconnect-interval-base (seconds)
sets the base minimal time between reconnects. Actual interval depends on net:reconnect-interval-multiplier and number of attempts to perform an
operation.
net:reconnect-interval-max (seconds)
sets maximum reconnect interval. When current interval after multiplication by net:reconnect-interval-multiplier reachs this value (or exceeds it), it is
reset back to net:reconnect-interval-base.
net:reconnect-interval-multiplier (real number)
sets multiplier by which base interval is multiplied each time new attempt to perform an operation fails. When the interval reachs maximum, it is reset to
base value. See net:reconnect-interval-base and net:reconnect-interval-max.
net:socket-bind-ipv4 (ipv4 address)
bind all IPv4 sockets to specified address. This can be useful to select a specific network interface to use. Default is empty which means not to bind IPv4
sockets, operating system will choose an address automatically using routing table.
net:socket-bind-ipv6 (ipv6 address)
the same for IPv6 sockets.
net:socket-buffer (bytes)
use given size for SO_SNDBUF and SO_RCVBUF socket options. 0 means system default.
net:socket-maxseg (bytes)
use given size for TCP_MAXSEG socket option. Not all operating systems support this option, but linux does.
net:timeout (time interval)
sets the network protocol timeout.
pget:default-n (number)
default number of chunks to split the file to in pget.
pget:save-status (time interval)
save pget transfer status this often. Set to 'never' to disable saving of the status file. The status is saved to a file with suffix
.lftp-pget-status.
sftp:charset (string)
the character set used by sftp server in file names and file listings. Default is empty which means the same as local. This setting is only used for sftp
protocol version prior to 4. Version 4 and later always use UTF-8.
sftp:connect-program (string)
the program to use for connecting to remote server. It should support '-l' option for user name, '-p' for port number. Default is 'ssh -a -x'. You can set
it to 'rsh', for example.
sftp:max-packets-in-flight (number)
The maximum number of unreplied packets in flight. If round trip time is significant, you should increase this and size-read/size-write. Default is
16.
sftp:protocol-version (number)
The protocol number to negotiate. Default is 4. The actual protocol version used depends on server.
sftp:server-program (string)
The server program implementing SFTP protocol. If it does not contain a slash '/', it is considered a ssh2 subsystem and -s option is used when starting
connect-program. Default is 'sftp'. You can use rsh as transport level protocol like this:

set sftp:connect-program rsh
set sftp:server-program /usr/libexec/openssh/sftp-server
Similarly you can run sftp over ssh1.
sftp:size-read (number)
Block size for reading. Default is 0x8000.
sftp:size-write (number)
Block size for writing. Default is 0x8000.
ssl:ca-file (path to file)
use specified file as Certificate Authority certificate.
ssl:ca-path (path to directory)
use specified directory as Certificate Authority certificate repository (OpenSSL only).
ssl:check-hostname (boolean)
when true, lftp checks if the host name used to connect to the server corresponds to the host name in its certificate.
ssl:crl-file (path to file)
use specified file as Certificate Revocation List certificate.
ssl:crl-path (path to directory)
use specified directory as Certificate Revocation List certificate repository (OpenSSL only).
ssl:key-file (path to file)
use specified file as your private key.
ssl:cert-file (path to file)
use specified file as your certificate.
ssl:verify-certificate (boolean)
if set to yes, then verify server's certificate to be signed by a known Certificate Authority and not be on Certificate Revocation List.
torrent:ip (ipv4 address)
IP address for the tracker. Specify it if you are using an http proxy.
torrent:max-peers (number)
maximum number of peers for a torrent. Least used peers are removed to maintain this limit.
torrent:port-range (from-to)
port range to accept connections on. A single port is selected when a torrent starts.
torrent:seed-max-time (time interval)
maximum seed time. After this period of time a complete torrent shuts down independently of ratio. It can be set to infinity if needed.
torrent:seed-min-peers (number)
minimum number of peers when the torrent is complete. If there are less, new peers are actively searched for.
torrent:stop-on-ratio (real number)
torrent stops when it's complete and ratio reached this number.
xfer:clobber (boolean)
if this setting is off, get commands will not overwrite existing files and generate an error instead.
xfer:destination-directory (path or URL to directory)
This setting is used as default -O option for get and mget commands. Default is empty, which means current directory (no -O option).
xfer:full-disk-fatal (boolean)
when true, lftp aborts a thansfer if it cannot write target file because of full disk or quota; when false, lftp waits for disk space to be freed.
xfer:eta-period (seconds)
the period over which weighted average rate is calculated to produce ETA.
xfer:eta-terse (boolean)
show terse ETA (only high order parts). Default is true.
xfer:log (boolean)
when true, lftp logs transfers to ~/.lftp/transfer_log.
xfer:max-redirections (number)
maximum number of redirections. This can be useful for downloading over HTTP. 0 prohibits redirections.
xfer:rate-period (seconds)
the period over which weighted average rate is calculated to be shown.
The name of a variable can be abbreviated unless it becomes ambiguous. The prefix before ':' can be omitted too. You can set one variable several times for
different closures, and thus you can get a particular settings for particular state. The closure is to be specified after variable name separated with slash
'/'.
The closure for 'dns:', 'net:', 'ftp:', 'http:', 'hftp:' domain variables is currently just the host name as you specify it in the 'open' command (with some
exceptions where closure is meaningless, e.g. dns:cache-size). For some 'cmd:' domain variables the closure is current URL without path. For other variables it
is not currently used. See examples in the sample lftp.conf.
Certain commands and settings take a time interval parameter. It has the format Nx[Nx...], where N is time amount (floating point) and x is time unit: d -
days, h - hours, m - minutes, s - seconds. Default unit is second. E.g. 5h30m or 5.5h. Also the interval can be 'infinity', 'inf', 'never', 'forever' - it
means infinite interval. E.g. 'sleep forever' or 'set dns:cache-expire never'.
Boolean settings can be one of (true, on, yes, 1, +) for a True value or one of (false, off, no, 0, -) for a False value.
Integer settings can have a suffix: k - kibi, m - mebi, g - gigi, etc. They can also have a prefix: 0 - octal, 0x - hexadecimal.

FTP asynchronous mode (pipelining)

Lftp can speed up ftp operations by sending several commands at once and then checking all the responses. See ftp:sync-mode variable. Sometimes this
does not work, thus synchronous mode is the default. You can try to turn synchronous mode off and see if it works for you. It is known that some network
software dealing with address translation works incorrectly in the case of several FTP commands in one network packet.
RFC959 says: ''The user-process sending another command before the completion reply would be in violation of protocol; but server-FTP processes should queue
any commands that arrive while a preceding command is in progress''. Also, RFC1123 says: ''Implementors MUST NOT assume any correspondence between READ
boundaries on the control connection and the Telnet EOL sequences (CR LF).'' and ''a single READ from the control connection may include more than one FTP
command''.
So it must be safe to send several commands at once, which speeds up operation a lot and seems to work with all Unix and VMS based ftp servers.
Unfortunately, windows based servers often cannot handle several commands in one packet, and so cannot some broken routers.

Options

-d
Switch on debugging mode
-e commands
Execute given commands and don't exit.
-p port
Use the given port to connect
-u user[,pass]
Use the given username and password to connect
-f script_file
Execute commands in the file and exit
-c commands
Execute the given commands and exit. Commands can be separated with a semicolon, '&&' or '||'.

Environment Variables
The following environment variables are processed by lftp:

HOME
Used for (local) tilde ('~') expansion

SHELL
Used by the ! command to determine the shell to run.

PAGER
This should be the name of the pager to use. It's used by the more and zmore commands.
http_proxy, https_proxy
Used to set initial http:proxy, hftp:proxy and https:proxy variables.
ftp_proxy
Used to set initial ftp:proxy or hftp:proxy variables, depending on URL protocol used in this environment variable.
no_proxy
Used to set initial net:no-proxy variable.
LFTP_MODULE_PATH
Used to set initial module:path variable.
LFTP_HOME
Used to locate the directory that stores user-specific configuration files. If unset, ~/.lftp will be used.
LS_COLORS
used to set initial color:dir-colors variable.

Files
/etc/lftp.conf

system-wide startup file. Actual location depends on --sysconfdir configure option. It is /etc when prefix is /usr, /usr/local/etc by
default.
~/.lftp/rc, ~/.lftprc
These files are executed on lftp startup after /etc/lftp.conf.
~/.lftp/log
The file things are logged to when lftp moves into the background in nohup mode.
~/.lftp/transfer_log
The file transfers are logged to when xfer:log setting is set to 'yes'.
~/.lftp/bookmarks
The file is used to store lftp's bookmarks. See the bookmark command.
~/.lftp/cwd_history
The file is used to store last working directories for each site visited.
~/.netrc
The file is consulted to get default login and password to ftp server. Passwords are also searched here if an URL with user name but with no password is
used.

See Also
ftpd(8), ftp(1)
RFC854 (telnet), RFC959 (ftp), RFC1123, RFC1945 (http/1.0), RFC2052 (SRV RR), RFC2228 (ftp security extensions), RFC2389 (ftp FEAT), RFC2428 (ftp/ipv6),
RFC2518 (WebDAV), RFC2616 (http/1.1), RFC2617 (http/1.1 authentication), RFC2640 (ftp i18n), RFC4217 (ftp over ssl).
http://www.ietf.org/internet-drafts/draft-ietf-ftpext-mlst-16.txt (ftp extensions over RFC959),
http://www.ietf.org/internet-drafts/draft-ietf-secsh-filexfer-10.txt (sftp).
http://wiki.theory.org/BitTorrentSpecification
Author
Alexander V. Lukyanov
lav@yars.free.net
Acknowledgments
This manual page was originally written by Christoph Lameter <clameter@debian.org>, for the Debian GNU/Linux system. The page was improved and updated
later by Nicolas Lichtmaier <nick@Feedback.com.ar>, James Troup <J.J.Troup@comp.brad.ac.uk> and Alexander V. Lukyanov
<lav@yars.free.net>.


Referenced By
lftp.conf(5),
lftpget(1)








Site Search











Library
linux docs
linux man pages
page load time


Toys
world sunlight
moon phase
trace explorer







",,"# lftp

> Sophisticated file transfer program.
> More information: <https://linux.die.net/man/1/lftp>.

- Connect to an FTP server:

`lftp {{ftp.example.com}}`

- Download multiple files (glob expression):

`mget {{path/to/*.png}}`

- Upload multiple files (glob expression):

`mput {{path/to/*.zip}}`

- Delete multiple files on the remote server:

`mrm {{path/to/*.txt}}`

- Rename a file on the remote server:

`mv {{original_filename}} {{new_filename}}`

- Download or update an entire directory:

`mirror {{path/to/remote_dir}} {{path/to/local_output_dir}}`

- Upload or update an entire directory:

`mirror -R {{path/to/local_dir}} {{path/to/remote_output_dir}}`
"
brew,,,"BREW(1) 			     brew			       BREW(1)



NAME
       brew - The Missing Package Manager for macOS

SYNOPSIS
       brew --version
       brew command [--verbose|-v] [options] [formula] ...

DESCRIPTION
       Homebrew is the easiest and most flexible way to install the UNIX tools
       Apple didn't include with macOS.

ESSENTIAL COMMANDS
       For the full command list, see the COMMANDS section.

       With --verbose or --debug, many commands print extra debugging informa-
       tion. Note that these options should only appear after a command.

   install formula:
       Install formula.

       formula is usually the name of the formula to install, but it has other
       syntaxes which are listed in the SPECIFYING FORMULAE section.

   uninstall formula:
       Uninstall formula.

   list:
       List all installed formulae.

   search (text|/text/):
       Perform a substring search of cask tokens and formula names  for  text.
       If  text  is flanked by slashes, it is interpreted as a regular expres-
       sion. The search for text is extended online to homebrew/core and home-
       brew/cask.  If no search term is provided, all locally available formu-
       lae are listed.

COMMANDS
   analytics [subcommand]
       Control Homebrew's anonymous aggregate user behaviour  analytics.  Read
       more at https://docs.brew.sh/Analytics.

       brew analytics [state]
	   Display the current state of Homebrew's analytics.

       brew analytics [on|off]
	   Turn Homebrew's analytics on or off respectively.

       brew analytics regenerate-uuid
	   Regenerate the UUID used for Homebrew's analytics.

   cask command [options] [cask]
       Homebrew  Cask  provides a friendly CLI workflow for the administration
       of macOS applications distributed as binaries.

       Commands:

       o   --cache
	   Display the file used to cache a cask

       o   audit
	   Check cask for Homebrew coding style violations

       o   cat
	   Dump raw source of a cask to the standard output

       o   create
	   Creates the given cask and opens it in an editor

       o   doctor
	   Checks for configuration issues

       o   edit
	   Open the given cask for editing

       o   fetch
	   Downloads remote application files to local cache

       o   help
	   Print help for cask commands

       o   home
	   Opens the homepage of the given cask

       o   info
	   Displays information about the given cask

       o   install
	   Installs the given cask

       o   list
	   Lists installed casks or the casks provided in the arguments

       o   outdated
	   List the outdated installed casks

       o   reinstall
	   Reinstalls the given cask

       o   style
	   Checks style of the given cask using RuboCop

       o   uninstall
	   Uninstalls the given cask

       o   upgrade
	   Upgrades all outdated casks or the specified casks

       o   zap
	   Zaps all files associated with the given cask



       See also: man brew

       --appdir
	      Target location for Applications. Default: /Applications

       --colorpickerdir
	      Target location for Color Pickers. Default: ~/Library/ColorPick-
	      ers

       --prefpanedir
	      Target location for Preference Panes. Default: ~/Library/Prefer-
	      encePanes

       --qlplugindir
	      Target location for QuickLook Plugins. Default: ~/Library/Quick-
	      Look

       --mdimporterdir
	      Target  location for Spotlight Plugins. Default: ~/Library/Spot-
	      light

       --dictionarydir
	      Target location for Dictionaries. Default:  ~/Library/Dictionar-
	      ies

       --fontdir
	      Target location for Fonts. Default: ~/Library/Fonts

       --servicedir
	      Target location for Services. Default: ~/Library/Services

       --input_methoddir
	      Target  location	for  Input  Methods.  Default: ~/Library/Input
	      Methods

       --internet_plugindir
	      Target location for Internet Plugins. Default:  ~/Library/Inter-
	      net Plug-Ins

       --audio_unit_plugindir
	      Target	location    for    Audio    Unit   Plugins.   Default:
	      ~/Library/Audio/Plug-Ins/Components

       --vst_plugindir
	      Target	 location     for      VST	Plugins.      Default:
	      ~/Library/Audio/Plug-Ins/VST

       --vst3_plugindir
	      Target	  location	for	VST3	 Plugins.     Default:
	      ~/Library/Audio/Plug-Ins/VST3

       --screen_saverdir
	      Target location for  Screen  Savers.  Default:  ~/Library/Screen
	      Savers

       --language
	      Set language of the Cask to install. The first matching language
	      is used, otherwise the default language on the Cask. The default
	      value is the language of your system

   cleanup [options] [formula|cask]
       Remove  stale  lock  files  and outdated downloads for all formulae and
       casks, and remove old versions of installed formulae. If arguments  are
       specified,  only  do this for the given formulae and casks. Removes all
       downloads more than 120 days old.  This	can  be  adjusted  with  HOME-
       BREW_CLEANUP_MAX_AGE_DAYS.

       --prune
	      Remove all cache files older than specified days.

       -n, --dry-run
	      Show what would be removed, but do not actually remove anything.

       -s     Scrub the cache, including downloads for even  the  latest  ver-
	      sions.  Note  downloads for any installed formulae or casks will
	      still not be deleted. If you want to delete those  too:  rm  -rf
	      ""$(brew --cache)""

       --prune-prefix
	      Only  prune  the	symlinks  and  directories from the prefix and
	      remove no other files.

   commands [options]
       Show lists of built-in and external commands.

       -q, --quiet
	      List only the names of commands without category headers.

       --include-aliases
	      Include aliases of internal commands.

   config
       Show Homebrew and system configuration info useful  for	debugging.  If
       you  file  a  bug report, you will be required to provide this informa-
       tion.

   deps [options] [formula]
       Show dependencies for formula. Additional options specific  to  formula
       may  be appended to the command. When given multiple formula arguments,
       show the intersection of dependencies for each formula.

       -n     Sort dependencies in topological order.

       --1    Only show dependencies one level down, instead of recursing.

       --union
	      Show the union of dependencies for multiple formula, instead  of
	      the intersection.

       --full-name
	      List dependencies by their full name.

       --include-build
	      Include :build dependencies for formula.

       --include-optional
	      Include :optional dependencies for formula.

       --include-test
	      Include :test dependencies for formula (non-recursive).

       --skip-recommended
	      Skip :recommended dependencies for formula.

       --include-requirements
	      Include requirements in addition to dependencies for formula.

       --tree Show  dependencies  as a tree. When given multiple formula argu-
	      ments, show individual trees for each formula.

       --annotate
	      Mark any build, test, optional, or recommended  dependencies  as
	      such in the output.

       --installed
	      List  dependencies for formulae that are currently installed. If
	      formula is specified, list only its dependencies that  are  cur-
	      rently installed.

       --all  List dependencies for all available formulae.

       --for-each
	      Switch  into  the  mode  used by the --all option, but only list
	      dependencies for each provided formula, one  formula  per  line.
	      This is used for debugging the --installed/--all display mode.

   desc [options] (text|/text/|formula)
       Display	formula's  name and one-line description. Formula descriptions
       are cached; the cache is created  on  the  first  search,  making  that
       search slower than subsequent ones.

       -s, --search
	      Search  both names and descriptions for text. If text is flanked
	      by slashes, it is interpreted as a regular expression.

       -n, --name
	      Search just names for text. If text is flanked by slashes, it is
	      interpreted as a regular expression.

       -d, --description
	      Search  just  descriptions  for  text.  If  text	is  flanked by
	      slashes, it is interpreted as a regular expression.

   doctor [options]
       Check your system for potential problems. Will  exit  with  a  non-zero
       status  if  any	potential  problems  are found. Please note that these
       warnings are just used to help the Homebrew maintainers with  debugging
       if  you	file  an  issue. If everything you use Homebrew for is working
       fine: please don't worry or file an issue; just ignore this.

       --list-checks
	      List all audit methods, which can be run	individually  if  pro-
	      vided as arguments.

       -D, --audit-debug
	      Enable debugging and profiling of audit methods.

   fetch [options] formula
       Download  a  bottle  (if available) or source packages for formula. For
       tarballs, also print SHA-256 checksums.

       --HEAD Fetch HEAD version instead of stable version.

       --devel
	      Fetch development version instead of stable version.

       -f, --force
	      Remove a previously cached version and re-fetch.

       -v, --verbose
	      Do a verbose VCS checkout, if the URL represents a VCS. This  is
	      useful for seeing if an existing VCS cache has been updated.

       --retry
	      Retry  if  downloading fails or re-download if the checksum of a
	      previously cached version no longer matches.

       --deps Also download dependencies for any listed formula.

       -s, --build-from-source
	      Download source packages rather than a bottle.

       --build-bottle
	      Download source packages (for eventual bottling) rather  than  a
	      bottle.

       --force-bottle
	      Download a bottle if it exists for the current or newest version
	      of macOS, even if it would not be used during installation.

   gist-logs [options] formula
       Upload logs for a failed build of formula to a new  Gist.  Presents  an
       error message if no logs are found.

       --with-hostname
	      Include the hostname in the Gist.

       -n, --new-issue
	      Automatically  create  a	new  issue  in	the appropriate GitHub
	      repository after creating the Gist.

       -p, --private
	      The Gist will be marked private and will not appear in  listings
	      but will be accessible with its link.

   home [formula]
       Open  formula's	homepage in a browser, or open Homebrew's own homepage
       if no formula is provided.

   info [options] [formula]
       Display brief statistics for your Homebrew installation.

       If formula is provided, show summary of information about formula.

       --analytics
	      List global Homebrew analytics data or, if specified,  installa-
	      tion  and  build	error data for formula (provided neither HOME-
	      BREW_NO_ANALYTICS nor HOMEBREW_NO_GITHUB_API are set).

       --days How many days of analytics data to retrieve. The value for  days
	      must be 30, 90 or 365. The default is 30.

       --category
	      Which type of analytics data to retrieve. The value for category
	      must be install, install-on-request or build-error; cask-install
	      or os-version may be specified if formula is not. The default is
	      install.

       --github
	      Open the GitHub source page for formula in a  browser.  To  view
	      formula history locally: brew log -p formula

       --json Print  a	JSON  representation of formula. Currently the default
	      and only accepted value for version is  v1.  See	the  docs  for
	      examples	of  using the JSON output: https://docs.brew.sh/Query-
	      ing-Brew

       --installed
	      Print JSON of formulae that are currently installed.

       --all  Print JSON of all available formulae.

       -v, --verbose
	      Show more verbose analytics data for formula.

   install [options] formula
       Install formula. Additional options specific to formula may be appended
       to the command.

       Unless  HOMEBREW_NO_INSTALL_CLEANUP  is	set, brew cleanup will then be
       run for the installed formulae or, every 30 days, for all formulae.

       -d, --debug
	      If brewing fails, open an  interactive  debugging  session  with
	      access to IRB or a shell inside the temporary build directory.

       --env  If  std is passed, use the standard build environment instead of
	      superenv. If super is passed, use superenv even if  the  formula
	      specifies the standard build environment.

       --ignore-dependencies
	      An  unsupported Homebrew development flag to skip installing any
	      dependencies of any kind. If the dependencies  are  not  already
	      present,	the formula will have issues. If you're not developing
	      Homebrew, consider adjusting your PATH rather  than  using  this
	      flag.

       --only-dependencies
	      Install  the  dependencies  with	specified  options  but do not
	      install the formula itself.

       --cc   Attempt to compile using the specified compiler, which should be
	      the  name of the compiler's executable, e.g. gcc-7 for GCC 7. In
	      order to use  LLVM's  clang,  specify  llvm_clang.  To  use  the
	      Apple-provided  clang,  specify  clang.  This  option  will only
	      accept compilers that are provided by Homebrew or  bundled  with
	      macOS.  Please  do not file issues if you encounter errors while
	      using this option.

       -s, --build-from-source
	      Compile formula from source even if a bottle is provided. Depen-
	      dencies  will still be installed from bottles if they are avail-
	      able.

       --force-bottle
	      Install from a bottle if it exists for  the  current  or	newest
	      version  of  macOS,  even  if  it would not normally be used for
	      installation.

       --include-test
	      Install testing dependencies required to run brew test  formula.

       --HEAD If  formula  defines  it, install the HEAD version, aka. master,
	      trunk, unstable.

       --fetch-HEAD
	      Fetch the upstream repository to detect if the HEAD installation
	      of  the  formula	is  outdated. Otherwise, the repository's HEAD
	      will only be checked for updates when a new stable  or  develop-
	      ment version has been released.

       --keep-tmp
	      Retain the temporary files created during installation.

       --build-bottle
	      Prepare  the  formula for eventual bottling during installation,
	      skipping any post-install steps.

       --bottle-arch
	      Optimise bottles for the specified architecture rather than  the
	      oldest  architecture  supported by the version of macOS the bot-
	      tles are built on.

       -f, --force
	      Install without checking for previously  installed  keg-only  or
	      non-migrated versions.

       -v, --verbose
	      Print the verification and postinstall steps.

       --display-times
	      Print install times for each formula at the end of the run.

       -i, --interactive
	      Download	and  patch formula, then open a shell. This allows the
	      user to run ./configure --help and otherwise  determine  how  to
	      turn the software package into a Homebrew package.

       -g, --git
	      Create  a  Git  repository,  useful  for creating patches to the
	      software.

   leaves
       List installed formulae that are not dependencies of another  installed
       formula.

   link, ln [options] formula
       Symlink	all  of formula's installed files into Homebrew's prefix. This
       is done automatically when you install formulae but can be  useful  for
       DIY installations.

       --overwrite
	      Delete files that already exist in the prefix while linking.

       -n, --dry-run
	      List files which would be linked or deleted by brew link --over-
	      write without actually linking or deleting any files.

       -f, --force
	      Allow keg-only formulae to be linked.

   list, ls [options] [formula|cask]
       List all installed formulae or casks

       If formula is provided, summarise the paths within its current keg.

       --full-name
	      Print formulae with fully-qualified names. If --full-name is not
	      passed,  other  options  (i.e.  -1, -l, -r and -t) are passed to
	      ls(1) which produces the actual output.

       --unbrewed
	      List files in Homebrew's prefix not installed by Homebrew.

       --versions
	      Show the version number for  installed  formulae,  or  only  the
	      specified formulae if formula are provided.

       --multiple
	      Only show formulae with multiple versions installed.

       --pinned
	      Show  the  versions  of  pinned  formulae, or only the specified
	      (pinned) formulae if formula are provided. See also pin,	unpin.

       --formula
	      List only formulae.

       --cask List only casks.

       -1     Force  output to be one entry per line. This is the default when
	      output is not to a terminal.

       -l     List in long format. If the output is to a terminal, a total sum
	      for all the file sizes is printed before the long listing.

       -r     Reverse  the order of the sort to list the oldest entries first.

       -t     Sort by time modified, listing most recently modified first.

   log [options] [formula]
       Show the git log for formula, or show the log for the Homebrew  reposi-
       tory if no formula is provided.

       -p, --patch
	      Also print patch from commit.

       --stat Also print diffstat from commit.

       --oneline
	      Print only one line per commit.

       -1     Print only one commit.

       -n, --max-count
	      Print only a specified number of commits.

   migrate [options] formula
       Migrate	renamed  packages to new names, where formula are old names of
       packages.

       -f, --force
	      Treat installed formula and provided formula as if they are from
	      the same taps and migrate them anyway.

   missing [options] [formula]
       Check  the  given  formula kegs for missing dependencies. If no formula
       are provided, check all kegs. Will exit with a non-zero status  if  any
       kegs are found to be missing dependencies.

       --hide Act  as  if  none  of the specified hidden are installed. hidden
	      should be a comma-separated list of formulae.

   options [options] [formula]
       Show install options specific to formula.

       --compact
	      Show all options on a single line separated by spaces.

       --installed
	      Show options for formulae that are currently installed.

       --all  Show options for all available formulae.

       --command
	      Show options for the specified command.

   outdated [options] [formula|cask]
       List installed casks and formulae that have an updated  version	avail-
       able.  By  default,  version  information  is  displayed in interactive
       shells, and suppressed otherwise.

       -q, --quiet
	      List only the names of  outdated	kegs  (takes  precedence  over
	      --verbose).

       -v, --verbose
	      Include detailed version information.

       --formula
	      Only output outdated formulae.

       --cask Only output outdated casks.

       --json Print  output in JSON format. There are two versions: v1 and v2.
	      v1 is deprecated and is currently the default if no  version  is
	      specified. v2 prints outdated formulae and casks.

       --fetch-HEAD
	      Fetch the upstream repository to detect if the HEAD installation
	      of the formula is outdated.  Otherwise,  the  repository's  HEAD
	      will  only  be checked for updates when a new stable or develop-
	      ment version has been released.

       --greedy
	      Print outdated casks with auto_updates or version :latest.

   pin formula
       Pin the specified formula, preventing them  from  being	upgraded  when
       issuing the brew upgrade formula command. See also unpin.

   postinstall formula
       Rerun the post-install steps for formula.

   readall [options] [tap]
       Import  all items from the specified tap, or from all installed taps if
       none is provided. This can be useful for debugging  issues  across  all
       items  when  making significant changes to formula.rb, testing the per-
       formance of loading all items or checking if any current formulae/casks
       have Ruby issues.

       --aliases
	      Verify any alias symlinks in each tap.

       --syntax
	      Syntax-check  all  of  Homebrew's  Ruby  files  (if  no <tap> is
	      passed).

   reinstall [options] formula
       Uninstall and then install formula using the same options it was origi-
       nally installed with, plus any appended brew formula options.

       Unless  HOMEBREW_NO_INSTALL_CLEANUP  is	set, brew cleanup will then be
       run for the reinstalled formulae or, every 30 days, for all formulae.

       -d, --debug
	      If brewing fails, open an  interactive  debugging  session  with
	      access to IRB or a shell inside the temporary build directory.

       -s, --build-from-source
	      Compile formula from source even if a bottle is available.

       -i, --interactive
	      Download	and  patch formula, then open a shell. This allows the
	      user to run ./configure --help and otherwise  determine  how  to
	      turn the software package into a Homebrew package.

       --force-bottle
	      Install  from  a	bottle	if it exists for the current or newest
	      version of macOS, even if it would  not  normally  be  used  for
	      installation.

       --keep-tmp
	      Retain the temporary files created during installation.

       -f, --force
	      Install  without	checking  for previously installed keg-only or
	      non-migrated versions.

       -v, --verbose
	      Print the verification and postinstall steps.

       --display-times
	      Print install times for each formula at the end of the run.

   search [options] [text|/text/]
       Perform a substring search of cask tokens and formula names  for  text.
       If  text  is flanked by slashes, it is interpreted as a regular expres-
       sion. The search for text is extended online to homebrew/core and home-
       brew/cask.

       If  no text is provided, list all locally available formulae (including
       tapped ones). No online search is performed.

       --formula
	      Without text, list all locally  available  formulae  (no	online
	      search  is  performed). With text, search online and locally for
	      formulae.

       --cask Without text, list all locally available casks (including tapped
	      ones,  no  online search is performed). With text, search online
	      and locally for casks.

       --desc Search for formulae with a description matching text  and  casks
	      with a name matching text.

       --macports
	      Search for text in the given package manager's list.

       --fink Search for text in the given package manager's list.

       --opensuse
	      Search for text in the given package manager's list.

       --fedora
	      Search for text in the given package manager's list.

       --debian
	      Search for text in the given package manager's list.

       --ubuntu
	      Search for text in the given package manager's list.

   shellenv
       Print  export  statements.  When  run  in a shell, this installation of
       Homebrew will be added to your PATH, MANPATH, and INFOPATH.

       The variables HOMEBREW_PREFIX, HOMEBREW_CELLAR and  HOMEBREW_REPOSITORY
       are  also  exported  to	avoid  querying  them multiple times. Consider
       adding evaluation of this  command's  output  to  your  dotfiles  (e.g.
       ~/.profile,  ~/.bash_profile,  or  ~/.zprofile) with: eval $(brew shel-
       lenv)

   switch formula version
       Symlink all of the specified version  of  formula's  installation  into
       Homebrew's prefix.

   tap [options] [user/repo] [URL]
       Tap a formula repository.

       If no arguments are provided, list all installed taps.

       With URL unspecified, tap a formula repository from GitHub using HTTPS.
       Since so many taps are hosted on GitHub, this command is a shortcut for
       brew tap user/repo https://github.com/user/homebrew-repo.

       With  URL  specified, tap a formula repository from anywhere, using any
       transport protocol that git(1) handles. The one-argument  form  of  tap
       simplifies  but also limits. This two-argument command makes no assump-
       tions, so taps can be cloned from places other than  GitHub  and  using
       protocols other than HTTPS, e.g. SSH, git, HTTP, FTP(S), rsync.

       --full Convert  a shallow clone to a full clone without untapping. Taps
	      are only cloned as shallow clones on continuous integration,  or
	      if --shallow was originally passed.

       --shallow
	      Fetch  tap  as  a shallow clone rather than a full clone. Useful
	      for continuous integration.

       --force-auto-update
	      Auto-update tap even if it is not hosted on GitHub. By  default,
	      only  taps  hosted  on  GitHub are auto-updated (for performance
	      reasons).

       --repair
	      Migrate tapped formulae from  symlink-based  to  directory-based
	      structure.

       --list-pinned
	      List all pinned taps.

   tap-info [options] [tap]
       Show detailed information about one or more taps.

       If  no  tap  names  are	provided,  display  brief  statistics  for all
       installed taps.

       --installed
	      Show information on each installed tap.

       --json Print a JSON representation of tap. Currently  the  default  and
	      only accepted value for version is v1. See the docs for examples
	      of using the JSON output: https://docs.brew.sh/Querying-Brew

   uninstall, rm, remove [options] formula
       Uninstall formula.

       -f, --force
	      Delete all installed versions of formula.

       --ignore-dependencies
	      Don't fail uninstall, even if formula is	a  dependency  of  any
	      installed formulae.

   unlink [options] formula
       Remove  symlinks for formula from Homebrew's prefix. This can be useful
       for temporarily disabling a formula: brew unlink formula && commands &&
       brew link formula

       -n, --dry-run
	      List files which would be unlinked without actually unlinking or
	      deleting any files.

   unpin formula
       Unpin formula, allowing them to be upgraded by  brew  upgrade  formula.
       See also pin.

   untap tap
       Remove a tapped formula repository.

   update [options]
       Fetch the newest version of Homebrew and all formulae from GitHub using
       git(1) and perform any necessary migrations.

       --merge
	      Use git merge to apply updates (rather than git rebase).

       --preinstall
	      Run on auto-updates  (e.g.  before  brew	install).  Skips  some
	      slower steps.

       -f, --force
	      Always do a slower, full update check (even if unnecessary).

   update-reset [repository]
       Fetch  and  reset  Homebrew  and all tap repositories (or any specified
       repository) using git(1) to their latest origin/master.

       Note: this will destroy all your uncommitted or committed changes.

   upgrade [options] [formula|cask]
       Upgrade outdated casks and outdated, unpinned formulae using  the  same
       options	they  were  originally	installed with, plus any appended brew
       formula options. If cask or formula are	specified,  upgrade  only  the
       given cask or formula kegs (unless they are pinned; see pin, unpin).

       Unless  HOMEBREW_NO_INSTALL_CLEANUP  is	set, brew cleanup will then be
       run for the upgraded formulae or, every 30 days, for all formulae.

       -d, --debug
	      If brewing fails, open an  interactive  debugging  session  with
	      access to IRB or a shell inside the temporary build directory.

       --formula
	      Only upgrade outdated formulae.

       --cask Only upgrade outdated casks.

       -s, --build-from-source
	      Compile formula from source even if a bottle is available.

       -i, --interactive
	      Download	and  patch formula, then open a shell. This allows the
	      user to run ./configure --help and otherwise  determine  how  to
	      turn the software package into a Homebrew package.

       --force-bottle
	      Install  from  a	bottle	if it exists for the current or newest
	      version of macOS, even if it would  not  normally  be  used  for
	      installation.

       --fetch-HEAD
	      Fetch the upstream repository to detect if the HEAD installation
	      of the formula is outdated.  Otherwise,  the  repository's  HEAD
	      will  only  be checked for updates when a new stable or develop-
	      ment version has been released.

       --ignore-pinned
	      Set a successful exit status even if  pinned  formulae  are  not
	      upgraded.

       --keep-tmp
	      Retain the temporary files created during installation.

       -f, --force
	      Install  without	checking  for previously installed keg-only or
	      non-migrated versions.

       -v, --verbose
	      Print the verification and postinstall steps.

       --display-times
	      Print install times for each formula at the end of the run.

       -n, --dry-run
	      Show what would be upgraded, but do not  actually  upgrade  any-
	      thing.

       --greedy
	      Upgrade casks with auto_updates or version :latest

   uses [options] formula
       Show  formulae  that  specify formula as a dependency (i.e. show depen-
       dents of formula). When given  multiple	formula  arguments,  show  the
       intersection  of  formulae that use formula. By default, uses shows all
       formulae that specify formula as a required or  recommended  dependency
       for their stable builds.

       --recursive
	      Resolve more than one level of dependencies.

       --installed
	      Only list formulae that are currently installed.

       --include-build
	      Include  all formulae that specify formula as :build type depen-
	      dency.

       --include-test
	      Include all formulae that specify formula as :test  type	depen-
	      dency.

       --include-optional
	      Include  all  formulae  that  specify  formula as :optional type
	      dependency.

       --skip-recommended
	      Skip all formulae that  specify  formula	as  :recommended  type
	      dependency.

   --cache [options] [formula|cask]
       Display Homebrew's download cache. See also HOMEBREW_CACHE.

       If  formula  is	provided,  display the file or directory used to cache
       formula.

       -s, --build-from-source
	      Show the cache file used when building from source.

       --force-bottle
	      Show the cache file used when pouring a bottle.

       --formula
	      Only show cache files for formulae.

       --cask Only show cache files for casks.

   --caskroom [cask]
       Display Homebrew's Caskroom path.

       If cask is provided, display the location in the  Caskroom  where  cask
       would be installed, without any sort of versioned directory as the last
       path.

   --cellar [formula]
       Display Homebrew's Cellar path. Default: $(brew --prefix)/Cellar, or if
       that directory doesn't exist, $(brew --repository)/Cellar.

       If  formula  is provided, display the location in the Cellar where for-
       mula would be installed, without any sort of versioned directory as the
       last path.

   --env [options] [formula]
       Summarise Homebrew's build environment as a plain list.

       If  the	command's output is sent through a pipe and no shell is speci-
       fied, the list is formatted for export to  bash(1)  unless  --plain  is
       passed.

       --shell
	      Generate	a  list  of  environment  variables  for the specified
	      shell, or --shell=auto to detect the current shell.

       --plain
	      Generate plain output even when piped.

   --prefix [formula]
       Display Homebrew's install  path.  Default:  /usr/local	on  macOS  and
       /home/linuxbrew/.linuxbrew on Linux.

       If  formula  is provided, display the location in the Cellar where for-
       mula is or would be installed.

   --repository, --repo [user/repo]
       Display where Homebrew's .git directory is located.

       If user/repo are provided, display where tap user/repo's  directory  is
       located.

   --version
       Print the version numbers of Homebrew, Homebrew/homebrew-core and Home-
       brew/homebrew-cask (if tapped) to standard output.

DEVELOPER COMMANDS
   audit [options] [formula]
       Check formula for Homebrew coding style violations. This should be  run
       before  submitting a new formula. If no formula are provided, check all
       locally available formulae and skip style  checks.  Will  exit  with  a
       non-zero status if any errors are found.

       --strict
	      Run additional, stricter style checks.

       --git  Run additional, slower style checks that navigate the Git repos-
	      itory.

       --online
	      Run additional, slower style checks that require a network  con-
	      nection.

       --new-formula
	      Run  various  additional style checks to determine if a new for-
	      mula is eligible for Homebrew. This should be used when creating
	      new formula and implies --strict and --online.

       --tap  Check the formulae within the given tap, specified as user/repo.

       --fix  Fix style violations automatically using RuboCop's  auto-correct
	      feature.

       --display-cop-names
	      Include the RuboCop cop name for each violation in the output.

       --display-filename
	      Prefix  every line of output with the file or formula name being
	      audited, to make output easy to grep.

       --skip-style
	      Skip running non-RuboCop style checks. Useful  if  you  plan  on
	      running brew style separately. Default unless a formula is spec-
	      ified by name

       -D, --audit-debug
	      Enable debugging and profiling of audit methods.

       --only Specify a comma-separated method list to only  run  the  methods
	      named audit_method.

       --except
	      Specify  a comma-separated method list to skip running the meth-
	      ods named audit_method.

       --only-cops
	      Specify a comma-separated cops list to check for	violations  of
	      only the listed RuboCop cops.

       --except-cops
	      Specify  a comma-separated cops list to skip checking for viola-
	      tions of the listed RuboCop cops.

   bottle [options] formula
       Generate a bottle (binary package) from a formula  that	was  installed
       with  --build-bottle.  If  the  formula specifies a rebuild version, it
       will be incremented in  the  generated  DSL.  Passing  --keep-old  will
       attempt	to  keep  it  at  its  original value, while --no-rebuild will
       remove it.

       --skip-relocation
	      Do not check if the bottle can be marked as relocatable.

       --force-core-tap
	      Build a bottle even if formula is not in	homebrew/core  or  any
	      installed taps.

       --no-rebuild
	      If  the  formula specifies a rebuild version, remove it from the
	      generated DSL.

       --keep-old
	      If the formula specifies a rebuild version, attempt to  preserve
	      its value in the generated DSL.

       --json Write  bottle  information  to a JSON file, which can be used as
	      the value for --merge.

       --merge
	      Generate an updated bottle block for a  formula  and  optionally
	      merge  it  into  the  formula  file.  Instead of a formula name,
	      requires the path to a JSON  file  generated  with  brew	bottle
	      --json formula.

       --write
	      Write  changes  to the formula file. A new commit will be gener-
	      ated unless --no-commit is passed.

       --no-commit
	      When passed with --write, a new commit will not generated  after
	      writing changes to the formula file.

       --root-url
	      Use the specified URL as the root of the bottle's URL instead of
	      Homebrew's default.

   bump [options] [formula]
       Display out-of-date brew formulae and  the  latest  version  available.
       Also displays whether a pull request has been opened with the URL.

       --limit
	      Limit number of package results returned.

   bump-cask-pr [options] [cask]
       Create a pull request to update cask with a new version.

       A best effort to determine the SHA-256 will be made if the value is not
       supplied by the user.

       -n, --dry-run
	      Print what would be done rather than doing it.

       --write
	      Make the expected file  modifications  without  taking  any  Git
	      actions.

       --commit
	      When  passed  with  --write, generate a new commit after writing
	      changes to the cask file.

       --no-audit
	      Don't run brew cask audit before opening the PR.

       --no-style
	      Don't run brew cask style --fix before opening the PR.

       --no-browse
	      Print the pull request URL instead of opening in a browser.

       --no-fork
	      Don't try to fork the repository.

       --version
	      Specify the new version for the cask.

       --message
	      Append message to the default pull request message.

       --url  Specify the URL for the new download.

       --sha256
	      Specify the SHA-256 checksum of the new download.

       -f, --force
	      Ignore duplicate open PRs.

   bump-formula-pr [options] [formula]
       Create a pull request to update formula with a new URL or a new tag.

       If a URL is specified, the SHA-256 checksum of the new download	should
       also  be  specified. A best effort to determine the SHA-256 and formula
       name will be made if either or both values  are	not  supplied  by  the
       user.

       If  a  tag  is specified, the Git commit revision corresponding to that
       tag should also be specified. A best effort to determine  the  revision
       will be made if the value is not supplied by the user.

       If  a  version  is  specified,  a  best effort to determine the URL and
       SHA-256 or the tag and revision will be made if	both  values  are  not
       supplied by the user.

       Note:  this  command  cannot  be  used  to  transition a formula from a
       URL-and-SHA-256 style specification into a tag-and-revision style spec-
       ification,  nor	vice  versa. It must use whichever style specification
       the formula already uses.

       -n, --dry-run
	      Print what would be done rather than doing it.

       --write
	      Make the expected file  modifications  without  taking  any  Git
	      actions.

       --commit
	      When  passed  with  --write, generate a new commit after writing
	      changes to the formula file.

       --no-audit
	      Don't run brew audit before opening the PR.

       --strict
	      Run brew audit --strict before opening the PR.

       --no-browse
	      Print the pull request URL instead of opening in a browser.

       --no-fork
	      Don't try to fork the repository.

       --mirror
	      Use the specified URL as a mirror URL. If URL is	a  comma-sepa-
	      rated list of URLs, multiple mirrors will be added.

       --version
	      Use  the specified version to override the value parsed from the
	      URL or tag. Note that --version=0  can  be  used	to  delete  an
	      existing version override from a formula if it has become redun-
	      dant.

       --message
	      Append message to the default pull request message.

       --url  Specify the URL for the new download. If a URL is specified, the
	      SHA-256 checksum of the new download should also be specified.

       --sha256
	      Specify the SHA-256 checksum of the new download.

       --tag  Specify the new git commit tag for the formula.

       --revision
	      Specify  the new git commit revision corresponding to the speci-
	      fied tag.

       -f, --force
	      Ignore duplicate open PRs. Remove all mirrors if	--mirror=  was
	      not specified.

   bump-revision [options] formula [formula ...]
       Create a commit to increment the revision of formula. If no revision is
       present, ""revision 1"" will be added.

       -n, --dry-run
	      Print what would be done rather than doing it.

       --message
	      Append message to the default commit message.

   cat formula
       Display the source of formula.

   command cmd
       Display the path to the file being used when invoking brew cmd.

   create [options] URL
       Generate a formula for the downloadable file at URL and open it in  the
       editor.	Homebrew will attempt to automatically derive the formula name
       and version, but if it fails, you'll have to make  your	own  template.
       The wget formula serves as a simple example. For the complete API, see:
       https://rubydoc.brew.sh/Formula

       --autotools
	      Create a basic template for an Autotools-style build.

       --cmake
	      Create a basic template for a CMake-style build.

       --crystal
	      Create a basic template for a Crystal build.

       --go   Create a basic template for a Go build.

       --meson
	      Create a basic template for a Meson-style build.

       --node Create a basic template for a Node build.

       --perl Create a basic template for a Perl build.

       --python
	      Create a basic template for a Python build.

       --ruby Create a basic template for a Ruby build.

       --rust Create a basic template for a Rust build.

       --no-fetch
	      Homebrew will not download URL to the cache and  will  thus  not
	      add  its	SHA-256  to the formula for you, nor will it check the
	      GitHub API for GitHub projects (to fill out its description  and
	      homepage).

       --HEAD Indicate that URL points to the package's repository rather than
	      a file.

       --set-name
	      Explicitly set the name of the new formula.

       --set-version
	      Explicitly set the version of the new formula.

       --set-license
	      Explicitly set the license of the new formula.

       --tap  Generate the new formula within  the  given  tap,  specified  as
	      user/repo.

       -f, --force
	      Ignore errors for disallowed formula names and named that shadow
	      aliases.

   diy [options]
       Automatically determine the installation prefix for non-Homebrew  soft-
       ware.  Using  the  output  from	this command, you can install your own
       software into the Cellar and then link it into Homebrew's  prefix  with
       brew link.

       --name Explicitly set the name of the package being installed.

       --version
	      Explicitly set the version of the package being installed.

   edit [formula]
       Open  formula  in  the editor set by EDITOR or HOMEBREW_EDITOR, or open
       the Homebrew repository for editing if no formula is provided.

   extract [options] formula tap
       Look through repository history to find the most recent version of for-
       mula and create a copy in tap/Formula/formula@version.rb. If the tap is
       not installed yet, attempt to install/clone the tap before  continuing.
       To  extract  a  formula	from  a  tap that is not homebrew/core use its
       fully-qualified form of user/repo/formula.

       --version
	      Extract the specified version of formula	instead  of  the  most
	      recent.

       -f, --force
	      Overwrite the destination formula if it already exists.

   formula formula
       Display the path where formula is located.

   install-bundler-gems
       Install Homebrew's Bundler gems.

   irb [options]
       Enter the interactive Homebrew Ruby shell.

       --examples
	      Show several examples.

       --pry  Use Pry instead of IRB. Implied if HOMEBREW_PRY is set.

   linkage [options] [formula]
       Check  the library links from the given formula kegs. If no formula are
       provided, check all kegs. Raises an error if run on uninstalled	formu-
       lae.

       --test Show  only  missing libraries and exit with a non-zero status if
	      any missing libraries are found.

       --reverse
	      For every library that a keg references, print  its  dylib  path
	      followed by the binaries that link to it.

       --cached
	      Print the cached linkage values stored in HOMEBREW_CACHE, set by
	      a previous brew linkage run.

   livecheck [formulae]
       Check for newer versions of formulae from upstream.

       If no formula argument is passed, the list  of  formulae  to  check  is
       taken from HOMEBREW_LIVECHECK_WATCHLIST or ~/.brew_livecheck_watchlist.

       --full-name
	      Print formulae with fully-qualified names.

       --tap  Check the formulae within the given tap, specified as user/repo.

       --installed
	      Check formulae that are currently installed.

       --json Output informations in JSON format.

       --all  Check all available formulae.

       --newer-only
	      Show the latest version only if it's newer than the formula.

   man [options]
       Generate Homebrew's manpages.

       --fail-if-changed
	      Return a failing status code if changes are detected in the man-
	      page outputs. This can be used to notify CI  when  the  manpages
	      are  out	of  date.  Additionally, the date used in new manpages
	      will match those in the existing manpages (to  allow  comparison
	      without factoring in the date).

       --link This is now done automatically by brew update.

   pr-automerge [options]
       Find  pull requests that can be automatically merged using brew pr-pub-
       lish.

       --tap  Target tap repository (default: homebrew/core).

       --with-label
	      Pull requests must have this label.

       --without-labels
	      Pull requests must not have these labels (default: do not merge,
	      new formula).

       --without-approval
	      Pull requests do not require approval to be merged.

       --publish
	      Run brew pr-publish on matching pull requests.

       --ignore-failures
	      Include pull requests that have failing status checks.

   pr-publish [options] pull_request [pull_request ...]
       Publish	bottles for a pull request with GitHub Actions. Requires write
       access to the repository.

       --tap  Target tap repository (default: homebrew/core).

       --workflow
	      Target workflow filename (default:  publish-commit-bottles.yml).

   pr-pull [options] pull_request [pull_request ...]
       Download  and  publish bottles, and apply the bottle commit from a pull
       request with artifacts generated  by  GitHub  Actions.  Requires  write
       access to the repository.

       --no-publish
	      Download	the  bottles,  apply  the bottle commit and upload the
	      bottles to Bintray, but don't publish them.

       --no-upload
	      Download the bottles and apply  the  bottle  commit,  but  don't
	      upload to Bintray.

       -n, --dry-run
	      Print what would be done rather than doing it.

       --clean
	      Do not amend the commits from pull requests.

       --keep-old
	      If  the formula specifies a rebuild version, attempt to preserve
	      its value in the generated DSL.

       --branch-okay
	      Do not warn if pulling to a branch besides  master  (useful  for
	      testing).

       --resolve
	      When a patch fails to apply, leave in progress and allow user to
	      resolve, instead of aborting.

       --warn-on-upload-failure
	      Warn instead of raising an error if  the	bottle	upload	fails.
	      Useful for repairing bottle uploads that previously failed.

       --workflow
	      Retrieve	 artifacts   from  the	specified  workflow  (default:
	      tests.yml).

       --artifact
	      Download artifacts with the specified name (default: bottles).

       --bintray-org
	      Upload to the specified  Bintray	organisation  (default:  home-
	      brew).

       --tap  Target tap repository (default: homebrew/core).

       --root-url
	      Use the specified URL as the root of the bottle's URL instead of
	      Homebrew's default.

       --bintray-mirror
	      Use the specified Bintray  repository  to  automatically	mirror
	      stable URLs defined in the formulae (default: mirror).

   pr-upload [options]
       Apply the bottle commit and publish bottles to Bintray.

       --no-publish
	      Apply  the  bottle commit and upload the bottles, but don't pub-
	      lish them.

       --keep-old
	      If the formula specifies a rebuild version, attempt to  preserve
	      its value in the generated DSL.

       -n, --dry-run
	      Print what would be done rather than doing it.

       --warn-on-upload-failure
	      Warn  instead  of  raising  an error if the bottle upload fails.
	      Useful for repairing bottle uploads that previously failed.

       --bintray-org
	      Upload to the specified  Bintray	organisation  (default:  home-
	      brew).

       --root-url
	      Use the specified URL as the root of the bottle's URL instead of
	      Homebrew's default.

   prof [command]
       Run Homebrew with a Ruby profiler, e.g. brew prof readall.

       --stackprof
	      Use stackprof instead of ruby-prof (the default).

   release-notes [options] [previous_tag] [end_ref]
       Print the merged pull requests on Homebrew/brew between two  Git  refs.
       If  no  previous_tag  is  provided it defaults to the latest tag. If no
       end_ref is provided it defaults to origin/master.

       --markdown
	      Print as a Markdown list.

   ruby (-e text|file)
       Run a Ruby instance with Homebrew's libraries loaded, e.g. brew ruby -e
       ""puts :gcc.f.deps"" or brew ruby script.rb.

       -r     Load a library using require.

       -e     Execute the given text string as a script.

   sh [options] [file]
       Homebrew  build environment that uses years-battle-hardened build logic
       to help your ./configure && make && make  install  and  even  your  gem
       install	succeed. Especially handy if you run Homebrew in an Xcode-only
       configuration since it adds tools like make to your  PATH  which  build
       systems would not find otherwise.

       --env  Use  the standard PATH instead of superenv's when std is passed.

       -c, --cmd
	      Execute commands in a non-interactive shell.

   sponsors
       Print a Markdown summary of Homebrew's GitHub  Sponsors,  suitable  for
       pasting into a README.

   style [options] [file|tap|formula]
       Check formulae or files for conformance to Homebrew style guidelines.

       Lists  of  file,  tap and formula may not be combined. If none are pro-
       vided, style will run style  checks  on	the  whole  Homebrew  library,
       including core code and all formulae.

       --fix  Fix  style violations automatically using RuboCop's auto-correct
	      feature.

       --display-cop-names
	      Include the RuboCop cop name for each violation in the output.

       --only-cops
	      Specify a comma-separated cops list to check for	violations  of
	      only the listed RuboCop cops.

       --except-cops
	      Specify  a comma-separated cops list to skip checking for viola-
	      tions of the listed RuboCop cops.

   tap-new user/repo
       Generate the template files for a new tap.

   test [options] formula
       Run the test method provided by an installed formula. There is no stan-
       dard  output or return code, but generally it should notify the user if
       something is wrong with the installed formula.

       Example: brew install jruby && brew test jruby

       --devel
	      Test the development version of a formula.

       --HEAD Test the head version of a formula.

       --keep-tmp
	      Retain the temporary files created for the test.

       --retry
	      Retry if a testing fails.

   tests [options]
       Run Homebrew's unit and integration tests.

       --coverage
	      Generate code coverage reports.

       --generic
	      Run only OS-agnostic tests.

       --no-compat
	      Do not load the compatibility layer when running tests.

       --online
	      Include tests that use the GitHub API and tests that use any  of
	      the taps for official external commands.

       --byebug
	      Enable debugging using byebug.

       --only Run  only test_script_spec.rb. Appending :line_number will start
	      at a specific line.

       --seed Randomise tests with the specified value	instead  of  a	random
	      seed.

   typecheck
       Check for typechecking errors using Sorbet.

       -q, --quiet
	      Silence all non-critical errors.

       --update-definitions
	      Update Tapioca gem definitions of recently bumped gems

       --fail-if-not-changed
	      Return  a failing status code if all gems are up to date and gem
	      definitions do not need a tapioca update

       --dir  Typecheck all files in a specific directory.

       --file Typecheck a single file.

       --ignore
	      Ignores input files that contain the given string in their paths
	      (relative to the input path passed to Sorbet).

   unpack [options] formula
       Unpack  the source files for formula into subdirectories of the current
       working directory.

       --destdir
	      Create subdirectories in the directory named by path instead.

       --patch
	      Patches for formula will be applied to the unpacked source.

       -g, --git
	      Initialise a Git repository in the unpacked source. This is use-
	      ful for creating patches for the software.

       -f, --force
	      Overwrite the destination directory if it already exists.

   update-license-data [options]
       Update SPDX license data in the Homebrew repository.

       --fail-if-not-changed
	      Return  a  failing status code if current license data's version
	      is the same as the upstream. This can be used to notify CI  when
	      the SPDX license data is out of date.

   update-python-resources [options] formula
       Update versions for PyPI resource blocks in formula.

       -p, --print-only
	      Print the updated resource blocks instead of changing formula.

       -s, --silent
	      Suppress any output.

       --ignore-non-pypi-packages
	      Don't fail if formula is not a PyPI package.

       --version
	      Use the specified version when finding resources for formula. If
	      no version is specified, the current version for formula will be
	      used.

   update-test [options]
       Run  a  test  of brew update with a new repository clone. If no options
       are passed, use origin/master as the start commit.

       --to-tag
	      Set HOMEBREW_UPDATE_TO_TAG to test updating between tags.

       --keep-tmp
	      Retain the temporary directory  containing  the  new  repository
	      clone.

       --commit
	      Use the specified commit as the start commit.

       --before
	      Use the commit at the specified date as the start commit.

   vendor-gems
       Install and commit Homebrew's vendored gems.

GLOBAL OPTIONS
       These options are applicable across multiple subcommands.

       -d, --debug
	      Display any debugging information.

       -q, --quiet
	      Suppress any warnings.

       -v, --verbose
	      Make some output more verbose.

       -h, --help
	      Show this message.

OFFICIAL EXTERNAL COMMANDS
   bundle [subcommand]
       Bundler for non-Ruby dependencies from Homebrew, Homebrew Cask, Mac App
       Store and Whalebrew.

       brew bundle [install]
	   Install and upgrade (by default) all dependencies  from  the  Brew-
       file.

       You can skip the installation of dependencies by adding space-separated
       values to one or more of the  following	environment  variables:  HOME-
       BREW_BUNDLE_BREW_SKIP,	  HOMEBREW_BUNDLE_CASK_SKIP,	 HOMEBREW_BUN-
       DLE_MAS_SKIP, HOMEBREW_BUNDLE_WHALEBREW_SKIP, HOMEBREW_BUNDLE_TAP_SKIP

       brew bundle will output a Brewfile.lock.json in the same  directory  as
       the  Brewfile if all dependencies are installed successfully. This con-
       tains dependency and system status information which can be  useful  in
       debugging  brew	bundle	failures  and  replicating  a ""last known good
       build"" state. You can opt-out of this behaviour by  setting  the  HOME-
       BREW_BUNDLE_NO_LOCK  environment  variable  or  passing	the  --no-lock
       option. You may wish to check this file into the same  version  control
       system  as your Brewfile (or ensure your version control system ignores
       it if you'd prefer to  rely  on	debugging  information	from  a  local
       machine).

       brew bundle dump
	   Write all installed casks/formulae/images/taps into a Brewfile.

       brew bundle cleanup
	   Uninstall all dependencies not listed from the Brewfile.

       This  workflow  is  useful  for	maintainers  or  testers who regularly
       install lots of formulae.

       brew bundle check
	   Check if all dependencies are installed from the Brewfile .

       This provides a successful exit code if everything is up-to-date,  mak-
       ing it useful for scripting.

       brew bundle list
	   List all dependencies present in a Brewfile.

       By default, only Homebrew dependencies are listed.

       brew bundle exec command
	   Run	an  external command in an isolated build environment based on
       the Brewfile dependencies.

       This sanitized  build  environment  ignores  unrequested  dependencies,
       which  makes sure that things you didn't specify in your Brewfile won't
       get picked up by commands like bundle install,  npm  install,  etc.  It
       will also add compiler flags which will help find keg-only dependencies
       like openssl, icu4c, etc.

       --file Read the Brewfile from this location. Use --file=-  to  pipe  to
	      stdin/stdout.

       --global
	      Read the Brewfile from ~/.Brewfile.

       -v, --verbose
	      install prints output from commands as they are run. check lists
	      all missing dependencies.

       --no-upgrade
	      install won't run brew upgrade on  outdated  dependencies.  Note
	      they may still be upgraded by brew install if needed.

       -f, --force
	      dump  overwrites an existing Brewfile. cleanup actually performs
	      its cleanup operations.

       --no-lock
	      install won't output a Brewfile.lock.json.

       --all  list all dependencies.

       --formula
	      list Homebrew dependencies.

       --cask list Homebrew Cask dependencies.

       --tap  list tap dependencies.

       --mas  list Mac App Store dependencies.

       --whalebrew
	      list Whalebrew dependencies.

       --describe
	      dump adds a description comment  above  each  line,  unless  the
	      dependency does not have a description.

       --no-restart
	      dump does not add restart_service to formula lines.

       --zap  cleanup casks using the zap command instead of uninstall.

   services [subcommand]
       Manage background services with macOS' launchctl(1) daemon manager.

       If sudo is passed, operate on /Library/LaunchDaemons (started at boot).
       Otherwise, operate on ~/Library/LaunchAgents (started at login).

       [sudo] brew services [list]
	   List all managed services for the current user (or root).

       [sudo] brew services run (formula|--all)
	   Run the service formula without registering to launch at login  (or
       boot).

       [sudo] brew services start (formula|--all)
	   Start  the service formula immediately and register it to launch at
       login (or boot).

       [sudo] brew services stop (formula|--all)
	   Stop the service formula immediately and unregister it from launch-
       ing at login (or boot).

       [sudo] brew services restart (formula|--all)
	   Stop  (if  necessary) and start the service formula immediately and
       register it to launch at login (or boot).

       [sudo] brew services cleanup
	   Remove all unused services.

       --all  Run subcommand on all services.

   test-bot [options] [formula]:
       Tests the full lifecycle of a Homebrew change to  a  tap  (Git  reposi-
       tory).  For  example,  for a GitHub Actions pull request that changes a
       formula brew test-bot will ensure the system is cleaned	and  setup  to
       test  the formula, install the formula, run various tests and checks on
       it, bottle (package) the binaries and test formulae that depend	on  it
       to ensure they aren't broken by these changes.

       Only supports GitHub Actions as a CI provider. This is because Homebrew
       uses GitHub Actions and it's freely available for  public  and  private
       use with macOS and Linux workers.

       --dry-run
	      print what would be done rather than doing it.

       --cleanup
	      clean all state from the Homebrew directory. Use with care!

       --skip-setup
	      don't check if the local system is set up correctly.

       --keep-old
	      run  brew  bottle  --keep-old  to build new bottles for a single
	      platform.

       --skip-relocation
	      run brew bottle --skip-relocation  to  build  new  bottles  that
	      don't require relocation.

       --local
	      ask  Homebrew  to write verbose logs under ./logs/ and set $HOME
	      to ./home/

       --tap  use the git repository of the given tap. Defaults  to  the  core
	      tap for syntax checking.

       --fail-fast
	      immediately exit on a failing step.

       -v, --verbose
	      print  test  step  output  in  real time. Has the side effect of
	      passing output as raw bytes instead of re-encoding in UTF-8.

       --test-default-formula
	      use a default testing formula when not building  a  tap  and  no
	      other formulae are specified.

       --bintray-org
	      upload to the given Bintray organisation.

       --root-url
	      use the specified URL as the root of the bottle's URL instead of
	      Homebrew's default.

       --git-name
	      set the Git author/committer names to the given name.

       --git-email
	      set the Git author/committer email to the given email.

       --ci-upload
	      use the Homebrew CI bottle upload options.

       --publish
	      publish the uploaded bottles.

       --skip-recursive-dependents
	      only test the direct dependents.

       --only-cleanup-before
	      Only run the pre-cleanup step. Needs --cleanup.

       --only-setup
	      Only run the local system setup check step.

       --only-tap-syntax
	      Only run the tap syntax check step.

       --only-formulae
	      Only run the formulae steps.

       --only-cleanup-after
	      Only run the post-cleanup step. Needs --cleanup.

CUSTOM EXTERNAL COMMANDS
       Homebrew, like git(1), supports external commands. These are executable
       scripts	that  reside  somewhere  in  the  PATH,  named brew-cmdname or
       brew-cmdname.rb, which can be invoked like brew	cmdname.  This	allows
       you to create your own commands without modifying Homebrew's internals.

       Instructions for creating your own commands can be found in  the  docs:
       https://docs.brew.sh/External-Commands

SPECIFYING FORMULAE
       Many  Homebrew  commands  accept  one  or more formula arguments. These
       arguments can take several different forms:

       The name of a formula
	      e.g. git, node, wget.

       The fully-qualified name of a tapped formula
	      Sometimes a formula from a tapped repository may	conflict  with
	      one  in  homebrew/core.  You  can still access these formulae by
	      using a special syntax, e.g. homebrew/dupes/vim or homebrew/ver-
	      sions/node4.

       An arbitrary file
	      Homebrew can install formulae from a local path. It can point to
	      either a formula file or a bottle.

SPECIFYING CASKS
       Many Homebrew Cask commands accept one or more  cask  arguments.  These
       can  be	specified  the	same way as the formula arguments described in
       SPECIFYING FORMULAE above.

ENVIRONMENT
       Note that environment variables must have a value set to  be  detected.
       For  example,  run  export  HOMEBREW_NO_INSECURE_REDIRECT=1 rather than
       just export HOMEBREW_NO_INSECURE_REDIRECT.

       HOMEBREW_ARCH
	      Linux only: Pass the set value to a type name  representing  the
	      compiler's -march option.

	      Default: native.

       HOMEBREW_ARTIFACT_DOMAIN
	      Prefix all download URLs, including those for bottles, with this
	      variable.  For  example,	HOMEBREW_ARTIFACT_DOMAIN=http://local-
	      host:8080  will  cause  a  formula  with	the  URL https://exam-
	      ple.com/foo.tar.gz  to  instead  download   from	 http://local-
	      host:8080/example.com/foo.tar.gz.

       HOMEBREW_AUTO_UPDATE_SECS
	      Automatically  check for updates once per this seconds interval.

	      Default: 300.

       HOMEBREW_BAT
	      If set, use bat for the brew cat command.

       HOMEBREW_BAT_CONFIG_PATH
	      Use   the   bat	configuration	file.	For   example,	 HOME-
	      BREW_BAT=$HOME/.bat/config.

	      Default: $HOME/.bat/config

       HOMEBREW_BINTRAY_KEY
	      Use  this  API key when accessing the Bintray API (where bottles
	      are stored).

       HOMEBREW_BINTRAY_USER
	      Use this username when accessing the Bintray API (where  bottles
	      are stored).

       HOMEBREW_BOTTLE_DOMAIN
	      Use  the	specified  URL as the download mirror for bottles. For
	      example, HOMEBREW_BOTTLE_DOMAIN=http://localhost:8080 will cause
	      all  bottles to download from the prefix http://localhost:8080/.

	      Default:	  macOS:     https://homebrew.bintray.com/,	Linux:
	      https://linuxbrew.bintray.com/.

       HOMEBREW_BREW_GIT_REMOTE
	      Use the specified URL as the Homebrew/brew git(1) remote.

	      Default: https://github.com/Homebrew/brew.

       HOMEBREW_BROWSER
	      Use this as the browser when opening project homepages.

	      Default: $BROWSER or the OS's default browser.

       HOMEBREW_CACHE
	      Use the specified directory as the download cache.

	      Default:	   macOS:     $HOME/Library/Caches/Homebrew,	Linux:
	      $XDG_CACHE_HOME/Homebrew or $HOME/.cache/Homebrew.

       HOMEBREW_CASK_OPTS
	      Options which should be used for all cask commands.  All	--*dir
	      options,	  --language,	--require-sha,	 --no-quarantine   and
	      --no-binaries are supported. For example, you  might  add  some-
	      thing like the following to your ~/.profile, ~/.bash_profile, or
	      ~/.zshenv:

       export	    HOMEBREW_CASK_OPTS='--appdir=~/Applications        --font-
       dir=/Library/Fonts'

       HOMEBREW_CLEANUP_MAX_AGE_DAYS
	      Cleanup all cached files older than this many days.

	      Default: 120.

       HOMEBREW_COLOR
	      If set, force colour output on non-TTY outputs.

       HOMEBREW_CORE_GIT_REMOTE
	      Use  the	specified  URL	as  the  Homebrew/homebrew-core git(1)
	      remote.

	      Default:	  macOS:    https://github.com/Homebrew/homebrew-core,
	      Linux: https://github.com/Homebrew/linuxbrew-core.

       HOMEBREW_CURLRC
	      If  set, do not pass --disable when invoking curl(1), which dis-
	      ables the use of curlrc.

       HOMEBREW_CURL_RETRIES
	      Pass the given retry count to --retry when invoking curl(1).

	      Default: 3.

       HOMEBREW_CURL_VERBOSE
	      If set, pass --verbose when invoking curl(1).

       HOMEBREW_DEVELOPER
	      If set, tweak behaviour to be more relevant for Homebrew	devel-
	      opers  (active or budding) by e.g. turning warnings into errors.

       HOMEBREW_DISABLE_LOAD_FORMULA
	      If set, refuse to load formulae. This is	useful	when  formulae
	      are not trusted (such as in pull requests).

       HOMEBREW_DISPLAY
	      Use this X11 display when opening a page in a browser, for exam-
	      ple with brew home. Primarily useful on Linux.

	      Default: $DISPLAY.

       HOMEBREW_DISPLAY_INSTALL_TIMES
	      If set, print install times for each formula at the end  of  the
	      run.

       HOMEBREW_EDITOR
	      Use this editor when editing a single formula, or several formu-
	      lae in the same directory.

	      Note: brew edit will open all of Homebrew as discontinuous files
	      and directories. Visual Studio Code can handle this correctly in
	      project mode, but many editors will do strange  things  in  this
	      case.

	      Default: $EDITOR or $VISUAL.

       HOMEBREW_FAIL_LOG_LINES
	      Output this many lines of output on formula system failures.

	      Default: 15.

       HOMEBREW_FORBIDDEN_LICENSES
	      A  space-separated  list	of  licenses.  Homebrew will refuse to
	      install a formula if that formula or any of its dependencies has
	      a license on this list.

       HOMEBREW_FORCE_BREWED_CURL
	      If  set, always use a Homebrew-installed curl(1) rather than the
	      system version. Automatically set if the system version of  curl
	      is too old.

       HOMEBREW_FORCE_BREWED_GIT
	      If  set,	always use a Homebrew-installed git(1) rather than the
	      system version. Automatically set if the system version  of  git
	      is too old.

       HOMEBREW_FORCE_HOMEBREW_ON_LINUX
	      If  set, running Homebrew on Linux will use URLs for macOS. This
	      is useful when merging pull requests for macOS while on Linux.

       HOMEBREW_FORCE_VENDOR_RUBY
	      If set, always use Homebrew's vendored, relocatable Ruby version
	      even if the system version of Ruby is new enough.

       HOMEBREW_GITHUB_API_PASSWORD
	      Use  this  password  for authentication with the GitHub API, for
	      features such as brew search. We strongly recommend using  HOME-
	      BREW_GITHUB_API_TOKEN instead.

       HOMEBREW_GITHUB_API_TOKEN
	      Use  this personal access token for the GitHub API, for features
	      such   as   brew	  search.    You    can    create    one    at
	      https://github.com/settings/tokens.  If  set,  GitHub will allow
	      you a greater number of API requests. For more information, see:
	      https://docs.github.com/en/rest/over-
	      view/resources-in-the-rest-api#rate-limiting.

	      Note: Homebrew  doesn't  require	permissions  for  any  of  the
	      scopes,  but some developer commands may require additional per-
	      missions.

       HOMEBREW_GITHUB_API_USERNAME
	      Use this username for authentication with the  GitHub  API,  for
	      features	such as brew search. We strongly recommend using HOME-
	      BREW_GITHUB_API_TOKEN instead.

       HOMEBREW_GIT_EMAIL
	      Set the Git author and committer name to this value.

       HOMEBREW_GIT_NAME
	      Set the Git author and committer email to this value.

       HOMEBREW_INSTALL_BADGE
	      Print this text before the installation summary of each success-
	      ful build.

	      Default: The ""Beer Mug"" emoji.

       HOMEBREW_LIVECHECK_WATCHLIST
	      Use  this file to get the list of default Formulae to check when
	      no Formula argument is passed to brew livecheck

	      Default: $HOME/.brew_livecheck_watchlist.

       HOMEBREW_LOGS
	      Use the specified directory to store log files.

	      Default:	   macOS:     $HOME/Library/Logs/Homebrew,	Linux:
	      $XDG_CACHE_HOME/Homebrew/Logs or $HOME/.cache/Homebrew/Logs.

       HOMEBREW_MAKE_JOBS
	      Use this value as the number of parallel jobs to run when build-
	      ing with make(1).

	      Default: The number of available CPU cores.

       HOMEBREW_NO_ANALYTICS
	      If set, do not send analytics. See: https://docs.brew.sh/Analyt-
	      ics.

       HOMEBREW_NO_AUTO_UPDATE
	      If set, do not automatically update before running brew install,
	      brew upgrade or brew tap.

       HOMEBREW_NO_BOTTLE_SOURCE_FALLBACK
	      If set, fail on the failure of installation from a bottle rather
	      than falling back to building from source.

       HOMEBREW_NO_COLOR
	      If set, do not print text with colour added.

	      Default: $NO_COLOR.

       HOMEBREW_NO_COMPAT
	      If set, disable all use of legacy compatibility code.

       HOMEBREW_NO_EMOJI
	      If  set,	do  not  print	HOMEBREW_INSTALL_BADGE on a successful
	      build.

	      Note: Only tries to print emoji on OS X Lion or newer.

       HOMEBREW_NO_GITHUB_API
	      If set, do not use the GitHub API, e.g. for searches or fetching
	      relevant issues on a failed install.

       HOMEBREW_NO_INSECURE_REDIRECT
	      If set, forbid redirects from secure HTTPS to insecure HTTP.

	      Note:  While  ensuring  your downloads are fully secure, this is
	      likely to cause from-source SourceForge, some GNU & GNOME  based
	      formulae to fail to download.

       HOMEBREW_NO_INSTALL_CLEANUP
	      If set, brew install, brew upgrade and brew reinstall will never
	      automatically cleanup installed/upgraded/reinstalled formulae or
	      all formulae every 30 days.

       HOMEBREW_PRY
	      If set, use Pry for the brew irb command.

       HOMEBREW_SKIP_OR_LATER_BOTTLES
	      If  set  with  HOMEBREW_DEVELOPER, do not use bottles from older
	      versions of macOS. This is useful in development	on  new  macOS
	      versions.

       HOMEBREW_SVN
	      Use this as the svn(1) binary.

	      Default: A Homebrew-built Subversion (if installed), or the sys-
	      tem-provided binary.

       HOMEBREW_TEMP
	      Use this path as the temporary directory for building  packages.
	      Changing	this  may be needed if your system temporary directory
	      and Homebrew prefix are on different volumes, as macOS has trou-
	      ble  moving symlinks across volumes when the target does not yet
	      exist. This issue typically occurs when using FileVault or  cus-
	      tom SSD configurations.

	      Default: macOS: /private/tmp, Linux: /tmp.

       HOMEBREW_UPDATE_REPORT_ONLY_INSTALLED
	      If  set, brew update only outputs updates to installed software.

       HOMEBREW_UPDATE_TO_TAG
	      If set, always use the latest stable tag (even if developer com-
	      mands have been run).

       HOMEBREW_VERBOSE
	      If set, always assume --verbose when running commands.

       HOMEBREW_DEBUG
	      If set, always assume --debug when running commands.

       HOMEBREW_VERBOSE_USING_DOTS
	      If  set,	verbose  output  will  print  a  . no more than once a
	      minute. This can be useful to avoid long-running	Homebrew  com-
	      mands being killed due to no output.

       all_proxy
	      Use  this SOCKS5 proxy for curl(1), git(1) and svn(1) when down-
	      loading through Homebrew.

       ftp_proxy
	      Use this FTP proxy for curl(1), git(1) and svn(1) when download-
	      ing through Homebrew.

       http_proxy
	      Use  this  HTTP  proxy for curl(1), git(1) and svn(1) when down-
	      loading through Homebrew.

       https_proxy
	      Use this HTTPS proxy for curl(1), git(1) and svn(1)  when  down-
	      loading through Homebrew.

       no_proxy
	      A  comma-separated  list	of hostnames and domain names excluded
	      from proxying by curl(1), git(1)	and  svn(1)  when  downloading
	      through Homebrew.

       SUDO_ASKPASS
	      When  this variable is set, the -A option is passed when calling
	      sudo(8)

USING HOMEBREW BEHIND A PROXY
       Set the http_proxy, https_proxy, all_proxy, ftp_proxy  and/or  no_proxy
       environment variables documented above.

       For example, to use an unauthenticated HTTP or SOCKS5 proxy:



	   export http_proxy=http://$HOST:$PORT

	   export all_proxy=socks5://$HOST:$PORT



       And for an authenticated HTTP proxy:



	   export http_proxy=http://$USER:$PASSWORD@$HOST:$PORT



SEE ALSO
       Homebrew Documentation: https://docs.brew.sh

       Homebrew API: https://rubydoc.brew.sh

       git(1), git-log(1)

AUTHORS
       Homebrew's Project Leader is Mike McQuaid.

       Homebrew's Project Leadership Committee is Misty De Meo, Shaun Jackman,
       Jonathan Chang, Sean Molenaar and Markus Reiter.

       Homebrew's Technical Steering Committee is Michka Popoff,  FX  Coudert,
       Markus Reiter, Misty De Meo and Mike McQuaid.

       Homebrew/brew's	Linux  maintainers  are  Michka Popoff, Shaun Jackman,
       Dawid Dziurla, Issy Long and Maxim Belkin.

       Homebrew's other  current  maintainers  are  Claudia  Pellegrino,  Zach
       Auten,  Rui  Chen, Vitor Galvao, Caleb Xu, Gautham Goli, Steven Peters,
       Bo  Anderson,  William  Woodruff,  Igor	Kapkov,  Sam  Ford,  Alexander
       Bayandin,  Izaak  Beekman, Eric Knibbe, Viktor Szakats, Thierry Moisan,
       Steven Peters, Tom Schoonjans, Issy Long, CoreCode, Randall, Rylan Pol-
       ster, SeekingMeaning, William Ma and Dustin Rodrigues.

       Former maintainers with significant contributions include Jan Viljanen,
       JCount, commitay, Dominyk Tiller,  Tim  Smith,  Baptiste  Fontaine,  Xu
       Cheng,  Martin Afanasjew, Brett Koonce, Charlie Sharpsteen, Jack Nagel,
       Adam Vandenberg,  Andrew  Janke,  Alex  Dunn,  neutric,	Tomasz	Pajor,
       Uladzislau  Shablinski,	Alyssa	Ross,  ilovezfs, Chongyu Zhu and Home-
       brew's creator: Max Howell.

BUGS
       See our issues on GitHub:

       Homebrew/brew
	      https://github.com/Homebrew/brew/issues

       Homebrew/homebrew-core
	      https://github.com/Homebrew/homebrew-core/issues

       Homebrew/homebrew-cask
	      https://github.com/Homebrew/homebrew-cask/issues




Homebrew			September 2020			       BREW(1)
","# brew

> The Homebrew package manager for Linux.

- Search for available formulas:

`brew search {{text}}`

- Install the latest stable version of a formula (use `--devel` for development versions):

`brew install {{formula}}`

- List all installed formulae:

`brew list`

- Upgrade an installed formula (if no formula name is given, all installed formulae are upgraded):

`brew upgrade {{formula}}`

- Fetch the newest version of Linuxbrew and of all formulae from GitHub:

`brew update`

- Show formulae that have a more recent version available:

`brew outdated`

- Display information about a formula (version, installation path, dependencies, etc.):

`brew info {{formula}}`

- Check the local Linuxbrew installation for potential problems:

`brew doctor`
"
lvcreate,,,,"# lvcreate

> Creates a logical volume in an existing volume group.
> A volume group is a collection of logical and physical volumes.

- Create a logical volume of 10 gigabytes in the volume group vg1:

`lvcreate -L {{10G}} {{vg1}}`

- Create a 1500 megabyte linear logical volume named mylv in the volume group vg1:

`lvcreate -L {{1500}} -n {{mylv}} {{vg1}}`

- Create a logical volume called mylv that uses 60% of the total space in volume group vg1:

`lvcreate -l {{60%VG}} -n {{mylv}} {{vg1}}`

- Create a logical volume called mylv that uses all of the unallocated space in the volume group vg1:

`lvcreate -l {{100%FREE}} -n {{mylv}} {{vg1}}`
"
mac2unix,,,,"# mac2unix

> Change macOS-style line endings to Unix-style.
> Replaces LF with CR.

- Change the line endings of a file:

`mac2unix {{filename}}`

- Create a copy with Unix-style line endings:

`mac2unix -n {{filename}} {{new_filename}}`
"
hwclock,,,,"# hwclock

> Used for reading or changing the hardware clock. Usually requires root.

- Display the current time as reported by the hardware clock:

`hwclock`

- Write the current software clock time to the hardware clock (sometimes used during system setup):

`hwclock --systohc`

- Write the current hardware clock time to the software clock:

`hwclock --hctosys`
"
pacman4console,https://github.com/YoctoForBeaglebone/pacman4console,"













GitHub - YoctoForBeaglebone/pacman4console: Console based PacMan Game








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















YoctoForBeaglebone

/

pacman4console







    Watch
 
      4
    




      Star


      35
    




          Fork


        7
      





        Console based PacMan Game
      



            GPL-2.0 License
        




35
        stars
 

7
        forks
 




      Star





    Watch









Code

 



Issues
0
 



Pull requests
0
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



0
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit



 
 
Git stats





18
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






Levels


 


 







.gitignore


 


 







COPYING


 


 







ChangeLog


 


 







Makefile


 


 







README


 


 







README.md


 


 







pacman.c


 


 







pacman.h


 


 







pacmanedit.c


 


 







screenshot.png


 


 





        View code
      







        README.md
      


Pacman For Console
Okay, so basically, I got tired of enabling flash on my browser so that I could
play Pacman.  That, and I was extremely bored one night.  So I decided to make
my own Pacman... for Console.
Licensing Information
See COPYING for details on the GNU/GPL version 2.
Compile/Install/Run
To make... gee... let's see... type make.
To install... type make install.
To run... type pacman [level_#]          where # is 1-9, for a premade level,
or      type pacmac [level_file_name]  for a custom level you made.
To uninstall... type make uninstall.
i.e.:

make && su -c ""make install""
pacman 3                                           # Start @ level 3
pacman /usr/local/share/pacman/Levels/level07.dat  # Play only level 7
echo "":-( I don't like it."" && make uninstall      # Uninstall :-(


The ASCII art

C	-	Pacman - That's you.
&	-	Ghosts - Boo.
.	-	Pellet - Yummy. Collect all of them to pass to the next level.
*	-	Power pellet - Makes you invincible for a short while.
Wall - No one can walk through it.
Blocker - A.K.A. Ghost wall. Only the Ghosts can walk through this.


13 Basic Playing Rules
In case you don't know the rules of Pacman (rules I programmed in), here are
most of them:

Pacman must collect all the pellets of food in the maze. 1 point per pellet.
Big pellets make Pacman invincible for a short amount of time.
If Pacman touches a ghost without being invincible, you die and lose 1 life.
If Pacman touches a ghost while invincible, the ghost is sent back to his
starting point.
Points are awarded for each ghost eaten in a row while invincible: 20, 40,
80, 160 (10*2^x).
Pacman cannot go through the Ghost Walls (Blockers).
Ghosts, cannot turn completely around unless there is no other option.
While Pacman is invincible, Ghosts will be a bit slower and tend to stay
away from him.
While Pacman is NOT invincible, Ghosts will tend to come toward him.
Pacman starts with 3 extra lives, once all three are gone, the game is
over.
Extra lives are awarded at 1000 points, 2000, 4000, 8000... (500*2^[x]).
If any character reaches a border of the maze, he will be transported to
the opposite side.
Each character can only go in one X or Y direction at a time.

The keys used are UP, DOWN, LEFT, RIGHT or W, S, A, D.
To make your own levels, see Levels/README.
Contact Information
Send comments and levels you have made to doctormike@gmail.com.
There is a homepage.








About

      Console based PacMan Game
    
Resources



      Readme
 
License



        GPL-2.0 License
    







    Releases

No releases published






    Packages 0


        No packages published 











Languages











C
91.1%





Makefile
4.4%





Perl
2.7%





C++
1.8%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# pacman4console

> A text-based console game inspired by the original Pacman.
> More information: <https://github.com/YoctoForBeaglebone/pacman4console>.

- Start a game at Level 1:

`pacman4console`

- Start a game on a certain level (there are nine official levels):

`pacman4console --level={{level_number}}`

- Start the pacman4console level editor, saving to a specified text file:

`pacman4consoleedit {{path/to/level_file}}`

- Play a custom level:

`pacman4console --level={{path/to/level_file}}`
"
compgen,,,,"# compgen

> A built-in command for auto-completion in bash, which is called on pressing TAB key twice.

- List all commands that you could run:

`compgen -c`

- List all aliases:

`compgen -a`

- List all functions that you could run:

`compgen -A function`

- Show shell reserved key words:

`compgen -k`

- See all available commands/aliases starting with 'ls':

`compgen -ac {{ls}}`
"
eval,,,"
BUILTIN(1)		  BSD General Commands Manual		    BUILTIN(1)

NAME
     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,
     breaksw, builtins, case, cd, chdir, command, complete, continue, default,
     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,
     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,
     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,
     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,
     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,
     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,
     telltc, test, then, time, times, trap, true, type, ulimit, umask,
     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,
     where, which, while -- shell built-in commands

SYNOPSIS
     builtin [-options] [args ...]

DESCRIPTION
     Shell builtin commands are commands that can be executed within the run-
     ning shell's process.  Note that, in the case of csh(1) builtin commands,
     the command is executed in a subshell if it occurs as any component of a
     pipeline except the last.

     If a command specified to the shell contains a slash ``/'', the shell
     will not execute a builtin command, even if the last component of the
     specified command matches the name of a builtin command.  Thus, while
     specifying ``echo'' causes a builtin command to be executed under shells
     that support the echo builtin command, specifying ``/bin/echo'' or
     ``./echo'' does not.

     While some builtin commands may exist in more than one shell, their oper-
     ation may be different under each shell which supports them.  Below is a
     table which lists shell builtin commands, the standard shells that sup-
     port them and whether they exist as standalone utilities.

     Only builtin commands for the csh(1) and sh(1) shells are listed here.
     Consult a shell's manual page for details on the operation of its builtin
     commands.	Beware that the sh(1) manual page, at least, calls some of
     these commands ``built-in commands'' and some of them ``reserved words''.
     Users of other shells may need to consult an info(1) page or other
     sources of documentation.

     Commands marked ``No**'' under External do exist externally, but are
     implemented as scripts using a builtin command of the same name.

	   Command	 External    csh(1)    sh(1)
	   !		 No	     No        Yes
	   %		 No	     Yes       No
	   .		 No	     No        Yes
	   :		 No	     Yes       Yes
	   @		 No	     Yes       Yes
	   {		 No	     No        Yes
	   }		 No	     No        Yes
	   alias	 No**	     Yes       Yes
	   alloc	 No	     Yes       No
	   bg		 No**	     Yes       Yes
	   bind 	 No	     No        Yes
	   bindkey	 No	     Yes       No
	   break	 No	     Yes       Yes
	   breaksw	 No	     Yes       No
	   builtin	 No	     No        Yes
	   builtins	 No	     Yes       No
	   case 	 No	     Yes       Yes
	   cd		 No**	     Yes       Yes
	   chdir	 No	     Yes       Yes
	   command	 No**	     No        Yes
	   complete	 No	     Yes       No
	   continue	 No	     Yes       Yes
	   default	 No	     Yes       No
	   dirs 	 No	     Yes       No
	   do		 No	     No        Yes
	   done 	 No	     No        Yes
	   echo 	 Yes	     Yes       Yes
	   echotc	 No	     Yes       No
	   elif 	 No	     No        Yes
	   else 	 No	     Yes       Yes
	   end		 No	     Yes       No
	   endif	 No	     Yes       No
	   endsw	 No	     Yes       No
	   esac 	 No	     No        Yes
	   eval 	 No	     Yes       Yes
	   exec 	 No	     Yes       Yes
	   exit 	 No	     Yes       Yes
	   export	 No	     No        Yes
	   false	 Yes	     No        Yes
	   fc		 No**	     No        Yes
	   fg		 No**	     Yes       Yes
	   filetest	 No	     Yes       No
	   fi		 No	     No        Yes
	   for		 No	     No        Yes
	   foreach	 No	     Yes       No
	   getopts	 No**	     No        Yes
	   glob 	 No	     Yes       No
	   goto 	 No	     Yes       No
	   hash 	 No	     No        Yes
	   hashstat	 No	     Yes       No
	   history	 No	     Yes       No
	   hup		 No	     Yes       No
	   if		 No	     Yes       Yes
	   jobid	 No	     No        Yes
	   jobs 	 No**	     Yes       Yes
	   kill 	 Yes	     Yes       No
	   limit	 No	     Yes       No
	   local	 No	     No        Yes
	   log		 No	     Yes       No
	   login	 Yes	     Yes       No
	   logout	 No	     Yes       No
	   ls-F 	 No	     Yes       No
	   nice 	 Yes	     Yes       No
	   nohup	 Yes	     Yes       No
	   notify	 No	     Yes       No
	   onintr	 No	     Yes       No
	   popd 	 No	     Yes       No
	   printenv	 Yes	     Yes       No
	   pushd	 No	     Yes       No
	   pwd		 Yes	     No        Yes
	   read 	 No**	     No        Yes
	   readonly	 No	     No        Yes
	   rehash	 No	     Yes       No
	   repeat	 No	     Yes       No
	   return	 No	     No        Yes
	   sched	 No	     Yes       No
	   set		 No	     Yes       Yes
	   setenv	 No	     Yes       No
	   settc	 No	     Yes       No
	   setty	 No	     Yes       No
	   setvar	 No	     No        Yes
	   shift	 No	     Yes       Yes
	   source	 No	     Yes       No
	   stop 	 No	     Yes       No
	   suspend	 No	     Yes       No
	   switch	 No	     Yes       No
	   telltc	 No	     Yes       No
	   test 	 Yes	     No        Yes
	   then 	 No	     No        Yes
	   time 	 Yes	     Yes       No
	   times	 No	     No        Yes
	   trap 	 No	     No        Yes
	   true 	 Yes	     No        Yes
	   type 	 No	     No        Yes
	   ulimit	 No	     No        Yes
	   umask	 No**	     Yes       Yes
	   unalias	 No**	     Yes       Yes
	   uncomplete	 No	     Yes       No
	   unhash	 No	     Yes       No
	   unlimit	 No	     Yes       No
	   unset	 No	     Yes       Yes
	   unsetenv	 No	     Yes       No
	   until	 No	     No        Yes
	   wait 	 No**	     Yes       Yes
	   where	 No	     Yes       No
	   which	 Yes	     Yes       No
	   while	 No	     Yes       Yes

SEE ALSO
     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),
     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)

HISTORY
     The builtin manual page first appeared in FreeBSD 3.4.

AUTHORS
     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.

BSD			       February 23, 2005			   BSD
","# eval

> Execute arguments as a single command in the current shell and return its result.

- Call `echo` with the ""foo"" argument:

`eval ""{{echo foo}}""`

- Set a variable in the current shell:

`eval ""{{foo=bar}}""`
"
apt-key,https://host.tld/filename.key,,,"# apt-key

> Key management utility for the APT Package Manager on Debian and Ubuntu.

- List trusted keys:

`apt-key list`

- Add a key to the trusted keystore:

`apt-key add {{public_key_file.asc}}`

- Delete a key from the trusted keystore:

`apt-key del {{key_id}}`

- Add a remote key to the trusted keystore:

`wget -qO - {{https://host.tld/filename.key}} | apt-key add -`

- Add a key from keyserver with only key id:

`apt-key adv --keyserver {{pgp.mit.edu}} --recv {{KEYID}}`
"
progress,https://github.com/Xfennec/progress,"













GitHub - Xfennec/progress: Linux tool to show progress for cp, mv, dd, ... (formerly known as cv)








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















Xfennec

/

progress







    Watch
 
      128
    




      Star


      5.1k
    




          Fork


        262
      





        Linux tool to show progress for cp, mv, dd, ... (formerly known as cv)
      



            GPL-3.0 License
        




5.1k
        stars
 

262
        forks
 




      Star





    Watch









Code

 



Issues
31
 



Pull requests
13
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



18
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




Xfennec

bump version to 0.15



…



b56ae2b

Jun 8, 2020





bump version to 0.15


b56ae2b



Git stats





151
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.gitignore


 


 







.travis.yml


 


 







LICENSE


 


 







Makefile


 


 







README.md


 


 







capture.png


 


 







hlist.c


 


 







hlist.h


 


 







progress.1


 


 







progress.c


 


 







progress.h


 


 







sizes.c


 


 







sizes.h


 


 





        View code
      







        README.md
      


progress - Coreutils Progress Viewer 
What is it?
This tool can be described as a Tiny, Dirty, Linux-and-OSX-Only C command
that looks for coreutils basic commands (cp, mv, dd, tar, gzip/gunzip,
cat, etc.) currently running on your system and displays the
percentage of copied data. It can also show estimated time and throughput,
and provides a ""top-like"" mode (monitoring).

(After many requests: the colors in the shell come from powerline-shell. Try it, it's cool.)
Formerly known as cv (Coreutils Viewer).
How do you install it?
On deb-based systems (Debian, Ubuntu, Mint, etc.) run:
apt install progress

On rpm-based systems (Red Hat, CentOS, SUSE, etc.), run:
yum install progress

On macOS, with homebrew, run:
brew install progress

On macOS, with MacPorts, run:
port install progress

How do you build it from source?
make && make install

It depends on library ncurses, you may have to install corresponding packages (may be something like 'libncurses5-dev' or 'ncurses-devel').
How do you run it?
Just launch the binary, progress.
What can I do with it?
A few examples. You can:


monitor all current and upcoming instances of coreutils commands in
a simple window:
  watch progress -q



see how your download is progressing:
  watch progress -wc firefox



look at your Web server activity:
  progress -c httpd



launch and monitor any heavy command using $!:
  cp bigfile newfile & progress -mp $!



and much more.
How does it work?
It simply scans /proc for interesting commands, and then looks at
directories fd and fdinfo to find opened files and seek positions,
and reports status for the largest file.
It's very light, and compatible with virtually any command.








About

      Linux tool to show progress for cp, mv, dd, ... (formerly known as cv)
    
Topics



  monitoring


  linux


  coreutils



Resources



      Readme
 
License



        GPL-3.0 License
    







    Releases



18
tags







    Packages 0


        No packages published 













    Contributors 21





 



 



 



 



 



 



 



 



 



 



 



      + 10 contributors





Languages










C
89.0%





Roff
7.8%





Makefile
3.2%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# progress

> Display/Monitor the progress of running coreutils.
> More information: <https://github.com/Xfennec/progress>.

- Show the progress of running coreutils:

`progress`

- Show the progress of running coreutils in quiet mode:

`progress -q`

- Launch and monitor a single long-running command:

`{{command}} & progress -mp $!`
"
groupdel,,,,"# groupdel

> Delete existing user groups from the system.

- Delete an existing group:

`groupdel {{group_name}}`
"
pidof,,,,"# pidof

> Gets the ID of a process using its name.

- List all process IDs with given name:

`pidof {{bash}}`

- List a single process ID with given name:

`pidof -s {{bash}}`

- List process IDs including scripts with given name:

`pidof -x {{script.py}}`

- Kill all processes with given name:

`kill ""$(pidof {{name}})"" `
"
mke2fs,,,,"# mke2fs

> Creates a Linux filesystem inside a partition.

- Create an ext2 filesystem in partition 1 of device b (`sdb1`):

`mkfs.ext2 {{/dev/sdb1}}`

- Create an ext3 filesystem in partition 1 of device b (`sdb1`):

`mkfs.ext3 {{/dev/sdb1}}`

- Create an ext3 filesystem in partition 1 of device b (`sdb1`):

`mkfs.ext3 {{/dev/sdb1}}`
"
lrztar,,,,"# lrztar

> A wrapper for `lrzip` to simplify compression of directories.
> See also: `tar`, `lrzuntar`, `lrunzip`.

- Archive a directory with `tar`, then compress:

`lrztar {{path/to/directory}}`

- Same as above, with ZPAQ - extreme compression, but very slow:

`lrztar -z {{path/to/directory}}`

- Specify the output file:

`lrztar -o {{path/to/file}} {{path/to/directory}}`

- Override the number of processor threads to use:

`lrztar -p {{8}} {{path/to/directory}}`

- Force overwriting of existing files:

`lrztar -f {{path/to/directory}}`
"
fsck,,,"
FSCK(8) 		  BSD System Manager's Manual		       FSCK(8)

NAME
     fsck -- filesystem consistency check and interactive repair

SYNOPSIS
     fsck -p [-f]
     fsck [-l maxparallel] [-q] [-y] [-n] [-d]

DESCRIPTION
     The first form of fsck preens a standard set of filesystems or the speci-
     fied filesystems.	It is normally used in the script /etc/rc during auto-
     matic reboot.  Here fsck reads the filesystem descriptor table (using
     getfsent(3)) to determine which filesystems to check.  Only partitions
     that have ``rw,'' ``rq'' or ``ro'' as options, and that have non-zero
     pass number are checked.  Filesystems with pass number 1 (normally just
     the root filesystem) are checked one at a time.  When pass 1 completes,
     all remaining filesystems are checked, running one process per disk
     drive.  The disk drive containing each filesystem is inferred from the
     shortest prefix of the device name that ends in one or more digits; the
     remaining characters are assumed to be the partition designator.  In
     preening mode, filesystems that are marked clean are skipped.  Filesys-
     tems are marked clean when they are unmounted, when they have been
     mounted read-only, or when fsck runs on them successfully.

     It should be noted that fsck is now essentially a wrapper that invokes
     other fsck_XXX utilities as needed.  Currently, fsck can invoke fsck_hfs,
     fsck_apfs, fsck_msdos, fsck_exfat, and fsck_udf.  If this underlying
     process that fsck invokes encounters serious inconsistencies or the
     filesystem type is not one of the above, it exits with an abnormal return
     status and an automatic reboot will then fail.  For each corrected incon-
     sistency one or more lines will be printed identifying the filesystem on
     which the correction will take place, and the nature of the correction.

     If sent a QUIT signal, fsck will finish the filesystem checks, then exit
     with an abnormal return status that causes an automatic reboot to fail.
     This is useful when you want to finish the filesystem checks during an
     automatic reboot, but do not want the machine to come up multiuser after
     the checks complete.

     Without the -p option, fsck audits and interactively repairs inconsistent
     conditions for filesystems.  It should be noted that some of the correc-
     tive actions which are not correctable under the -p option will result in
     some loss of data.  The amount and severity of data lost may be deter-
     mined from the diagnostic output.	If the operator does not have write
     permission on the filesystem fsck will default to a -n action.

     The following flags are interpreted by fsck and passed along to the
     underlying tool that it spawns.

     -f 	 Force fsck to check `clean' filesystems when preening.

     -l 	 Limit the number of parallel checks to the number specified
		 in the following argument.  By default, the limit is the num-
		 ber of disks, running one process per disk.  If a smaller
		 limit is given, the disks are checked round-robin, one
		 filesystem at a time.

     -R 	 Specify a particular passno number for which fsck is to
		 check.  You may only specify 1 or 2.  Only those filesystems
		 matching that particular passno entry (if using fstab) will
		 be checked.  For more information on the passno field, see
		 fstab(5).

     -p 	 ""Preen"" mode, described above.

     -q 	 Do a quick check to determine if the filesystem was unmounted
		 cleanly.

     -y 	 Assume a yes response to all questions asked by fsck; this
		 should be used with great caution as this is a free license
		 to continue after essentially unlimited trouble has been
		 encountered.

     -n 	 Assume a no response to all questions asked by fsck except
		 for `CONTINUE?', which is assumed to be affirmative; do not
		 open the filesystem for writing.

     If no filesystems are given to fsck then a default list of filesystems is
     read using getfsent(3).

     Because of inconsistencies between the block device and the buffer cache,
     the raw device should always be used.

SEE ALSO
     fs(5), fsck_hfs(8), fsck_apfs(8), fsck_msdos(8), getfsent(3), fstab(5,)
     reboot(8)

4th Berkeley Distribution	 May 18, 2010	     4th Berkeley Distribution
","# fsck

> Check the integrity of a filesystem or repair it. The filesystem should be unmounted at the time the command is run.

- Check filesystem /dev/sda, reporting any damaged blocks:

`fsck {{/dev/sda}}`

- Check filesystem /dev/sda, reporting any damaged blocks and interactively letting the user choose to repair each one:

`fsck -r {{/dev/sda}}`

- Check filesystem /dev/sda, reporting any damaged blocks and automatically repairing them:

`fsck -a {{/dev/sda}}`
"
rpcinfo,,,"
RPCINFO(8)		  BSD System Manager's Manual		    RPCINFO(8)

NAME
     rpcinfo -- report RPC information

SYNOPSIS
     rpcinfo [--rpcbvers version] [-m | -s] [host]
     rpcinfo [--rpcbvers version] -T netid host program [version]
     rpcinfo [--rpcbvers version] -a server address -T netid program [version]
     rpcinfo [--rpcbvers version] -b [-T netid] program version
     rpcinfo [--rpcbvers version] -d [-T netid] program version
     rpcinfo -l [-T netid] [host] program version
     rpcinfo [--rpcbvers version] --getaddr [-T netid] [host] program version
     rpcinfo --getversaddr [-T netid] [host] program version
     rpcinfo --indirect [-T netid] [host] program version
     rpcinfo [--rpcbvers version] --time [-T netid] [host]
     rpcinfo {--help | -h}
     rpcinfo -p [host]
     rpcinfo [-n portnum] -u host program [version]
     rpcinfo [-n portnum] -t host program [version]

DESCRIPTION
     rpcinfo makes an RPC call to an RPC server and reports what it finds.
     Unless otherwise specified or noted below the default rpcbind protocol
     version is 3.  With no or only generic options, call the rpcbind dump
     procedure on the specified host or ``localhost'' if host is not specified
     and display the results.  For versions 3 and 4 display the program num-
     ber, the version, the ``netid'', the universal address that the services
     is listening on, symbolic name of the program if known, and then the
     owner that registered the <program, version, netid, address> tuple.  For
     version 2 of the protocol list the program, version, protocol, port, and
     symbolic program name.  See the --summary option below for a typically
     more useful output. rpcbind defaults the netid to ``tcp'' for the dump
     procedure.

     The program argument can be either a name or a number.

     If a version is specified, rpcinfo attempts to call that version of the
     specified program.  Otherwise, if the version is optional rpcinfo
     attempts to find all the registered version numbers for the specified
     program by calling version 0 (which is presumed not to exist; if it does
     exist, rpcinfo attempts to obtain this information by calling an
     extremely high version number instead) and attempts to call each regis-
     tered version.

     A required transport option is needed for the second and third lines of
     the synopsis which is used to ping, i.e., call the null procedure of the
     specified program and version. The results will be displayed on stdout.
     If version is not specified each valid version found as described above
     will be called.  The third synopsis will use the supplied universal
     address over the transport specified by netid to call the null procedure
     of the specified program in the same manner as above. In addition the
     last two lines of the synopsis can ``ping'' the server as described in
     the Legacy Options section below.

GENERIC OPTIONS
     --rpcbvers version
	     Attempt to use the supplied rpcbind version. Note some options
	     below are version specific and this option may be ignored. If
	     specifying version 2 (portmapper), netid below must be one of
	     ``udp'' or ``tcp''.

     -T netid
	     Specify the netid to use. Supported netids are ``udp'', ``tcp'',
	     ``udp6'', and ``tcp6''.

     --timeout seconds
	     Timeout used in creating client handles and the client calls to
	     rpcbind. Current default is 12 seconds.

     Generic options may be supplied with any of the rpcinfo options below,
     though some options will override their values.

LEGACY OPTIONS
     The options below imply version 2 (portmapper) rpcbind calls. They are
     compatible with older versions of rpcinfo.

     {-p | --portmap} [-T netid] [host]
	     Probe the portmapper on host, and print a list of all registered
	     RPC programs.  If host is not specified, it defaults to the value
	     ``localhost''.

     {-u | --udpping} host program [version]
	     Make an RPC call to the NULL procedure of program on the speci-
	     fied host using UDP, and report whether a response was received.

     {-t | --tcpping} host program [version]
	     Make an RPC call to the NULL procedure of program on the speci-
	     fied host using TCP, and report whether a response was received.

     {-n | --portnum} portnum
	     Use portnum as the port number for the -t and -u options instead
	     of the port number given by the portmapper.

OPTIONS
     {-b | --broadcast} program version
	     Make an RPC multicast over INET6 to the RPCB_MULTICAST_ADDR,
	     ``FF02::202'', and broadcast over INET using UDP to procedure 0
	     of the specified program and version and report all hosts that
	     respond.  rpcifno will first use RPCBIND version 3 and then call
	     the broadcast procedure of the portmapper protocol to collect
	     older hosts. There is a reply cache kept so duplicates will not
	     be returned unless the cache fills.

	     Note that the -b option by its self is compatible with the older
	     portmapper.  However, specifying --rpcbvers 2 will short circuit
	     the rpcbind version 3 calls and only call the portmapper.

     {-d | --delete} [-T netid] program version
	     Delete registration for the RPC service of the specified program
	     and version.  If the netid is specified, only unregister the
	     program and version over that transport.  This option can be
	     exercised only by the super-user or the user who registered the
	     the RPC service.

     --getaddr [-T netid] [host] program version
	     Get the universal address that the client can use to contact the
	     program and version from host over netid.	If host is not speci-
	     fied localhost is assumed. If netid is not specified ``udp'' is
	     assumed. If the specified version is not available but some other
	     version is, return the universal address for one of those ver-
	     sions of the program.

     --getversaddr [-T netid] [host] program version
	     Get the universal address that the client can use to contact the
	     program and version from host over netid.	If host is not speci-
	     fied localhost is assumed. If netid is not specified ``udp'' is
	     assumed. If the version is not available then that will be indi-
	     cated. This requires the remote rpcbind support version 4.

     -h      Print out the synopsis of this program.

     --help  Print out the synopsis and an explanation of the options.

     --indirect [-T netid] [host] program version
	     Send a indirect call to the null procedure of program and version
	     on the specified host or localhost.  This requires the remote
	     rpcbind to support version 4.

     {-l | --list} [-T netid] [host] program version
	     List the transports available over the transport family specified
	     by the netid for the given program and version on the optional
	     host or localhost if not specified.  Requires the remote rpcbind
	     to support version 4.  The default transport family is INET.

     {-m | --metrics}
	     Print the metrics of rpcbind daemon for the specified host or
	     localhost if not specified.  Requires support for rpcbind ver-
	     sion 4 on the remote.

     {-s | --summary}
	     Print a summary of programs registered on host or ``localhost''
	     if host is not specified.	For each program registered list any
	     versions followed by any transports supported by that program.
	     Try to list the symbolic name of the transport and the owner that
	     registered the program.

     --time [host]
	     Return rpcbind's version of time on the specified host.

EXAMPLES
     To show all of the RPC services registered on the local machine use:

	   example% rpcinfo

     To show all of the RPC services registered on the machine named klaxon
     use:

	   example% rpcinfo klaxon

     More usefully to show the services registered on klaxon use:

	   example% rpcinfo -s klaxon

     To show all of the RPC services from an older host only running version 2
     of rpcbind on a host named horn use:

	   example% rpcinfo -p horn

     To show all machines on the local net that are running the NFS File ser-
     vice use:

	   example% rpcinfo -b nfs 'version'

     where 'version' is one of the current nfs versions of interest.

     To delete the registration for version 1 of the rquotad service use:

	   example% rpcinfo -d rquotad 1

SEE ALSO
     rpc(5), rpcbind(8)

     RPC Programming Guide.

     RFC 1833 Binding Protocols for ONC RPC Version 2.

     RFC 5665 IANA Considerations for Remote Procedure Call (RPC) Network
     Identifiers and Universal Address Formats.

BUGS
     In summary mode the maximum number of versions and transports is 16. The
     first 16 versions and the first 16 transports received from the server
     are displayed and the rest is silently ignored.

     In the second synopsis line, for a host that is specified as a link-local
     INET6 address will always return ``no route to host''.

     In releases prior to SunOS 3.0, the Network File System (NFS) did not
     register itself with the portmapper; rpcinfo cannot be used to make RPC
     calls to the NFS server on hosts running such releases.

BSD			       November 14, 2012			   BSD
","# rpcinfo

> Makes an RPC call to an RPC server and reports what it finds.

- Show full table of all RPC services registered on localhost:

`rpcinfo`

- Show concise table of all RPC services registered on localhost:

`rpcinfo -s {{localhost}}`

- Display table of statistics of rpcbind operations on localhost:

`rpcinfo -m`

- Display list of entries of given service name (mountd) and version number (2) on a remote nfs share:

`rpcinfo -l {{remote_nfs_server_ip}} {{mountd}} {{2}}`

- Delete the registration for version 1 of the mountd service for all transports:

`rpcinfo -d {{mountd}} {{1}}`
"
sysctl,,,"
SYSCTL(8)		  BSD System Manager's Manual		     SYSCTL(8)

NAME
     sysctl -- get or set kernel state

SYNOPSIS
     sysctl [-bdehiNnoqx] name[=value] ...
     sysctl [-bdehNnoqx] -a

DESCRIPTION
     The sysctl utility retrieves kernel state and allows processes with
     appropriate privilege to set kernel state.  The state to be retrieved or
     set is described using a ``Management Information Base'' (``MIB'') style
     name, described as a dotted set of components.

     The following options are available:

     -A      Equivalent to -o -a (for compatibility).

     -a      List all the currently available non-opaque values.  This option
	     is ignored if one or more variable names are specified on the
	     command line.

     -b      Force the value of the variable(s) to be output in raw, binary
	     format.  No names are printed and no terminating newlines are
	     output.  This is mostly useful with a single variable.

     -d      Print the description of the variable instead of its value.

     -e      Separate the name and the value of the variable(s) with `='.
	     This is useful for producing output which can be fed back to the
	     sysctl utility.  This option is ignored if either -N or -n is
	     specified, or a variable is being set.

     -h      Format output for human, rather than machine, readability.

     -i      Ignore unknown OIDs.  The purpose is to make use of sysctl for
	     collecting data from a variety of machines (not all of which are
	     necessarily running exactly the same software) easier.

     -N      Show only variable names, not their values.  This is particularly
	     useful with shells that offer programmable completion.  To enable
	     completion of variable names in zsh(1) (ports/shells/zsh), use
	     the following code:

		   listsysctls () { set -A reply $(sysctl -AN ${1%.*}) }
		   compctl -K listsysctls sysctl

	     To enable completion of variable names in tcsh(1), use:

		   complete sysctl 'n/*/`sysctl -Na`/'

     -n      Show only variable values, not their names.  This option is use-
	     ful for setting shell variables.  For instance, to save the page-
	     size in variable psize, use:

		   set psize=`sysctl -n hw.pagesize`

     -o      Show opaque variables (which are normally suppressed).  The for-
	     mat and length are printed, as well as a hex dump of the first
	     sixteen bytes of the value.

     -q      Suppress some warnings generated by sysctl to standard error.

     -X      Equivalent to -x -a (for compatibility).

     -x      As -o, but prints a hex dump of the entire value instead of just
	     the first few bytes.

     The information available from sysctl consists of integers, strings, and
     opaque types.  The sysctl utility only knows about a couple of opaque
     types, and will resort to hexdumps for the rest.  The opaque information
     is much more useful if retrieved by special purpose programs such as
     ps(1), systat(1), and netstat(1).

     The string and integer information is summarized below.  For a detailed
     description of these variable see sysctl(3).

     The changeable column indicates whether a process with appropriate privi-
     lege can change the value.  String and integer values can be set using
     sysctl.

     Name					 Type	       Changeable
     hw.activecpu				 integer       no
     hw.busfrequency				 integer       no
     hw.busfrequency_max			 integer       no
     hw.busfrequency_min			 integer       no
     hw.byteorder				 integer       no
     hw.cacheconfig				 struct        no
     hw.cachelinesize				 integer       no
     hw.cachesize				 struct        no
     hw.cpu64bit_capable			 integer       no
     hw.cpufamily				 integer       no
     hw.cpufrequency				 integer       no
     hw.cpufrequency_max			 integer       no
     hw.cpufrequency_min			 integer       no
     hw.cpusubtype				 integer       no
     hw.cputhreadtype				 integer       no
     hw.cputype 				 integer       no
     hw.l1dcachesize				 integer       no
     hw.l1icachesize				 integer       no
     hw.l2cachesize				 integer       no
     hw.l3cachesize				 integer       no
     hw.logicalcpu				 integer       no
     hw.logicalcpu_max				 integer       no
     hw.memsize 				 integer       no
     hw.ncpu					 integer       no
     hw.packages				 integer       no
     hw.pagesize				 integer       no
     hw.physicalcpu				 integer       no
     hw.physicalcpu_max 			 integer       no
     hw.tbfrequency				 integer       no
     kern.argmax				 integer       no
     kern.bootargs				 string        no
     kern.boottime				 struct        no
     kern.clockrate				 struct        no
     kern.coredump				 integer       yes
     kern.corefile				 string        yes
     kern.flush_cache_on_write			 integer       yes
     kern.hostid				 integer       yes
     kern.hostname				 string        yes
     kern.job_control				 integer       no
     kern.maxfiles				 integer       yes
     kern.maxfilesperproc			 integer       yes
     kern.maxnbuf				 integer       yes
     kern.maxproc				 integer       yes
     kern.maxprocperuid 			 integer       yes
     kern.maxvnodes				 integer       yes
     kern.msgbuf				 integer       yes
     kern.nbuf					 integer       no
     kern.netboot				 integer       no
     kern.ngroups				 integer       no
     kern.nisdomainname 			 string        yes
     kern.num_files				 integer       no
     kern.num_tasks				 integer       no
     kern.num_taskthreads			 integer       no
     kern.num_threads				 integer       no
     kern.num_vnodes				 integer       no
     kern.nx					 integer       yes
     kern.osrelease				 string        no
     kern.osrevision				 integer       no
     kern.ostype				 string        no
     kern.osversion				 string        yes
     kern.posix1version 			 integer       no
     kern.procname				 string        yes
     kern.safeboot				 integer       no
     kern.saved_ids				 integer       no
     kern.secure_kernel 			 integer       no
     kern.securelevel				 integer       yes
     kern.singleuser				 integer       no
     kern.sleeptime				 struct        no
     kern.slide 				 integer       no
     kern.stack_depth_max			 integer       no
     kern.stack_size				 integer       no
     kern.sugid_coredump			 integer       yes
     kern.sugid_scripts 			 integer       yes
     kern.symfile				 string        no
     kern.usrstack				 integer       no
     kern.usrstack64				 integer       no
     kern.uuid					 string        no
     kern.version				 string        no
     kern.waketime				 struct        no
     machdep.cpu.address_bits.physical		 integer       no
     machdep.cpu.address_bits.virtual		 integer       no
     machdep.cpu.brand				 integer       no
     machdep.cpu.brand_string			 string        no
     machdep.cpu.cache.L2_associativity 	 integer       no
     machdep.cpu.cache.linesize 		 integer       no
     machdep.cpu.cache.size			 integer       no
     machdep.cpu.core_count			 integer       no
     machdep.cpu.cores_per_package		 integer       no
     machdep.cpu.extfamily			 integer       no
     machdep.cpu.extfeature_bits		 integer       no
     machdep.cpu.extfeatures			 string        no
     machdep.cpu.extmodel			 integer       no
     machdep.cpu.family 			 integer       no
     machdep.cpu.feature_bits			 integer       no
     machdep.cpu.features			 string        no
     machdep.cpu.leaf7_feature_bits		 integer       no
     machdep.cpu.leaf7_features 		 string        no
     machdep.cpu.logical_per_package		 integer       no
     machdep.cpu.max_basic			 integer       no
     machdep.cpu.max_ext			 integer       no
     machdep.cpu.microcode_version		 integer       no
     machdep.cpu.model				 integer       no
     machdep.cpu.processor_flag 		 integer       no
     machdep.cpu.signature			 integer       no
     machdep.cpu.stepping			 integer       no
     machdep.cpu.thread_count			 integer       no
     machdep.cpu.tlb.data.large 		 integer       no
     machdep.cpu.tlb.data.large_level1		 integer       no
     machdep.cpu.tlb.data.small 		 integer       no
     machdep.cpu.tlb.data.small_level1		 integer       no
     machdep.cpu.tlb.inst.large 		 integer       no
     machdep.cpu.tlb.inst.small 		 integer       no
     machdep.cpu.tlb.shared			 integer       no
     machdep.cpu.ucupdate			 integer       yes
     machdep.cpu.vendor 			 string        no
     machdep.cpu.xsave.extended_state		 integer       no
     machdep.tsc.deep_idle_rebase		 integer       yes
     machdep.tsc.frequency			 integer       no
     machdep.tsc.nanotime.generation		 integer       no
     machdep.tsc.nanotime.shift 		 integer       no
     net.inet.ip.forwarding			 integer       yes
     net.inet.ip.portrange.first		 integer       yes
     net.inet.ip.portrange.hifirst		 integer       yes
     net.inet.ip.portrange.hilast		 integer       yes
     net.inet.ip.portrange.last 		 integer       yes
     net.inet.ip.portrange.lowfirst		 integer       yes
     net.inet.ip.portrange.lowlast		 integer       yes
     net.inet.ip.redirect			 integer       yes
     net.inet.ip.ttl				 integer       yes
     net.inet.udp.checksum			 integer       yes
     net.inet.udp.maxdgram			 integer       yes
     vm.loadavg 				 struct        no
     vm.swapusage				 struct        no
     user.bc_base_max				 integer       no
     user.bc_dim_max				 integer       no
     user.bc_scale_max				 integer       no
     user.bc_string_max 			 integer       no
     user.coll_weights_max			 integer       no
     user.cs_path				 string        no
     user.expr_nest_max 			 integer       no
     user.line_max				 integer       no
     user.posix2_c_bind 			 integer       no
     user.posix2_c_dev				 integer       no
     user.posix2_char_term			 integer       no
     user.posix2_fort_dev			 integer       no
     user.posix2_fort_run			 integer       no
     user.posix2_localedef			 integer       no
     user.posix2_sw_dev 			 integer       no
     user.posix2_upe				 integer       no
     user.posix2_version			 integer       no
     user.re_dup_max				 integer       no
     user.stream_max				 integer       no
     user.tzname_max				 integer       no

FILES
     <sys/sysctl.h>	   definitions for top level identifiers, second level
			   kernel and hardware identifiers, and user level
			   identifiers
     <sys/socket.h>	   definitions for second level network identifiers
     <sys/gmon.h>	   definitions for third level profiling identifiers
     <vm/vm_param.h>	   definitions for second level virtual memory identi-
			   fiers
     <netinet/in.h>	   definitions for third level Internet identifiers
			   and fourth level IP identifiers
     <netinet/icmp_var.h>  definitions for fourth level ICMP identifiers
     <netinet/udp_var.h>   definitions for fourth level UDP identifiers

EXAMPLES
     For example, to retrieve the maximum number of processes allowed in the
     system, one would use the following request:

	   sysctl kern.maxproc

     To set the maximum number of processes allowed per uid to 1000, one would
     use the following request:

	   sysctl kern.maxprocperuid=1000

     Information about the system clock rate may be obtained with:

	   sysctl kern.clockrate

     Information about the load average history may be obtained with:

	   sysctl vm.loadavg

     More variables than these exist, and the best and likely only place to
     search for their deeper meaning is undoubtedly the source where they are
     defined.

COMPATIBILITY
     The -w option has been deprecated and is silently ignored.

SEE ALSO
     sysctl(3), sysctl.conf(5)

HISTORY
     A sysctl utility first appeared in 4.4BSD.

     In FreeBSD 2.2, sysctl was significantly remodeled.

BSD			       January 17, 2011 			   BSD
","# sysctl

> List and change kernel runtime variables.

- Show all available variables and their values:

`sysctl -a`

- Set a changeable kernel state variable:

`sysctl -w {{section.tunable}}={{value}}`

- Get currently open file handlers:

`sysctl fs.file-nr`

- Get limit for simultaneous open files:

`sysctl fs.file-max`

- Apply changes from /etc/sysctl.conf:

`sysctl -p`
"
cpufreq-set,,,,"# cpufreq-set

> A tool to modify CPU frequency settings.
> The frequency value should range between the output of command `cpufreq-info -l`.

- Set the CPU frequency policy of CPU 1 to ""userspace"":

`sudo cpufreq-set -c {{1}} -g {{userspace}}`

- Set the current minimum CPU frequency of CPU 1:

`sudo cpufreq-set -c {{1}} --min {{min_frequency}}`

- Set the current maximum CPU frequency of CPU 1:

`sudo cpufreq-set -c {{1}} --max {{max_frequency}}`

- Set the current work frequency of CPU 1:

`sudo cpufreq-set -c {{1}} -f {{work_frequency}}`
"
feh,,,,"# feh

> Lightweight image viewing utility.

- View images locally or using a URL:

`feh {{path/to/images}}`

- View images recursively:

`feh --recursive {{path/to/images}}`

- View images without window borders:

`feh --borderless {{path/to/images}}`

- Exit after the last image:

`feh --cycle-once {{path/to/images}}`

- Set the slideshow cycle delay:

`feh --slideshow-delay {{seconds}} {{path/to/images}}`

- Set your wallpaper (centered, filled, maximized, scaled or tiled):

`feh --bg-{{center|fill|max|scale|tile}} {{path/to/image}}`
"
betterlockscreen,,,,"# betterlockscreen

> Simple, minimal lock screen.

- Lock the screen:

`betterlockscreen --lock`

- Change the lock screen background:

`betterlockscreen -u {{path/to/image.png}}`

- Lock the screen, showing some custom text:

`betterlockscreen -l pixel -t ""{{custom lock screen text}}""`

- Lock the screen, with a custom monitor off timeout in seconds:

`betterlockscreen --off {{5}} -l`
"
fc-list,,,"FC-LIST(1)							    FC-LIST(1)



NAME
       fc-list - list available fonts

SYNOPSIS
       fc-list	[ -vVh ]  [ --verbose ]  [  [ -f format ]  [ --format format ]
       ]  [  [ -q ]  [ --quiet ]  ]  [ --version ]  [ --help ]

	[ pattern  [ element... ]   ]

DESCRIPTION
       fc-list lists fonts and styles available on the system for applications
       using  fontconfig.   If	any  elements  are  specified,	only those are
       printed.  Otherwise family and style are printed, unless verbose output
       is requested.

OPTIONS
       This  program  follows  the  usual  GNU	command line syntax, with long
       options starting with  two  dashes  (`-').  A  summary  of  options  is
       included below.

       -v     Print  verbose  output of the whole font pattern for each match,
	      or elements if any is provided.

       -f     Format output according to the format specifier format.

       -q     Suppress all normal output. returns 1 as the error  code	if  no
	      fonts matched.

       -V     Show version of the program and exit.

       -h     Show summary of options.

       pattern
	      If  this	argument  is set, only fonts matching pattern are dis-
	      played.

       element
	      If set, the element property is displayed for matching fonts.

EXAMPLES
       fc-list
	      Lists all font faces.

       fc-list :lang=hi
	      Lists font faces that cover Hindi.

       fc-list : family style file spacing
	      Lists the filename and spacing value for each font  face.  ``:''
	      is an empty pattern that matches all fonts.

SEE ALSO
       fc-match(1)  FcFontList(3) FcPatternFormat(3) fc-cat(1) fc-cache(1) fc-
       pattern(1) fc-query(1) fc-scan(1)

       The fontconfig user's guide, in	HTML  format:  /usr/share/doc/fontcon-
       fig/fontconfig-user.html.

AUTHOR
       This  manual  page was written by Keith Packard <keithp@keithp.com> and
       Josselin Mouette <joss@debian.org>.



				 Aug 13, 2008			    FC-LIST(1)
","# fc-list

> List available fonts installed on the system.

- Return a list of installed fonts in your system:

`fc-list`

- Return a list of installed fonts with given name:

`fc-list | grep '{{DejaVu Serif}}'`

- Return the number of installed fonts in your system:

`fc-list | wc -l`
"
watch,,,"WATCH(1)			 User Commands			      WATCH(1)



NAME
       watch - execute a program periodically, showing output fullscreen

SYNOPSIS
       watch [options] command

DESCRIPTION
       watch  runs  command  repeatedly, displaying its output and errors (the
       first screenfull).  This allows you to watch the program output	change
       over  time.   By default, command is run every 2 seconds and watch will
       run until interrupted.

OPTIONS
       -d, --differences [permanent]
	      Highlight the differences between  successive  updates.	Option
	      will  read optional argument that changes highlight to be perma-
	      nent, allowing to see what has changed at least once since first
	      iteration.

       -n, --interval seconds
	      Specify  update  interval.   The	command will not allow quicker
	      than 0.1 second interval, in which the smaller values  are  con-
	      verted. Both '.' and ',' work for any locales.

       -p, --precise
	      Make watch attempt to run command every interval seconds. Try it
	      with  ntptime  and  notice  how  the  fractional	seconds  stays
	      (nearly) the same, as opposed to normal mode where they continu-
	      ously increase.

       -t, --no-title
	      Turn off the header showing the interval, command,  and  current
	      time  at	the top of the display, as well as the following blank
	      line.

       -b, --beep
	      Beep if command has a non-zero exit.

       -e, --errexit
	      Freeze updates on command error, and exit after a key press.

       -g, --chgexit
	      Exit when the output of command changes.

       -c, --color
	      Interpret ANSI color and style sequences.

       -x, --exec
	      Pass command to exec(2) instead of sh -c which reduces the  need
	      to use extra quoting to get the desired effect.

       -h, --help
	      Display help text and exit.

       -v, --version
	      Display version information and exit.

EXIT STATUS
	      0      Success.
	      1      Various failures.
	      2      Forking the process to watch failed.
	      3      Replacing	child  process	stdout	with  write  side pipe
		     failed.
	      4      Command execution failed.
	      5      Closing child process write pipe failed.
	      7      IPC pipe creation failed.
	      8      Getting  child  process  return  value  with   waitpid(2)
		     failed, or command exited up on error.
	      other  The  watch  will  propagate  command exit status as child
		     exit status.
NOTES
       POSIX option processing is used (i.e., option processing stops  at  the
       first  non-option argument).  This means that flags after command don't
       get interpreted by watch itself.
BUGS
       Upon terminal resize, the screen will not be correctly repainted  until
       the  next  scheduled update.  All --differences highlighting is lost on
       that update as well.

       Non-printing characters are stripped from program output.  Use ""cat -v""
       as part of the command pipeline if you want to see them.

       Combining  Characters  that are supposed to display on the character at
       the last column on the screen may display one column early, or they may
       not display at all.

       Combining  Characters  never  count as different in --differences mode.
       Only the base character counts.

       Blank lines directly after a line which ends in the last column do  not
       display.

       --precise mode doesn't yet have advanced temporal distortion technology
       to compensate for a command that takes more than  interval  seconds  to
       execute.   watch also can get into a state where it rapid-fires as many
       executions of command as it can to catch up from a previous  executions
       running longer than interval (for example, netstat taking ages on a DNS
       lookup).
EXAMPLES
       To watch for mail, you might do
	      watch -n 60 from
       To watch the contents of a directory change, you could use
	      watch -d ls -l
       If you're only interested in files owned by user joe, you might use
	      watch -d 'ls -l | fgrep joe'
       To see the effects of quoting, try these out
	      watch echo $$
	      watch echo '$$'
	      watch echo ""'""'$$'""'""
       To see the effect of precision time keeping, try adding -p to
	      watch -n 10 sleep 1
       You can watch for your administrator to install the latest kernel with
	      watch uname -r
       (Note that -p isn't guaranteed to work across  reboots,	especially  in
       the face of ntpdate or other bootup time-changing mechanisms)



procps-ng			  2018-03-03			      WATCH(1)
","# watch

> Execute a command repeatedly, and monitor the output in full-screen mode.

- Monitor files in the current directory:

`watch {{ls}}`

- Monitor disk space and highlight the changes:

`watch -d {{df}}`

- Monitor ""node"" processes, refreshing every 3 seconds:

`watch -n {{3}} ""{{ps aux | grep node}}""`
"
rpm,,,,"# rpm

> RPM Package Manager.

- Show version of httpd package:

`rpm -q {{httpd}}`

- List versions of all matching packages:

`rpm -qa '{{mariadb*}}'`

- Forcibly install a package regardless of currently installed versions:

`rpm -U {{package_name.rpm}} --force`

- Identify owner of a file and show version of the package:

`rpm -qf {{/etc/postfix/main.cf}}`

- List package-owned files:

`rpm -ql {{kernel}}`

- Show scriptlets from an RPM file:

`rpm -qp --scripts {{package_name.rpm}}`

- Show changed, missing and/or incorrectly installed files of matching packages:

`rpm -Va '{{php-*}}'`
"
feedreader,https://jangernert.github.io/FeedReader/,"


FeedReader - RSS desktop client















Toggle navigation




FeedReader



Features
Installation
Support & Getting Involved




   


FeedReader RSS desktop client

































            	FeedReader is a modern desktop application designed to complement existing web-based RSS accounts.

            		It combines all the advantages of web based services like synchronisation across all your devices with everything you expect from a modern desktop application.
            	





Features
FeedReader works with




Feedbin


A fast, simple service that delivers a great reading experience.




feedly


One of the most popular online RSS services available.




FreshRSS


A free, self-hostable aggregator. Probably the best, according to the develpers.






InoReader


Popular alternative to feedly with similar features.




Local RSS


No online account or server needed. All data on your own harddrive.




Nextcloud


Self hosted cloud that can do RSS and much, much more.






The Old Reader


Welcome to the ultimate social RSS reader for The Open Web.




Tiny Tiny RSS


Self hosted powerful but lightweight RSS reader.




Push to Read-it-later




Instapaper


Save Anything. Read Anywhere.




Pocket


The world’s leading save-for-later service.




Wallabag


Save the web, freely.



Share with others




Email


Share via email right from FeedReader.




Telegram


Share articles to your friends and groups easly from FeedReader.




Twitter


Tweet about articles.



What makes FeedReader special?




Consistent article formating


 Read the complete article nicely formated directly inside FeedReader and choose one of 4 themes.




Customizability


 FeedReader is more flexible than it might first seem. Just open up dconf-editor and start tweaking.




Desktop notifications


 Always stay up to date. FeedReader will notify you whenever there are new articles for you.






Podcasts


 Listen to podcasts right from within FeedReader.




Fast search and filters


 Remember that one article from last week you can’t find anymore? With FeedReader you can.




Handy keyboard shortcuts


 Don’t like clicking? No problem! FeedReader has keyboard-shortcut’s for most of it’s actions.






Tagging


 Keep track of all your articles. Create tags to categorize and sort articles.



And much more ...



Installation



Flatpak


Manual Installation




Latest stable FeedReader
FeedReader is now availble as Flatpak and should be installable on all major Linux distributions that support the Flatpak Application Framework eg. Fedora, Debian, Ubuntu, elementaryOS, Arch, openSuSE, Mageia and many more.
For more information about Flatpak and how to use or install it for your distribution see the Flatpak webpage.
You will need the following packages installed:
(names can differ depending on the distribution)
xdg-desktop-portal
xdg-desktop-portal-gtk

The Flatpak package is distributed using Flathub. The Flathub repository needs to be configured correctly in order to receive the latest updates. The Flathub website has a quick setup for each distribution.
Install the latest stable FeedReader with just one command.
flatpak install flathub org.gnome.FeedReader



Required dependencies:
The packages names can differ depending on the distribution
build-essential
meson
ninja-build
vala (>=0.26)
pkg-config
libgirepository1.0-dev
libgtk-3-dev (>= 3.22)
libsoup2.4-dev
libjson-glib-dev
libwebkit2gtk-4.0-dev (or 3.0
libsqlite3-dev
libsecret-1-dev
libnotify-dev
libxml2-dev
libunity-dev (optional)
librest-dev
libgee-0.8-dev
libgstreamer1.0-dev
libgstreamer-plugins-base1.0-dev (gstreamer-pbutils-1.0)
libgoa-1.0-dev (>= 3.20)
libcurl-dev
libpeas-dev

1 - Navigate to the directory which contains the source and run meson to generate the required build-files:
meson -C builddir --prefix=/usr

2 - Compile the source-code and install the binaries:
sudo ninja -C builddir install




NOTE: If you run FeedReader with the TinyTinyRSS-backend please install the ""api_feedreader""-extension. Running FeedReader with the TinyTinyRSS-backend and without the extension is NOT supported.



Support & Getting Involved


Support




                You can support the development of FeedReader over at Bountysource and throw in a few bucks at any bug you would like to be fixed or any
                feature you would like to see implemented.
            


Translation




                Help us translate Feedreader to other languages at Weblate and join Feedreader translators team.
            




Bugs and new features




            The source code is available on GitHub.
            The list of the open issues can be found here. 
            The team working on FeedReader can be reached on Gitter chat room



Grabber Configuration




                Have you encountered a feed that does only contain a small preview of the article? Then help us change that. 
                FeedReader uses Full-Text RSS site config files. 
                Which allows the application to grab the whole content of an article. If a only contains the preview of the article, then the website config file is missing or outdated.
                You can either create a PR upstream or report that there. 
            



   



Designed by Aleksandar Todorović & Bilal Elmoussaoui using the Readable Bootstrap theme. 







",,"# feedreader

> A GUI desktop RSS client.
> More information: <https://jangernert.github.io/FeedReader/>.

- Print the count of unread articles:

`feedreader --unreadCount`

- Add a URL for a feed to follow:

`feedreader --addFeed={{feed_url}}`

- Grab a specific article using its URL:

`feedreader --grabArticle={{article_url}}`

- Download all images from a specific article:

`feedreader --url={{feed_url}} --grabImages={{article_path}}`

- Play media from a URL:

`feedreader --playMedia={{article_url}}`
"
iptables,,,,"# iptables

> Program that allows configuration of tables, chains and rules provided by the Linux kernel firewall.

- View chains, rules, and packet/byte counters for all tables:

`sudo iptables -vnL`

- Set chain policy rule:

`sudo iptables -P {{chain}} {{rule}}`

- Append rule to chain policy for IP:

`sudo iptables -A {{chain}} -s {{ip}} -j {{rule}}`

- Append rule to chain policy for IP considering protocol and port:

`sudo iptables -A {{chain}} -s {{ip}} -p {{protocol}} --dport {{port}} -j {{rule}}`

- Delete chain rule:

`sudo iptables -D {{chain}} {{rule_line_number}}`

- Save iptables configuration of a given table to a file:

`sudo iptables-save -t {{tablename}} > {{path/to/iptables_file}}`

- Restore iptables configuration from a file:

`sudo iptables-restore < {{path/to/iptables_file}}`
"
hlint,http://hackage.haskell.org/package/hlint,"











    hlint: Source code suggestions
  













Hackage :: [Package]



Search 



Browse
What's new
Upload
User accounts



hlint: Source code suggestions

      [ bsd3, development, library, program ]
      [ Propose Tags  ]
    

HLint gives suggestions on how to improve your source code.

    [Skip to Readme]
    
    




Versions [faq]
1.0.0.0, 1.0.0.1, 1.2, 1.4, 1.6, 1.6.1, 1.6.2, 1.6.3, 1.6.4, 1.6.5, 1.6.6, 1.6.7, 1.6.8, 1.6.9, 1.6.10, 1.6.11, 1.6.12, 1.6.13, 1.6.14, 1.6.15, 1.6.16, 1.6.17, 1.6.18, 1.6.19, 1.6.20, 1.6.21, 1.7, 1.7.1, 1.7.2, 1.7.3, 1.8, 1.8.1, 1.8.2, 1.8.3, 1.8.4, 1.8.5, 1.8.6, 1.8.7, 1.8.8, 1.8.9, 1.8.10, 1.8.11, 1.8.12, 1.8.13, 1.8.14, 1.8.15, 1.8.16, 1.8.17, 1.8.18, 1.8.19, 1.8.20, 1.8.21, 1.8.22, 1.8.23, 1.8.24, 1.8.25, 1.8.26, 1.8.27, 1.8.28, 1.8.29, 1.8.30, 1.8.31, 1.8.32, 1.8.33, 1.8.34, 1.8.35, 1.8.36, 1.8.37, 1.8.39, 1.8.40, 1.8.41, 1.8.42, 1.8.43, 1.8.44, 1.8.45, 1.8.46, 1.8.47, 1.8.48, 1.8.49, 1.8.50, 1.8.51, 1.8.52, 1.8.53, 1.8.54, 1.8.55, 1.8.56, 1.8.57, 1.8.58, 1.8.59, 1.8.60, 1.8.61, 1.9, 1.9.1, 1.9.2, 1.9.3, 1.9.4, 1.9.5, 1.9.6, 1.9.7, 1.9.8, 1.9.9, 1.9.10, 1.9.11, 1.9.12, 1.9.13, 1.9.14, 1.9.15, 1.9.16, 1.9.17, 1.9.18, 1.9.19, 1.9.20, 1.9.21, 1.9.22, 1.9.23, 1.9.24, 1.9.25, 1.9.26, 1.9.27, 1.9.28, 1.9.29, 1.9.30, 1.9.31, 1.9.32, 1.9.33, 1.9.34, 1.9.35, 1.9.36, 1.9.37, 1.9.38, 1.9.39, 1.9.40, 1.9.41, 2.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.0.10, 2.0.11, 2.0.12, 2.0.13, 2.0.14, 2.0.15, 2.1, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.1.5, 2.1.6, 2.1.7, 2.1.8, 2.1.9, 2.1.10, 2.1.11, 2.1.12, 2.1.13, 2.1.14, 2.1.15, 2.1.16, 2.1.17, 2.1.18, 2.1.19, 2.1.20, 2.1.21, 2.1.22, 2.1.23, 2.1.24, 2.1.25, 2.1.26, 2.2, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.2.6, 2.2.7, 2.2.8, 2.2.9, 2.2.10, 2.2.11, 3.0, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 3.1, 3.1.1, 3.1.2, 3.1.3, 3.1.4, 3.1.5, 3.1.6, 3.2 (info)


Change log
CHANGES.txt


Dependencies
aeson (>=1.1.2.0), ansi-terminal (>=0.8.1), base (==4.*), bytestring, cmdargs (>=0.10), containers, cpphs (>=1.20.1), data-default (>=0.3), directory, extra (>=1.7.3), file-embed, filepath, filepattern (>=0.1.1), ghc (==8.10.*), ghc-boot, ghc-boot-th, ghc-lib-parser (==8.10.*), ghc-lib-parser-ex (>=8.10.0.16 && <8.10.1), hlint, hscolour (>=1.21), process, refact (>=0.3), text, transformers, uniplate (>=1.5), unordered-containers, utf8-string, vector, yaml (>=0.5.0) [details]


License
BSD-3-Clause


Copyright
Neil Mitchell 2006-2020


Author
Neil Mitchell <ndmitchell@gmail.com>


Maintainer
Neil Mitchell <ndmitchell@gmail.com>



Category
Development


Home page


              https://github.com/ndmitchell/hlint#readme
            



Bug tracker


              https://github.com/ndmitchell/hlint/issues
            



Source repo
head: git clone https://github.com/ndmitchell/hlint.git


Uploaded
by NeilMitchell at 2020-09-14T15:52:22Z


Distributions
Arch:3.2, Debian:2.1.10, Fedora:3.1.6, FreeBSD:1.9.21, LTSHaskell:2.1.11, NixOS:3.1.6, Stackage:2.1.24, openSUSE:3.1.6


Executables
hlint


Downloads
240321 total (2844 in the last 30 days)


 Rating
2.75 (votes: 11)
	  [estimated by Bayesian average]


Your Rating


λ
λ
λ




Status
Docs uploaded by userBuild status unknown [no reports yet]



 

Modules[Index] [Quick Jump]LanguageHaskellLanguage.Haskell.HLint


FlagsNameDescriptionDefaultTypethreadedBuild with support for multithreaded executionEnabledManualgplUse GPL libraries, specifically hscolourEnabledManualghc-libForce dependency on ghc-lib-parser even if GHC API in the ghc package is supportedDisabledManualhsyamlUse HsYAML instead of yamlDisabledManualUse -f <flag> to enable a flag, or -f -<flag> to disable that flag. More info


Downloadshlint-3.2.tar.gz [browse] (Cabal source package)Package description (as included in the package)


Maintainer's Corner
For package maintainers and hackage trustees



            edit package information
          





Readme for hlint-3.2
      [back to package description]
      HLint    
HLint is a tool for suggesting possible improvements to Haskell code. These suggestions include ideas such as using alternative functions, simplifying code and spotting redundancies. This document is structured as follows:

Installing and running HLint
FAQ
Customizing the hints
Hacking HLint

Bugs and limitations
Bugs can be reported on the bug tracker. There are some issues that I do not intend to fix:

HLint operates on each module at a time in isolation, as a result HLint does not know about types or which names are in scope. This decision is deliberate, allowing HLint to parallelise and be used incrementally on code that may not type-check. If fixities are required to parse the code properly, they can be supplied.
The presence of seq may cause some hints (i.e. eta-reduction) to change the semantics of a program.
Some transformed programs may require additional type signatures, particularly if the transformations trigger the monomorphism restriction or involve rank-2 types.
Sometimes HLint will change the code in a way that causes values to default to different types, which may change the behaviour.
HLint assumes duplicate identical expressions within in a single expression are used at the same type.
The RebindableSyntax extension can cause HLint to suggest incorrect changes.
HLint can be configured with knowledge of C Pre Processor flags, but it can only see one conditional set of code at a time.
HLint turns on many language extensions so it can parse more documents, occasionally some break otherwise legal syntax - e.g. {-#INLINE foo#-} doesn't work with MagicHash, foo $bar means something different with TemplateHaskell. These extensions can be disabled with -XNoMagicHash or -XNoTemplateHaskell etc.
HLint doesn't run any custom preprocessors, e.g. markdown-unlit or record-dot-preprocessor, so code making use of them will usually fail to parse.

Installing and running HLint
Installation follows the standard pattern of any Haskell library or program: type cabal update to update your local hackage database, then cabal install hlint to install HLint.
Once HLint is installed, run hlint source where source is either a Haskell file, or a directory containing Haskell files. A directory will be searched recursively for any files ending with .hs or .lhs. For example, running HLint over darcs would give:
$ hlint darcs-2.1.2

darcs-2.1.2\src\CommandLine.lhs:94:1: Warning: Use concatMap
Found:
    concat $ map escapeC s
Perhaps:
    concatMap escapeC s

darcs-2.1.2\src\CommandLine.lhs:103:1: Suggestion: Use fewer brackets
Found:
    ftable ++ (map (\ (c, x) -> (toUpper c, urlEncode x)) ftable)
Perhaps:
    ftable ++ map (\ (c, x) -> (toUpper c, urlEncode x)) ftable

darcs-2.1.2\src\Darcs\Patch\Test.lhs:306:1: Warning: Use a more efficient monadic variant
Found:
    mapM (delete_line (fn2fp f) line) old
Perhaps:
    mapM_ (delete_line (fn2fp f) line) old

... lots more hints ...

Each hint says which file/line the hint relates to, how serious an issue it is, a description of the hint, what it found, and what you might want to replace it with. In the case of the first hint, it has suggested that instead of applying concat and map separately, it would be better to use the combination function concatMap.
The first hint is marked as an warning, because using concatMap in preference to the two separate functions is always desirable. In contrast, the removal of brackets is probably a good idea, but not always. Reasons that a hint might be a suggestion include requiring an additional import, something not everyone agrees on, and functions only available in more recent versions of the base library.
Any configuration can be done via .hlint.yaml file.
Bug reports: The suggested replacement should be equivalent - please report all incorrect suggestions not mentioned as known limitations.
Suggested usage
HLint usage tends to proceed in three distinct phases:

Initially, run hlint . --report to generate report.html containing a list of all issues HLint has found. Fix those you think are worth fixing and keep repeating.
Once you are happy, run hlint . --default > .hlint.yaml, which will generate a settings file ignoring all the hints currently outstanding. Over time you may wish to edit the list.
For larger projects, add custom hints or rules.

Most hints are intended to be a good idea in most circumstances, but not universally - judgement is required. When contributing to someone else's project, HLint can identify pieces of code to look at, but only make changes you consider improvements - not merely to adhere to HLint rules.
Running with Continuous Integration
On CI you might wish to run hlint . (or hlint src if you only want to check the src directory). To avoid the cost of compilation you may wish to fetch the latest HLint binary release.
For the CI systems Travis, Appveyor and Azure Pipelines add the line:
curl -sSL https://raw.github.com/ndmitchell/hlint/master/misc/run.sh | sh -s .

The arguments after -s are passed to hlint, so modify the final . if you want other arguments. This command works on Windows, Mac and Linux.
Integrations
HLint is integrated into lots of places:

Lots of editors have HLint plugins (quite a few have more than one HLint plugin).
HLint is part of the multiple editor plugins ghc-mod and Intero.
HLint Source Plugin makes HLint available as a GHC plugin.
Splint is another source plugin that doesn't require reparsing the GHC source if you are on the latest GHC version.
Code Climate is a CI for analysis which integrates HLint.
Danger can be used to automatically comment on pull requests with HLint suggestions.
Restyled includes an HLint Restyler to automatically run hlint --refactor on files changed in GitHub Pull Requests.
lpaste integrates with HLint - suggestions are shown at the bottom.
hlint-test helps you write a small test runner with HLint.
hint-man automatically submits reviews to opened pull requests in your repositories with inline hints.
CircleCI has a plugin to run HLint more easily.

Automatically Applying Hints
HLint can automatically apply some suggestions using the --refactor flag. If passed, instead of printing out the hints, HLint will output the refactored file on stdout. For --refactor to work it is necessary to have the refactor executable from the apply-refact package on your $PATH. HLint uses that tool to perform the refactoring.
When using --refactor you can pass additional options to the refactor binary using --refactor-options flag. Some useful flags include -i (which replaces the original file) and -s (which asks for confirmation before performing a hint). The --with-refactor flag can be used to specify an alternative location for the refactor binary. Simple bindings for Vim, Emacs and Atom are available.
While the --refactor flag is useful, not all hints support refactoring. See hints.md for which hints don't support refactoring.
Reports
HLint can generate a lot of information, making it difficult to search for particular types of errors. The --report flag will cause HLint to generate a report file in HTML, which can be viewed interactively. Reports are recommended when there are more than a handful of hints.
Language Extensions
HLint enables most Haskell extensions, disabling only those which steal too much syntax (e.g. Arrows, TransformListComp and TypeApplications). Individual extensions can be enabled or disabled with, for instance, -XArrows, or -XNoMagicHash. The flag -XHaskell2010 selects Haskell 2010 compatibility. You can also pass them via .hlint.yaml file. For example: - arguments: [-XArrows].
Emacs Integration
Emacs integration has been provided by Alex Ott. The integration is similar to compilation-mode, allowing navigation between errors. The script is at hs-lint.el, and a copy is installed locally in the data directory. To use, add the following code to the Emacs init file:
(require 'hs-lint)
(defun my-haskell-mode-hook ()
    (local-set-key ""\C-cl"" 'hs-lint))
(add-hook 'haskell-mode-hook 'my-haskell-mode-hook)

GHCi Integration
GHCi integration has been provided by Gwern Branwen. The integration allows running :hlint from the GHCi prompt. The script is at hlint.ghci, and a copy is installed locally in the data directory. To use, add the contents to your GHCi startup file.
Parallel Operation
To run HLint on 4 processors append the flags -j4. HLint will usually perform fastest if n is equal to the number of physical processors, which can be done with -j alone.
If your version of GHC does not support the GHC threaded runtime then install with the command: cabal install --flags=""-threaded""
C preprocessor support
HLint runs the cpphs C preprocessor over all input files, by default using the current directory as the include path with no defined macros. These settings can be modified using the flags --cpp-include and --cpp-define. To disable the C preprocessor use the flag -XNoCPP. There are a number of limitations to the C preprocessor support:

HLint will only check one branch of an #if, based on which macros have been defined.
Any missing #include files will produce a warning on the console, but no information in the reports.

FAQ
Why are hints not applied recursively?
Consider:
foo xs = concat (map op xs)

This will suggest eta reduction to concat . map op, and then after making that change and running HLint again, will suggest use of concatMap. Many people wonder why HLint doesn't directly suggest concatMap op. There are a number of reasons:

HLint aims to both improve code, and to teach the author better style. Doing modifications individually helps this process.
Sometimes the steps are reasonably complex, by automatically composing them the user may become confused.
Sometimes HLint gets transformations wrong. If suggestions are applied recursively, one error will cascade.
Some people only make use of some of the suggestions. In the above example using concatMap is a good idea, but sometimes eta reduction isn't. By suggesting them separately, people can pick and choose.
Sometimes a transformed expression will be large, and a further hint will apply to some small part of the result, which appears confusing.
Consider f $ (a b). There are two valid hints, either remove the $ or remove the brackets, but only one can be applied.

Why doesn't the compiler automatically apply the optimisations?
HLint doesn't suggest optimisations, it suggests code improvements - the intention is to make the code simpler, rather than making the code perform faster. The GHC compiler automatically applies many of the rules suggested by HLint, so HLint suggestions will rarely improve performance.
Why doesn't HLint know the fixity for my custom !@%$ operator?
HLint knows the fixities for all the operators in the base library, as well as operators whose fixities are declared in the module being linted, but no others. HLint works on a single file at a time, and does not resolve imports, so cannot see fixity declarations from imported modules. You can tell HLint about fixities by putting them in a hint file named .hlint.yaml with the syntax - fixity: ""infixr 5 !@%$"". You can also use --find to automatically produce a list of fixity declarations in a file.
Which hints are ignored?
Some hints are off-by-default. Some are ignored by the configuration settings. To see all hints pass --show. This feature is often useful in conjunction with --report which shows the hints in an interactive web page, allowing them to be browsed broken down by hint.
Which hints are used?
HLint uses the hlint.yaml file it ships with by default (containing things like the concatMap hint above), along with the first .hlint.yaml file it finds in the current directory or any parent thereof. To include other hints, pass --hint=filename.yaml.
Why do I sometimes get a ""Note"" with my hint?
Most hints are perfect substitutions, and these are displayed without any notes. However, some hints change the semantics of your program - typically in irrelevant ways - but HLint shows a warning note. HLint does not warn when assuming typeclass laws (such as == being symmetric). Some notes you may see include:

Increases laziness - for example foldl (&&) True suggests and including this note. The new code will work on infinite lists, while the old code would not. Increasing laziness is usually a good idea.
Decreases laziness - for example (fst a, snd a) suggests a including this note. On evaluation the new code will raise an error if a is an error, while the old code would produce a pair containing two error values. Only a small number of hints decrease laziness, and anyone relying on the laziness of the original code would be advised to include a comment.
Removes error - for example foldr1 (&&) suggests and including the note Removes error on []. The new code will produce True on the empty list, while the old code would raise an error. Unless you are relying on the exception thrown by the empty list, this hint is safe - and if you do rely on the exception, you would be advised to add a comment.

What is the difference between error/warning/suggestion?
Every hint has a severity level:

Error - by default only used for parse errors.
Warning - for example concat (map f x) suggests concatMap f x as a ""warning"" severity hint. From a style point of view, you should always replace a combination of concat and map with concatMap.
Suggestion - for example x !! 0 suggests head x as a ""suggestion"" severity hint. Typically head is a simpler way of expressing the first element of a list, especially if you are treating the list inductively. However, in the expression f (x !! 4) (x !! 0) (x !! 7), replacing the middle argument with head makes it harder to follow the pattern, and is probably a bad idea. Suggestion hints are often worthwhile, but should not be applied blindly.

The difference between warning and suggestion is one of personal taste, typically my personal taste. If you already have a well developed sense of Haskell style, you should ignore the difference. If you are a beginner Haskell programmer you may wish to focus on warning hints before suggestion hints.
Is it possible to use pragma annotations in code that is read by ghci (conflicts with OverloadedStrings)?
Short answer: yes, it is!
If the language extension OverloadedStrings is enabled, ghci may however report error messages such as:
Ambiguous type variable ‘t0’ arising from an annotation
prevents the constraint ‘(Data.Data.Data t0)’ from being solved.

In this case, a solution is to add the :: String type annotation. For example:
{-# ANN someFunc (""HLint: ignore Use fmap"" :: String) #-}

See discussion in issue #372.
Why do I get a parse error?
HLint enables/disables a set of extensions designed to allow as many files to parse as possible, but sometimes you'll need to enable an additional extension (e.g. Arrows, QuasiQuotes, ...), or disable some (e.g. MagicHash) to enable your code to parse.
You can enable extensions by specifying additional command line arguments in .hlint.yaml, e.g.: - arguments: [-XQuasiQuotes].
Customizing the hints
To customize the hints given by HLint, create a file .hlint.yaml in the root of your project. For a suitable default run:
hlint --default > .hlint.yaml

This default configuration contains lots of examples, including:

Adding command line arguments to all runs, e.g. --color or -XNoMagicHash.
Ignoring certain hints, perhaps within certain modules/functions.
Restricting use of GHC flags/extensions/functions, e.g. banning Arrows and unsafePerformIO.
Adding additional project-specific hints.

You can see the output of --default here.
If you wish to use the Dhall configuration language to customize HLint, there is an example and type definition.
Ignoring hints
Some of the hints are subjective, and some users believe they should be ignored. Some hints are applicable usually, but occasionally don't always make sense. The ignoring mechanism provides features for suppressing certain hints. Ignore directives can either be written as pragmas in the file being analysed, or in the hint files. Examples of pragmas are:

{-# ANN module ""HLint: ignore"" #-} or {-# HLINT ignore #-} or {- HLINT ignore -} - ignore all hints in this module (use module literally, not the name of the module).
{-# ANN module ""HLint: ignore Eta reduce"" #-} or {-# HLINT ignore ""Eta reduce"" #-} or {- HLINT ignore ""Eta reduce"" -} - ignore all eta reduction suggestions in this module.
{-# ANN myFunction ""HLint: ignore"" #-} or {-# HLINT ignore myFunction #-} or {- HLINT ignore myFunction -} - don't give any hints in the function myFunction.
{-# ANN myFunction ""HLint: error"" #-} or {-# HLINT error myFunction #-} or {- HLINT error myFunction -} - any hint in the function myFunction is an error.
{-# ANN module ""HLint: error Use concatMap"" #-} or {-# HLINT error ""Use concatMap"" #-} or {- HLINT error ""Use concatMap"" -} - the hint to use concatMap is an error (you may also use warn or suggest in place of error for other severity levels).

For ANN pragmas it is important to put them after any import statements. If you have the OverloadedStrings extension enabled you will need to give an explicit type to the annotation, e.g. {-# ANN myFunction (""HLint: ignore"" :: String) #-}. The ANN pragmas can also increase compile times or cause more recompilation than otherwise required, since they are evaluated by TemplateHaskell.
For {-# HLINT #-} pragmas GHC may give a warning about an unrecognised pragma, which can be suppressed with -Wno-unrecognised-pragmas.
For {- HLINT -} comments they are likely to be treated as comments in syntax highlighting, which can lead to them being overlooked.
Ignore directives can also be written in the hint files:

- ignore: {name: Eta reduce} - suppress all eta reduction suggestions.
- ignore: {name: Eta reduce, within: [MyModule1, MyModule2]} - suppress eta reduction hints in the MyModule1 and MyModule2 modules.
- ignore: {within: MyModule.myFunction} - don't give any hints in the function MyModule.myFunction.
- error: {within: MyModule.myFunction} - any hint in the function MyModule.myFunction is an error.
- error: {name: Use concatMap} - the hint to use concatMap is an error (you may also use warn or suggest in place of error for other severity levels).

These directives are applied in the order they are given, with later hints overriding earlier ones.
You can choose to ignore all hints with - ignore: {} then selectively enable the ones you want (e.g. - warn: {name: Use const}), but it isn't a totally smooth experience (see #747 and #748).
Finally, hlint defines the __HLINT__ preprocessor definition (with value 1), so problematic definitions (including those that don't parse) can be hidden with:
#ifndef __HLINT__
foo = ( -- HLint would fail to parse this
#endif

Adding hints
The hint suggesting concatMap can be defined as:
- warn: {lhs: concat (map f x), rhs: concatMap f x}

This line can be read as replace concat (map f x) with concatMap f x. All single-letter variables are treated as substitution parameters. For examples of more complex hints see the supplied hlint.yaml file in the data directory. This hint will automatically match concat . map f and concat $ map f x, so there is no need to give eta-reduced variants of the hints. Hints may tagged with error, warn or suggest to denote how severe they are by default. In addition, hint is a synonym for suggest. If you come up with interesting hints, please submit them for inclusion.
You can search for possible hints to add from a source file with the --find flag, for example:
$ hlint --find=src/Utils.hs
-- hints found in src/Util.hs
- warn: {lhs: ""null (intersect a b)"", rhs: ""disjoint a b""}
- warn: {lhs: ""dropWhile isSpace"", rhs: ""trimStart""}
- fixity: ""infixr 5 !:""

These hints are suitable for inclusion in a custom hint file. You can also include Haskell fixity declarations in a hint file, and these will also be extracted. If you pass only --find flags then the hints will be written out, if you also pass files/folders to check, then the found hints will be automatically used when checking.
Hints can specify more advanced aspects, with names and side conditions. To see examples and descriptions of these features look at the default hint file and the hint interpretation module comments.
Restricting items
HLint can restrict what Haskell code is allowed, which is particularly useful for larger projects which wish to enforce coding standards - there is a short example in the HLint repo itself. As an example of restricting extensions:
- extensions:
  - default: false
  - name: [DeriveDataTypeable, GeneralizedNewtypeDeriving]
  - {name: CPP, within: CompatLayer}

The above block declares that GHC extensions are not allowed by default, apart from DeriveDataTypeable and GeneralizedNewtypeDeriving which are available everywhere. The CPP extension is only allowed in the module CompatLayer. Much like extensions, you can use flags to limit the GHC_OPTIONS flags that are allowed to occur. You can also ban certain functions:
- functions:
  - {name: nub, within: []}
  - {name: unsafePerformIO, within: CompatLayer}

This declares that the nub function can't be used in any modules, and thus is banned from the code. That's probably a good idea, as most people should use an alternative that isn't O(n^2) (e.g. nubOrd). We also whitelist where unsafePerformIO can occur, ensuring that there can be a centrally reviewed location to declare all such instances. Finally, we can restrict the use of modules with:
- modules:
  - {name: [Data.Set, Data.HashSet], as: Set}
  - {name: Control.Arrow, within: []}
  - {name: Control.Monad.State, badidents: [modify, get, put], message: ""Use Control.Monad.State.Class instead""}

This fragment requires that all imports of Set must be qualified Data.Set as Set, enforcing consistency. It also ensures the module Control.Arrow can't be used anywhere. It also prevents explicit imports of the modify identifier from Control.Monad.State (this is meant to allow you to prevent people from importing reexported identifiers).
You can customize the Note: for restricted modules, functions and extensions, by providing a message field (default: may break the code).
Hacking HLint
Contributions to HLint are most welcome, following my standard contribution guidelines. You can run the tests either from within a ghci session by typing :test or by running the standalone binary's tests via cabal run -- hlint --test or stack run -- hlint --test. After changing hints, you will need to regenerate the hints.md file with hlint --generate-summary.
New tests for individual hints can be added directly to source and hint files by adding annotations bracketed in <TEST></TEST> code comment blocks. As some examples:
{-
    Tests to check the zipFrom hint works

<TEST>
zip [1..length x] x -- zipFrom 1 x
zip [1..length y] x
zip [1..length x] x -- ??? @Warning
</TEST>
-}

The general syntax is lhs -- rhs with lhs being the expression you expect to be rewritten as rhs. The absence of rhs means you expect no hints to fire. In addition ??? lets you assert a warning without a particular suggestion, while @ tags require a specific severity -- both these features are used less commonly.
Acknowledgements
Many improvements to this program have been made by Niklas Broberg in response to feature requests. Additionally, many people have provided help and patches, including Lennart Augustsson, Malcolm Wallace, Henk-Jan van Tuyl, Gwern Branwen, Alex Ott, Andy Stewart, Roman Leshchinskiy, Johannes Lippmann, Iustin Pop, Steve Purcell, Mitchell Rosen and others.


 







    Produced by hackage and Cabal 3.0.2.99.
  




",,"# hlint

> Tool for suggesting improvements to Haskell code.
> More information: <http://hackage.haskell.org/package/hlint>.

- Display suggestions for a given file:

`hlint {{path/to/file}} options`

- Check all Haskell files and generate a report:

`hlint {{path/to/directory}} --report`

- Automatically apply most suggestions:

`hlint {{path/to/file}} --refactor`

- Display additional options:

`hlint {{path/to/file}} --refactor-options`

- Generate a settings file ignoring all outstanding hints:

`hlint {{path/to/file}} --default > {{.hlint.yaml}}`
"
microcom,,,,"# microcom

> A minimalistic terminal program, used to access remote devices via a serial, CAN or telnet connection from the console.

- Open a serial port using the specified baud rate:

`microcom --port {{path/to/serial_port}} --speed {{baud_rate}}`

- Establish a telnet connection to the specified host:

`microcom --telnet {{hostname}}:{{port}}`
"
getfacl,,,,"# getfacl

> Get file access control lists.

- Display the file access control list:

`getfacl {{path/to/file_or_directory}}`

- Display the file access control list with numeric user and group IDs:

`getfacl -n {{path/to/file_or_directory}}`

- Display the file access control list with tabular output format:

`getfacl -t {{path/to/file_or_directory}}`
"
timedatectl,,,,"# timedatectl

> Control the system time and date.

- Check the current system clock time:

`timedatectl`

- Set the local time of the system clock directly:

`timedatectl set-time {{""yyyy-MM-dd hh:mm:ss""}}`

- List available timezones:

`timedatectl list-timezones`

- Set the system timezone:

`timedatectl set-timezone {{timezone}}`

- Enable Network Time Protocol (NTP) synchronization:

`timedatectl set-ntp on`
"
a2ensite,https://manpages.debian.org/buster/apache2/a2ensite.8.en.html,"



a2ensite(8) — apache2 — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / apache2
     
     
     
     / a2ensite(8)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


EXIT STATUS


EXAMPLES


FILES


SEE ALSO


AUTHOR







other versions




buster 2.4.38-3+deb10u3


buster-backports 2.4.46-1~bpo10+1


testing 2.4.46-1


unstable 2.4.46-1






Scroll to navigation



A2ENSITE(8)
System Manager's Manual
A2ENSITE(8)




NAME¶
a2ensite, a2dissite - enable or disable an apache2 site / virtual host


SYNOPSIS¶
a2ensite [ [-q|--quiet] site]
a2dissite [ [-q|--quiet] site]


DESCRIPTION¶
This manual page documents briefly the a2ensite and a2dissite
  commands.
a2ensite is a script that enables the specified site (which
    contains a <VirtualHost> block) within the apache2
    configuration. It does this by creating symlinks within
    /etc/apache2/sites-enabled. Likewise, a2dissite disables a
    site by removing those symlinks. It is not an error to enable a site which
    is already enabled, or to disable one which is already disabled.
Apache treats the very first virtual host enabled specially as
    every request not matching any actual directive is being redirected there.
    Thus it should be called 000-default in order to sort before the
    remaining hosts to be loaded first.


OPTIONS¶

-q, --quiet
Don't show informative messages.
-m, --maintmode
Enables the maintainer mode, that is the program invocation is effectuated
      automatically by a maintainer script. This switch should not be used by
      end users.
-p, --purge
When disabling a module, purge all traces of the module in the internal
      state data base.



EXIT STATUS¶
a2ensite and a2dissite exit with status 0 if all sites are
  processed successfully, 1 if errors occur, 2 if an invalid option was used.


EXAMPLES¶
a2dissite 000-default
Disables the default site.


FILES¶

/etc/apache2/sites-available
Directory with files giving information on available sites.
/etc/apache2/sites-enabled
Directory with links to the files in sites-available for enabled
      sites.



SEE ALSO¶
apache2ctl(8).


AUTHOR¶
This manual page was written by Stefan Fritsch <sf@debian.org> (based on
  the a2enmod manual page by Daniel Stone <daniel@sfarc.net>) for the
  Debian GNU/Linux distribution.




8 June 2007










Source file:


a2ensite.8.en.gz (from apache2 2.4.38-3+deb10u3)




Source last updated:


2019-10-15T19:53:42Z




Converted to HTML:


2020-09-01T03:18:56Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# a2ensite

> Enable an Apache virtual host on Debian-based OSes.
> More information: <https://manpages.debian.org/buster/apache2/a2ensite.8.en.html>.

- Enable a virtual host:

`sudo a2ensite {{virtual_host}}`

- Don't show informative messages:

`sudo a2ensite --quiet {{virtual_host}}`
"
lvreduce,,,,"# lvreduce

> Reduce the size of a logical volume.

- Reduce a volume's size to 120GB:

`lvreduce --size {{120G}} {{logical_volume}}`

- Reduce a volume's size by 40GB as well as the underlying filesystem:

`lvreduce --size -{{40G}} -r {{logical_volume}}`
"
xvfb-run,https://www.x.org/wiki/,"


X.Org




















X.Org






Edit
Page History
Repo Info





The X.Org project provides an open source implementation of the X Window System. The development work is being done in conjunction with the freedesktop.org community.  The X.Org Foundation is the educational non-profit corporation whose Board serves this effort, and whose Members lead this work. 
The last full release of the entire X.Org stack was X11R7.7 - since then individual X.Org modules have been released independently as needed - see the xorg-announce archives for details of those releases, and https://www.x.org/releases/individual/ for downloads. Information about all releases is available.  (Important: If you have an older release, please see the Security page for information on security updates.)



Follow X.Org on:



You may be interested in: 


Documentation 
Development-related news. 
X.Org events. 
Press releases. 
The Annual Report on the State of the X.Org Foundation 
Related projects. 

Reporting problems, asking questions and getting help

Check to see if your question is answered in the FAQ.
Check the issues for the xorg group in the freedesktop gitlab to report bugs against X.Org. 
Check the Xorg mailing list archives 
Send other questions or comments to the xorg mailing list. 
Or get help on XorgIRC. 

Development

The DeveloperStart page includes information for developers along with links to per-module developer pages. 

Mailing Lists
On XorgMailingLists you can find a list of X-related mailing lists hosted on lists.freedesktop.org.  More mailing lists on X Window System and related technologies along with subscription directions are available at XOrg Foundation.
Getting X
The best place to get X is from your operating system or distribution vendor.  X.Org currently provides no binaries. 
There are many Mirrors from which you can download source code to the X Window System. If you would like to be a mirror, feel free to do so and add yourself to the Mirrors page. 
Development snapshots are currently on hiatus; most modules now update slowly enough that frequent snapshots aren't needed. 
Security
For security advisories please check our SecurityPage. 
Please notify us of any security issues by sending mail to xorg_security@x.org . 
Sponsorship and Donations
The X.Org Foundation welcomes sponsorship (both cash and in-kind), and tries hard to put the donations of sponsors to transparent good use.  The Foundation is an extremely low-overhead all-volunteer organization.  If you are interested in contributing, please see our SponsorshipPage. 
Donate via SPI Paypal:

Donate via SPI Click & Pledge:

Donation via check or money order:
Make your check payable to Software in the Public Interest, Inc. and
write ""X.org"" in the memo or reference field.  For more information
including the mailing address, please see
https://spi-inc.org/donations/
Acknowledgements
Our thanks go to Portland State University and
Massachusetts Institute of Technology for
providing the hosting of x.org/freedesktop.org, to
Sun and HP for providing the
x.org/freedesktop.org hardware, and to Sun,
DealsLands, and others who have
provided generous financial sponsorship and in-kind support.
Our thanks also go to the contributors to the X Window System technology over the years. Many of these are acknowledged in previous distribution release notes. 
Copying
The content of this wiki is licensed under the MIT License unless stated otherwise by the author of specific wiki pages.
This license has been selected to ease documentation sharing with the xserver source code.





Last edited Mon Nov 11 10:34:33 2019







",,"# xvfb-run

> Run a command in a virtual X server environment.
> More information: <https://www.x.org/wiki/>.

- Run the specified command in a virtual X server:

`xvfb-run {{command}}`

- Try to get a free server number, if the default (99) is not available:

`xvfb-run --auto-servernum {{command}}`

- Pass arguments to the Xvfb server:

`xvfb-run --server-args ""{{-screen 0 1024x768x24}}"" {{command}}`
"
sensible-editor,,,,"# sensible-editor

> Open the default editor.

- Open a file in the default editor:

`sensible-editor {{file}}`

- Open a file in the default editor, with the cursor at the end of the file:

`sensible-editor + {{file}}`

- Open a file in the default editor, with the cursor at the beginning of line 10:

`sensible-editor +10 {{file}}`

- Open 3 files in vertically splitted editor windows at the same time:

`sensible-editor -O3 {{file_1}} {{file_2}} {{file_3}}`
"
setxkbmap,,,,"# setxkbmap

> Set the keyboard using the X Keyboard Extension.

- Set the keyboard in French AZERTY:

`setxkbmap {{fr}}`

- Set multiple keyboard layouts, their variants and switching option:

`setxkbmap -layout {{us,de}} -variant {{,qwerty}} -option {{'grp:alt_caps_toggle'}}`

- Get help:

`setxkbmap -help`

- List all layouts:

`localectl list-x11-keymap-layouts`

- List variants for the layout:

`localectl list-x11-keymap-variants {{de}}`

- List available switching options:

`localectl list-x11-keymap-options | grep grp:`
"
ip-address,,,,"# ip address

> IP Address management subcommand.

- List network interfaces and their associated IP addresses:

`ip address`

- Filter to show only active network interfaces:

`ip address show up`

- Display information about a specific network interface:

`ip address show dev {{eth0}}`

- Add an IP address to a network interface:

`ip address add {{ip_address}} dev {{eth0}}`

- Remove an IP address from a network interface:

`ip address delete {{ip_address}} dev {{eth0}}`

- Delete all IP addresses in a given scope from a network interface:

`ip address flush dev {{eth0}} scope {{global|host|link}}`
"
lrzuntar,,,,"# lrzuntar

> A wrapper for `lrunzip` to simplify decompression of directories.
> See also: `lrztar`, `lrzip`.

- Decompress from a file to the current directory:

`lrzuntar {{path/to/archive.tar.lrz}}`

- Decompress from a file to the current directory using a specific number of processor threads:

`lrzuntar -p {{8}} {{path/to/archive.tar.lrz}}`

- Decompress from a file to the current directory and silently overwrite items that already exist:

`lrzuntar -f {{archive.tar.lrz}}`

- Specify the output path:

`lrzuntar -O {{path/to/directory}} {{archive.tar.lrz}}`

- Delete the compressed file after decompression:

`lrzuntar -D {{path/to/archive.tar.lrz}}`
"
beep,,,"curs_beep(3X)							 curs_beep(3X)



NAME
       beep, flash - curses bell and screen flash routines

SYNOPSIS
       #include <curses.h>

       int beep(void);
       int flash(void);

DESCRIPTION
       The  beep  and flash routines are used to alert the terminal user.  The
       routine beep sounds an audible alarm on the terminal, if possible; oth-
       erwise it flashes the screen (visible bell).  The routine flash flashes
       the screen, and if that is not possible, sounds the alert.  If  neither
       alert is possible, nothing happens.  Nearly all terminals have an audi-
       ble alert (bell or beep), but only some can flash the screen.

RETURN VALUE
       These routines return OK if they succeed in beeping  or	flashing,  ERR
       otherwise.

EXTENSIONS
       SVr4's beep and flash routines always returned OK, so it was not possi-
       ble to tell when the beep or flash failed.

PORTABILITY
       These functions are described in the  XSI  Curses  standard,  Issue  4.
       Like SVr4, it specifies that they always return OK.

SEE ALSO
       curses(3X)



								 curs_beep(3X)
","# beep

> A utility to beep the PC speaker.

- Play a beep:

`beep`

- Play a beep that repeats:

`beep -r {{repetitions}}`

- Play a beep at a specified frequency (Hz) and duration (milliseconds):

`beep -f {{frequency}} -l {{duration}}`

- Play each new frequency and duration as a distinct beep:

`beep -f {{frequency}} -l {{duration}} -n -f {{frequency}} -l {{duration}}`

- Play the C major scale:

`beep -f 262 -n -f 294 -n -f 330 -n -f 349 -n -f 392 -n -f 440 -n -f 494 -n -f 523`
"
rc-update,,,,"# rc-update

> Add and remove OpenRC services to and from runlevels.
> See also `openrc`.

- List all services and the runlevels they are added to:

`rc-update show`

- Add a service to a runlevel:

`sudo rc-update add {{service_name}} {{runlevel}}`

- Delete a service from a runlevel:

`sudo rc-update delete {{service_name}} {{runlevel}}`

- Delete a service from all runlevels:

`sudo rc-update --all delete {{service_name}}`
"
rfkill,,,,"# rfkill

> Enable and disable wireless devices.

- List devices:

`rfkill`

- Filter by columns:

`rfkill -o {{ID,TYPE,DEVICE}}`

- Block devices by type (e.g. bluetooth, wlan):

`rfkill block {{bluetooth}}`

- Unblock devices by type (e.g. bluetooth, wlan):

`rfkill unblock {{wlan}}`

- Output in JSON format:

`rfkill -J`
"
lsscsi,,,,"# lsscsi

> List SCSI devices (or hosts) and their attributes.

- List all SCSI devices:

`lsscsi`

- List all SCSI devices with detailed attributes:

`lsscsi -L`

- List all SCSI devices with human readable disk capacity:

`lsscsi -s`
"
hexdump,,,"
HEXDUMP(1)		  BSD General Commands Manual		    HEXDUMP(1)

NAME
     hexdump -- ASCII, decimal, hexadecimal, octal dump

SYNOPSIS
     hexdump [-bcCdovx] [-e format_string] [-f format_file] [-n length]
	     [-s skip] file ...

DESCRIPTION
     The hexdump utility is a filter which displays the specified files, or
     the standard input, if no files are specified, in a user specified for-
     mat.

     The options are as follows:

     -b      One-byte octal display.  Display the input offset in hexadecimal,
	     followed by sixteen space-separated, three column, zero-filled,
	     bytes of input data, in octal, per line.

     -C      Canonical hex+ASCII display.  Display the input offset in hexa-
	     decimal, followed by sixteen space-separated, two column, hexa-
	     decimal bytes, followed by the same sixteen bytes in %_p format
	     enclosed in ``|'' characters.

     -c      One-byte character display.  Display the input offset in hexadec-
	     imal, followed by sixteen space-separated, three column, space-
	     filled, characters of input data per line.

     -d      Two-byte decimal display.	Display the input offset in hexadeci-
	     mal, followed by eight space-separated, five column, zero-filled,
	     two-byte units of input data, in unsigned decimal, per line.

     -e format_string
	     Specify a format string to be used for displaying data.

     -f format_file
	     Specify a file that contains one or more newline separated format
	     strings.  Empty lines and lines whose first non-blank character
	     is a hash mark (#) are ignored.

     -n length
	     Interpret only length bytes of input.

     -o      Two-byte octal display.  Display the input offset in hexadecimal,
	     followed by eight space-separated, six column, zero-filled, two
	     byte quantities of input data, in octal, per line.

     -s offset
	     Skip offset bytes from the beginning of the input.  By default,
	     offset is interpreted as a decimal number.  With a leading 0x or
	     0X, offset is interpreted as a hexadecimal number, otherwise,
	     with a leading 0, offset is interpreted as an octal number.
	     Appending the character b, k, m, or g to offset causes it to be
	     interpreted as a multiple of 512, 1024, 1048576, or 1073741824,
	     respectively.

     -v      Cause hexdump to display all input data.  Without the -v option,
	     any number of groups of output lines, which would be identical to
	     the immediately preceding group of output lines (except for the
	     input offsets), are replaced with a line comprised of a single
	     asterisk.

     -x      Two-byte hexadecimal display.  Display the input offset in hexa-
	     decimal, followed by eight, space separated, four column, zero-
	     filled, two-byte quantities of input data, in hexadecimal, per
	     line.

     For each input file, hexdump sequentially copies the input to standard
     output, transforming the data according to the format strings specified
     by the -e and -f options, in the order that they were specified.

   Formats
     A format string contains any number of format units, separated by white-
     space.  A format unit contains up to three items: an iteration count, a
     byte count, and a format.

     The iteration count is an optional positive integer, which defaults to
     one.  Each format is applied iteration count times.

     The byte count is an optional positive integer.  If specified it defines
     the number of bytes to be interpreted by each iteration of the format.

     If an iteration count and/or a byte count is specified, a single slash
     must be placed after the iteration count and/or before the byte count to
     disambiguate them.  Any whitespace before or after the slash is ignored.

     The format is required and must be surrounded by double quote ("" "")
     marks.  It is interpreted as a fprintf-style format string (see
     fprintf(3)), with the following exceptions:

	   o   An asterisk (*) may not be used as a field width or precision.

	   o   A byte count or field precision is required for each ``s'' con-
	       version character (unlike the fprintf(3) default which prints
	       the entire string if the precision is unspecified).

	   o   The conversion characters ``h'', ``l'', ``n'', ``p'' and ``q''
	       are not supported.

	   o   The single character escape sequences described in the C stan-
	       dard are supported:

		     NUL		  \0
		     <alert character>	  \a
		     <backspace>	  \b
		     <form-feed>	  \f
		     <newline>		  \n
		     <carriage return>	  \r
		     <tab>		  \t
		     <vertical tab>	  \v

     The hexdump utility also supports the following additional conversion
     strings:

     _a[dox]	 Display the input offset, cumulative across input files, of
		 the next byte to be displayed.  The appended characters d, o,
		 and x specify the display base as decimal, octal or hexadeci-
		 mal respectively.

     _A[dox]	 Identical to the _a conversion string except that it is only
		 performed once, when all of the input data has been pro-
		 cessed.

     _c 	 Output characters in the default character set.  Nonprinting
		 characters are displayed in three character, zero-padded
		 octal, except for those representable by standard escape
		 notation (see above), which are displayed as two character
		 strings.

     _p 	 Output characters in the ASCII character set.	Non-ASCII
		 characters are displayed as a single ``.''.

     _u 	 Output US ASCII characters, with the exception that control
		 characters are displayed using the following, lower-case,
		 names.  Characters greater than 0xff, hexadecimal, are dis-
		 played as hexadecimal strings.

		 000 NUL  001 SOH  002 STX  003 ETX  004 EOT  005 ENQ
		 006 ACK  007 BEL  008 BS   009 HT   00A LF   00B VT
		 00C FF   00D CR   00E SO   00F SI   010 DLE  011 DC1
		 012 DC2  013 DC3  014 DC4  015 NAK  016 SYN  017 ETB
		 018 CAN  019 EM   01A SUB  01B ESC  01C FS   01D GS
		 01E RS   01F US   0FF DEL

     The default and supported byte counts for the conversion characters are
     as follows:

	   %_c, %_p, %_u, %c	   One byte counts only.

	   %d, %i, %o, %u, %X, %x  Four byte default, one, two and four byte
				   counts supported.

	   %E, %e, %f, %G, %g	   Eight byte default, four and twelve byte
				   counts supported.

     The amount of data interpreted by each format string is the sum of the
     data required by each format unit, which is the iteration count times the
     byte count, or the iteration count times the number of bytes required by
     the format if the byte count is not specified.

     The input is manipulated in ``blocks'', where a block is defined as the
     largest amount of data specified by any format string.  Format strings
     interpreting less than an input block's worth of data, whose last format
     unit both interprets some number of bytes and does not have a specified
     iteration count, have the iteration count incremented until the entire
     input block has been processed or there is not enough data remaining in
     the block to satisfy the format string.

     If, either as a result of user specification or hexdump modifying the
     iteration count as described above, an iteration count is greater than
     one, no trailing whitespace characters are output during the last itera-
     tion.

     It is an error to specify a byte count as well as multiple conversion
     characters or strings unless all but one of the conversion characters or
     strings is _a or _A.

     If, as a result of the specification of the -n option or end-of-file
     being reached, input data only partially satisfies a format string, the
     input block is zero-padded sufficiently to display all available data
     (i.e., any format units overlapping the end of data will display some
     number of the zero bytes).

     Further output by such format strings is replaced by an equivalent number
     of spaces.  An equivalent number of spaces is defined as the number of
     spaces output by an s conversion character with the same field width and
     precision as the original conversion character or conversion string but
     with any ``+'', `` '', ``#'' conversion flag characters removed, and ref-
     erencing a NULL string.

     If no format strings are specified, the default display is a one-byte
     hexadecimal display.

DIAGNOSTICS
     The hexdump utility exits 0 on success, and >0 if an error occurs.

EXAMPLES
     Note that the following format strings, used with -e, must be enclosed in
     single quotes.

     Display the input in perusal format:

	   ""%06.6_ao ""	12/1 ""%3_u ""
	   ""\t\t"" ""%_p ""
	   ""\n""

     Implement the -x option:

	   ""%07.7_Ax\n""
	   ""%07.7_ax  "" 8/2 ""%04x "" ""\n""

SEE ALSO
     gdb(1), od(1)

BSD				 July 10, 2004				   BSD
","# hexdump

> An ASCII, decimal, hexadecimal, octal dump.

- Print the hexadecimal representation of a file:

`hexdump {{file}}`

- Display the input offset in hexadecimal and its ASCII representation in two columns:

`hexdump -C {{file}}`

- Display the hexadecimal representation of a file, but interpret only n bytes of the input:

`hexdump -C -n{{number_of_bytes}} {{file}}`
"
inxi,,,,"# inxi

> Print a summary of system information and resources for debugging purposes.

- Print a short summary of CPU, memory, hard drive and kernel information:

`inxi`

- Print a full description of CPU, memory, disk, network and process information:

`inxi -Fz`

- Print information about the distribution's repository:

`inxi -r`
"
vpnc,,,,"# vpnc

> A VPN client for the Cisco 3000 VPN Concentrator.

- Connect with a defined configuration file:

`sudo vpnc {{config_file}}`

- Terminate the previously created connection:

`sudo vpnc-disconnect`
"
mkswap,,,,"# mkswap

> Sets up a Linux swap area on a device or in a file.

- Setup a given partition as swap area:

`sudo mkswap {{/dev/sdb7}}`

- Use a given file as swap area:

`sudo mkswap {{path/to/file}}`

- Check a partition for bad blocks before creating the swap area:

`sudo mkswap -c {{/dev/sdb7}}`

- Specify a label for the file (to allow `swapon` to use the label):

`sudo mkswap -L {{swap1}} {{path/to/file}}`
"
numlockx,http://www.mike-devlin.com/linux/README-numlockx.htm,Not Acceptable!Not Acceptable!An appropriate representation of the requested resource could not be found on this server. This error was generated by Mod_Security.,,"# numlockx

> Control the number lock key status in X11 sessions.
> More information: <http://www.mike-devlin.com/linux/README-numlockx.htm>.

- Show the current number lock status:

`numlockx status`

- Turn the number lock on:

`numlockx on`

- Turn the number lock off:

`numlockx off`

- Toggle the current state:

`numlockx toggle`
"
imgp,,,,"# imgp

> Command line image resizer and rotator for JPEG and PNG images.

- Convert single images and/or whole directories containing valid image formats:

`imgp -x {{1366x1000}} {{path/to/dir}} {{path/to/file}}`

- Scale an image by 75% and overwrite the source image to a target resolution:

`imgp -x {{75}} -w {{path/to/file}}`

- Rotate an image clockwise by 90 degrees:

`imgp -o {{90}} {{path/to/file}}`
"
kpackagetool5,https://techbase.kde.org/Development/Tutorials/Plasma5/QML2/GettingStarted#Kpackagetool5,"


Development/Tutorials/Plasma5/QML2/GettingStarted - KDE TechBase


























EnglishLogin with Phabricator 












              KDE TechBase            





Actions




                View              


                    View source                  



                    History                  




                  Page                


                    Discussion                  






Navigation


HomeHelpRecent changes 



Contributor Help Pages


Tasks and ToolsModify a pageAdd new contentPage elementsTypographical guidelinesMore markup help 



Translator Help Pages


Get a Translator AccountLanguages representedTranslation WorkflowTranslate a PageOff-line TranslationTranslation StatisticsMore Help pages 



Tools


What links hereRelated changesSpecial pagesPrintable versionPermanent linkPage information 





< Development‎ | Tutorials‎ | Plasma5

Development/Tutorials/Plasma5/QML2/GettingStarted

Contents

1 Abstract
2 Package Structure
3 The Code

3.1 The .desktop file
3.2 main.qml
3.3 CMakeLists.txt


4 Representations
5 Minimum size
6 Localization
7 Install and Test

7.1 Kpackagetool5


8 Testing the Applet
9 Wow that was fun!
10 Find and try out existing Plasmoids

10.1 plasmawindowed
10.2 plasmoidviewer




Abstract
This tutorial needs KDE Frameworks 5 / Plasma 5  to build.
We are going to create a simple plasmoid in this tutorial. To keep things simple, we are going to make have use QML 2.0 and it will use Plasma Components in our tutorial .

Package Structure
You create a .desktop file and the .qml file. They have to be in the usual Plasma package structure:

plasmoid/metadata.desktop
plasmoid/contents/ui/main.qml
(where ""plasmoid"" should be replaced with the name of your package)
Your directory structure should now be as follows:

myproject/CMakeLists.txt
myproject/plasmoid/
myproject/plasmoid/metadata.desktop
myproject/plasmoid/contents/
myproject/plasmoid/contents/ui/
myproject/plasmoid/contents/ui/main.qml

The Code
The .desktop file
Every Plasmoid needs a .desktop file to tell plasma how it should be started and what name it carries. 
metadata.desktop

[Desktop Entry]
Encoding=UTF-8
Name=Tutorial
Comment=Tutorial on getting started with Plasma 5 plasmoids.
Type=Service

X-KDE-Library=plasma_applet_tutorial
X-KDE-ParentApp=
X-KDE-PluginInfo-Author=Heena
X-KDE-PluginInfo-Email=[email protected]
X-KDE-PluginInfo-License=GPL
X-KDE-PluginInfo-Name=org.kde.tutorial
X-KDE-PluginInfo-Version=2.0
X-KDE-PluginInfo-Website=plasma.kde.org
X-KDE-ServiceTypes=Plasma/Applet
X-Plasma-API=declarativeappletscript
X-Plasma-MainScript=ui/main.qml
X-KDE-PluginInfo-Category=Windows and Tasks

The most important bits are:-

X-KDE-Library  which specifies which library will provide the configuration dialog. In this example then ""plasma_applet_tutorial"" assignment is just a place holder.
X-KDE-PluginInfo-Name For X-KDE-PluginInfo-Category, refer to the  PIG.

These are the ""glue"" between your class and plasma, without it, nothing will start.

main.qml
import QtQuick 2.0
import org.kde.plasma.components 2.0 as PlasmaComponents

PlasmaComponents.Label {
    text: ""Hello world in Plasma 5 "";
    color: ""black"";
}

CMakeLists.txt
This CMakeLists.txt file describes where your plasmoid will be installed.

# Set minimum CMake version (required for CMake 3.0 or later)
cmake_minimum_required(VERSION 2.8.12)

# Use Extra CMake Modules (ECM) for common functionality.
# See http://api.kde.org/ecm/manual/ecm.7.html
# and http://api.kde.org/ecm/manual/ecm-kde-modules.7.html
find_package(ECM REQUIRED NO_MODULE)
# Needed by find_package(KF5Plasma) below.
set(CMAKE_MODULE_PATH ${ECM_MODULE_PATH} ${CMAKE_MODULE_PATH})

# Locate plasma_install_package macro.
find_package(KF5Plasma REQUIRED)

# Add installatation target (""make install"").
plasma_install_package(plasmoid org.kde.tutorial)

For more details on CMake please read Guidelines_and_HOWTOs/CMake

Representations
The plasmoid can provide two components: compactRepresentation and FullRepresentation

import QtQuick 2.0
import QtQuick.Layouts 1.1
import org.kde.plasma.plasmoid 2.0
import org.kde.plasma.core 2.0 as PlasmaCore

Item {
    Plasmoid.compactRepresentation: CompactRepresentation {}
    Plasmoid.fullRepresentation: FullRepresentation {}
}

where the files CompactRepresentation.qml and FullRepresentation.qml exist in the plasmoid package.
They are both optional: if compactRepresentation is not present, a default one will be created (the plasmoid icon) if fullRepresentation is not defined, the root item will be picked instead.
If a fullRepresentaion is defined, the root item will not contain any graphical element (they will be never shown) but is only supposed to contain models and data that must be accessible from both the compact and the full representation.

Minimum size
if the root object of the plasmoid (or the fullRepresentation if present) has the Layout attached property exposed, they will be used as the minimum size for the plasmoid. If they will change during the plasmoid execution, the plasmoid minimum size will be updated accordingly.

import QtQuick 2.0
import QtQuick.Layouts 1.1
import org.kde.plasma.components 2.0 as PlasmaComponents
import org.kde.plasma.plasmoid 2.0                                                                                                                                                                                                
import org.kde.plasma.core 2.0 as PlasmaCore

PlasmaComponents.Label {
    Layout.minimumWidth : plasmoid.formFactor == PlasmaCore.Types.Horizontal ? height : 1
    Layout.minimumHeight : plasmoid.formFactor == PlasmaCore.Types.Vertical ? width  : 1
    text: ""Hello world in plasma5"";
}

In the above example, the minimum width will be the height in case the formFactor is Horizontal .Similarly , if the formFactor is Vertical then minimumHeight shall be the width as shown in the above example .

Localization
It is possible to localize strings with the usual i18n(), i18nc(), i18np() global functions.


Install and Test
Since this plasmoid contains no native (compiled) code you can directly try and execute it using

qmlscene main.qml

Kpackagetool5
kpackagetool5 is the Plasma Package Manager, which you can use to install, test and remove your new plasmoid.
You can install your plasmoid into ~/.local/share/plasma as described in this section, though obviously this is just temporary. CMake, below, is recommended.
From the myproject folder defined above, use the Plasma Package Manager:

kpackagetool5 -t Plasma/Applet --install plasmoid

You can pass to the --install option of kpackagetool5 the full path of the directory containing the metadata.desktop file or any relative path to it.
Notice that your Plasmoid is now available via the +Add Widgets function from the (Right Click Menu) on Plasma Desktop. For clarity of this tutorial, note that the name of your Plasmoid is Tutorial, as defined by the Name in your .desktop file

Name=Tutorial
After updating your code, to install the new version of your Plasmoid, from the myproject folder defined above, use the Plasma Package Manager:

kpackagetool5 -t Plasma/Applet --upgrade plasmoid

To remove the plasmoid, use the Plasma Package Manager:

kpackagetool5 -t Plasma/Applet --remove org.kde.tutorial

Testing the Applet
You can test your Plasmoid without installing it with the plasmoidviewer tool:


plasmoidviewer --applet package
The --applet parameter can accept two options:

the path (full or relative) to your metadata.desktop file, or
the packaged version of your plasmoid, such as org.kde.tutorial,  which can usually be found in ~/.local/share/plasma/plasmoids/
Either one will launch your plasmoid in a sample window, as shown above.
The ""FormFactors"" and ""Location"" buttons help to see how the Plasmoid behaves in different situations.
If your current Development Environment differs from the Test Installation, you have to run cmake with -DCMAKE_INSTALL_PREFIX=$KF5. Then run make. If successful the applet can be installed by running sudo make install
and run kbuildsycoca5 (so that KDE apps will know about the new desktop files).
In order to test your Applet you can load the Plasma 5 plasmoid in plasmashell as shown :

kbuildsycoca5 #Needed once to let KDE know there is a new plugin
plasmashell

You can even find your plasmoid in ~./local5 after you build it .
Where applet_name is the value specified into .desktop for the X-KDE-PluginInfo-Name key.

Wow that was fun!
Congrats! you just  made your first qml 2.0 Plasmoid.

Find and try out existing Plasmoids
Here you will learn how to find existing installed plasmoid packages and selectively start one from command line.
If you are working from within Plasma you can call

eval $(dbus-launch)
first which will speed things up. But beware that a second DBUS can interfere with your existing Plasma session.
To get a list of installed Plasma packages call

plasmapkg2 --list
The result will look similar to this:

org.kde.desktopcontainment
org.kde.milou
org.kde.muonnotifier
org.kde.panel
org.kde.plasma.activitybar
org.kde.plasma.analogclock
org.kde.plasma.battery
org.kde.plasma.calculator
org.kde.plasma.calendar
org.kde.plasma.clipboard
org.kde.plasma.devicenotifier
org.kde.plasma.digitalclock
org.kde.plasma.fifteenpuzzle
org.kde.plasma.folder
org.kde.plasma.fuzzyclock
org.kde.plasma.icon
org.kde.plasma.katesessions
org.kde.plasma.kicker
org.kde.plasma.kickoff
org.kde.plasma.kimpanel
org.kde.plasma.lock_logout
org.kde.plasma.mediacontroller
org.kde.plasma.networkmanagement
org.kde.plasma.notes
org.kde.plasma.notifications
org.kde.plasma.pager
org.kde.plasma.panelspacer
org.kde.plasma.printmanager
org.kde.plasma.showActivityManager
org.kde.plasma.showdesktop
org.kde.plasma.systemloadviewer
org.kde.plasma.systemmonitor.cpu
org.kde.plasma.systemmonitor.diskactivity
org.kde.plasma.systemmonitor.diskusage
org.kde.plasma.systemmonitor.memory
org.kde.plasma.systemmonitor.net
org.kde.plasma.systemtray
org.kde.plasma.taskmanager
org.kde.plasma.timer
org.kde.plasma.trash
org.kde.plasma.webbrowser
org.kde.plasma.windowlist
plasmawindowed
Pick one of those lines of your choice and run for example

plasmawindowed org.kde.plasma.kickoff
which will launch the Kickoff Application Launcher in a separate window.

plasmoidviewer
Instead of plasmawindowed you can also use plasmoidviewer (in the plasmate repo):

plasmoidviewer --applet org.kde.plasma.kickoff

For testing an installed Plasmoid, the --applet parameter takes the X-KDE-PluginInfo-Name of the plasmoid in its .desktop file.
The ""FormFactors"" and ""Location"" buttons help to see how the Plasmoid behaves in different situations.



 


          Retrieved from ""https://techbase.kde.org/index.php?title=Development/Tutorials/Plasma5/QML2/GettingStarted&oldid=105983""        





                                 This page was last edited on 29 April 2020, at 12:59.                                Content is available under Creative Commons License SA 4.0 unless otherwise noted.                            







Donate to KDE Why Donate?










 €
             Donate via PayPal

Other ways to donate




Visit the KDE MetaStore
Show your love for KDE! Purchase books, mugs, apparel, and more to support KDE.
Click here to browse






About Wiki
Privacy policyAbout KDE TechBaseDisclaimers 

Products
Plasma
KDE Applications
KDE Frameworks
Plasma Mobile
KDE neon
WikiToLearn


Develop
TechBase Wiki
API Documentation
Qt Documentation
Inqlude Documentation


News & Press
Announcements
KDE.news
Planet KDE
Screenshots
Press Contact


Resources
Community Wiki
UserBase Wiki
Miscellaneous Stuff
Support
International Websites
Download KDE Software
Code of Conduct


Destinations
KDE Store
KDE e.V.
KDE Free Qt Foundation
KDE Timeline






          Maintained by KDE Webmasters


          KDE® and the K Desktop Environment® logo are registered trademarks of KDE e.V. |
          Legal












 
 -->
  

",,"# kpackagetool5

> KPackage Manager: Install, list, remove Plasma packages.
> More information: <https://techbase.kde.org/Development/Tutorials/Plasma5/QML2/GettingStarted#Kpackagetool5>.

- List all known package types that can be installed:

`kpackagetool5 --list-types`

- Install the package from a directory:

`kpackagetool5 --type {{package_type}} --install {{path/to/directory}}`

- Update installed package from a directory:

`kpackagetool5 --type {{package_type}} --upgrade {{path/to/directory}}`

- List installed plasmoids (--global for all users):

`kpackagetool5 --type Plasma/Applet --list --global`

- Remove a plasmoid by name:

`kpackagetool5 --type Plasma/Applet --remove ""{{name}}""`
"
unix2mac,,,,"# unix2mac

> Change Unix-style line endings to macOS-style.
> Replaces CR with LF.

- Change the line endings of a file:

`unix2mac {{filename}}`

- Create a copy with macOS-style line endings:

`unix2mac -n {{filename}} {{new_filename}}`
"
xbacklight,https://gitlab.freedesktop.org/xorg/app/xbacklight,"


















Projects · xorg / app / xbacklight · GitLab





































Skip to content




GitLab



Projects
Groups
Snippets

Help
















Loading...

























Help






Help


Support


Community forum



Keyboard shortcuts
?




Submit feedback


Contribute to GitLab







Sign in / Register





Toggle navigation











X


xbacklight







Project overview



Project overview


Details
Activity
Releases





Repository



Repository


Files
Commits
Branches
Tags
Contributors
Graph
Compare






Issues


3



Issues


3



List


Boards


Labels

Service Desk


Milestones







Merge Requests


0



Merge Requests


0







CI / CD



CI / CD



Pipelines


Jobs


Schedules








Operations



Operations



Environments







Packages & Registries



Packages & Registries


Container Registry






Analytics



Analytics


CI / CD
Repository
Value Stream






Snippets



Snippets






Members



Members





Collapse sidebar


Close sidebar



Activity



Graph


Create a new issue


Jobs


Commits


Issue Boards









Open sidebar



xorgapp xbacklight

Details















X




xbacklight







Project ID: 487




Rand R









Star

0









49 Commits

1 Branch

8 Tags

328 KB Files

328 KB Storage






Utility to adjust backlight brightness using RandR extension


Read more













master


Switch branch/tag












Find file



Select Archive Format




Download source code


zip
tar.gz
tar.bz2
tar









Clone






Clone with SSH










Clone with HTTPS












Copy HTTPS clone URL





Copy SSH clone URLgit@gitlab.freedesktop.org:xorg/app/xbacklight.git


Copy HTTPS clone URLhttps://gitlab.freedesktop.org/xorg/app/xbacklight.git









README

LICENSE











",,"# xbacklight

> Utility to adjust backlight brightness using the RandR extension.
> More information: <https://gitlab.freedesktop.org/xorg/app/xbacklight>.

- Get the current screen brightness as a percentage:

`xbacklight`

- Set the screen brightness to 40%:

`xbacklight -set {{40}}`

- Increase current brightness by 25%:

`xbacklight -inc {{25}}`

- Decrease current brightness by 75%:

`xbacklight -dec {{75}}`

- Increase backlight to 100%, over 60 seconds (value given in ms), using 60 steps:

`xbacklight -set {{100}} -time {{60000}} -steps {{60}}`
"
snapper,http://snapper.io/manpages/snapper.html,"


snapper







Name
snapper — Command-line program for filesystem snapshot management



Synopsis

snapper  [--global-opts]  command  [--command-opts] [command-arguments]


snapper  {--help}




DESCRIPTION
Snapper is a command-line program for filesystem snapshot management. It can
    create, delete and compare snapshots and undo changes done between snapshots.
Snapper never modifies the content of snapshots. Thus snapper creates
    read-only snapshots if supported by the kernel. Supported filesystems are
    btrfs and ext4 as well as snapshots of LVM logical volumes with
    thin-provisioning. Some filesystems might not be supported depending on your
    installation.



CONCEPTS


Configurations
For each filesystem or subvolume that should be snapshotted by
      snapper, a configuration file is required, see
      snapper-configs(5). The
      setup can be done with the create-config command.



Snapshots
Snapper distinguishes three types of snapshots.



pre


Pre snapshots should always have a corresponding post
	    snapshot. The intention of pre/post snapshot pairs is to snapshot the
	    filesystem before and after a modification.


post


See pre type.


single


These snapshots have no special relationship to other snapshots.



Note that filesystem-wise all three types are the same.



Snapshot Description and Userdata
With each snapshot a description and some userdata can be associated. The
      description is a string. The userdata is a list of key-value pairs where the
      keys and values are strings.
Do not use non-ASCII characters for the snapshot description, userdata or
      any other strings, unless you always use the UTF-8 character encoding.



Automatic Snapshot Creation
Next to manual snapshot creation, snapshots are also created automatically.



A cron-job creates hourly snapshots.


Certain programs like YaST and zypper create pre/post
	  snapshot pairs when modifying the system.






Cleanup Algorithms
Snapper provides several algorithms to clean up old snapshots. The
      algorithms are executed in a daily cron-job. This can be configured in the
      corresponding configurations files along with parameters for every
      algorithm.



number


Deletes old snapshots when a certain number of snapshots is
	    reached.


timeline


Deletes old snapshots but keeps a number of hourly, daily,
	    weekly, monthly and yearly snapshots.


empty-pre-post


Deletes pre/post snapshot pairs with empty diffs.



The number and timeline cleanup algorithms can also try to
      keep the space used by snapshots below a limit and the free space of
      the filesystem above a limit. For the first condition quota must be
      setup, see command setup-quota. Additional the NUMBER_LIMIT and
      TIMELINE_LIMIT variables in the config file must have ranges (min- and
      max-value). The algorithms will then make two passes:

      



Delete snapshots above the max-value independent of
	  the snapshot and filesystem space.


Delete snapshots above the min-value until the limits for
	  the snapshot and filesystem are reached.





      The limit for the used space can be configured via the
      SPACE_LIMIT variable. Note: Only snapshots that have a cleanup
      algorithm set are taken into account when calculating the space
      used by snapshots.

      The limit for the free space can be configured via the
      FREE_LIMIT variable.

      



Filters
Some files keep state information of the system,
      e.g. /etc/mtab. Such files should never be
      reverted. To help users, snapper allows one to ignore these files.
Each line in all
      files /etc/snapper/filters/*.txt specifies a
      pattern. When snapper computes the difference between two snapshots it
      ignores all files and directories matching any of those patterns by
      using
      fnmatch(3)
      with the flag FNM_LEADING_DIR.
Note that filters do not exclude files or directories from being
      snapshotted. For that, use subvolumes or mount points.




GLOBAL OPTIONS




-q, --quiet



Suppress normal output. Error messages will still be printed, though.



-v, --verbose



Increase verbosity.



--utc



Display dates and times in UTC. By default, local time is used.



--iso



Display dates and times in ISO format. ISO format is always used for machine-readable
	  outputs.



-t, --table-style style



Specifies table style. Table style is identified by an integer number.



--machine-readable format



Specifies a machine-readable output format. Possible options are csv and json.



--csvout



Sets CSV output format. See
                RFC 4180
                for the details, except lines end with a LF, not CR+LF.



--jsonout



Sets JSON output format.



--separator character



Specifies the character separator for CSV output format.



-c, --config name



Use specified configuration instead of the default configuration. The default
	  configuration is named ""root"".



--no-dbus



Operate without a DBus connection.
Use with caution since a running snapperd will not know about
	  modifications made to the system.



-r, --root path



Operate on target root. Only works together with no-dbus and only for some commands.



-a, --ambit ambit



Operate in the specified ambit. Can be used to override the ambit detection.
	  Allowed ambits are auto, classic and transactional.



--version



Print version and exit.






COMMANDS
Snapper provides a number of commands. Each
    command accepts the options listed in the GLOBAL OPTIONS section. These options must
    be specified before the command name. In addition,
    many commands have specific options, which are listed in this
    section. These command-specific options must be specified
    after the name of the command and
    before any of the command arguments.




help



Show short help text.



list-configs [options]



List available configurations.



--columns columns


Select columns to show separated by comma.
Possible columns are: config, subvolume.






create-config [options] subvolume



Create a new configuration for a filesystem or subvolume. For this command you
	  will likely need the global option --config, see
	  GLOBAL OPTIONS and
	  CONCEPTS.



-f, --fstype fstype


Manually set filesystem type. Supported values are btrfs, ext4 and lvm. For
		lvm, snapper uses LVM thin-provisioned snapshots. The filesystem type on top of
		LVM must be provided in parentheses, e.g. lvm(xfs).
Without this option snapper tries to detect the filesystem.


-t, --template name


Name of template for the new configuration file.






delete-config



Delete a configuration for a filesystem or subvolume. For this
	  command you will likely need to global option
	  --config, see GLOBAL
	  OPTIONS and CONCEPTS.



get-config [options]



Displays the settings of the configuration.



--columns columns


Select columns to show separated by comma.
Possible columns are: key, value.
Columns are not selected when JSON format is used.





set-config configdata


Changes the settings of the configuration. The settings
	  configdata are a list of key-value-pairs separated
	  by spaces and the key and value must be separated by an equal sign,
	  e.g. ""NUMBER_CLEANUP=yes NUMBER_LIMIT=10"". The value of SUBVOLUME and FSTYPE
	  cannot be changed.



list (ls) [options]



List snapshots.



-t, --type type


Selects type of snapshots to list. Possible values are
		all, single and pre-post.



--disable-used-space



Disable display of used space.
Calculating the used space needs some time. Thus
		this option can speedup the listing.



-a, --all-configs



List snapshots from all configs accessible by the user.


--columns columns


Select columns to show separated by comma.
Possible columns are: config, subvolume, number, default, active, date, user,
                      used-space, cleanup, description, userdata, pre-number, post-number, post-date.



For each snapshot the output consists of several
	  columns. Some need explanation:



#, Pre # and Post #


The number of the snapshot.
For btrfs the number can be followed by a sign.
		A ""-"" indicates that the snapshot is
		the currently mounted snapshot and a
		""+"" indicates that the snapshot will
		be mounted next time (It is the btrfs default subvolume). If both
		conditions apply a
		""*"" is displayed.


Used Space


For btrfs the exclusive space of the btrfs quota
		group corresponding to the snapshot.
Display of used space is automatically disabled
		if not available, e.g. quota not enabled on btrfs.






create [options]



Create a new snapshot.



-t, --type type


Specifies the type of the new snapshot. Possible values
		are single, pre and post.


--pre-number number


For post snapshots the number of the pre snapshot must
		be provided.



-p, --print-number



Print number of the created snapshot.


-d, --description description


Description for the snapshot.


-c, --cleanup-algorithm cleanup-algorithm


Set the cleanup algorithm for the snapshot.


-u, --userdata userdata


Set userdata for the snapshot. The key-value pairs must
		be separated by comma and the key and value must be separated
		by an equal sign, e.g. requestid=42,user=arthur.


--command command


Create a pre and post snapshot and run command in between.



--read-only



Create a read-only snapshot. This is the default.



--read-write



Create a read-write snapshot.


--from number


Create a snapshot from the snapshot with the
		provided number instead of snapshot 0.






modify [options] number



Modify a snapshot.



-d, --description description


New description for snapshot.


-c, --cleanup-algorithm cleanup-algorithm


Set the cleanup algorithm for the snapshot.


-u, --userdata userdata


Set userdata for the snapshot. The key-value pairs must
		be separated by comma and the key and value must be separated
		by an equal sign, e.g. requestid=42,user=arthur.






delete (remove|rm) number |
	number1-number2



Delete a snapshot or a range of snapshots.




-s, --sync



Sync the filesystem after deleting the snapshots. The
		details depend on the filesystem type.
Btrfs normally asynchronously frees space after deleting
		snapshots. With this option snapper will wait until the space once used by the
		deleted snapshots is actually available again.



Snapshot 0 cannot be deleted. For btrfs the currently
	  mounted snapshot and the snapshot that will be mounted next time
	  (the btrfs default subvolume) can also not be deleted.



mount number



Mount a snapshot. Not required for all filesystem types.



umount number



Unmount a snapshot. Not required for all filesystem types.



status [options] number1..number2



Compare the snapshots number1 and
	  number2. This will show a list of files
	  and directories that have been created, modified or deleted in the
	  time between the two snapshots have been made.



-o, --output file


Write output to file file.



The output consists of a string encoding the status followed by
	  the filename. The characters of the status string are:



A ""+"" means the file was
	      created, a ""-"" means the file was deleted. A
	      ""c"" means the content of the file has changed
	      and a ""t"" means the type of the file has
	      changed (e.g. from regular file to directory).


A ""p"" means the permissions
	      are have changed.


An ""u"" means the user
	      ownership has changed.


A ""g"" means the group
	      ownership has changed.


A ""x"" means the extended
	      attribute information has changed.


An ""a"" means the ACL
	      information has changed.



If there is no change a ""."" is outputted.



diff [options] number1..number2 [files]



Compare the snapshots number1 and
	  number2. This will show a diff of the
	  content of files and directories that have been created, modified or
	  deleted in the time between the two snapshots have been made.



-i, --input file


Read files to diff from file file.


--diff-cmd command


Command used for comparing files. The default is
		/usr/bin/diff --new-file --unified. The two files to
		compare are passed as parameters to the command.


-x, --extensions options


Extra options passed to the diff command.






undochange [options] number1..number2 [files]



Undo changes done between snapshot number1 and number2.



-i, --input file


Read files for which to undo changes from file file.






rollback [options] [number]



Creates two new snapshots and sets the default subvolume. Per
	  default the system boots from the default subvolume of the root filesystem.
	  The exact actions depend on whether a number is provided or not:



Without a number, a first read-only snapshot of the
	      default subvolume is created. A second read-write snapshot of the current
	      system is created. The system is set to boot from the second snapshot.


With a number, a first read-only snapshot of the current
	      system is created. A second read-write snapshot is created of
	      number. The system is set to boot from the second
	      snapshot.



Rollback is only supported with btrfs and requires a properly
	  configured system.




-p, --print-number



Print number of the second created snapshot.


-d, --description description


Description for the snapshot.


-c, --cleanup-algorithm cleanup-algorithm


Set the cleanup algorithm for the snapshot.


-u, --userdata userdata


Set userdata for the snapshot. The key-value pairs must
		be separated by comma and the key and value must be separated
		by an equal sign, e.g. requestid=42,user=arthur.



The rollback command also sets the description, the cleanup
	  algorithm and some userdata unless the values are specified on the command
	  line. This will automate cleanup of snapshots created by rollbacks.
In other ambits than classic the rollback command does what is required
	  to do a rollback. Anyway it is recommended to use specific programs in that
	  case.



setup-quota



Sets up quota. Currently only supported with btrfs.



cleanup [options] cleanup-algorithm



Run the cleanup algorithm
	  cleanup-algorithm. Currently implemented cleanup algorithms
	  are number, timeline and empty-pre-post. To run all cleanup algorithms, all can be
	  provided as cleanup-algorithm.



--path path


Cleanup all configs affecting path. Only useful for btrfs.


--free-space free-space


Try to make free-space available. Only useful for btrfs.






xadiff number1..number2 [files]



Compare the extended attributes between snapshot
	  number1 and
	  number2. See examples below:



 +:user.foo for created attributes


 -:user.bar for removed attributes


-+:security.selinux for modified attributes









PERMISSIONS
Non-root users can be allowed to use a configuration by setting
    ALLOW_USERS or ALLOW_GROUPS in the config file. For all operations to work, the
    user must also be able to read and access the .snapshots
    directory inside the subvolume. The .snapshots directory
    must be owned by root and must not be writable by anybody else.
Here are some methods how to achieve that:



Make the directory accessible for everyone:


chmod a+rx .snapshots




Make the directory accessible for a group the user belongs to, e.g.:


chown :users .snapshots




Make the directory accessible for the user using ACLs, e.g.:


setfacl -m u:tux:rx .snapshots





The last method can be performed by snapper, see the SYNC_ACL setting in
    snapper-configs(5).



FILES




/etc/sysconfig/snapper



Global configuration file.



/etc/snapper/configs



Directory containing configuration files.



/etc/snapper/config-templates



Directory containing configuration templates.



/etc/snapper/filters/*.txt



Filter files.



/var/log/snapper.log



Logfile. Please include this file in bug reports.






NOTES
There is no mechanism to ensure consistency of the files while a
    snapshot it made. E.g. the files of a database can be inconsistent while
    the database is running.
Consistency after undochange is not guaranteed. E.g. when the
    creation of a user is undone, there might still exist files from that
    user.
Support for individual filesystems, rollback and extended attributes
    are compile-time options and may not be available.



HOMEPAGE

http://snapper.io/




AUTHORS
Arvin Schnell <aschnell@suse.com>



SEE ALSO

snapper-configs(5),
      snapper-zypp-plugin(8),
      pam_snapper(8),
      btrfs(8),
      lvm(8),
      attr(5),
      acl(5)




",,"# snapper

> Filesystem snapshot management tool.
> More information: <http://snapper.io/manpages/snapper.html>.

- List snapshot configs:

`snapper list-configs`

- Create snapper config:

`snapper -c {{config}} create-config {{path/to/directory}}`

- Create a snapshot with a description:

`snapper -c {{config}} create -d {{""snapshot_description""}}`

- List snapshots for a config:

`snapper -c {{config}} list`

- Delete a snapshot:

`snapper -c {{config}} delete {{snapshot_number}}`

- Delete a range of snapshots:

`snapper -c {{config}} delete {{snapshot_X}}-{{snapshot_Y}}`
"
sam,https://github.com/awslabs/aws-sam-cli,"













GitHub - aws/aws-sam-cli: CLI tool to build, test, debug, and deploy Serverless applications using AWS SAM








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















aws

/

aws-sam-cli







    Watch
 
      169
    




      Star


      5.2k
    




          Fork


        816
      





        CLI tool to build, test, debug, and deploy Serverless applications using AWS SAM
      



aws.amazon.com/serverless/sam/





            View license
        




5.2k
        stars
 

816
        forks
 




      Star





    Watch









Code

 



Issues
285
 



Pull requests
30
 



Actions

 



Projects
0
 



Wiki

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Wiki
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










develop














14
branches



73
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




wchengru

chore: bump SAM CLI version to 1.3.2 (#2251)



…



da31b4f

Sep 24, 2020





chore: bump SAM CLI version to 1.3.2 (#2251)


da31b4f



Git stats





984
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.github



feat: Allow pinned requirements for linux installs from source (#1917)



Apr 13, 2020







build-image-src



Add SAM_CLI_VERSION build arg to provided image (#2245)



Sep 23, 2020







designs



fix(docs): md table-format for sam-build-cmd design (#1984)



Jun 15, 2020







docs



design: samconfig (#1503)



Nov 23, 2019







media



fix: set youtube link in readme (#1378)



Aug 27, 2019







requirements



Chore: Bumped aws-sam-translator to version 1.27.0 and aws-sam-cli to…



Sep 22, 2020







samcli



chore: bump SAM CLI version to 1.3.2 (#2251)



Sep 24, 2020







snap



feat(install): Add snapcraft config and link to snap package in README (



Apr 4, 2019







tests



fix: use parameter overrides from configuration file or command line (#…



Sep 23, 2020







.coveragerc



SAM CLI Refresh 🎉 (#383)



May 8, 2018







.gitignore



Matdumsa/gitpod setup (#2039)



Jul 24, 2020







.gitpod.Dockerfile



Matdumsa/gitpod setup (#2039)



Jul 24, 2020







.gitpod.yml



Matdumsa/gitpod setup (#2039)



Jul 24, 2020







.pre-commit-config.yaml



chore: Apply Black automatic code formatting (#1186)



Sep 4, 2019







.pylintrc



Build for Layers (#1936)



May 15, 2020







CODE_OF_CONDUCT.md



Adding standard files (#335)



Mar 22, 2018







CONTRIBUTING.md



Matdumsa/gitpod setup (#2039)



Jul 24, 2020







DESIGN.md



feat: Telemetry Implementation (#1287)



Jul 24, 2019







DEVELOPMENT_GUIDE.md



Matdumsa/gitpod setup (#2039)



Jul 24, 2020







LICENSE



fix: Update copyright in LICENSE (#1295)



Jul 26, 2019







MANIFEST.in



Release v1.0.0 (#2111)



Jul 20, 2020







Makefile



Build for Layers (#1936)



May 15, 2020







NOTICE



Release v1.0.0 (#2111)



Jul 20, 2020







README.md



chore: Updated Slack #samdev Invite Link (#2225)



Sep 16, 2020







THIRD-PARTY-LICENSES



Release v1.0.0 (#2111)



Jul 20, 2020







appveyor-windows-build-dotnet.yml



feat: dotnetcore3.1 support (#1908)



Mar 31, 2020







appveyor-windows-build-go.yml



fix: adding APPVEYOR_CONSOLE_DISABLE_PTY environment variable to fix …



Mar 18, 2020







appveyor-windows-build-java-container.yml



fix: adding APPVEYOR_CONSOLE_DISABLE_PTY environment variable to fix …



Mar 18, 2020







appveyor-windows-build-java-ruby-inprocess.yml



fix: adding APPVEYOR_CONSOLE_DISABLE_PTY environment variable to fix …



Mar 18, 2020







appveyor-windows-build-nodejs.yml



fix: adding APPVEYOR_CONSOLE_DISABLE_PTY environment variable to fix …



Mar 18, 2020







appveyor-windows-build-python.yml



chore: Bump aws-lambda-builders and SAM CLI to 1.0.0 (#2116)



Jul 20, 2020







appveyor-windows-build-ruby.yml



fix: adding APPVEYOR_CONSOLE_DISABLE_PTY environment variable to fix …



Mar 18, 2020







appveyor-windows.yml



feat: allow a custom builder workflow selection (#1957)



May 20, 2020







appveyor.yml



Removing hack for docker issue as it is fixed by AppVeyor. (#2050)



Jun 16, 2020







pyproject.toml



refactor: init, generate_event and providers code move (#1685)



Dec 18, 2019







pytest.ini



fix: removing object deletion and using same stack name for integrati…



Mar 9, 2020







setup.cfg



fix: update license key in setup() to expected value by PyPi (#966)



Jan 29, 2019







setup.py



chore: Support Python3.8 (#1519)



Dec 24, 2019





        View code
      






        README.md
      










AWS SAM


The AWS Serverless Application Model (SAM) is an open-source framework for building serverless applications.
It provides shorthand syntax to express functions, APIs, databases, and event source mappings.
With just a few lines of configuration, you can define the application you want and model it.


Get Started
To get started with building SAM-based applications, use the SAM CLI. SAM CLI provides a Lambda-like execution
environment that lets you locally build, test, debug, and deploy applications defined by SAM templates.

Install SAM CLI
Build & Deploy a ""Hello World"" Web App
Install AWS Toolkit to use SAM with your favorite IDEs.

Next Steps: Learn to build a more complex serverless application.

Extract text from images and store in a database using Amazon S3 and Amazon Rekognition services.
Detect when records are added to a database using Amazon DynamoDB database and asynchronous stream processing.

Detailed References: Explains SAM commands and usage in depth.

CLI Commands
SAM Template Specification
Policy Templates

Why SAM


Single-deployment configuration. SAM makes it easy to organize related components and resources, and operate on a single stack. You can use SAM to share configuration (such as memory and timeouts) between resources, and deploy all related resources together as a single, versioned entity.


Local debugging and testing. Use SAM CLI to locally build, test, and debug SAM applications on a Lambda-like execution environment. It tightens the development loop by helping you find & troubleshoot issues locally that you might otherwise identify only after deploying to the cloud.


Deep integration with development tools. You can use SAM with a suite of tools you love and use.

IDEs: PyCharm, IntelliJ, Visual Studio Code, Visual Studio, AWS Cloud9
Build: CodeBuild
Deploy: CodeDeploy, Jenkins
Continuous Delivery Pipelines: CodePipeline
Discover Serverless Apps & Patterns: AWS Serverless Application Repository



Built-in best practices. You can use SAM to define and deploy your infrastructure as configuration. This makes it possible for you to use and enforce best practices through code reviews. Also, with a few lines of configuration, you can enable safe deployments through CodeDeploy, and can enable tracing using AWS X-Ray.


Extension of AWS CloudFormation. Because SAM is an extension of AWS CloudFormation, you get the reliable deployment capabilities of AWS CloudFormation. You can define resources by using CloudFormation in your SAM template. Also, you can use the full suite of resources, intrinsic functions, and other template features that are available in CloudFormation.


What is this Github repository? 💻
This Github Repository contains source code for SAM CLI. Here is the development team talking about this code:

SAM CLI code is written in Python. Source code is well documented, very modular, with 95% unit test coverage.
It uses this awesome Python library called Click to manage the command line interaction and uses Docker to run Lambda functions locally.
We think you'll like the code base. Clone it and run make pr!

Contribute to SAM
We love our contributors ❤️ We have over 100 contributors who have built various parts of the product.
Read this testimonial from @ndobryanskyy to learn
more about what it was like contributing to SAM.
Depending on your interest and skill, you can help build the different parts of the SAM project;
Enhance the SAM Specification
Make pull requests, report bugs, and share ideas to improve the full SAM template specification.
Source code is located on Github at awslabs/serverless-application-model.
Read the SAM Specification Contributing Guide
to get started.
Strengthen SAM CLI
Add new commands or enhance existing ones, report bugs, or request new features for the SAM CLI.
Source code is located on Github at awslabs/aws-sam-cli. Read the SAM CLI Contributing Guide to
get started.
Update SAM Developer Guide
SAM Developer Guide provides comprehensive getting started guide and reference documentation.
Source code is located on Github at awsdocs/aws-sam-developer-guide.
Read the SAM Documentation Contribution Guide to get
started.
Join the SAM Community on Slack
Join the SAM developers channel (#samdev) on Slack to collaborate with fellow community members and the AWS SAM team.








About

      CLI tool to build, test, debug, and deploy Serverless applications using AWS SAM
    



aws.amazon.com/serverless/sam/


Topics



  serverless


  aws


  lambda


  serverlessapplicationmodel


  sam


  docker


  api-gateway


  python



Resources



      Readme
 
License



        View license
    







    Releases
      73





Release 1.3.2

          Latest
 
Sep 24, 2020

 

        + 72 releases







    Packages 0


        No packages published 







        Used by 659
 




























            + 651
          







    Contributors 176





 



 



 



 



 



 



 



 



 



 



 



      + 165 contributors





Languages














Python
97.0%





Go
2.0%





Java
0.3%





Ruby
0.2%





C#
0.2%





Shell
0.1%





Other
0.2%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# sam

> AWS Serverless Application Model (SAM) CLI.
> More information: <https://github.com/awslabs/aws-sam-cli>.

- Initialize a serverless application:

`sam init`

- Initialize a serverless application with a specific runtime:

`sam init --runtime {{python3.7}}`

- Package a SAM application:

`sam package`

- Build your Lambda function code:

`sam build`

- Run your serverless application locally:

`sam local start-api`

- Deploy an AWS SAM application:

`sam deploy`
"
chkconfig,,,,"# chkconfig

> Manage the runlevel of services on CentOS 6.

- List services with runlevel:

`chkconfig --list`

- Show a service's runlevel:

`chkconfig --list {{ntpd}}`

- Enable service at boot:

`chkconfig {{sshd}} on`

- Enable service at boot for runlevels 2, 3, 4, and 5:

`chkconfig --level {{2345}} {{sshd}} on`

- Disable service at boot:

`chkconfig {{ntpd}} off`

- Disable service at boot for runlevel 3:

`chkconfig --level {{3}} {{ntpd}} off`
"
kexec,,,,"# kexec

> Directly reboot into a new kernel.

- Load a new kernel:

`kexec -l {{path/to/kernel}} --initrd={{path/to/initrd}} --command-line={{arguments}}`

- Load a new kernel with current boot parameters:

`kexec -l {{path/to/kernel}} --initrd={{path/to/initrd}} --reuse-cmdline`

- Execute a currently loaded kernel:

`kexec -e`

- Unload current kexec target kernel:

`kexec -u`
"
chage,,,,"# chage

> Change user account and password expiry information.

- List password information for the user:

`chage -l {{username}}`

- Enable password expiration in 10 days:

`sudo chage -M {{10}} {{username}}`

- Disable password expiration:

`sudo chage -M -1 {{username}}`

- Set account expiration date:

`sudo chage -E {{YYYY-MM-DD}}`

- Force user to change password on next log in:

`sudo chage -d 0`
"
script,,,"
SCRIPT(1)		  BSD General Commands Manual		     SCRIPT(1)

NAME
     script -- make typescript of terminal session

SYNOPSIS
     script [-adkpqr] [-F pipe] [-t time] [file [command ...]]

DESCRIPTION
     The script utility makes a typescript of everything printed on your ter-
     minal.  It is useful for students who need a hardcopy record of an inter-
     active session as proof of an assignment, as the typescript file can be
     printed out later with lpr(1).

     If the argument file is given, script saves all dialogue in file.	If no
     file name is given, the typescript is saved in the file typescript.

     If the argument command is given, script will run the specified command
     with an optional argument vector instead of an interactive shell.

     The following options are available:

     -a      Append the output to file or typescript, retaining the prior con-
	     tents.

     -d      When playing back a session with the -p flag, do not sleep
	     between records when playing back a timestamped session.

     -F pipe
	     Immediately flush output after each write.  This will allow a
	     user to create a named pipe using mkfifo(1) and another user may
	     watch the live session using a utility like cat(1).

     -k      Log keys sent to the program as well as output.

     -p      Play back a session recorded with the -r flag in real time.

     -q      Run in quiet mode, omit the start, stop and command status mes-
	     sages.

     -r      Record a session with input, output, and timestamping.

     -t time
	     Specify the interval at which the script output file will be
	     flushed to disk, in seconds.  A value of 0 causes script to flush
	     after every character I/O event.  The default interval is 30 sec-
	     onds.

     The script ends when the forked shell (or command) exits (a control-D to
     exit the Bourne shell (sh(1)), and exit, logout or control-D (if
     ignoreeof is not set) for the C-shell, csh(1)).

     Certain interactive commands, such as vi(1), create garbage in the type-
     script file.  The script utility works best with commands that do not
     manipulate the screen.  The results are meant to emulate a hardcopy ter-
     minal, not an addressable one.

ENVIRONMENT
     The following environment variables are utilized by script:

     SCRIPT
	    The SCRIPT environment variable is added to the sub-shell.	If
	    SCRIPT already existed in the users environment, its value is
	    overwritten within the sub-shell.  The value of SCRIPT is the name
	    of the typescript file.

     SHELL  If the variable SHELL exists, the shell forked by script will be
	    that shell.  If SHELL is not set, the Bourne shell is assumed.
	    (Most shells set this variable automatically).

SEE ALSO
     csh(1)

HISTORY
     The script command appeared in 3.0BSD.

     The -d, -p and -r options first appeared in NetBSD 2.0 and were ported to
     FreeBSD 9.2.

BUGS
     The script utility places everything in the log file, including linefeeds
     and backspaces.  This is not what the naive user expects.

     It is not possible to specify a command without also naming the script
     file because of argument parsing compatibility issues.

     When running in -k mode, echo cancelling is far from ideal.  The slave
     terminal mode is checked for ECHO mode to check when to avoid manual echo
     logging.  This does not work when the terminal is in a raw mode where the
     program being run is doing manual echo.

     If script reads zero bytes from the terminal, it switches to a mode when
     it only attempts to read once a second until there is data to read.  This
     prevents script from spinning on zero-byte reads, but might cause a
     1-second delay in processing of user input.

BSD			       December 4, 2013 			   BSD
","# script

> Record all terminal output to file.

- Record a new session to a file named `typescript` in the current directory:

`script`

- Record a new session to a custom filepath:

`script {{path/to/session.out}}`

- Record a new session, appending to an existing file:

`script -a {{path/to/session.out}}`

- Record timing information (data is outputted to the standard error):

`script -t 2> {{path/to/timingfile}}`
"
file-rename,,,,"# rename

> Rename multiple files.
> NOTE: this page refers to the command from the `file-rename` Debian package.

- Rename files using a Perl Common Regular Expression (substitute 'foo' with 'bar' wherever found):

`rename {{'s/foo/bar/'}} {{*}}`

- Dry-run - display which renames would occur without performing them:

`rename -n {{'s/foo/bar/'}} {{*}}`

- Force renaming even if the operation would remove existing destination files:

`rename -f {{'s/foo/bar/'}} {{*}}`

- Convert filenames to lower case (use `-f` in case-insensitive filesystems to prevent ""already exists"" errors):

`rename 'y/A-Z/a-z/' {{*}}`

- Replace whitespace with underscores:

`rename 's/\s+/_/g' {{*}}`
"
cmus,,,,"# cmus

> Commandline Music Player.
> Use arrow keys to navigate, `<enter/return>` to select, and numbers 1-8 switch between different views.

- Open cmus from specified directory:

`cmus {{path/to/directory}}`

- Add file/directory to library:

`:add {{path/to/file_or_directory}}`

- Pause/unpause current song:

`c`

- Toggle shuffle mode on/off:

`s`

- Quit cmus:

`q`
"
lldb,,,"
LLDB(1) 		  BSD General Commands Manual		       LLDB(1)

NAME
     lldb -- The debugger

SYNOPSIS
     lldb [-hvdexw] [-a arch] [-c core-file] [-l script-language]
	  [-s lldb-commands] [-n process-name] [-p pid] [[--] <PROGRAM-ARG1>
	  <PROGRAM-ARG2> ...]

DESCRIPTION
     lldb is the command line interface for the LLDB debugger library.	lldb
     can debug C, C++, Objective-C, Objective-C++ and Swift programs.

     The following options are available:

     -h, --help
	     Prints out the usage information for the lldb debugger.  The
	     --help text may be more up-to-date and authoritative than the
	     command line options described in this man page.

     -v, --version
	     Prints out the version number of the lldb debugger.

     -a, --arch arch
	     Specifies which architecture lldb will use when launching the
	     specified program (assuming the provided executable is built for
	     multiple architectures.)

     -f, --file filename
	     Specifies the executable file that lldb will be launching /
	     attaching to.

     -n, --attach-name process-name
	     Specifies the name of a currently-running process to attach to.
	     (or the name of a process to wait for if -w is used.)

     -w, --wait-for
	     When used in concert with -n process-name, indicates that lldb
	     should wait for a new process of that name to be started -- and
	     attach to it as early in the process-launch as possible.

     -p, --attach-pid pid
	     Specifies a currently running process that lldb should attach to.

     -c, --core core-file
	     Specifies the core file to examine.

     -l, --script-language language
	     Tells the debugger to use the specified scripting language for
	     user-defined scripts, rather than the default.  Valid scripting
	     languages that can be specified include Python, Perl, Ruby and
	     Tcl.  Currently only the Python extensions have been implemented.

     -d, --debug
	     Tells the debugger to print out extra information for debugging
	     itself.

     -s, --source filename
	     Tells lldb to read in and execute the file ""filename"", which
	     should contain lldb commands.

     -e, --editor
	     Instructs lldb to open source files using the host's ""external
	     editor"" mechanism.

     -x, --no-lldbinit
	     Do not automatically parse any '.lldbinit' files.

	     (If you do not provide -f then the first argument will be the
	     file to be debugged so 'lldb -- <filename> [<ARG1> [<ARG2>]]'
	     also works.  Remember to end the options with ""--"" if any of your
	     arguments have a ""-"" in them.)

USING LLDB
     In lldb there is a help command which can be used to find descriptions
     and examples of all lldb commands.  To get help on ""breakpoint set"" you
     would type ""help breakpoint set"".

     There is also an apropos command which will search the help text of all
     commands for a given term -- this is useful for locating a command by
     topic.  For instance, ""apropos breakpoint"" will list any command that has
     the word ""breakpoint"" in its help text.

FILES
     lldb will read settings/aliases/commands from three files at startup, if
     they exist.

     First, it will read a ~/.lldbinit-debugger command file.  If you are
     using the lldb command line interface, this is ~/.lldbinit-lldb.  If you
     are using lldb inside a GUI debugger like Xcode this will be
     ~/.lldbinit-Xcode.  This is a useful place to put settings that you want
     to apply only when a given lldb command interpreter is used.

     Second, ~/.lldbinit is read.

     Third, an .lldbinit file in the current working directory (where lldb is
     started) will be read.

SEE ALSO
     The LLDB project page http://lldb.llvm.org/ has many different resources
     for lldb users -- the gdb/lldb command equivalence page
     http://lldb.llvm.org/lldb-gdb.html can be especially helpful for users
     coming from gdb.

BUGS
     To report bugs, please visit http://llvm.org/bugs/

AUTHOR
     Maintained by the LLDB Team, http://lldb.llvm.org/

BSD			       December 16, 2015			   BSD
","# lldb

> The LLVM Low-Level Debugger.

- Debug an executable:

`lldb {{executable}}`

- Attach `lldb` to a running process with a given PID:

`lldb -p {{pid}}`

- Wait for a new process to launch with a given name, and attach to it:

`lldb -w -n {{process_name}}`
"
ssh-add,,,"
SSH-ADD(1)		  BSD General Commands Manual		    SSH-ADD(1)

NAME
     ssh-add -- adds private key identities to the authentication agent

SYNOPSIS
     ssh-add [-cDdkLlqXx] [-E fingerprint_hash] [-t life] [file ...]
     ssh-add -s pkcs11
     ssh-add -e pkcs11

DESCRIPTION
     ssh-add adds private key identities to the authentication agent,
     ssh-agent(1).  When run without arguments, it adds the files
     ~/.ssh/id_rsa, ~/.ssh/id_dsa, ~/.ssh/id_ecdsa, and ~/.ssh/id_ed25519.
     After loading a private key, ssh-add will try to load corresponding cer-
     tificate information from the filename obtained by appending -cert.pub to
     the name of the private key file.	Alternative file names can be given on
     the command line.

     If any file requires a passphrase, ssh-add asks for the passphrase from
     the user.	The passphrase is read from the user's tty.  ssh-add retries
     the last passphrase if multiple identity files are given.

     The authentication agent must be running and the SSH_AUTH_SOCK environ-
     ment variable must contain the name of its socket for ssh-add to work.

     The options are as follows:

     -c      Indicates that added identities should be subject to confirmation
	     before being used for authentication.  Confirmation is performed
	     by ssh-askpass(1).  Successful confirmation is signaled by a zero
	     exit status from ssh-askpass(1), rather than text entered into
	     the requester.

     -D      Deletes all identities from the agent.

     -d      Instead of adding identities, removes identities from the agent.
	     If ssh-add has been run without arguments, the keys for the
	     default identities and their corresponding certificates will be
	     removed.  Otherwise, the argument list will be interpreted as a
	     list of paths to public key files to specify keys and certifi-
	     cates to be removed from the agent.  If no public key is found at
	     a given path, ssh-add will append .pub and retry.

     -E fingerprint_hash
	     Specifies the hash algorithm used when displaying key finger-
	     prints.  Valid options are: ``md5'' and ``sha256''.  The default
	     is ``sha256''.

     -e pkcs11
	     Remove keys provided by the PKCS#11 shared library pkcs11.

     -k      When loading keys into or deleting keys from the agent, process
	     plain private keys only and skip certificates.

     -L      Lists public key parameters of all identities currently repre-
	     sented by the agent.

     -l      Lists fingerprints of all identities currently represented by the
	     agent.

     -q      Be quiet after a successful operation.

     -s pkcs11
	     Add keys provided by the PKCS#11 shared library pkcs11.

     -t life
	     Set a maximum lifetime when adding identities to an agent.  The
	     lifetime may be specified in seconds or in a time format speci-
	     fied in sshd_config(5).

     -X      Unlock the agent.

     -x      Lock the agent with a password.

     -K      When adding identities, each passphrase will also be stored in
	     the user's keychain.  When removing identities with -d, each
	     passphrase will be removed from it.

     -A      Add identities to the agent using any passphrase stored in the
	     user's keychain.

ENVIRONMENT
     DISPLAY and SSH_ASKPASS
	     If ssh-add needs a passphrase, it will read the passphrase from
	     the current terminal if it was run from a terminal.  If ssh-add
	     does not have a terminal associated with it but DISPLAY and
	     SSH_ASKPASS are set, it will execute the program specified by
	     SSH_ASKPASS (by default ``ssh-askpass'') and open an X11 window
	     to read the passphrase.  This is particularly useful when calling
	     ssh-add from a .xsession or related script.  (Note that on some
	     machines it may be necessary to redirect the input from /dev/null
	     to make this work.)

     SSH_AUTH_SOCK
	     Identifies the path of a UNIX-domain socket used to communicate
	     with the agent.

FILES
     ~/.ssh/id_dsa
	     Contains the DSA authentication identity of the user.

     ~/.ssh/id_ecdsa
	     Contains the ECDSA authentication identity of the user.

     ~/.ssh/id_ed25519
	     Contains the Ed25519 authentication identity of the user.

     ~/.ssh/id_rsa
	     Contains the RSA authentication identity of the user.

     Identity files should not be readable by anyone but the user.  Note that
     ssh-add ignores identity files if they are accessible by others.

EXIT STATUS
     Exit status is 0 on success, 1 if the specified command fails, and 2 if
     ssh-add is unable to contact the authentication agent.

SEE ALSO
     ssh(1), ssh-agent(1), ssh-askpass(1), ssh-keygen(1), sshd(8)

AUTHORS
     OpenSSH is a derivative of the original and free ssh 1.2.12 release by
     Tatu Ylonen.  Aaron Campbell, Bob Beck, Markus Friedl, Niels Provos, Theo
     de Raadt and Dug Song removed many bugs, re-added newer features and cre-
     ated OpenSSH.  Markus Friedl contributed the support for SSH protocol
     versions 1.5 and 2.0.

BSD			      September 25, 2020			   BSD
","# ssh-add

> Manage loaded ssh keys in the ssh-agent.
> Ensure that ssh-agent is up and running for the keys to be loaded in it.

- Add the default ssh keys in ""~/.ssh"" to the ssh-agent:

`ssh-add`

- Add a specific key to the ssh-agent:

`ssh-add {{path/to/private_key}}`

- List fingerprints of currently loaded keys:

`ssh-add -l`

- Delete a key from the ssh-agent:

`ssh-add -d {{path/to/private_key}}`

- Delete all currently loaded keys from the ssh-agent:

`ssh-add -D`
"
certbot,,,,"# certbot

> The Let's Encrypt Agent for automatically obtaining and renewing TLS certificates.
> Successor to `letsencrypt`.

- Obtain a new certificate via webroot authorization, but do not install it automatically:

`sudo certbot certonly --webroot --webroot-path {{path/to/webroot}} --domain {{subdomain.example.com}}`

- Obtain a new certificate via nginx authorization, installing the new certificate automatically:

`sudo certbot --nginx --domain {{subdomain.example.com}}`

- Obtain a new certificate via apache authorization, installing the new certificate automatically:

`sudo certbot --apache --domain {{subdomain.example.com}}`

- Renew all Let's Encrypt certificates that expire in 30 days or less (don't forget to restart any servers that use them afterwards):

`sudo certbot renew`

- Simulate the obtaining of a new certificate, but don't actually save any new certificates to disk:

`sudo certbot --webroot --webroot-path {{path/to/webroot}} --domain {{subdomain.example.com}} --dry-run`

- Obtain an untrusted test certificate instead:

`sudo certbot --webroot --webroot-path {{path/to/webroot}} --domain {{subdomain.example.com}} --test-cert`
"
runsvdir,,,,"# runsvdir

> Run an entire directory of services.

- Start and manage all services in a directory as the current user:

`runsvdir {{path/to/services}}`

- Start and manage all services in a directory as root:

`sudo runsvdir {{path/to/services}}`

- Start services in separate sessions:

`runsvdir -P {{path/to/services}}`
"
debchange,https://manpages.debian.org/debchange,"



debchange(1) — devscripts — Debian buster — Debian Manpages
















MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / devscripts
     
     
     
     / debchange(1)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


Directory name checking


OPTIONS


CONFIGURATION VARIABLES


ENVIRONMENT


SEE ALSO


AUTHOR







other versions




buster 2.19.5+deb10u1


buster-backports 2.20.4~bpo10+1


testing 2.20.4


unstable 2.20.4






other languages




Deutsch


English


français






Scroll to navigation



DEBCHANGE(1)
General Commands Manual
DEBCHANGE(1)




NAME¶
debchange - Tool for maintenance of the debian/changelog file in a source
  package


SYNOPSIS¶
debchange [options] [text ...]

dch [options] [text ...]


DESCRIPTION¶
debchange or its alias dch will add a new comment line to the
  Debian changelog in the current source tree. This command must be run from
  within that tree. If the text of the change is given on the command line,
  debchange will run in batch mode and simply add the text, with line
  breaks as necessary, at the appropriate place in debian/changelog (or
  the changelog specified by options, as described below). If the text given on
  the command line is a null string, debchange will run in batch mode
  without adding any text. If the text given on the command line is a space
  string, debchange will run in batch mode and add a blank changelog
  entry. If no text is specified then debchange will run the editor as
  determined by sensible-editor for you to edit the file. (The
  environment variables VISUAL and EDITOR are used in this order
  to determine which editor to use.) Editors which understand the +n
  option for starting the editing on a specified line will use this to move to
  the correct line of the file for editing. If the editor is quit without
  modifying the temporary file, debchange will exit without touching the
  existing changelog. Note that the changelog is assumed to be encoded
  with the UTF-8 encoding. If it is not, problems may occur. Please see the
  iconv(1) manpage to find out how to convert changelogs from legacy
  encodings. Finally, a changelog or NEWS file can be created from
  scratch using the --create option described below.
debchange also supports automatically producing bug-closing
    changelog entries, using the --closes option. This will usually query
    the BTS, the Debian Bug Tracking System (see https://bugs.debian.org/) to
    determine the title of the bug and the package in which it occurs. This
    behaviour can be stopped by giving a --noquery option or by setting
    the configuration variable DEBCHANGE_QUERY_BTS to no, as
    described below. In either case, the editor (as described above) will always
    be invoked to give an opportunity to modify the entries, and the changelog
    will be accepted whether or not modifications are made. An extra changelog
    entry can be given on the command line in addition to the closes
  entries.
At most one of --append, --increment, --edit,
    --release, and --newversion may be specified as listed below.
    If no options are specified, debchange will use heuristics to guess
    whether or not the package has been successfully released, and behave as if
    --increment had been specified if the package has been released, or
    otherwise as if --append has been specified.
Two different sets of heuristics can be used, as controlled by the
    --release-heuristic option or the DEBCHANGE_RELEASE_HEURISTIC
    configuration variable. The default changelog heuristic assumes the
    package has been released unless its changelog contains UNRELEASED in
    the distribution field. If this heuristic is enabled then the distribution
    will default to UNRELEASED in new changelog entries, and the
    --mainttrailer option described below will be automatically enabled.
    This can be useful if a package can be released by different maintainers, or
    if you do not keep the upload logs. The alternate log heuristic
    determines if a package has been released by looking for an appropriate
    dupload(1) or dput(1) log file in the parent directory. A
    warning will be issued if the log file is found but a successful upload is
    not recorded. This may be because the previous upload was performed with a
    version of dupload prior to 2.1 or because the upload failed.
If either --increment or --newversion is used, the
    name and email for the new version will be determined as follows. If the
    environment variable DEBFULLNAME is set, this will be used for the
    maintainer full name; if not, then NAME will be checked. If the
    environment variable DEBEMAIL is set, this will be used for the email
    address. If this variable has the form ""name <email>"", then
    the maintainer name will also be taken from here if neither
    DEBFULLNAME nor NAME is set. If this variable is not set, the
    same test is performed on the environment variable EMAIL. Next, if
    the full name has still not been determined, then use getpwuid(3) to
    determine the name from the password file. If this fails, use the previous
    changelog entry. For the email address, if it has not been set from
    DEBEMAIL or EMAIL, then look in /etc/mailname, then
    attempt to build it from the username and FQDN, otherwise use the email
    address in the previous changelog entry. In other words, it's a good idea to
    set DEBEMAIL and DEBFULLNAME when using this script.
Support is included for changelogs that record changes by multiple
    co-maintainers of a package. If an entry is appended to the current
    version's entries, and the maintainer is different from the maintainer who
    is listed as having done the previous entries, then lines will be added to
    the changelog to tell which maintainers made which changes. Currently only
    one of the several such styles of recording this information is supported,
    in which the name of the maintainer who made a set of changes appears on a
    line before the changes, inside square brackets. This can be switched on and
    off using the --[no]multimaint option or the
    DEBCHANGE_MULTIMAINT configuration file option; the default is to
    enable it. Note that if an entry has already been marked in this way, then
    this option will be silently ignored.
If the directory name of the source tree has the form
    package-version, then debchange will also attempt to
    rename it if the (upstream) version number changes. This can be prevented by
    using the --preserve command line or configuration file option as
    described below.
If --force-bad-version or --allow-lower-version is
    used, debchange will not stop if the new version is less than the
    current one. This is especially useful while doing backports.


Directory name checking¶
In common with several other scripts in the devscripts package,
  debchange will climb the directory tree until it finds a
  debian/changelog file. As a safeguard against stray files causing
  potential problems, it will examine the name of the parent directory once it
  finds the debian/changelog file, and check that the directory name
  corresponds to the package name. Precisely how it does this is controlled by
  two configuration file variables DEVSCRIPTS_CHECK_DIRNAME_LEVEL and
  DEVSCRIPTS_CHECK_DIRNAME_REGEX, and their corresponding command-line
  options --check-dirname-level and --check-dirname-regex.
DEVSCRIPTS_CHECK_DIRNAME_LEVEL can take the following
    values:

0
Never check the directory name.
1
Only check the directory name if we have had to change directory in our
      search for debian/changelog. This is the default behaviour.
2
Always check the directory name.

The directory name is checked by testing whether the current
    directory name (as determined by pwd(1)) matches the regex given by
    the configuration file option DEVSCRIPTS_CHECK_DIRNAME_REGEX or by
    the command line option --check-dirname-regex regex. Here
    regex is a Perl regex (see perlre(3perl)), which will be
    anchored at the beginning and the end. If regex contains a
    '/', then it must match the full directory path. If not, then it must
    match the full directory name. If regex contains the string
    ´PACKAGE', this will be replaced by the source package name,
    as determined from the changelog. The default value for the regex is:
    ´PACKAGE(-.+)?', thus matching directory names such as
    PACKAGE and PACKAGE-version.
The default changelog to be edited is debian/changelog;
    however, this can be changed using the --changelog or --news
    options or the CHANGELOG environment variable, as described
  below.


OPTIONS¶

--append, -a
Add a new changelog entry at the end of the current version's
    entries.
--increment, -i
Increment either the final component of the Debian release number or, if
      this is a native Debian package, the version number. On Ubuntu or Tanglu,
      this will also change the suffix from buildX to ubuntu1/tanglu1. Use
      -R, --rebuild for a no change rebuild increment. This
      creates a new section at the beginning of the changelog with appropriate
      headers and footers. Also, if this is a new version of a native Debian
      package, the directory name is changed to reflect this. If
      DEBCHANGE_RELEASE_HEURISTIC is changelog (default) and the
      current release is UNRELEASED, this will only change the version of
      the current changelog stanza. Otherwise, this will create a new changelog
      stanza with the new version.
--newversion version, -v version
This specifies the version number (including the Debian release part)
      explicitly and behaves as the --increment option in other respects.
      It will also change the directory name if the upstream version number has
      changed. If DEBCHANGE_RELEASE_HEURISTIC is changelog
      (default) and the current release is UNRELEASED, this will only
      change the version of the current changelog stanza. Otherwise, this will
      create a new changelog stanza with the new version.
--edit, -e
Edit the changelog in an editor.
--release, -r
Finalize the changelog for a release. Update the changelog timestamp. If
      the distribution is set to UNRELEASED, change it to the
      distribution from the previous changelog entry (or another distribution as
      specified by --distribution). If there are no previous changelog
      entries and an explicit distribution has not been specified,
      unstable will be used.
--force-save-on-release
When --release is used, an editor is opened to allow inspection of
      the changelog. The user is required to save the file to accept the
      modified changelog, otherwise the original will be kept (default).
--no-force-save-on-release
Do not do so. Note that a dummy changelog entry may be supplied in order
      to achieve the same effect - e.g. debchange --release """".
      The entry will not be added to the changelog but its presence will
      suppress the editor.
--create
This will create a new debian/changelog file (or NEWS if the
      --news option is used). You must be in the top-level directory to
      use this; no directory name checking will be performed. The package name
      and version can either be specified using the --package and
      --newversion options, determined from the directory name using the
      --fromdirname option or entered manually into the generated
      changelog file. The maintainer name is determined from the
      environment if this is possible, and the distribution is specified either
      using the --distribution option or in the generated
      changelog file.
--empty
When used in combination with --create, suppress the automatic
      addition of an ""initial release"" changelog entry (so that
      the next invocation of debchange adds the first entry). Note that
      this will cause a dpkg-parsechangelog warning on the next
      invocation due to the lack of changes.
--package package
This specifies the package name to be used in the new changelog; this may
      only be used in conjunction with the --create, --increment
      and --newversion options.
--nmu, -n
Increment the Debian release number for a non-maintainer upload by either
      appending a "".1"" to a non-NMU version number (unless the
      package is Debian native, in which case ""+nmu1"" is
      appended) or by incrementing an NMU version number, and add an NMU
      changelog comment. This happens automatically if the packager is neither
      in the Maintainer nor the Uploaders field in
      debian/control, unless DEBCHANGE_AUTO_NMU is set to
      no or the --no-auto-nmu option is used.
--bin-nmu
Increment the Debian release number for a binary non-maintainer upload by
      either appending a ""+b1"" to a non-binNMU version number
      or by incrementing a binNMU version number, and add a binNMU changelog
      comment.
--qa, -q
Increment the Debian release number for a Debian QA Team upload, and add a
      QA upload changelog comment.
--rebuild, -R
Increment the Debian release number for a no-change rebuild by appending a
      ""build1"" or by incrementing a rebuild version number.
--security, -s
Increment the Debian release number for a Debian Security Team
      non-maintainer upload, and add a Security Team upload changelog
      comment.
--lts
Increment the Debian release number for a LTS Security Team non-maintainer
      upload, and add a LTS Security Team upload changelog comment.
--team
Increment the Debian release number for a team upload, and add a Team
      upload changelog comment.
--upstream, -U
Don't append distro-name1 to the version on a derived distribution.
      Increment the Debian version.
--bpo
Increment the Debian release number for an upload to buster-backports, and
      add a backport upload changelog comment.
--stable
Increment the Debian release number for an upload to the current stable
      release.
--local, -lsuffix

     Add a suffix to the Debian version number for a local build.
--force-bad-version, -b
Force a version number to be less than the current one (e.g., when
      backporting).
--allow-lower-version pattern
Allow a version number to be less than the current one if the new version
      matches the specified pattern.
--force-distribution
Force the provided distribution to be used, even if it doesn't match the
      list of known distributions (e.g. for unofficial distributions).
--auto-nmu
Attempt to automatically determine whether a change to the changelog
      represents a Non Maintainer Upload. This is the default.
--no-auto-nmu
Disable automatic NMU detection. Equivalent to setting
      DEBCHANGE_AUTO_NMU to no.
--fromdirname, -d
This will take the upstream version number from the directory name, which
      should be of the form package-version. If the
      upstream version number has increased from the most recent changelog
      entry, then a new entry will be made with version number
      version-1 (or version if the package is Debian
      native), with the same epoch as the previous package version. If the
      upstream version number is the same, this option will behave in the same
      way as -i.
--closes nnnnn[,nnnnn ...]
Add changelog entries to close the specified bug numbers. Also invoke the
      editor after adding these entries. Will generate warnings if the BTS
      cannot be contacted (and --noquery has not been specified), or if
      there are problems with the bug report located.
--[no]query
Should we attempt to query the BTS when generating closes entries?
--preserve, -p
Preserve the source tree directory name if the upstream version number (or
      the version number of a Debian native package) changes. See also the
      configuration variables section below.
 --no-preserve, --nopreserve
Do not preserve the source tree directory name (default).
--vendor vendor
Override the distributor ID over the default returned by dpkg-vendor. This
      name is used for heuristics applied to new package versions and for sanity
      checking of the target distribution.
--distribution dist, -D dist
Use the specified distribution in the changelog entry being edited,
      instead of using the previous changelog entry's distribution for new
      entries or the existing value for existing entries.
--urgency urgency, -u urgency
Use the specified urgency in the changelog entry being edited, instead of
      using the default ""medium"" for new entries or the
      existing value for existing entries.
--changelog file, -c file
This will edit the changelog file instead of the standard
      debian/changelog. This option overrides any CHANGELOG
      environment variable setting. Also, no directory traversing or checking
      will be performed when this option is used.
--news [newsfile]
This will edit newsfile (by default, debian/NEWS) instead of
      the regular changelog. Directory searching will be performed. The
      changelog will be examined in order to determine the current package
      version.
--[no]multimaint
Should we indicate that parts of a changelog entry have been made by
      different maintainers? Default is yes; see the discussion above and also
      the DEBCHANGE_MULTIMAINT configuration file option below.
--[no]multimaint-merge
Should all changes made by the same author be merged into the same
      changelog section? Default is no; see the discussion above and also the
      DEBCHANGE_MULTIMAINT_MERGE configuration file option below.
--maintmaint, -m
Do not modify the maintainer details previously listed in the changelog.
      This is useful particularly for sponsors wanting to automatically add a
      sponsorship message without disrupting the other changelog details. Note
      that there may be some interesting interactions if multi-maintainer mode
      is in use; you will probably wish to check the changelog manually before
      uploading it in such cases.
--controlmaint, -M
Use maintainer details from the debian/control Maintainer
      field rather than relevant environment variables (DEBFULLNAME,
      DEBEMAIL, etc.). This option might be useful to restore details of
      the main maintainer in the changelog trailer after a bogus edit (e.g. when
      -m was intended but forgot) or when releasing a package in the name
      of the main maintainer (e.g. the team).
--[no]mainttrailer, -t
If mainttrailer is set, it will avoid modifying the existing
      changelog trailer line (i.e. the maintainer and date-stamp details),
      unless used with options that require the trailer to be modified (e.g.
      --create, --release, -i, --qa, etc.) This
      option differs from --maintmaint in that it will use
      multi-maintainer mode if appropriate, with the exception of editing the
      trailer. See also the DEBCHANGE_MAINTTRAILER configuration file
      option below.
--check-dirname-level N
See the above section ""Directory name checking"" for an
      explanation of this option.
--check-dirname-regex regex
See the above section ""Directory name checking"" for an
      explanation of this option.
--no-conf, --noconf
Do not read any configuration files. This can only be used as the first
      option given on the command-line.
--release-heuristic log|changelog
Controls how debchange determines if a package has been released,
      when deciding whether to create a new changelog entry or append to an
      existing changelog entry.
--help, -h
Display a help message and exit successfully.
--version
Display version and copyright information and exit successfully.



CONFIGURATION VARIABLES¶
The two configuration files /etc/devscripts.conf and ~/.devscripts
  are sourced in that order to set configuration variables. Command line options
  can be used to override configuration file settings. Environment variable
  settings are ignored for this purpose. The currently recognised variables are:

DEBCHANGE_PRESERVE
If this is set to yes, then it is the same as the --preserve
      command line parameter being used.
DEBCHANGE_QUERY_BTS
If this is set to no, then it is the same as the --noquery
      command line parameter being used.
DEVSCRIPTS_CHECK_DIRNAME_LEVEL,
    DEVSCRIPTS_CHECK_DIRNAME_REGEX
See the above section ""Directory name checking"" for an
      explanation of these variables. Note that these are package-wide
      configuration variables, and will therefore affect all devscripts
      scripts which check their value, as described in their respective manpages
      and in devscripts.conf(5).
DEBCHANGE_RELEASE_HEURISTIC
Controls how debchange determines if a package has been released,
      when deciding whether to create a new changelog entry or append to an
      existing changelog entry. Can be either log or
    changelog.
DEBCHANGE_MULTIMAINT
If set to no, debchange will not introduce
      multiple-maintainer distinctions when a different maintainer appends an
      entry to an existing changelog. See the discussion above. Default is
      yes.
DEBCHANGE_MULTIMAINT_MERGE
If set to yes, when adding changes in multiple-maintainer mode
      debchange will check whether previous changes by the current
      maintainer exist and add the new changes to the existing block rather than
      creating a new block. Default is no.
DEBCHANGE_MAINTTRAILER
If this is set to no, then it is the same as the
      --nomainttrailer command line parameter being used.
DEBCHANGE_TZ
Use this timezone for changelog entries. Default is the user/system
      timezone as shown by `date -R` and affected by the environment
      variable TZ.
DEBCHANGE_LOWER_VERSION_PATTERN
If this is set, then it is the same as the --allow-lower-version
      command line parameter being used.
DEBCHANGE_AUTO_NMU
If this is set to no then debchange will not attempt to
      automatically determine whether the current changelog stanza represents an
      NMU. The default is yes. See the discussion of the --nmu
      option above.
DEBCHANGE_FORCE_SAVE_ON_RELEASE
If this is set to no, then it is the same as the
      --no-force-save-on-release command line parameter being used.
DEBCHANGE_VENDOR
Use this vendor instead of the default (dpkg-vendor output). See
      --vendor for details.



ENVIRONMENT¶

DEBEMAIL, EMAIL, DEBFULLNAME, NAME
See the above description of the use of these environment variables.
CHANGELOG
This variable specifies the changelog to edit in place of
      debian/changelog. No directory traversal or checking is performed
      when this variable is set. This variable is overridden by the
      --changelog command-line setting.
VISUAL, EDITOR
These environment variables (in this order) determine the editor used by
      sensible-editor.



SEE ALSO¶
debc(1), debclean(1), dput(1), dupload(1),
  devscripts.conf(5)


AUTHOR¶
The original author was Christoph Lameter <clameter@debian.org>. Many
  substantial changes and improvements were made by Julian Gilbey
  <jdg@debian.org>.




Debian Utilities
DEBIAN









Source file:


debchange.1.en.gz (from devscripts 2.19.5+deb10u1)




Source last updated:


2019-08-04T21:15:44Z




Converted to HTML:


2020-08-08T10:08:51Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# debchange

> Tool for maintenance of the debian/changelog file in a Debian source package.
> More information: <https://manpages.debian.org/debchange>.

- Add a new version for a non-maintainer upload to the changelog:

`debchange --nmu`

- Add a changelog entry to the current version:

`debchange --append`

- Add a changelog entry to close the bug with specified ID:

`debchange --closes {{bug_id}}`
"
dnsrecon,https://github.com/darkoperator/dnsrecon,"













GitHub - darkoperator/dnsrecon: DNS Enumeration Script








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















darkoperator

/

dnsrecon







    Watch
 
      86
    




      Star


      1.3k
    




          Fork


        347
      





        DNS Enumeration Script
      



1.3k
        stars
 

347
        forks
 




      Star





    Watch









Code

 



Issues
11
 



Pull requests
0
 



Actions

 



Projects
0
 



Wiki

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Wiki
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














3
branches



9
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




L1ghtn1ng

Merge pull request #141 from L1ghtn1ng/dev



…



8df2617

Sep 21, 2020





Merge pull request #141 from L1ghtn1ng/dev

Fix deprication warnings

8df2617



Git stats





421
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.github


 


 







lib


 


 







msf_plugin


 


 







tools


 


 







.gitattributes


 


 







.gitignore


 


 







.lgtm.yml


 


 







Changelog.md


 


 







Dockerfile


 


 







README.md


 


 







dnsrecon.py


 


 







namelist.txt


 


 







requirements.txt


 


 







setup.cfg


 


 







setup.py


 


 







snoop.txt


 


 







subdomains-top1mil-20000.txt


 


 







subdomains-top1mil-5000.txt


 


 







subdomains-top1mil.txt


 


 





        View code
      







        README.md
      








DNSRecon

DNSRecon is a Python port of a Ruby script that I wrote to learn the language and about DNS in early 2007.
This time I wanted to learn about Python and extend the functionality of the original tool and in the process re-learn how DNS works and how could it be used in the process of a security assessment and network troubleshooting.
This script provides the ability to perform:

Check all NS Records for Zone Transfers.
Enumerate General DNS Records for a given Domain (MX, SOA, NS, A, AAAA, SPF and TXT).
Perform common SRV Record Enumeration.
Top Level Domain (TLD) Expansion.
Check for Wildcard Resolution.
Brute Force subdomain and host A and AAAA records given a domain and a wordlist.
Perform a PTR Record lookup for a given IP Range or CIDR.
Check a DNS Server Cached records for A, AAAA and CNAME Records provided a list of host records in a text file to check.

Python Version
DNSRecon requires python3.6+








About

      DNS Enumeration Script
    
Resources



      Readme
 






    Releases
      9





Version 0.9.1

          Latest
 
Apr 25, 2019

 

        + 8 releases







    Packages 0


        No packages published 













    Contributors 40





 



 



 



 



 



 



 



 



 



 



 



      + 29 contributors





Languages










Python
94.9%





Ruby
4.9%





Dockerfile
0.2%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# dnsrecon

> DNS enumeration tool.
> More information: <https://github.com/darkoperator/dnsrecon>.

- Scan a domain and save the results to a SQLite database:

`dnsrecon --domain {{example.com}} --db {{path/to/database.sqlite}}`

- Scan a domain, specifying the nameserver and performing a zone transfer:

`dnsrecon --domain {{example.com}} --name_server {{nameserver.example.com}} --type axfr`

- Scan a domain, using a dictionary of subdomains and hostnames for bruteforcing:

`dnsrecon --domain {{example.com}} --dictionary {{path/to/dictionary.txt}} --type brt`

- Scan a domain, performing a reverse lookup of IP ranges from the SPF record and saving the results to a JSON file:

`dnsrecon --domain {{example.com}} -s --json`

- Scan a domain, performing a Google enumeration and saving the results to a CSV file:

`dnsrecon --domain {{example.com}} -g --csv`

- Scan a domain, performing DNS cache snooping:

`dnsrecon --domain {{example.com}} --type snoop --name_server {{nameserver.example.com}} --dictionary {{path/to/dictionary.txt}}`

- Scan a domain, performing zone walking:

`dnsrecon --domain {{example.com}} --type zonewalk`
"
xdotool,,,,"# xdotool

> Command line automation for X11.

- Retrieve the X-Windows window ID of the running Firefox window(s):

`xdotool search --onlyvisible --name {{firefox}}`

- Click the right mouse button:

`xdotool click {{3}}`

- Get the id of the currently active window:

`xdotool getactivewindow`

- Focus on the window with id of 12345:

`xdotool windowfocus --sync {{12345}}`

- Type a message, with a 500ms delay for each letter:

`xdotool type --delay {{500}} ""Hello world""`

- Press the enter key:

`xdotool key {{KP_Enter}}`
"
lshw,,,,"# lshw

> List detailed information about hardware configurations as root user.

- Launch the GUI:

`sudo lshw -X`

- List all hardwares in tabular format:

`sudo lshw -short`

- List all disks and storage controllers in tabular format:

`sudo lshw -class disk -class storage -short`

- Save all network interfaces to an HTML file:

`sudo lshw -class network -html > {{interfaces.html}}`
"
flameshot,https://flameshot.js.org,"


Flameshot













",,"# flameshot 

> Screenshot utility with a gui interface.
> Supports basic image editing, such as text, shapes, colors, and imgur.
> More information: <https://flameshot.js.org>.

- Launch flameshot in gui mode:

`flameshot launcher`

- Take a screenshot by clicking and dragging:

`flameshot gui`

- Take a full screen screenshot:

`flameshot full`

- Set the save path to write screenshots to:

`flameshot full --path {{path/to/directory}}`

- Delay the screenshot for N milliseconds and output to clipboard:

`flameshot full --delay {{2000}} --clipboard`
"
useradd,,,,"# useradd

> Create a new user.

- Create new user:

`useradd {{name}}`

- Create new user with a default home directory:

`useradd --create-home {{name}}`

- Create new user with specified shell:

`useradd --shell {{/path/to/shell}} {{name}}`

- Create new user belonging to additional groups (mind the lack of whitespace):

`useradd --groups {{group1,group2}} {{name}}`

- Create new system user without a home directory:

`useradd --no-create-home --system {{name}}`
"
x11vnc,,,,"# x11vnc

> A VNC server that will enable VNC on an existing display ser.
> By default, the server will automatically terminate once all clients disconnect from it.

- Launch a VNC server that allows multiple clients to connect:

`x11vnc -shared`

- Launch a VNC server in view-only mode, and which won't terminate once the last client disconnects:

`x11vnc -forever -viewonly`

- Launch a VNC server on a specific display and screen (both starting at index zero):

`x11vnc -display :{{display}}.{{screen}}`

- Launch a VNC server on the third display's default screen:

`x11vnc -display :{{2}}`

- Launch a VNC server on the first display's second screen:

`x11vnc -display :{{0}}.{{1}}`
"
tic,https://pubs.opengroup.org/onlinepubs/007908799/xcurses/terminfo.html,"


Terminfo



The Single UNIX ® Specification, Version 2
Copyright © 1997 The Open Group




 Terminfo Source Format (ENHANCED CURSES)

The requirements in this chapter are in effect only for implementations
that claim Enhanced Curses compliance.

The terminfo database contains a description of the capabilities of a
variety of devices, such as terminals and printers.  Devices are described by
specifying a set of capabilities, by quantifying certain aspects of the
device, and by specifying character sequences that effect particular results.

This chapter specifies the format of terminfo source files.

X/Open-compliant implementations must provide a facility that accepts
source files in the format specified in this chapter as a means of
entering information into the terminfo database.
The facility for installing this information into the database
is implementation-specific.  A valid terminfo entry describing
a given model of terminal can be added to terminfo on any
X/Open-compliant implementation to permit use of the same terminal model.



Source File Syntax

describes the syntax of terminfo source files.  A grammar
and lexical conventions appear in

Formal Grammar
.
A list of all terminal capabilities defined by X/Open appears in

Defined Capabilities
.
An example follows in

Sample Entry
.

describes the specification of devices in general, such as video terminals.

describes the specification of printers.

The terminfo database is often used by screen-oriented applications such
as vi and Curses
programs, as well as by some utilities such as ls and more.  This
usage allows them to work with a variety of devices without changes to the
programs.
 Source File Syntax

Source files can use the ISO 8859-1 codeset.  The behaviour when the source
file is in another codeset is unspecified.  Traditional practice has been to
translate information from other codesets into the source file syntax.

terminfo source files consist of one or more device descriptions.
Each description defines a mnemonic name for the terminal model.  Each
description consists of a header (beginning in column 1) and one or more lines
that list the features for that particular device.  Every line in a
terminfo source file must end in a comma.  Every line in a
terminfo source file except the header must be indented with one or more
white spaces (either spaces or tabs).

Entries in terminfo source files consist of a number of comma-separated
fields.  White space after each comma is ignored.  Embedded commas must be
escaped by using a backslash.  The following example shows the format of a
terminfo source file:
delim $$
delim off
The first line, commonly referred to as the header line, must begin in column
one and must contain at least two aliases separated by vertical bars.  The
last field in the header line must be the long name of the device and it may
contain any string.

Alias names must be unique in the terminfo database
and they must conform to file naming conventions established by
implementation-specific terminfo compilation utilities.
Implementations will recognise alias names consisting only of characters
from the portable filename character set except that implementations 
need not accept a first character  of minus (-).
For example, a
typical restriction is that they cannot contain white space or
slashes.  There may be further constraints imposed on source file values by
the implementation-specific terminfo compilation utilities.

provides conventions for choosing alias names.

Each capability in terminfo is of one of the following types:



Boolean capabilities show that a device has or does not have a particular
feature.


Numeric capabilities quantify particular features of a device.


String capabilities provide sequences that can be used to perform
particular operations on devices.



Capability names adhere to an informal length limit of five
characters.  Whenever possible, capability
names are chosen to be the same as or similar to those specified by the
ANSI X3.64-1979 standard.  Semantics are also intended to match those of the ANSI standard.

All string capabilities may have padding specified, with the exception of
those used for input.  Input capabilities, listed under the Strings
section in the following tables, have names beginning with key_.  These
capabilities are defined in
<term.h>.

 Minimum Guaranteed Limits

All X/Open-compliant implementations support at least the following limits
for the terminfo source file:
Source File Characteristic
Minimum Guaranteed Value
Length of a line
1023 bytes
Length of a terminal alias
14 bytes
Length of a terminal model name
128 bytes
Width of a single field
128 bytes
Length of a string value
1000 bytes
Length of a string representing a numeric value
99 digits
Magnitude of a numeric value
0 up to and including 32767

An implementation may support higher limits than those specified above.
 Formal Grammar

The grammar and lexical conventions in this section together
describe the syntax for terminfo terminal descriptions within a terminfo
source file.  A terminal description that satisfies the requirements of this
section will be accepted by all implementations.


descriptions : START_OF_HEADER_LINE  rest_of_header_line feature_lines
          | descriptions START_OF_HEADER_LINE rest_of_header_line 
          | feature_lines
          ;
An ALIAS that begins in column one.  This is handled by the lexical analyzer.

rest_of_header_line : PIPE LONGNAME COMMA NEWLINE
          | aliases PIPE LONGNAME COMMA NEWLINE
          ;

feature_lines : start_feature_line rest_of_feature_line
          | feature_lines start_feature_line rest_of_feature_line
          ;

start_feature_line : START_FEATURE_LINE_BOOLEAN
A BOOLEAN feature that begins after column one but is the first
feature on the feature line.  This is handled by the lexical analyzer.
          | START_FEATURE_LINE_NUMERIC
A NUMERIC feature that begins after column one but is the first
feature on the feature line.  This is handled by the lexical analyzer.
          | START_FEATURE_LINE_STRING
A STRING feature that begins after column one but is the first
feature on the feature line.  This is handled by the lexical analyzer.
          ;

rest_of_feature_line : features COMMA NEWLINE
          | COMMA NEWLINE
          ;

features : COMMA feature
          | features COMMA feature
          ;

aliases : PIPE ALIAS
          | aliases PIPE ALIAS
          ;

feature : BOOLEAN
          | NUMERIC
          | STRING
          ;


The lexical conventions for terminfo descriptions are as follows:



White space consists of the ' ' and <tab> character.


An ALIAS may contain any graph characters other than ',','/' and '|'.
Graph characters are those characters for which
isgraph()
returns non-zero.


A LONGNAME may contain any print characters other than ',' and '|'.
Print characters are those characters for which
isprint()
returns non-zero.


A BOOLEAN feature may contain any print characters other
than ',', '=', and '#'.


A NUMERIC feature consists of:



A name which may contain any print character other than ',', '=', and '#'.


The '#' character.


A positive integer which conforms to the C language
convention for integer constants.




A STRING feature consists of:



A name which may contain any print character other than ',', '=', and '#'.


The '=' character.


A string which may contain any print characters other than ','.




White space immediately following a ',' is ignored.


Comments consist of <bol>, optional whitespace, a required '#',
and a terminating <eol>.


A header line must begin in column one.


A feature line must not begin in column one.


Blank lines are ignored.


 Defined Capabilities

X/Open defines the capabilities listed in the following table.  All
X/Open-compliant implementations must accept each of these capabilities in an
entry in a terminfo source file.
Implementations use this information to determine how properly to operate
the current terminal.  In addition, implementations return any of the current
terminal's capabilities when the application calls the query functions listed
in

Source File Syntax

(in the cases where the following table lists a
Termcap
code) and

Source File Syntax
.

The table of capabilities has the following columns:

VariableNames for use by the Curses functions that operate on the terminfo
database.  These names are reserved and the application must not define them.

CapnameThe short name for a capability specified in the terminfo source file.
It is used for updating the source file and by the tput command.

TermcapCodes provided for compatibility with older applications.  These codes
are TO BE WITHDRAWN.  Because of this, not all Capnames have
Termcap codes.


 Booleans

Cap-
Term-

Variable
name
cap
Description
auto_left_margin
bw
bw
cub1 wraps from column 0 to last column
auto_right_margin
am
am
Terminal has automatic margins
back_color_erase
bce
ut
Screen erased with background colour
can_change
ccc
cc
Terminal can re-define existing colour
ceol_standout_glitch
xhp
xs
Standout not erased by overwriting (hp)
col_addr_glitch
xhpa
YA
Only positive motion for hpa/mhpa caps
cpi_changes_res
cpix
YF
Changing character pitch changes resolution
cr_cancels_micro_mode
crxm
YB
Using cr turns off micro mode
dest_tabs_magic_smso
xt
xt
Destructive tabs, magic smso char (t1061)
eat_newline_glitch
xenl
xn
Newline ignored after 80 columns (Concept)
erase_overstrike
eo
eo
Can erase overstrikes with a blank
generic_type
gn
gn
Generic line type (e.g., dialup, switch)
hard_copy
hc
hc
Hardcopy terminal
hard_cursor
chts
HC
Cursor is hard to see
has_meta_key
km
km
Has a meta key (shift, sets parity bit)
has_print_wheel
daisy
YC
Printer needs operator to change



character set
has_status_line
hs
hs
Has extra ""status line""
hue_lightness_saturation
hls
hl
Terminal uses only HLS colour



notation (Tektronix)
insert_null_glitch
in
in
Insert mode distinguishes nulls
lpi_changes_res
lpix
YG
Changing line pitch changes resolution
memory_above
da
da
Display may be retained above the screen
memory_below
db
db
Display may be retained below the screen
move_insert_mode
mir
mi
Safe to move while in insert mode
move_standout_mode
msgr
ms
Safe to move in standout modes
needs_xon_xoff
nxon
nx
Padding won't work, xon/xoff required
no_esc_ctlc
xsb
xb
Beehive (f1=escape, f2=ctrl C)
no_pad_char
npc
NP
Pad character doesn't exist
non_dest_scroll_region
ndscr
ND
Scrolling region is nondestructive
non_rev_rmcup
nrrmc
NR
smcup does not reverse rmcup
over_strike
os
os
Terminal overstrikes on hard-copy terminal
prtr_silent
mc5i
5i
Printer won't echo on screen
row_addr_glitch
xvpa
YD
Only positive motion for vpa/mvpa caps
semi_auto_right_margin
sam
YE
Printing in last column causes cr
status_line_esc_ok
eslok
es
Escape can be used on the status line
tilde_glitch
hz
hz
Hazeltine; can't print tilde (~)
transparent_underline
ul
ul
Underline character overstrikes
xon_xoff
xon
xo
Terminal uses xon/xoff handshaking

 Numbers

Cap-
Term-

Variable
name
cap
Description
bit_image_entwining
bitwin
Yo
Number of passes for each bit-map row
bit_image_type
bitype
Yp
Type of bit image device
buffer_capacity
bufsz
Ya
Number of bytes buffered before printing
buttons
btns
BT
Number of buttons on the mouse
columns
cols
co
Number of columns in a line
dot_horz_spacing
spinh
Yc
Spacing of dots horizontally in dots per inch
dot_vert_spacing
spinv
Yb
Spacing of pins vertically in pins per inch
init_tabs
it
it
Tabs initially every # spaces
label_height
lh
lh
Number of rows in each label
label_width
lw
lw
Number of columns in each label
lines
lines
li
Number of lines on a screen or a page
lines_of_memory
lm
lm
Lines of memory if > lines; 0 means varies
max_attributes
ma
ma
 Maximum combined video attributes terminal can display 
magic_cookie_glitch
xmc
sg
Number of blank characters left by smso or rmso
max_colors
colors
Co
Maximum number of colours on the screen
max_micro_address
maddr
Yd
Maximum value in micro_..._address
max_micro_jump
mjump
Ye
Maximum value in parm_..._micro
max_pairs
pairs
pa
Maximum number of colour-pairs on the screen
maximum_windows
wnum
MW
Maximum number of definable windows
micro_col_size
mcs
Yf
Character step size when in micro mode
micro_line_size
mls
Yg
Line step size when in micro mode
no_color_video
ncv
NC
Video attributes that can't be used with colours
num_labels
nlab
Nl
Number of labels on screen (start at 1)
number_of_pins
npins
Yh
Number of pins in print-head
output_res_char
orc
Yi
Horizontal resolution in units per character
output_res_line
orl
Yj
Vertical resolution in units per line
output_res_horz_inch
orhi
Yk
Horizontal resolution in units per inch
output_res_vert_inch
orvi
Yl
Vertical resolution in units per inch
padding_baud_rate
pb
pb
Lowest baud rate where padding needed
print_rate
cps
Ym
Print rate in characters per second
virtual_terminal
vt
vt
Virtual terminal number
wide_char_size
widcs
Yn
Character step size when in double-wide mode
width_status_line
wsl
ws
Number of columns in status line

 Strings

Cap-
Term-

Variable
name
cap
Description
acs_chars
acsc
ac
Graphic charset pairs aAbBcC
alt_scancode_esc
scesa
S8
Alternate escape for scancode emulation



(default is for VT100)
back_tab
cbt
bt
Back tab
bell
bel
bl
Audible signal (bell)
bit_image_carriage_return
bicr
Yv
Move to beginning of same row
bit_image_newline
binel
Zz
Move to next row of the bit image
bit_image_repeat
birep
Xy
Repeat bit-image cell #1 #2 times
carriage_return
cr
cr
Carriage return
change_char_pitch
cpi
ZA
Change number of characters per inch
change_line_pitch
lpi
ZB
Change number of lines per inch
change_res_horz
chr
ZC
Change horizontal resolution
change_res_vert
cvr
ZD
Change vertical resolution
change_scroll_region
csr
cs
Change to lines #1 through #2 (VT100)
char_padding
rmp
rP
Like ip but when in replace mode
char_set_names
csnm
Zy
Returns a list of character set names
clear_all_tabs
tbc
ct
Clear all tab stops
clear_margins
mgc
MC
Clear all margins (top, bottom,



and sides)
clear_screen
clear
cl
Clear screen and home cursor
clr_bol
el1
cb
Clear to beginning of line, inclusive
clr_eol
el
ce
Clear to end of line
clr_eos
ed
cd
Clear to end of display
code_set_init
csin
ci
Init sequence for multiple codesets
color_names
colornm
Yw
Give name for colour #1
column_address
hpa
ch
Set horizontal position to absolute #1
command_character
cmdch
CC
Terminal settable cmd character



in prototype
create_window
cwin

Define win #1 to go from #2,#3 to #4,#5
cursor_address
cup
cm
Move to row #1 col #2
cursor_down
cud1
do
Down one line
cursor_home
home
ho
Home cursor (if no cup)
cursor_invisible
civis
vi
Make cursor invisible
cursor_left
cub1
le
Move left one space.
cursor_mem_address
mrcup
CM
Memory relative cursor addressing
cursor_normal
cnorm
ve
Make cursor appear normal



(undo vs/vi)
cursor_right
cuf1
nd
Non-destructive space (cursor or



carriage right)
cursor_to_ll
ll
ll
Last line, first column (if no cup)
cursor_up
cuu1
up
Upline (cursor up)
cursor_visible
cvvis
vs
Make cursor very visible
define_bit_image_region
defbi
Yx
Define rectangular bit-image region
define_char
defc
ZE
Define a character in a character set
delete_character
dch1
dc
Delete character
delete_line
dl1
dl
Delete line
device_type
devt
dv
Indicate language/codeset support
dial_phone
dial
DI
Dial phone number #1
dis_status_line
dsl
ds
Disable status line
display_clock
dclk
DK
Display time-of-day clock
display_pc_char
dispc
S1
Display PC character
down_half_line
hd
hd
Half-line down (forward 1/2 linefeed)
ena_acs
enacs
eA
Enable alternate character set
end_bit_image_region
endbi
Yy
End a bit-image region
enter_alt_charset_mode
smacs
as
Start alternate character set
enter_am_mode
smam
SA
Turn on automatic margins
enter_blink_mode
blink
mb
Turn on blinking
enter_bold_mode
bold
md
Turn on bold (extra bright) mode
enter_ca_mode
smcup
ti
String to begin programs that use cup
enter_delete_mode
smdc
dm
Delete mode (enter)
enter_dim_mode
dim
mh
Turn on half-bright mode
enter_doublewide_mode
swidm
ZF
Enable double wide printing
enter_draft_quality
sdrfq
ZG
Set draft quality print
enter_horizontal_hl_mode
ehhlm

Turn on horizontal highlight mode
enter_insert_mode
smir
im
Insert mode (enter)
enter_italics_mode
sitm
ZH
Enable italics
enter_left_hl_mode
elhlm

Turn on left highlight mode
enter_leftward_mode
slm
ZI
Enable leftward carriage motion
enter_low_hl_mode
elohlm

Turn on low highlight mode
enter_micro_mode
smicm
ZJ
Enable micro motion capabilities
enter_near_letter_quality
snlq
ZK
Set near-letter quality print
enter_normal_quality
snrmq
ZL
Set normal quality print
enter_pc_charset_mode
smpch
S2
Enter PC character display mode
enter_protected_mode
prot
mp
Turn on protected mode
enter_reverse_mode
rev
mr
Turn on reverse video mode
enter_right_hl_mode
erhlm

Turn on right highlight mode
enter_scancode_mode
smsc
S4
Enter PC scancode mode
enter_secure_mode
invis
mk
Turn on blank mode (characters invisible)
enter_shadow_mode
sshm
ZM
Enable shadow printing
enter_standout_mode
smso
so
Begin standout mode
enter_subscript_mode
ssubm
ZN
Enable subscript printing
enter_superscript_mode
ssupm
ZO
Enable superscript printing
enter_top_hl_mode
ethlm

Turn on top highlight mode
enter_underline_mode
smul
us
Start underscore mode
enter_upward_mode
sum
ZP
Enable upward carriage motion
enter_vertical_hl_mode
evhlm

Turn on vertical highlight mode
enter_xon_mode
smxon
SX
Turn on xon/xoff handshaking
erase_chars
ech
ec
Erase #1 characters
exit_alt_charset_mode
rmacs
ae
End alternate character set
exit_am_mode
rmam
RA
Turn off automatic margins
exit_attribute_mode
sgr0
me
Turn off all attributes
exit_ca_mode
rmcup
te
String to end programs that use cup
exit_delete_mode
rmdc
ed
End delete mode
exit_doublewide_mode
rwidm
ZQ
Disable double wide printing
exit_insert_mode
rmir
ei
End insert mode
exit_italics_mode
ritm
ZR
Disable italics
exit_leftward_mode
rlm
ZS
Enable rightward (normal)



carriage motion
exit_micro_mode
rmicm
ZT
Disable micro motion capabilities
exit_pc_charset_mode
rmpch
S3
Disable PC character display mode
exit_scancode_mode
rmsc
S5
Disable PC scancode mode
exit_shadow_mode
rshm
ZU
Disable shadow printing
exit_standout_mode
rmso
se
End standout mode
exit_subscript_mode
rsubm
ZV
Disable subscript printing
exit_superscript_mode
rsupm
ZW
Disable superscript printing
exit_underline_mode
rmul
ue
End underscore mode
exit_upward_mode
rum
ZX
Enable downward (normal)



carriage motion
exit_xon_mode
rmxon
RX
Turn off xon/xoff handshaking
fixed_pause
pause
PA
Pause for 2-3 seconds
flash_hook
hook
fh
Flash the switch hook
flash_screen
flash
vb
Visible bell (may move cursor)
form_feed
ff
ff
Hardcopy terminal page eject
from_status_line
fsl
fs
Return from status line
get_mouse
getm
Gm
Curses should get button events
goto_window
wingo
WG
Go to window #1
hangup
hup
HU
Hang-up phone
init_1string
is1
i1
Terminal or printer initialisation string
init_2string
is2
is
Terminal or printer initialisation string
init_3string
is3
i3
Terminal or printer initialisation string
init_file
if
if
Name of initialisation file
init_prog
iprog
iP
Path name of program for initialisation
initialize_color
initc
IC
Set colour #1 to RGB #2, #3, #4
initialize_pair
initp
Ip
Set colour-pair #1 to fg #2, bg #3
insert_character
ich1
ic
Insert character
insert_line
il1
al
Add new blank line
insert_padding
ip
ip
Insert pad after character inserted


The ""key_"" strings are sent by specific keys.  The ""key_""
descriptions include the macro, defined in
<curses.h>,
for the code returned by
getch()
when the key is pressed (see
getch()).

Cap-
Term-

Variable
name
cap
Description
key_a1
ka1
K1
upper left of keypad
key_a3
ka3
K3
upper right of keypad
key_b2
kb2
K2
center of keypad
key_backspace
kbs
kb
sent by backspace key
key_beg
kbeg

1
key_btab
kcbt
kB
sent by back-tab key
key_c1
kc1
K4
lower left of keypad
key_c3
kc3
K5
lower right of keypad
key_cancel
kcan

2
key_catab
ktbc
ka
sent by clear-all-tabs key
key_clear
kclr
kC
sent by clear-screen or erase key
key_close
kclo

3
key_command
kcmd

4
key_copy
kcpy

5
key_create
kcrt

6
key_ctab
kctab
kt
sent by clear-tab key
key_dc
kdch1
kD
sent by delete-character key
key_dl
kdl1
kL
sent by delete-line key
key_down
kcud1
kd
sent by terminal down-arrow key
key_eic
krmir
kM
sent by rmir or smir in insert mode
key_end
kend

7
key_enter
kent

8
key_eol
kel
kE
sent by clear-to-end-of-line key
key_eos
ked
kS
sent by clear-to-end-of-screen key
key_exit
kext

9
key_f0
kf0
k0
sent by function key f0
key_f1
kf1
k1
sent by function key f1
 .
 .
.
 .
 .
 .
.
 .
 .
 .
.
 .
key_f62
kf62
Fq
sent by function key f62
key_f63
kf63
Fr
sent by function key f63
key_find
kfnd

0
key_help
khlp
%1
sent by help key
key_home
khome
kh
sent by home key
key_ic
kich1
kI
sent by ins-char/enter ins-mode key
key_il
kil1
kA
sent by insert-line key
key_left
kcub1
kl
sent by terminal left-arrow key
key_ll
kll
kH
sent by home-down key
key_mark
kmrk
%2
sent by mark key
key_message
kmsg
%3
sent by message key
key_mouse
kmous
Km
0631, Mouse event has occured
key_move
kmov
%4
sent by move key
key_next
knxt
%5
sent by next-object key
key_npage
knp
kN
sent by next-page key
key_open
kopn
%6
sent by open key
key_options
kopt
%7
sent by options key
key_ppage
kpp
kP
sent by previous-page key
key_previous
kprv
%8
sent by previous-object key
key_print
kprt
%9
sent by print or copy key
key_redo
krdo
%0
sent by redo key
key_reference
kref
&1
sent by ref(erence) key
key_refresh
krfr
&2
sent by refresh key
key_replace
krpl
&3
sent by replace key
key_restart
krst
&4
sent by restart key
key_resume
kres
&5
sent by resume key
key_right
kcuf1
kr
sent by terminal right-arrow key
key_save
ksav
&6
sent by save key
key_sbeg
kBEG
&9
sent by shifted beginning key
key_scancel
kCAN
&0
sent by shifted cancel key
key_scommand
kCMD
*1
sent by shifted command key
key_scopy
kCPY
*2
sent by shifted copy key
key_screate
kCRT
*3
sent by shifted create key
key_sdc
kDC
*4
sent by shifted delete-char key
key_sdl
kDL
*5
sent by shifted delete-line key
key_select
kslt
*6
sent by select key
key_send
kEND
*7
sent by shifted end key
key_seol
kEOL
*8
sent by shifted clear-line key
key_sexit
kEXT
*9
sent by shifted exit key
key_sf
kind
kF
sent by scroll-forward/down key
key_sfind
kFND
*0
sent by shifted find key
key_shelp
kHLP
#1
sent by shifted help key
key_shome
kHOM
#2
sent by shifted home key
key_sic
kIC
#3
sent by shifted input key
key_sleft
kLFT
#4
sent by shifted left-arrow key
key_smessage
kMSG
%a
sent by shifted message key
key_smove
kMOV
%b
sent by shifted move key
key_snext
kNXT
%c
sent by shifted next key
key_soptions
kOPT
%d
sent by shifted options key
key_sprevious
kPRV
%e
sent by shifted prev key
key_sprint
kPRT
%f
sent by shifted print key
key_sr
kri
kR
sent by scroll-backward/up key
key_sredo
kRDO
%g
sent by shifted redo key
key_sreplace
kRPL
%h
sent by shifted replace key
key_sright
kRIT
%i
sent by shifted right-arrow key
key_srsume
kRES
%j
sent by shifted resume key
key_ssave
kSAV
!1
sent by shifted save key
key_ssuspend
kSPD
!2
sent by shifted suspend key
key_stab
khts
kT
sent by set-tab key
key_sundo
kUND
!3
sent by shifted undo key
key_suspend
kspd
&7
sent by suspend key
key_undo
kund
&8
sent by undo key
key_up
kcuu1
ku
sent by terminal up-arrow key
keypad_local
rmkx
ke
Out of ""keypad-transmit"" mode
keypad_xmit
smkx
ks
Put terminal in ""keypad-transmit"" mode
lab_f0
lf0
l0
Labels on function key f0 if not f0
lab_f1
lf1
l1
Labels on function key f1 if not f1
lab_f2
lf2
l2
Labels on function key f2 if not f2
lab_f3
lf3
l3
Labels on function key f3 if not f3
lab_f4
lf4
l4
Labels on function key f4 if not f4
lab_f5
lf5
l5
Labels on function key f5 if not f5
lab_f6
lf6
l6
Labels on function key f6 if not f6
lab_f7
lf7
l7
Labels on function key f7 if not f7
lab_f8
lf8
l8
Labels on function key f8 if not f8
lab_f9
lf9
l9
Labels on function key f9 if not f9
lab_f10
lf10
la
Labels on function key f10 if not f10
label_format
fln
Lf
Label format
label_off
rmln
LF
Turn off soft labels
label_on
smln
LO
Turn on soft labels
meta_off
rmm
mo
Turn off ""meta mode""
meta_on
smm
mm
Turn on ""meta mode"" (8th bit)
micro_column_address
mhpa
ZY
Like column_address for micro adjustment
micro_down
mcud1
ZZ
Like cursor_down for micro adjustment
micro_left
mcub1
Za
Like cursor_left for micro adjustment
micro_right
mcuf1
Zb
Like cursor_right for micro adjustment
micro_row_address
mvpa
Zc
Like row_address for micro adjustment
micro_up
mcuu1
Zd
Like cursor_up for micro adjustment
mouse_info
minfo
Mi
Mouse status information
newline
nel
nw
Newline (behaves like cr followed by lf)
order_of_pins
porder
Ze
Matches software bits to print-head pins
orig_colors
oc
oc
Set all colour(-pair)s to the original ones
orig_pair
op
op
Set default colour-pair to the original one
pad_char
pad
pc
Pad character (rather than null)
parm_dch
dch
DC
Delete #1 chars
parm_delete_line
dl
DL
Delete #1 lines
parm_down_cursor
cud
DO
Move down #1 lines.
parm_down_micro
mcud
Zf
Like parm_down_cursor for micro adjust.
parm_ich
ich
IC
Insert #1 blank chars
parm_index
indn
SF
Scroll forward #1 lines.
parm_insert_line
il
AL
Add #1 new blank lines
parm_left_cursor
cub
LE
Move cursor left #1 spaces
parm_left_micro
mcub
Zg
Like parm_left_cursor for micro adjust.
parm_right_cursor
cuf
RI
Move right #1 spaces.
parm_right_micro
mcuf
Zh
Like parm_right_cursor for micro adjust.
parm_rindex
rin
SR
Scroll backward #1 lines.
parm_up_cursor
cuu
UP
Move cursor up #1 lines.
parm_up_micro
mcuu
Zi
Like parm_up_cursor for micro adjust.
pc_term_options
pctrm
S6
PC terminal options
pkey_key
pfkey
pk
Prog funct key #1 to type string #2
pkey_local
pfloc
pl
Prog funct key #1 to execute string #2
pkey_plab
pfxl
xl
Prog key #1 to xmit string #2 and show string #3
pkey_xmit
pfx
px
Prog funct key #1 to xmit string #2
plab_norm
pln
pn
Prog label #1 to show string #2
print_screen
mc0
ps
Print contents of the screen
prtr_non
mc5p
pO
Turn on the printer for #1 bytes
prtr_off
mc4
pf
Turn off the printer
prtr_on
mc5
po
Turn on the printer
pulse
pulse
PU
Select pulse dialing
quick_dial
qdial
QD
 Dial phone number #1, without progress detection 
remove_clock
rmclk
RC
Remove time-of-day clock
repeat_char
rep
rp
Repeat char #1 #2 times
req_for_input
rfi
RF
Send next input char (for ptys)
req_mouse_pos
reqmp
RQ
Request mouse position report
reset_1string
rs1
r1
Reset terminal completely to sane modes
reset_2string
rs2
r2
Reset terminal completely to sane modes
reset_3string
rs3
r3
Reset terminal completely to sane modes
reset_file
rf
rf
Name of file containing reset string
restore_cursor
rc
rc
Restore cursor to position of last sc
row_address
vpa
cv
Set vertical position to absolute #1
save_cursor
sc
sc
Save cursor position
scancode_escape
scesc
S7
Escape for scancode emulation
scroll_forward
ind
sf
Scroll text up
scroll_reverse
ri
sr
Scroll text down
select_char_set
scs
Zj
Select character set
set0_des_seq
s0ds
s0
Shift into codeset 0 (EUC set 0, ASCII)
set1_des_seq
s1ds
s1
Shift into codeset 1
set2_des_seq
s2ds
s2
Shift into codeset 2
set3_des_seq
s3ds
s3
Shift into codeset 3
set_a_attributes
sgr1

Define second set of video attributes #1-#6
set_a_background
setab
AB
Set background colour to #1 using ANSI escape
set_a_foreground
setaf
AF
Set foreground colour to #1 using ANSI escape
set_attributes
sgr
sa
Define first set of video attributes #1-#9
set_background
setb
Sb
Set background colour to #1
set_bottom_margin
smgb
Zk
Set bottom margin at current line
set_bottom_margin_parm
smgbp
Zl
Set bottom margin at line #1 or #2



lines from bottom
set_clock
sclk
SC
Set clock to hours (#1), minutes (#2), seconds (#3)
set_color_band
setcolor
Yz
Change to ribbon colour #1
set_color_pair
scp
sp
Set current colour pair to #1
set_foreground
setf
Sf
Set foreground colour to #1
set_left_margin
smgl
ML
Set left margin at current column
set_left_margin_parm
smglp
Zm
Set left (right) margin at column #1 (#2)
set_lr_margin
smglr
ML
Sets both left and right margins
set_page_length
slines
YZ
Set page length to #1 lines
set_pglen_inch
slength
YI
Set page length to #1 hundredth of an inch
set_right_margin
smgr
MR
Set right margin at current column
set_right_margin_parm
smgrp
Zn
Set right margin at column #1
set_tab
hts
st
Set a tab in all rows, current column
set_tb_margin
smgtb
MT
Sets both top and bottom margins
set_top_margin
smgt
Zo
Set top margin at current line
set_top_margin_parm
smgtp
Zp
Set top (bottom) margin at line #1 (#2)
set_window
wind
wi
Current window is lines #1-#2 cols #3-#4
start_bit_image
sbim
Zq
Start printing bit image graphics
start_char_set_def
scsd
Zr
Start definition of a character set
stop_bit_image
rbim
Zs
End printing bit image graphics
stop_char_set_def
rcsd
Zt
End definition of a character set
subscript_characters
subcs
Zu
List of ""subscript-able"" characters
superscript_characters
supcs
Zv
List of ""superscript-able"" characters
tab
ht
ta
Tab to next 8-space hardware tab stop
these_cause_cr
docr
Zw
Printing any of these chars causes cr
to_status_line
tsl
ts
Go to status line, col #1
tone
tone
TO
Select touch tone dialing
user0
u0
u0
User string 0
user1
u1
u1
User string 1
user2
u2
u2
User string 2
user3
u3
u3
User string 3
user4
u4
u4
User string 4
user5
u5
u5
User string 5
user6
u6
u6
User string 6
user7
u7
u7
User string 7
user8
u8
u8
User string 8
user9
u9
u9
User string 9
underline_char
uc
uc
Underscore one char and move past it
up_half_line
hu
hu
Half-line up (reverse 1/2 linefeed)
wait_tone
wait
WA
Wait for dial tone
xoff_character
xoffc
XF
X-off character
xon_character
xonc
XN
X-on character
zero_motion
zerom
Zx
No motion for the subsequent character

 Sample Entry

The following entry describes the AT&T 610 terminal.


610|610bct|ATT610|att610|AT&T610;80column;98key keyboard,
	am, eslok, hs, mir, msgr, xenl, xon,
	cols#80, it#8, lh#2, lines#24, lw#8, nlab#8, wsl#80,
	acsc=""aaffggjjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~,
	bel=^G, blink=\E[5m, bold=\E[1m, cbt=\E[Z,
	civis=\E[?25l, clear=\E[H\E[J, cnorm=\E[?25h\E[?12l,
	cr=\r, csr=\E[%i%p1%d;%p2%dr, cub=\E[%p1%dD, cub1=\b,
	cud=\E[%p1%dB, cud1=\E[B, cuf=\E[%p1%dC, cuf1=\E[C,
	cup=\E[%i%p1%d;%p2%dH, cuu=\E[%p1%dA, cuu1=\E[A,
	cvvis=\E[?12;25h, dch=\E[%p1%dP, dch1=\E[P, dim=\E[2m,
	dl=\E[%p1%dM, dl1=\E[M, ed=\E[J, el=\E[K, el1=\E[1K,
	flash=\E[?5h$<200>\E[?5l, fsl=\E8, home=\E[H, ht=\t,
	ich=\E[%p1%d@, il=\E[%p1%dL, il1=\E[L, ind=\ED, .ind=\ED$<9>,
	invis=\E[8m,
	is1=\E[8;0 | \E[?3;4;5;13;15l\E[13;20l\E[?7h\E[12h\E(B\E)0,
	is2=\E[0m^O, is3=\E(B\E)0, kLFT=\E[\s@, kRIT=\E[\sA,
	kbs=^H, kcbt=\E[Z, kclr=\E[2J, kcub1=\E[D, kcud1=\E[B,
	kcuf1=\E[C, kcuu1=\E[A, kfP=\EOc, kfP0=\ENp,
	kfP1=\ENq, kfP2=\ENr, kfP3=\ENs, kfP4=\ENt, kfI=\EOd,
	kfB=\EOe, kf4=\EOf, kf=\EOg, kf6=\EOh, kf7=\EOi,
	kf8=\EOj, kf9=\ENo, khome=\E[H, kind=\E[S, kri=\E[T,
	ll=\E[24H, mc4=\E[?4i, mc5=\E[?5i, nel=\EE,
	pfxl=\E[%p1%d;%p2%l%02dq%?%p1%{9}%<%t\s\s\sF%p1%1d\s\s\s\s\s
\s\s\s\s\s\s%;%p2%s,
	pln=\E[%p1%d;0;0;0q%p2%:-16.16s, rc=\E8, rev=\E[7m,
	ri=\EM, rmacs=^O, rmir=\E[4l, rmln=\E[2p, rmso=\E[m,
	rmul=\E[m, rs2=\Ec\E[?3l, sc=\E7,
	sgr=\E[0%?%p6%t;1%;%?%p5%t;2%;%?%p2%t;4%;%?%p4%t;5%;
%?%p3%p1% | %t;7%;%?%p7%t;8%;m%?%p9%t^N%e^O%;,
	sgr0=\E[m^O, smacs=^N, smir=\E[4h, smln=\E[p,
	smso=\E[7m, smul=\E[4m, tsl=\E7\E[25;%i%p1%dx,


 Types of Capabilities in the Sample Entry
The sample entry shows the formats for the three types of terminfo
capabilities:  Boolean, numeric, and string.  All capabilities specified in
the terminfo source file must be followed by commas, including the last
capability in the source file.  In terminfo source files, capabilities
are referenced by their capability names (as shown in the
Capname
column of the previous tables).
 Boolean Capabilities
A boolean capability is true if its
Capname
is present in the entry, and false if its
Capname
is not present in the entry.

The `@' character following a
Capname
is used to explicitly declare that a boolean capability is false, in
situations described in
.
 Numeric Capabilities
Numeric capabilities are followed by the character `#' and then a positive
integer value.  The example assigns the value 80 to the cols numeric
capability by coding:


cols#80


Values for numeric capabilities may be specified in decimal, octal or
hexadecimal, using normal C-language conventions.
 String Capabilities
String-valued capabilities such as el (clear to end of line
sequence) are listed by the
Capname,
an `=', and a string
ended by the next occurrence of a comma.

A delay in milliseconds may appear anywhere in such a capability,
preceded by $ and enclosed in angle brackets, as in el=\EK$<3>.
The Curses implementation achieves delays by outputting to the terminal an
appropriate number of system-defined padding characters.  The
tputs()
function provides delays when used to send such a capability to the terminal.

The delay can be any of the following:  a number, a number
followed by an asterisk, such as 5*, a number followed by a slash,
such as 5/, or a number followed by both, such as 5*/.



A `*' shows that the required delay is proportional to the
number of lines affected by the operation, and the amount given is the
delay required per affected unit.  (In the case of insert characters, the
factor is still the number of lines affected.  This is always 1 unless the
device has in and the software uses it.) When a `*' is specified, it
is sometimes useful to give a delay of the form 3.5 to specify a delay
per unit to tenths of milliseconds.  (Only one decimal place is allowed.)


A `/' indicates that the delay is mandatory and padding characters are
transmitted regardless of the setting of xon.
If `/' is not specified or if a device has xon
defined, the delay information is advisory and is only used for cost
estimates or when the device is in raw mode.  However, any delay specified
for bel or flash is treated as mandatory.



The following notation is valid in terminfo source files for specifying
special characters:
Notation
Represents Character
^x
Control-x (for any appropriate x)
\a
Alert
\b
Backspace
\E or \e
An ESCAPE character
\f
Form feed
\l
Linefeed
\n
Newline
\r
Carriage return
\s
Space
\t
Tab
\^
Caret (^)
\\
Backslash (\)
\,
Comma (,)
\:
Colon (:)
\0
Null
\nnn
Any character, specified as three octal digits

(See the XBD specification, General Terminal Interface  .)
 Commented-out Capabilities
Sometimes individual capabilities must be commented out.  To do this, put a
period before the capability name.  For example, see the second ind in
the example in

Sample Entry
.
Note that capabilities are defined in a left-to-right
order and, therefore, a prior definition will override a later definition.



UNIX ® is a registered Trademark of The Open Group.
Copyright © 1997 The Open Group
 [ Main Index | XSH | XCU | XBD | XCURSES | XNS ]


","tic(1M) 							       tic(1M)



NAME
       tic - the terminfo entry-description compiler

SYNOPSIS
       tic  [-1CGILNTUVacfgrstx]  [-e  names]  [-o  dir]  [-R  subset] [-v[n]]
       [-w[n]] file

DESCRIPTION
       The command tic translates a terminfo file from source format into com-
       piled  format.	The  compiled  format  is  necessary  for use with the
       library routines in ncurses(3X).

       The results are	normally  placed  in  the  system  terminfo  directory
       /usr/share/terminfo.  There are two ways to change this behavior.

       First, you may override the system default by setting the variable TER-
       MINFO in your shell environment to a valid (existing) directory name.

       Secondly, if tic cannot get access to /usr/share/terminfo or your  TER-
       MINFO  directory,  it  looks for the directory $HOME/.terminfo; if that
       directory exists, the entry is placed there.

       Libraries that read terminfo entries are expected to check for  a  TER-
       MINFO  directory first, look at $HOME/.terminfo if TERMINFO is not set,
       and finally look in /usr/share/terminfo.

       -1     restricts the output to a single column

       -a     tells tic to retain commented-out capabilities rather than  dis-
	      carding them.  Capabilities are commented by prefixing them with
	      a period.  This sets the -x option, because it treats  the  com-
	      mented-out  entries  as  user-defined  names.   If the source is
	      termcap, accept the 2-character names  required  by  version  6.
	      Otherwise these are ignored.

       -C     Force  source translation to termcap format.  Note: this differs
	      from the -C option of infocmp(1M) in that  it  does  not	merely
	      translate capability names, but also translates terminfo strings
	      to termcap format.  Capabilities that are not  translatable  are
	      left  in	the entry under their terminfo names but commented out
	      with two preceding dots.

       -c     tells tic to only check file for errors, including syntax  prob-
	      lems  and  bad  use  links.   If	you  specify -C (-I) with this
	      option, the code will print warnings about entries which,  after
	      use  resolution, are more than 1023 (4096) bytes long.  Due to a
	      fixed buffer length in older termcap libraries (and a documented
	      limit in terminfo), these entries may cause core dumps.

       -e names
	      Limit  writes  and translations to the following comma-separated
	      list of terminals.  If any name or alias of a  terminal  matches
	      one  of  the  names  in  the  list, the entry will be written or
	      translated as normal.  Otherwise no output will be generated for
	      it.   The  option  value is interpreted as a file containing the
	      list if it contains a '/'.  (Note: depending on how tic was com-
	      piled, this option may require -I or -C.)

       -f     Display	  complex     terminfo	   strings    which    contain
	      if/then/else/endif expressions indented for readability.

       -G     Display constant literals in  decimal  form  rather  than  their
	      character equivalents.

       -g     Display  constant  character literals in quoted form rather than
	      their decimal equivalents.

       -I     Force source translation to terminfo format.

       -L     Force source translation to terminfo format  using  the  long  C
	      variable names listed in <term.h>

       -N     Disable smart defaults.  Normally, when translating from termcap
	      to terminfo, the compiler makes a number	of  assumptions  about
	      the   defaults   of   string  capabilities  reset1_string,  car-
	      riage_return,  cursor_left,  cursor_down,  scroll_forward,  tab,
	      newline, key_backspace, key_left, and key_down, then attempts to
	      use obsolete termcap capabilities to deduce correct values.   It
	      also normally suppresses output of obsolete termcap capabilities
	      such as bs.  This option forces a more literal translation  that
	      also preserves the obsolete capabilities.

       -odir  Write  compiled  entries to given directory.  Overrides the TER-
	      MINFO environment variable.

       -Rsubset
	      Restrict output to a given subset.  This option is for use  with
	      archaic  versions  of  terminfo  like  those on SVr1, Ultrix, or
	      HP/UX that do not support the full set of SVR4/XSI  Curses  ter-
	      minfo;  and  outright  broken ports like AIX 3.x that have their
	      own extensions incompatible with	SVr4/XSI.   Available  subsets
	      are ""SVr1"", ""Ultrix"", ""HP"", ""BSD"" and ""AIX""; see terminfo(5) for
	      details.

       -r     Force entry resolution (so there are no remaining  tc  capabili-
	      ties)  even  when doing translation to termcap format.  This may
	      be needed if you are preparing a	termcap  file  for  a  termcap
	      library  (such as GNU termcap through version 1.3 or BSD termcap
	      through 4.3BSD) that does not handle  multiple  tc  capabilities
	      per entry.

       -s     Summarize  the  compile  by  showing  the  directory  into which
	      entries are written, and the number of entries  which  are  com-
	      piled.

       -T     eliminates  size-restrictions  on  the  generated text.  This is
	      mainly useful for  testing  and  analysis,  since  the  compiled
	      descriptions  are limited (e.g., 1023 for termcap, 4096 for ter-
	      minfo).

       -t     tells tic to discard commented-out capabilities.	Normally  when
	      translating  from  terminfo to termcap, untranslatable capabili-
	      ties are commented-out.

       -U   tells tic to not post-process the data after  parsing  the	source
	    file.  Normally, it infers data which is commonly missing in older
	    terminfo data, or in termcaps.

       -V   reports the version of ncurses which was used in this program, and
	    exits.

       -vn  specifies that (verbose) output be written to standard error trace
	    information showing tic's progress.  The optional parameter n is a
	    number  from  1  to 10, inclusive, indicating the desired level of
	    detail of information.  If n is omitted, the default level	is  1.
	    If	n  is  specified  and  greater	than 1, the level of detail is
	    increased.

       -wn  specifies the width of the output.	The parameter is optional.  If
	    it is omitted, it defaults to 60.

       -x   Treat  unknown capabilities as user-defined.  That is, if you sup-
	    ply a capability name which tic does not recognize, it will  infer
	    its  type  (boolean, number or string) from the syntax and make an
	    extended table entry for that.   User-defined  capability  strings
	    whose name begins with ``k'' are treated as function keys.

       file contains one or more terminfo terminal descriptions in source for-
	    mat [see terminfo(5)].  Each description in the file describes the
	    capabilities of a particular terminal.

       The debug flag levels are as follows:

       1      Names of files created and linked

       2      Information related to the ``use'' facility

       3      Statistics from the hashing algorithm

       5      String-table memory allocations

       7      Entries into the string-table

       8      List of tokens encountered by scanner

       9      All values computed in construction of the hash table

       If the debug level n is not given, it is taken to be one.

       All  but  one  of  the capabilities recognized by tic are documented in
       terminfo(5).  The exception is the use capability.

       When a use=entry-name field is discovered in a terminal entry currently
       being  compiled,  tic  reads  in the binary from /usr/share/terminfo to
       complete the entry.  (Entries created from file will be used first.  If
       the  environment  variable  TERMINFO is set, that directory is searched
       instead of /usr/share/terminfo.)  tic duplicates  the  capabilities  in
       entry-name for the current entry, with the exception of those capabili-
       ties that explicitly are defined in the current entry.

       When an entry, e.g., entry_name_1, contains a  use=entry_name_2	field,
       any   canceled	capabilities  in  entry_name_2	must  also  appear  in
       entry_name_1 before use= for  these  capabilities  to  be  canceled  in
       entry_name_1.

       If  the	environment variable TERMINFO is set, the compiled results are
       placed there instead of /usr/share/terminfo.

       Total compiled entries cannot exceed 4096 bytes.  The name field cannot
       exceed  512  bytes.   Terminal names exceeding the maximum alias length
       (32 characters on systems with long filenames, 14 characters otherwise)
       will  be  truncated  to	the maximum alias length and a warning message
       will be printed.

COMPATIBILITY
       There is  some  evidence  that  historic  tic  implementations  treated
       description  fields with no whitespace in them as additional aliases or
       short names.  This tic does not do that, but it does warn when descrip-
       tion  fields may be treated that way and check them for dangerous char-
       acters.

EXTENSIONS
       Unlike the stock SVr4 tic command,  this  implementation  can  actually
       compile termcap sources.  In fact, entries in terminfo and termcap syn-
       tax can be mixed in a single source file.  See terminfo(5) for the list
       of termcap names taken to be equivalent to terminfo names.

       The  SVr4  manual  pages  are not clear on the resolution rules for use
       capabilities.  This implementation of tic will find  use  targets  any-
       where  in  the source file, or anywhere in the file tree rooted at TER-
       MINFO (if TERMINFO is defined), or in the user's $HOME/.terminfo direc-
       tory (if it exists), or (finally) anywhere in the system's file tree of
       compiled entries.

       The error messages from this tic have the same format as  GNU  C  error
       messages, and can be parsed by GNU Emacs's compile facility.

       The  -C,  -G, -I, -N, -R, -T, -V, -a, -e, -f, -g, -o, -r, -s, -t and -x
       options are not supported under SVr4.  The SVr4 -c mode does not report
       bad use links.

       System  V  does	not  compile  entries  to  or  read  entries from your
       $HOME/.terminfo directory unless TERMINFO is explicitly set to it.

FILES
       /usr/share/terminfo/?/*
	    Compiled terminal description database.

SEE ALSO
       infocmp(1M), captoinfo(1M), infotocap(1M),  toe(1M),  curses(3X),  ter-
       minfo(5).

       This describes ncurses version 5.7 (patch 20081102).



								       tic(1M)
","# tic

> Compile terminfo and install for ncurses.
> More information: <https://pubs.opengroup.org/onlinepubs/007908799/xcurses/terminfo.html>.

- Compile and install terminfo for a terminal:

`tic -xe {{terminal}} {{path/to/terminal.info}}`

- Check terminfo file for errors:

`tic -c {{path/to/terminal.info}}`

- Print database locations:

`tic -D`
"
unshadow,https://www.openwall.com/john/,"

John the Ripper password cracker












Products

Openwall GNU/*/Linux   server OS
Linux Kernel Runtime Guard
John the Ripper   password cracker

Free & Open Source for any platform
in the cloud
Pro for Linux
Pro for macOS

Wordlists   for password cracking
passwdqc   policy enforcement

Free & Open Source for Unix
Pro for Windows (Active Directory)

yescrypt   KDF & password hashing
yespower   Proof-of-Work (PoW)
crypt_blowfish   password hashing
phpass   ditto in PHP
tcb   better password shadowing
Pluggable Authentication Modules
scanlogd   port scan detector
popa3d   tiny POP3 daemon
blists   web interface to mailing lists
msulogin   single user mode login
php_mt_seed   mt_rand() cracker

Services
Publications

Articles
Presentations

Resources

Mailing lists
Community wiki
Source code repositories (GitHub)
Source code repositories (CVSweb)
File archive & mirrors
How to verify digital signatures
OVE IDs

What's new



John the Ripper password cracker

John the Ripper is an Open Source password security auditing and password recovery tool available for many operating systems.
John the Ripper jumbo supports hundreds of hash and cipher types, including for: user passwords of Unix flavors
(Linux, *BSD, Solaris, AIX, QNX, etc.), macOS, Windows, ""web apps"" (e.g., WordPress), groupware (e.g., Notes/Domino), and
database servers (SQL, LDAP, etc.);
network traffic captures (Windows network authentication, WiFi WPA-PSK, etc.);
encrypted private keys (SSH, GnuPG, cryptocurrency wallets, etc.),
filesystems and disks (macOS .dmg files and ""sparse bundles"", Windows BitLocker, etc.),
archives (ZIP, RAR, 7z), and document files (PDF, Microsoft Office's, etc.)
These are just some of the examples - there are many more.





Password authentication for web and mobile apps (e-book)



John the Ripper is free and Open Source software,
distributed primarily in source code form.
If you would rather use a commercial product, please consider
John the Ripper Pro,
which is distributed primarily in the form of ""native"" packages
for the target operating systems and in general is meant to be easier to
install and use while delivering optimal performance.


Proceed to John the Ripper Pro homepage for your OS:

John the Ripper Pro for Linux
John the Ripper Pro for macOS


On Windows, consider Hash Suite

(developed by a contributor to John the Ripper)


On Android, consider Hash Suite Droid


Download the latest John the Ripper jumbo release
(release notes) or development snapshot:


1.9.0-jumbo-1 sources in
tar.xz, 33 MB (signature) or
tar.gz, 43 MB (signature)


1.9.0-jumbo-1 64-bit Windows binaries in
7z, 22 MB (signature) or
zip, 63 MB (signature)



1.9.0-jumbo-1 32-bit Windows binaries in
7z, 21 MB (signature) or
zip, 61 MB (signature)

Development source code in GitHub repository
(download as
tar.gz or
zip)


Run John the Ripper jumbo in the cloud (AWS):

John the Ripper in the cloud homepage


Download the latest John the Ripper core release
(release notes):


1.9.0 core sources in
tar.xz, 8.6 MB (signature) or
tar.gz, 13 MB (signature)
Development source code in CVS repository


To verify authenticity and integrity of your John the Ripper downloads, please
use our
GnuPG public key.

Please refer to these pages on

how to extract John the Ripper source code from the tar.gz and tar.xz archives and
how to build (compile) John the Ripper core
(for jumbo, please refer to instructions inside the archive).
You may also consider the unofficial builds on the contributed resources list further down this page.

These and older versions of John the Ripper, patches, unofficial builds, and many other related files are also
available from the Openwall file archive.

You may browse the documentation for John the Ripper core online, including a
summary of changes between core versions.
Also relevant is our
presentation on the history of password security.

There's a collection of wordlists for use with John the Ripper.
It includes lists of common passwords, wordlists for 20+ human languages, and files with the common passwords and
unique words for all the languages combined, also with mangling rules applied and any duplicates purged.

yescrypt and crypt_blowfish
are implementations of yescrypt, scrypt, and bcrypt - some of the strong password hashes also found in John the Ripper -
released separately for defensive use in your software or on your servers.

passwdqc is a proactive password/passphrase strength checking and policy enforcement toolset,
which can prevent your users from choosing passwords that would be easily cracked with programs like John the Ripper.

We may help you integrate modern password hashing with
yescrypt or crypt_blowfish,
and/or proactive password strength checking with
passwdqc,
into your OS installs, software, or online services.
Please check out our services.

There's a mailing list where you can share your experience with John the Ripper and ask questions.

Please be sure to specify an informative message subject whenever
you post to the list
(that is, something better than ""question"" or ""problem"").
To subscribe, enter your e-mail address below or send an empty message to
<john-users-subscribe at lists.openwall.com>.
You will be required to confirm your subscription by ""replying""
to the automated confirmation request that will be sent to you.
You will be able to
unsubscribe
at any time and we will not use your e-mail
address for any other purpose or share it with a third party.
However, if you post to the list, other subscribers and those
viewing the archives may see your address(es) as specified on your message.

The list archive is available
locally and via
MARC.
Additionally, there's a

list of selected most useful and currently relevant postings on the
community wiki.



Your e-mail address:






Contributed resources for John the Ripper:

Community wiki with
custom builds,
benchmarks, and more
Custom builds for Windows (up to 1.8.0.13-jumbo)
Custom builds for macOS (up to 1.8.0.9-jumbo)
Custom builds for Solaris (packages up to 1.7.6, non-packaged up to 1.7.8-jumbo-7)
Custom builds for Android (up to 1.8.0)
Ubuntu snap package
(documentation,
announcement)

OpenVMS and SYSUAF.DAT support
(signature)
by Jean-loup Gailly

OpenVMS executables for Alpha and VAX
(signature)
Local copies of
the above files by Jean-loup Gailly and
a much newer implementation by David Jones



Local copies of these and many other related packages are also

available from the Openwall file archive.

John the Ripper is part of
Owl,
Debian GNU/Linux, Fedora Linux, Gentoo Linux, Mandriva Linux, SUSE Linux,
and a number of other Linux distributions.
It is in the ports/packages collections of FreeBSD, NetBSD, and OpenBSD.

John the Ripper is a registered project with
Open Hub
and it is listed at
SecTools.




Quick Comment:







Powered by Openwall GNU/*/Linux -
Powered by OpenVZ


29439148


",,"# unshadow

> Utility provided by the John the Ripper project to obtain the traditional Unix password file if the system uses shadow passwords.
> More information: <https://www.openwall.com/john/>.

- Combine the /etc/shadow and /etc/passwd of the current system:

`sudo unshadow /etc/passwd /etc/shadow`

- Combine two arbitrary shadow and password files:

`sudo unshadow {{/path/to/passwd}} {{/path/to/shadow}}`
"
ltrace,,,,"# ltrace

> Display dynamic library calls of a process.

- Print (trace) library calls of a program binary:

`ltrace ./{{program}}`

- Count library calls. Print a handy summary at the bottom:

`ltrace -c {{/path/to/program}}`

- Trace calls to malloc and free, omit those done by libc:

`ltrace -e malloc+free-@libc.so* {{/path/to/program}}`

- Write to file instead of terminal:

`ltrace -o {{file}} {{/path/to/program}}`
"
firewall-cmd,,,,"# firewall-cmd

> The firewalld command line client.

- View the available firewall zones:

`firewall-cmd --get-active-zones`

- View the rules which are currently applied:

`firewall-cmd --list-all`

- Permanently move the interface into the block zone, effectively blocking all communication:

`firewall-cmd --permanent --zone={{block}} --change-interface={{enp1s0}}`

- Permanently open the port for a service in the specified zone (like port `443` when in the `public` zone):

`firewall-cmd --permanent --zone={{public}} --add-service={{https}}`

- Permanently close the port for a service in the specified zone (like port `80` when in the `public` zone):

`firewall-cmd --permanent --zone={{public}} --remove-service={{http}}`

- Permanently open two arbitrary ports in the specified zone:

`firewall-cmd --permanent --zone={{public}} --add-port={{25565/tcp}} --add-port={{19132/udp}}`

- Reload firewalld to force rule changes to take effect:

`firewall-cmd --reload`
"
findfs,https://mirrors.edge.kernel.org/pub/linux/utils/util-linux,"
Index of /pub/linux/utils/util-linux/

Index of /pub/linux/utils/util-linux/../
v2.13/                                             19-Jan-2012 11:54       -
v2.14/                                             19-Jan-2012 11:42       -
v2.15/                                             19-Jan-2012 11:31       -
v2.16/                                             19-Jan-2012 11:18       -
v2.17/                                             19-Jan-2012 11:21       -
v2.18/                                             19-Jan-2012 10:59       -
v2.19/                                             19-Jan-2012 10:53       -
v2.20/                                             19-Jan-2012 12:02       -
v2.21/                                             25-May-2012 11:10       -
v2.22/                                             13-Dec-2012 12:02       -
v2.23/                                             31-Jul-2013 12:40       -
v2.24/                                             24-Apr-2014 10:18       -
v2.25/                                             24-Oct-2014 13:08       -
v2.26/                                             30-Apr-2015 10:44       -
v2.27/                                             02-Nov-2015 11:06       -
v2.28/                                             07-Sep-2016 12:06       -
v2.29/                                             22-Feb-2017 15:26       -
v2.30/                                             21-Sep-2017 09:51       -
v2.31/                                             19-Dec-2017 15:18       -
v2.32/                                             16-Jul-2018 11:29       -
v2.33/                                             09-Apr-2019 13:57       -
v2.34/                                             14-Jun-2019 10:46       -
v2.35/                                             20-May-2020 14:00       -
v2.36/                                             23-Jul-2020 09:59       -

",,"# findfs

> Finds a filesystem by label or UUID.
> More information: <https://mirrors.edge.kernel.org/pub/linux/utils/util-linux>.

- Search block devices by filesystem label:

`findfs LABEL={{label}}`

- Search by filesystem UUID:

`findfs UUID={{uuid}}`

- Search by partition label (GPT or MAC partition table):

`findfs PARTLABEL={{partition_label}}`

- Search by partition UUID (GPT partition table only):

`findfs PARTUUID={{partition_uuid}}`
"
ntfsfix,,,,"# ntfsfix

> Fix common problems on an NTFS partition.

- Fix a given NTFS partition:

`sudo ntfsfix {{/dev/sdb2}}`
"
n,,,,"# n

> Tool to manage multiple node versions.

- Install a given version of node. If the version is already installed, it will be activated:

`n {{version}}`

- Display installed versions and interactively activate one of them:

`n`

- Remove a version:

`n rm {{version}}`

- Execute a file with a given version:

`n use {{version}} {{file.js}}`

- Output binary path for a version:

`n bin {{version}}`
"
arp-scan,,,,"# arp-scan

> Send ARP packets to hosts (specified as IP addresses or hostnames) to scan the local network.

- Scan the current local network:

`arp-scan --localnet`

- Scan an IP network with a custom bitmask:

`arp-scan {{192.168.1.1}}/{{24}}`

- Scan an IP network within a custom range:

`arp-scan {{127.0.0.0}}-{{127.0.0.31}}`

- Scan an IP network with a custom net mask:

`arp-scan {{10.0.0.0}}:{{255.255.255.0}}`
"
lxc,,,,"# lxc

> Manage Linux containers using the lxd REST API.
> Any container names or patterns can be prefixed with the name of a remote server.

- List local containers matching a string. Omit the string to list all local containers:

`lxc list {{match_string}}`

- List images matching a string. Omit the string to list all images:

`lxc image list [{{remote}}:]{{match_string}}`

- Create a new container from an image:

`lxc init [{{remote}}:]{{image}} {{container}}`

- Start a container:

`lxc start [{{remote}}:]{{container}}`

- Stop a container:

`lxc stop [{{remote}}:]{{container}}`

- Show detailed info about a container:

`lxc info [{{remote}}:]{{container}}`

- Take a snapshot of a container:

`lxc snapshot [{{remote}}:]{{container}} {{snapshot}}`
"
trizen,,,,"# trizen

> Arch Linux utility for building packages from the Arch User Repository (AUR).

- Synchronize and update all AUR packages:

`trizen -Syua`

- Install a new package:

`trizen -S {{package}}`

- Remove a package and its dependencies:

`trizen -Rs {{package}}`

- Search the package database for a keyword:

`trizen -Ss {{keyword}}`

- Show information about a package:

`trizen -Si {{package}}`

- List installed packages and versions:

`trizen -Qe`
"
sbatch,,,,"# sbatch

> Submit a batch job to the SLURM scheduler.

- Submit a batch job:

`sbatch {{path/to/job.sh}}`

- Submit a batch job with a custom name:

`sbatch --job-name={{myjob}} {{path/to/job.sh}}`

- Submit a batch job with a time limit of 30 minutes:

`sbatch --time={{00:30:00}} {{path/to/job.sh}}`

- Submit a job and request multiple nodes:

`sbatch --nodes={{3}} {{path/to/job.sh}}`
"
dmesg,,,"
DMESG(8)		  BSD System Manager's Manual		      DMESG(8)

NAME
     dmesg -- display the system message buffer

SYNOPSIS
     dmesg [-M core] [-N system]

DESCRIPTION
     Dmesg displays the contents of the system message buffer.	This command
     needs to be run as root.

SEE ALSO
     syslogd(8)

HISTORY
     The dmesg command appeared in 4.0BSD.

4th Berkeley Distribution	 June 5, 1993	     4th Berkeley Distribution
","# dmesg

> Write the kernel messages to standard output.

- Show kernel messages:

`dmesg`

- Show kernel error messages:

`dmesg --level err`

- Show kernel messages and keep reading new ones, similar to `tail -f` (available in kernels 3.5.0 and newer):

`dmesg -w`

- Show how much physical memory is available on this system:

`dmesg | grep -i memory`

- Show kernel messages 1 page at a time:

`dmesg | less`

- Show kernel messages with a timestamp (available in kernels 3.5.0 and newer):

`dmesg -T`

- Show kernel messages in human-readable form (available in kernels 3.5.0 and newer):

`dmesg -H`

- Colorize output (available in kernels 3.5.0 and newer):

`dmesg -L`
"
pidstat,,,,"# pidstat

> Show system resource usage, including CPU, memory, IO etc.

- Show CPU statistics at a 2 second interval for 10 times:

`pidstat {{2}} {{10}}`

- Show page faults and memory utilization:

`pidstat -r`

- Show input/output usage per process id:

`pidstat -d`

- Show information on a specific PID:

`pidstat -p {{PID}}`

- Show memory statistics for all processes whose command name include ""fox"" or ""bird"":

`pidstat -C ""{{fox|bird}}"" -r -p ALL`
"
hdparm,,,,"# hdparm

> Get and set SATA and IDE hard drive parameters.

- Request the identification info of a given device:

`sudo hdparm -I /dev/{{device}}`

- Get the Advanced Power Management level:

`sudo hdparm -B /dev/{{device}}`

- Set the Advanced Power Management value (values 1-127 permit spin-down, and values 128-254 do not):

`sudo hdparm -B {{1}} /dev/{{device}}`

- Display the device's current power mode status:

`sudo hdparm -C /dev/{{device}}`

- Force a drive to immediately enter standby mode (usually causes a drive to spin down):

`sudo hdparm -y /dev/{{device}}`

- Put the drive into idle (low-power) mode, also setting its standby timeout:

`sudo hdparm -S {{standby_timeout}} {{device}}`
"
units,,,"
UNITS(1)		  BSD General Commands Manual		      UNITS(1)

NAME
     units -- conversion program

SYNOPSIS
     units [-f filename] [-qv] [from-unit to-unit]

OPTIONS
     The following options are available:

     -f filename
	     Specify the name of the units data file to load.

     -q      Suppress prompting of the user for units and the display of sta-
	     tistics about the number of units loaded.

     -v      Print the version number.

     from-unit to-unit
	     Allow a single unit conversion to be done directly from the com-
	     mand line.  The program will not print prompts.  It will print
	     out the result of the single specified conversion.

DESCRIPTION
     The units program converts quantities expressed in various scales to
     their equivalents in other scales.  The units program can only handle
     multiplicative scale changes.  It cannot convert Celsius to Fahrenheit,
     for example.  It works interactively by prompting the user for input:

	 You have: meters
	 You want: feet
		 * 3.2808399
		 / 0.3048

	 You have: cm^3
	 You want: gallons
		 * 0.00026417205
		 / 3785.4118

	 You have: meters/s
	 You want: furlongs/fortnight
		 * 6012.8848
		 / 0.00016630952

	 You have: 1|2 inch
	 You want: cm
		 * 1.27
		 / 0.78740157

     Powers of units can be specified using the '^' character as shown in the
     example, or by simple concatenation: 'cm3' is equivalent to 'cm^3'.  Mul-
     tiplication of units can be specified by using spaces, a dash or an
     asterisk.	Division of units is indicated by the slash ('/').  Note that
     multiplication has a higher precedence than division, so 'm/s/s' is the
     same as 'm/s^2' or 'm/s s'.  Division of numbers must be indicated using
     the vertical bar ('|').  To convert half a meter, you would write '1|2
     meter'.  If you write '1/2 meter' then the units program would interpret
     that as equivalent to '0.5/meter'.  If you enter incompatible unit types,
     the units program will print a message indicating that the units are not
     conformable and it will display the reduced form for each unit:

	 You have: ergs/hour
	 You want: fathoms kg^2 / day
	 conformability error
		 2.7777778e-11 kg m^2 / sec^3
		 2.1166667e-05 kg^2 m / sec

     The conversion information is read from a units data file.  The default
     file includes definitions for most familiar units, abbreviations and met-
     ric prefixes.  Some constants of nature included are:

	   pi	      ratio of circumference to diameter
	   c	      speed of light
	   e	      charge on an electron
	   g	      acceleration of gravity
	   force      same as g
	   mole       Avogadro's number
	   water      pressure per unit height of water
	   mercury    pressure per unit height of mercury
	   au	      astronomical unit

     The unit 'pound' is a unit of mass.  Compound names are run together so
     'pound force' is a unit of force.	The unit 'ounce' is also a unit of
     mass.  The fluid ounce is 'floz'.	British units that differ from their
     US counterparts are prefixed with 'br', and currency is prefixed with its
     country name: 'belgiumfranc', 'britainpound'.  When searching for a unit,
     if the specified string does not appear exactly as a unit name, then
     units will try to remove a trailing 's' or a trailing 'es' and check
     again for a match.

     To find out what units are available read the standard units file.  If
     you want to add your own units you can supply your own file.  A unit is
     specified on a single line by giving its name and an equivalence.	Be
     careful to define new units in terms of old ones so that a reduction
     leads to the primitive units which are marked with '!' characters.  The
     units program will not detect infinite loops that could be caused by
     careless unit definitions.  Comments in the unit definition file begin
     with a '/' character at the beginning of a line.

     Prefixes are defined in the same was as standard units, but with a trail-
     ing dash at the end of the prefix name.  If a unit is not found even
     after removing trailing 's' or 'es', then it will be checked against the
     list of prefixes.	Prefixes will be removed until a legal base unit is
     identified.

     Here is an example of a short units file that defines some basic units.

	   m	     !a!
	   sec	     !b!
	   micro-    1e-6
	   minute    60 sec
	   hour      60 min
	   inch      0.0254 m
	   ft	     12 inches
	   mile      5280 ft

FILES
     /usr/share/misc/units.lib	the standard units library

AUTHORS
     Adrian Mariano <adrian@cam.cornell.edu>

BUGS
     The effect of including a '/' in a prefix is surprising.

     Exponents entered by the user can be only one digit.  You can work around
     this by multiplying several terms.

     The user must use | to indicate division of numbers and / to indicate
     division of symbols.  This distinction should not be necessary.

     The program contains various arbitrary limits on the length of the units
     converted and on the length of the data file.

     The program should use a hash table to store units so that it does not
     take so long to load the units list and check for duplication.

BSD				 July 14, 1993				   BSD
","# units

> Provide the conversion between two units of measure.
> Typing 'search {{text}}' in the prompt will display a list of all of the units containing {{text}}.

- Run in interactive mode:

`units`

- Show the conversion between two simple units:

`units {{quarts}} {{tablespoons}}`

- Convert between units with quantities:

`units {{15 pounds}} {{kilograms}}`

- Show the conversion between two compound units:

`units {{""meters / second""}} {{""inches / hour""}}`

- Show the conversion between units with different dimensions:

`units {{""acres""}} {{""ft^2""}}`
"
ebuild,,,,"# ebuild

> A low level interface to the Gentoo Portage system.

- Create or update the package manifest:

`ebuild {{path/to/file.ebuild}} manifest`

- Clean the temporary build directories for the build file:

`ebuild {{path/to/file.ebuild}} clean`

- Fetch sources if they do not exist:

`ebuild {{path/to/file.ebuild}} fetch`

- Extract the sources to a temporary build directory:

`ebuild {{path/to/file.ebuild}} unpack`

- Compile the extracted sources:

`ebuild {{path/to/file.ebuild}} compile`

- Install the package to a temporary install directory:

`ebuild {{path/to/file.ebuild}} install`

- Install the temporary files to the live filesystem:

`ebuild {{path/to/file.ebuild}} qmerge`

- Fetch, unpack, compile, install and qmerge the specified ebuild file:

`ebuild {{path/to/file.ebuild}} merge`
"
rc-status,,,,"# rc-status

> Show status info about runlevels.
> See also `openrc`.

- Show a summary of services and their status:

`rc-status`

- Include services in all runlevels in the summary:

`rc-status --all`

- List services that have crashed:

`rc-status --crashed`

- List manually started services:

`rc-status --manual`

- List supervised services:

`rc-status --supervised`

- Get the current runlevel:

`rc-status --runlevel`

- List all runlevels:

`rc-status --list`
"
duperemove,https://markfasheh.github.io/duperemove/,"


Duperemove by markfasheh








Duperemove
Tools for deduping file systems
View on GitHub
Download .zip
Download .tar.gz



Duperemove
Duperemove is a simple tool for finding duplicated extents and
submitting them for deduplication. When given a list of files it will
hash their contents on a block by block basis and compare those hashes
to each other, finding and categorizing extents that match each
other. When given the -d option, duperemove will submit those
extents for deduplication using the Linux kernel extent-same ioctl.
Duperemove can store the hashes it computes in a 'hashfile'. If
given an existing hashfile, duperemove will only compute hashes
for those files which have changed since the last run.  Thus you can run
duperemove repeatedly on your data as it changes, without having to
re-checksum unchanged data.
Duperemove can also take input from the fdupes program.
See the duperemove man page for further details about running duperemove.

Requirements
The latest stable code (v0.11) can be found
  in master branch.
Kernel: Duperemove needs a kernel version equal to or greater than 3.13
Libraries: Duperemove uses glib2 and sqlite3.

FAQ
Please see the FAQ section
  in the
    duperemove man page
For bug reports and feature requests please use the github issue tracker

Examples
Please see the examples section of the duperemove man
page
for a complete set of usage examples, including hashfile usage.

A simple example, with program output
Duperemove takes a list of files and directories to scan for
dedupe. If a directory is specified, all regular files within it will
be scanned. Duperemove can also be told to recursively scan
directories with the '-r' switch. If '-h' is provided, duperemove will
print numbers in powers of 1024 (e.g., ""128K"").
Assume this abitrary layout for the following examples.
.
├── dir1
│   ├── file3
│   ├── file4
│   └── subdir1
│       └── file5
├── file1
└── file2

This will dedupe files 'file1' and 'file2':
duperemove -dh file1 file2

This does the same but adds any files in dir1 (file3 and file4):
duperemove -dh file1 file2 dir1

This will dedupe exactly the same as above but will recursively walk
dir1, thus adding file5.
duperemove -dhr file1 file2 dir1/

An actual run, output will differ according to duperemove version.
Using 128K blocks
Using hash: murmur3
Using 4 threads for file hashing phase
csum: /btrfs/file1  [1/5] (20.00%)
csum: /btrfs/file2  [2/5] (40.00%)
csum: /btrfs/dir1/subdir1/file5     [3/5] (60.00%)
csum: /btrfs/dir1/file3     [4/5] (80.00%)
csum: /btrfs/dir1/file4     [5/5] (100.00%)
Total files:  5
Total hashes: 80
Loading only duplicated hashes from hashfile.
Hashing completed. Calculating duplicate extents - this may take some time.
Simple read and compare of file data found 3 instances of extents that might benefit from deduplication.
Showing 2 identical extents of length 512.0K with id 0971ffa6
Start       Filename
512.0K  ""/btrfs/file1""
1.5M    ""/btrfs/dir1/file4""
Showing 2 identical extents of length 1.0M with id b34ffe8f
Start       Filename
0.0 ""/btrfs/dir1/file4""
0.0 ""/btrfs/dir1/file3""
Showing 3 identical extents of length 1.5M with id f913dceb
Start       Filename
0.0 ""/btrfs/file2""
0.0 ""/btrfs/dir1/file3""
0.0 ""/btrfs/dir1/subdir1/file5""
Using 4 threads for dedupe phase
[0x147f4a0] Try to dedupe extents with id 0971ffa6
[0x147f770] Try to dedupe extents with id b34ffe8f
[0x147f680] Try to dedupe extents with id f913dceb
[0x147f4a0] Dedupe 1 extents (id: 0971ffa6) with target: (512.0K, 512.0K), ""/btrfs/file1""
[0x147f770] Dedupe 1 extents (id: b34ffe8f) with target: (0.0, 1.0M), ""/btrfs/dir1/file4""
[0x147f680] Dedupe 2 extents (id: f913dceb) with target: (0.0, 1.5M), ""/btrfs/file2""
Kernel processed data (excludes target files): 4.5M
Comparison of extent info shows a net change in shared extents of: 5.5M


Links of interest
The duperemove wiki
has both design and performance documentation.
duperemove-tests has
a growing assortment of regression tests.
Duperemove web page

Duperemove is maintained by markfasheh.
This page was generated by GitHub Pages using the Cayman theme by Jason Long.



",,"# duperemove

> Finds duplicate file system extents and optionally schedule them for deduplication.
> An extent is small part of a file inside the file system.
> On some file systems one extent can be referenced multiple times, when parts of the content of the files are identical.
> More information: <https://markfasheh.github.io/duperemove/>.

- Search for duplicate extents in a directory and show them:

`duperemove -r {{path/to/directory}}`

- Deduplicate duplicate extents on a Btrfs or XFS (experimental) file system:

`duperemove -r -d {{path/to/directory}}`

- Use a hash file to store extent hashes (less memory usage and can be reused on subsequent runs):

`duperemove -r -d --hashfile={{path/to/hashfile}} {{path/to/directory}}`

- Limit I/O threads (for hashing and dedupe stage) and CPU threads (for duplicate extent finding stage):

`duperemove -r -d --hashfile={{path/to/hashfile}} --io-threads={{N}} --cpu-threads={{N}} {{path/to/directory}}`
"
logwatch,,,,"# logwatch

> Summarizes many different logs for common services (e.g., apache, pam_unix, sshd, etc.) in a single report.

- Analyze logs for a range of dates at certain level of detail:

`logwatch --range {{yesterday|today|all|help}} --detail {{low|medium|others}}'`

- Restrict report to only include information for a selected service:

`logwatch --range {{all}} --service {{apache|pam_unix|etc}}`
"
lscpu,,,,"# lscpu

> Displays information about the CPU architecture.

- Display information about all CPUs:

`lscpu`

- Display information in a table:

`lscpu --extended`

- Display only information about offline CPUs in a table:

`lscpu --extended --offline`
"
sar,,,,"# sar

> Monitor performance of various Linux subsystems.

- Report I/O and transfer rate issued to physical devices, one per second (press CTRL+C to quit):

`sar -b {{1}}`

- Report a total of 10 network device statistics, one per 2 seconds:

`sar -n DEV {{2}} {{10}}`

- Report CPU utilization, one per 2 seconds:

`sar -u ALL {{2}}`

- Report a total of 20 memory utilization statistics, one per second:

`sar -r ALL {{1}} {{20}}`

- Report the run queue length and load averages, one per second:

`sar -q {{1}}`

- Report paging statistics, one per 5 seconds:

`sar -B {{5}}`
"
yaourt,,,,"# yaourt

> Arch Linux utility for building packages from the Arch User Repository.

- Synchronize and update all packages (including AUR):

`yaourt -Syua`

- Install a new package (includes AUR):

`yaourt -S {{package_name}}`

- Remove a package and its dependencies (includes AUR packages):

`yaourt -Rs {{package_name}}`

- Search the package database for a keyword (including AUR):

`yaourt -Ss {{package_name}}`

- List installed packages, versions, and repositories (AUR packages will be listed under the repository name 'local'):

`yaourt -Q`
"
urxvt,,,,"# urxvt

> Rxvt-unicode.
> A customizable terminal emulator.

- Open a new urxvt window:

`urxvt`

- Run in a specific directory:

`urxvt -cd {{path/to/directory}}`

- Run a command in a new urxvt window:

`urxvt -e {{command}}`

- Run a command and keep the window open:

`urxvt --hold -e {{command}}`

- Run a command within the ""sh"" shell:

`urxvt -e {{sh}} -c {{command}}`
"
zypper,,,,"# zypper

> SUSE & openSUSE package management utility.

- Synchronize list of packages and versions available:

`zypper refresh`

- Install a new package:

`zypper install {{package}}`

- Remove a package:

`zypper remove {{package}}`

- Upgrade installed packages to newest available versions:

`zypper update`

- Search package via keyword:

`zypper search {{keyword}}`
"
xrandr,,,,"# xrandr

> Set the size, orientation and/or reflection of the outputs for a screen.

- Display the current state of the system (known screens, resolutions, ...):

`xrandr --query`

- Disable disconnected outputs and enable connected ones with default settings:

`xrandr --auto`

- Change the resolution and update frequency of DisplayPort 1 to 1920x1080, 60Hz:

`xrandr --output {{DP1}} --mode {{1920x1080}} --rate {{60}}`

- Set the resolution of HDMI2 to 1280x1024 and put it on the right of DP1:

`xrandr --output {{HDMI2}} --mode {{1280x1024}} --right-of {{DP1}}`

- Disable the VGA1 output:

`xrandr --output {{VGA1}} --off`
"
google-chrome,https://chrome.google.com," 















Google Chrome - Download the Fast, Secure Browser from Google
































 

 























Menu



Menu








icon chrome logo




Jump to content





Home

The Browser by Google

Features
          
icon-expand-features



Overview

Google address bar

Password check

Sync

Dark mode

Tabs

Articles for you

Extensions



Support
          






Download Chrome




close drawer







icon chrome logo






Home

The Browser by Google

Features
          
icon-expand-features



Overview

Google address bar

Password check

Sync

Dark mode

Tabs

Articles for you

Extensions



Support
          





Download Chrome







      Google uses cookies to deliver its services, to personalize ads, and to analyze traffic. You can adjust your privacy controls anytime in your  Google settings or learn more.


Ok, got it




 











        The browser built by Google

Download Chrome


For Windows 10/8.1/8/7 32-bit.
For Windows 10/8.1/8/7 64-bit.
This computer will no longer receive Google Chrome updates because Windows XP and Windows Vista are no longer supported.


For Mac OS X 10.10 or later.
This computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.
This computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.


Debian/Ubuntu/Fedora/openSUSE.






Set Google Chrome as my default browser




Help make Google Chrome better by automatically sending usage statistics and crash reports to Google.
        Learn more




Help make Google Chrome better by automatically sending usage statistics and crash reports to Google.
        Learn more




Help make Google Chrome better by automatically sending usage statistics and crash reports to Google.
        Learn more




Help make Google Chrome better by automatically sending usage statistics and crash reports to Google.
        Learn more




Set Google Chrome as my default browser




Help make Google Chrome better by automatically sending usage statistics and crash reports to Google.
        Learn more




Help make Google Chrome better by automatically sending usage statistics and crash reports to Google.
        Learn more




Help make Google Chrome better by automatically sending usage statistics and crash reports to Google.
        Learn more




Help make Google Chrome better by automatically sending usage statistics and crash reports to Google.
        Learn more




Set Google Chrome as my default browser




Help make Google Chrome better by automatically sending usage statistics and crash reports to Google.
        Learn more


            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

            By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service


 














Built by google
Browse with the power of Google
With Google apps like Gmail, Google Pay, and Google Assistant, Chrome can help you stay productive and get more out of your browser.
Explore Google tools
          











Safety by design
Take control of your online safety
Chrome works hard to protect your data and privacy online. With easy-to-use privacy controls, Chrome lets you customize your settings and browsing experience to how you see fit.
Explore safety
          











Helpful features built-in
Fast, easy-to-use tools for browsing
From password check, dark mode, and the Google address bar, Chrome helps you get things done and stay safe online.
Explore features
          











More from chrome
Discover more tools and resources










For enterprises
Keep people and data secure with seamless updates and intuitive policy enforcement.


Go to Chrome Enterprise
          











For developers
Develop websites for the next version of the open web with Chrome for developers.


Go to Chrome Dev
          











For early adopters
Preview upcoming Chrome features before they are released with Chrome Beta.


Go to Chrome Beta
          











For explorers
Get on the bleeding edge of the web and get nightly updates with Chrome Canary.


Go to Chrome Canary
          
















Prev




Next













            Get the Browser by Google

Download Chrome now
          



















 Follow us




Youtube






Twitter






Facebook










              Chrome Family





Other Platforms

Chromebooks
          



Chromecast
          



Chrome Cleanup Tool
          






              Enterprise





Download Chrome Browser
          



Chrome Browser for Enterprise
          



Chrome Devices
          



Chrome OS
          



Google Cloud
          



G Suite
          






              Education





Google Chrome Browser
          



Devices
          



Web Store
          






              Dev and Partners





Chromium
          



Chrome OS
          



Chrome Web Store
          



Chrome Experiments
          



Chrome Beta

Chrome Dev

Chrome Canary




              Stay Connected





Google Chrome Blog
          



Update Chrome

Chrome Help
          










Google






Privacy and Terms

About Google

Google Products






Help


Help

Change language or region


Bahasa Melayu - Malaysia

CatalÃ  - Espanya

Dansk - Danmark

Deutsch - Deutschland

Eesti - Eesti

English - Australia

English - Canada

English - United Kingdom

English - Hong Kong SAR China

English - Ireland

English - India

English - Philippines

English - Pakistan

English - Singapore

English - United States

EspaÃ±ol - LatinoamÃ©rica

EspaÃ±ol - EspaÃ±a

Filipino - Pilipinas

FranÃ§ais - France

Hrvatski - Hrvatska

Indonesia - Indonesia

Italiano - Italia

LatvieÅ¡u - Latvija

LietuviÅ³ - Lietuva

Magyar - MagyarorszÃ¡g

Nederlands - Nederland

Norsk BokmÃ¥l - Norge

Polski - Polska

PortuguÃªs - Portugal

PortuguÃªs - Brasil

RomÃ¢nÄ - RomÃ¢nia

SlovenÄina - Slovensko

SlovenÅ¡Äina - Slovenija

Suomi - Suomi

Svenska - Sverige

Tiáº¿ng Viá»t - Viá»t Nam

TÃ¼rkÃ§e - TÃ¼rkiye

ÄeÅ¡tina - Äesko

ÎÎ»Î»Î·Î½Î¹ÎºÎ¬ - ÎÎ»Î»Î¬Î´Î±

ÐÑÐ»Ð³Ð°ÑÑÐºÐ¸ - ÐÑÐ»Ð³Ð°ÑÐ¸Ñ

Ð ÑÑÑÐºÐ¸Ð¹ - Ð Ð¾ÑÑÐ¸Ñ

Ð¡ÑÐ¿ÑÐºÐ¸ - Ð¡ÑÐ±Ð¸ÑÐ°

Ð£ÐºÑÐ°ÑÐ½ÑÑÐºÐ° - Ð£ÐºÑÐ°ÑÐ½Ð°

×¢××¨××ª

Ø§ÙØ¹Ø±Ø¨ÙØ© - Ø§ÙÙÙÙÙØ© Ø§ÙØ¹Ø±Ø¨ÙØ© Ø§ÙØ³Ø¹ÙØ¯ÙØ©

ÙØ§Ø±Ø³Û

à¤¹à¤¿à¤¨à¥à¤¦à¥ - à¤­à¤¾à¤°à¤¤

à¹à¸à¸¢ - à¹à¸à¸¢

ä¸­æ - ä¸­å½

ä¸­æ - ä¸­å½é¦æ¸¯ç¹å«è¡æ¿åº

ä¸­æ - å°ç£

æ¥æ¬èª - æ¥æ¬

íêµ­ì´ - ëíë¯¼êµ­








Close


Download Chrome for Windows
For Windows 10/8.1/8/7 32-bit.
For Windows 10/8.1/8/7 64-bit.
This computer will no longer receive Google Chrome updates because Windows XP and Windows Vista are no longer supported.


Download Chrome for Mac
For Mac OS X 10.10 or later.
This computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.
This computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.


Download Chrome for Linux
Debian/Ubuntu/Fedora/openSUSE.
Please select your download package:



64 bit .deb (For Debian/Ubuntu)


64 bit .rpm (For Fedora/openSUSE)
Not Debian/Ubuntu or Fedora/openSUSE? There may be a community-supported version for your distribution here.


Download Chrome for iOS


By downloading Chrome, you agree to the Google Terms of Service  and Chrome and Chrome OS Additional Terms of Service

Note: Installing Google Chrome will add the Google repository so your system will automatically keep Google Chrome up to date. If you donât want Google's repository, do âsudo touch /etc/default/google-chromeâ before installing the package.




Set Google Chrome as my default browser



Help make Google Chrome better by automatically sending usage statistics and crash reports to Google.
        Learn more



Accept and Install





Download Chrome

Download for Windows
For Windows 10/8.1/8/7 32-bit

For Windows 10/8.1/8/7 64-bit

This computer will no longer receive Google Chrome updates because Windows XP and Windows Vista are no longer supported.



Download for Mac
Mac OS X 10.10 or later

This computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.


This computer will no longer receive Google Chrome updates because Mac OS X 10.6 - 10.9 are no longer supported.



Download for Linux
Debian/Ubuntu/Fedora/openSUSE



Download for phone or tablet


Android

iOS

Download for another desktop OS


Windows 10/8.1/8/7 64-bit

Windows 10/8.1/8/7 32-bit

Mac OS X 10.10 or later

Linux

Frozen versions


Windows XP

Windows Vista

Mac 10.6 - 10.8

Mac 10.9





Looks like youâre already using Chrome browser. Nice!


The device you have runs on Chrome OS, which already has Chrome browser built-in. No need to manually install or update it â with automatic updates, youâll always get the latest version. Learn more about automatic updates.
Looking for Chrome for a different operating system?
See the full list of supported operating systems.






















































































































































































































































































",,"# google-chrome

> The web browser from Google.
> More information: <https://chrome.google.com>.

- Run with a custom profile directory:

`google-chrome --user-data-dir={{path/to/directory}}`

- Run without CORS validation, useful to test an API:

`google-chrome --user-data-dir={{path/to/directory}} --disable-web-security`
"
rofi,https://github.com/davatorium/rofi,"













GitHub - davatorium/rofi: Rofi: A window switcher, application launcher and dmenu replacement








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















davatorium

/

rofi







    Watch
 
      95
    




      Star


      6.4k
    




          Fork


        338
      





        Rofi: A window switcher, application launcher and dmenu replacement
      



            View license
        




6.4k
        stars
 

338
        forks
 




      Star





    Watch









Code

 



Issues
64
 



Pull requests
14
 



Actions

 



Projects
2
 



Wiki

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Wiki
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










next














30
branches



30
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




DaveDavenport

Add list with packaged version (thx @zero77)



…



58a51f7

Sep 21, 2020





Add list with packaged version (thx @zero77)

Fixes: #1197

58a51f7



Git stats





3,240
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.github



Update bug_report.md



Sep 1, 2020







Examples



[Script] Add 'info' row option, that gets passed to ROFI_INFO environ…



May 24, 2020







config



Run indenter.



Aug 28, 2020







data



Add png version of logo.



Oct 31, 2016







doc



[Man] update-rofi-sensible-terminal.1 manpage



Sep 19, 2020







include



[Calc] Add min/max operator support to calc()



Sep 14, 2020







lexer



[Calc] Add min/max operator support to calc()



Sep 14, 2020







m4



Add lex version check.



Apr 4, 2017







pkgconfig



Make -plugin-path commandline flag be read before loading plugins



Oct 16, 2017







releasenotes



Fix release note error of supported prefix



Sep 11, 2020







resources



First testing to use GResource to load default theme.



Oct 31, 2017







script



[ThemeSelector] Use rasi config file format, not xresources.



Jun 17, 2020







source



[HELP] Fix typo in help msgs (#1198)



Sep 17, 2020







subprojects



[meson] Test possible 'workaround' for meson 0.55 issue



Aug 1, 2020







test



[Test] fix theme parser test for latest change in grammar parser



Sep 13, 2020







themes



Remove unneeded '# from shipped themes.



Aug 29, 2020







.gitignore



Add support for additional field on script entries `meta` (#1052)



Feb 1, 2020







.gitlab-ci.yml



Add texinfo.



Sep 24, 2017







.gitmodules



changed ligbwater's url from git to https



Dec 4, 2017







.travis.yml



[Travis] Add coverage for meson build



May 14, 2020







AUTHORS



Update authors list.



Sep 26, 2017







CODE_OF_CONDUCT.md



Create CODE_OF_CONDUCT.md (#608)



Jun 17, 2017







COPYING



Update copyright dates.



Jan 1, 2020







Changelog



Update Changelog



Sep 6, 2020







INSTALL.md



Remove xenial warning from INSTALL.md



Sep 13, 2020







Makefile.am



[Man] update-rofi-sensible-terminal.1 manpage



Sep 19, 2020







README.md



Add list with packaged version (thx @zero77)



Sep 21, 2020







configure.ac



Update version in configure.ac to 1.6.0-dev



Sep 6, 2020







libgwater-xcb-nolibtool.mk



gitmodules: Move to subprojects/



May 4, 2017







meson.build



[Man] update-rofi-sensible-terminal.1 manpage



Sep 19, 2020







meson_options.txt



[Timings] Move into new debug system. (#961)



May 11, 2019





        View code
      






        README.md
      












A window switcher, Application launcher and dmenu replacement
Rofi started as a clone of simpleswitcher, written by Sean Pringle - a
popup window switcher roughly based on superswitcher.
Simpleswitcher laid the foundations, and therefore Sean Pringle deserves most of the credit for this tool. Rofi
(renamed, as it lost the simple property) has been extended with extra features, like an application launcher and
ssh-launcher, and can act as a drop-in dmenu replacement, making it a very versatile tool.
Rofi, like dmenu, will provide the user with a textual list of options where one or more can be selected.
This can either be running an application, selecting a window, or options provided by an external script.
Its main features are:

Fully configurable keyboard navigation
Type to filter

Tokenized: type any word in any order to filter
Case insensitive (togglable)
Support for fuzzy-, regex-, and glob matching


UTF-8 enabled

UTF-8-aware string collating
International keyboard support (`e -> è)


RTL language support
Cairo drawing and Pango font rendering
Built-in modes:

Window switcher mode

EWMH compatible WM


Application launcher
Desktop file application launcher
SSH launcher mode
Combi mode, allowing several modes to be merged into one list


History-based ordering — last 25 choices are ordered on top based on use (optional)
Levenshtein distance ordering of matches (optional)
Drop-in dmenu replacement

Many added improvements


Easily extensible using scripts
Theming

Rofi has several built-in modes implementing common use cases and can be extended by scripts (either called from
Rofi or calling Rofi).
Below is a list of the different modes:
Window Switcher

The window switcher shows the following informations in columns (can be customized):

Desktop name
Window class
Window title

Window mode features:

Closing applications with Shift-Delete
Custom command with Shift-Return

Application launcher

The run mode allows users to quickly search for and launch a program.
Run mode features:

Shift-Return to run the selected program in a terminal
Favorites list, with frequently used programs sorted on top
Custom entries, like aliases, added by executing a command

Desktop File Application launcher
The desktop run mode allows users to quickly search and launch an application from the freedesktop.org Desktop
Entries. These are used by most Desktop Environments to populate launchers and menus.
Drun mode features:

Favorites list, with frequently used programs sorted on top
Auto starting terminal applications in a terminal

SSH launcher

Quickly ssh into remote machines. Parses ~/.ssh/config and ~/.ssh/known_hosts to find hosts.
Script mode
Loads external scripts to add modes to Rofi, for example a file-browser.
rofi  -show fb -modi fb:../Examples/rofi-file-browser.sh

COMBI mode
Combine multiple modes in one view. This is especially useful when merging the window and run mode into one view.
Allowing to quickly switch to an application, either by switching to it when it is already running or starting it.
Example to combine Desktop run and the window switcher:
rofi -combi-modi window,drun -show combi -modi combi

dmenu replacement

Drop in dmenu replacement. (Screenshot shows rofi used by
teiler ).
Rofi features several improvements over dmenu to improve usability. There is the option to add
an extra message bar (-mesg), pre-entering of text (-filter), or selecting entries based on a
pattern (-select). Also highlighting (-u and -a) options and modi to force user to select one
provided option (-only-match). In addition to this, rofi's dmenu mode can select multiple lines and
write them to stdout.
Usage
If used with -show [mode], rofi will immediately open in the specified [mode].
If used with -dmenu, rofi will use data from STDIN to let the user select an option.
For example, to show a run dialog:
rofi -show run
To show a ssh dialog:
rofi -show ssh
dmenu
If rofi is passed the -dmenu option, or run as dmenu (ie, /usr/bin/dmenu is symlinked to /usr/bin/rofi),
it will use the data passed from STDIN.
~/scripts/my_script.sh | rofi -dmenu
echo -e ""Option #1\nOption #2\nOption #3"" | rofi -dmenu

In both cases, rofi will output the user's selection to STDOUT.
Switching Between Modi
Type Shift-/Left/Right to switch between active modi.
Key bindings



Key
Action




Ctrl-v, Insert
Paste from clipboard


Ctrl-Shift-v, Shift-Insert
Paste primary selection


Ctrl-w
Clear the line


Ctrl-u
Delete till the start of line


Ctrl-a
Move to beginning of line


Ctrl-e
Move to end of line


Ctrl-f, Right
Move forward one character


Alt-f, Ctrl-Right
Move forward one word


Ctrl-b, Left
Move back one character


Alt-b, Ctrl-Left
Move back one word


Ctrl-d, Delete
Delete character


Ctrl-Alt-d
Delete word


Ctrl-h, Backspace, Shift-Backspace
Backspace (delete previous character)


Ctrl-Alt-h
Delete previous word


Ctrl-j,Ctrl-m,Enter
Accept entry


Ctrl-n,Down
Select next entry


Ctrl-p,Up
Select previous entry


Page Up
Go to the previous page


Page Down
Go to the next page


Ctrl-Page Up
Go to the previous column


Ctrl-Page Down
Go to the next column


Ctrl-Enter
Use entered text as a command (in ssh/run modi)


Shift-Enter
Launch the application in a terminal (in run mode)


Shift-Enter
Return the selected entry and move to the next item while keeping Rofi open. (in dmenu)


Shift-Right
Switch to the next modi. The list can be customized with the -modi option.


Shift-Left
Switch to the previous modi. The list can be customized with the -modi option.


Ctrl-Tab
Switch to the next modi. The list can be customized with the -modi option.


Ctrl-Shift-Tab
Switch to the previous modi. The list can be customized with the -modi option.


Ctrl-space
Set selected item as input text.


Shift-Del
Delete entry from history.


grave
Toggle case sensitivity.


Alt-grave
Toggle levenshtein sort.


Alt-Shift-S
Take a screenshot and store it in the Pictures directory.



For the full list of key bindings, see: rofi -show keys or rofi -help.
Configuration
There are currently three methods of setting configuration options:

Local configuration. Normally, depending on XDG, in ~/.config/rofi/config. This uses the Xresources format.
Xresources: A method of storing key values in the Xserver. See
here for more information.
Command line options: Arguments are passed to Rofi.

A distribution can ship defaults in /etc/rofi.conf.
The Xresources options and the command line options are aliased. To define option X set:
`rofi.X: value`

In the Xresources file. To set/override this from command line pass the same key
prefixed with '-':
`rofi -X value`

To get a list of available options formatted as Xresources entries, run:
`rofi -dump-Xresources`

or in a more readable format:
`rofi -help`

The configuration system supports the following types:

String
Integer (signed and unsigned)
Char
Boolean

The Boolean option has a non-default command line syntax, to enable option X you do:
`rofi -X`

to disable it:
`rofi -no-X`

Manpage
For more detailed information, please see the manpage, the wiki, or the forum.
Installation
Please see the installation guide for instructions on how to
install Rofi.
What is rofi not?
Rofi is not:

A preview application. In other words, it will not show a (small) preview of images, movies or other files.
A UI toolkit.
A library to be used in other applications.
An application that can support every possible use-case. It tries to be generic enough to be usable by everybody.
Specific functionality can be added using scripts.
Just a dmenu replacement. The dmenu functionality is a nice 'extra' to rofi, not its main purpose.









About

      Rofi: A window switcher, application launcher and dmenu replacement
    
Topics



  rofi


  dmenu


  dmenu-replacement


  application-launcher


  window-switcher


  c


  i3



Resources



      Readme
 
License



        View license
    







    Releases
      30





The Masked Launcher

          Latest
 
Sep 6, 2020

 

        + 29 releases







    Packages 0


        No packages published 













    Contributors 101





 



 



 



 



 



 



 



 



 



 



 



      + 90 contributors





Languages














C
87.5%





Yacc
2.8%





Lex
2.4%





Shell
2.4%





M4
1.6%





Makefile
1.4%





Other
1.9%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# rofi

> An application launcher and window switcher.
> More Information: <https://github.com/davatorium/rofi>.

- Show the list of apps:

`rofi -show drun`

- Show the list of all commands:

`rofi -show run`

- Switch between windows:

`rofi -show window`

- Pipe a list of items to stdin and print the selected item to stdout:

`printf ""{{Choice1\nChoice2\nChoice3}}"" | rofi -dmenu`
"
firejail,,,,"# firejail

> Securely sandboxes processes to containers using built-in Linux capabilities.

- Integrate firejail with your desktop environment:

`sudo firecfg`

- Open a restricted Mozilla Firefox:

`firejail {{firefox}}`

- Start a restricted Apache server on a known interface and address:

`firejail --net={{eth0}} --ip={{192.168.1.244}} {{/etc/init.d/apache2}} {{start}}`

- List running sandboxes:

`firejail --list`

- List network activity from running sandboxes:

`firejail --netstats`

- Shutdown a running sandbox:

`firejail --shutdown={{7777}}`
"
bitwise,https://github.com/mellowcandle/bitwise,"













GitHub - mellowcandle/bitwise: Terminal based bit manipulator in ncurses








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















mellowcandle

/

bitwise







    Watch
 
      9
    




      Star


      352
    




          Fork


        17
      





        Terminal based bit manipulator in ncurses
      



            GPL-3.0 License
        




352
        stars
 

17
        forks
 




      Star





    Watch









Code

 



Issues
6
 



Pull requests
0
 



Actions

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














6
branches



14
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit



 
 
Git stats





232
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.github/ISSUE_TEMPLATE


 


 







debian


 


 







inc


 


 







m4


 


 







resources


 


 







src


 


 







tests


 


 







.editorconfig


 


 







.gitignore


 


 







.travis.yml


 


 







AUTHORS


 


 







COPYING


 


 







ChangeLog


 


 







LICENSE


 


 







Makefile.am


 


 







NEWS


 


 







README


 


 







README.md


 


 







bitwise.1


 


 







bootstrap.sh


 


 







configure.ac


 


 







snapcraft.yaml


 


 







ubuntu_release.sh


 


 





        View code
      







        README.md
      


Bitwise
Terminal based bitwise calculator in curses






Bitwise is multi base interactive calculator supporting dynamic base conversion and bit manipulation.
It's a handy tool for low level hackers, kernel developers and device drivers developers.
Some of the features include:

Interactive ncurses interface
Command line calculator supporting all bitwise operations.
Individual bit manipulator.
Bitwise operations such as NOT, OR, AND, XOR, and shifts.



Usage
bitwise can be used both Interactively and in command line mode.
Command line calculator mode
In command line mode, bitwise will calculate the given expression and will output the result in all bases including binary representation.
bitwise detects the base by the preface of the input (0x/0X for hexadecimal, leading 0 for octal, b for binary, and the rest is decimal).
Examples:
Simple base conversion

C style syntax Calculator

Interactive mode
bitwise starts in interactive mode if no command line parameters are passed or if the -i | --interactive flag is passed.
In this mode, you can input a number and manipulate it and see the other bases change dynamically.
It also allows changing individual bits in the binary.
You can show the help screen by pressing  F1 .
Navigation in interactive mode
To move around use the arrow keys, or use vi key bindings :  h   j   k   l .
Leave the program by pressing  q .
Binary specific movement
You can toggle a bit bit using the  space  key.
You can jump a byte forward using  w  and backwards one byte using  b .
Bitwise operation in interactive mode
Setting the bit width:
Reducing or extending the bit width interactively is also very easy, just use:
 !  for 8bit,  @   for 16Bit,  $  for 32Bit and  *  for 64Bit.
When changing the bit width, the number is masked with the new width, so you might lost precision, use with care.
NOT:
Press  ~  to perform the NOT operator.
Shifts
Press  <  and  >  to perform the left or right shift.
expression calculator in interactive mode
You can enter expression calculator mode by typing  :  (Just like in vim).
To exit the mode, just press  ESC .
In this mode, you can type any expression you like to be evaluated.
The result will be printed in the history window and also printed in the binary and various bases on top.
operators and functions

All C operators are supported, additionally, you can use the ""$"" symbol to refer to the last result.
Refer to a specific bit by using the function BIT(x).

commands

help - Show the help screen.
clear - Clear the history window.
width [8 | 16 | 32 | 64] - Set the required width mask
output [decimal | hex | octal | binary | all] - Set the default output for results.
q - Exit

Integration with other software
Vim

vim-bitwise

Installation
Linux
Ubuntu
sudo add-apt-repository ppa:ramon-fried/bitwise
sudo apt-get update
sudo apt-get install bitwise

Snap
If your distribution supports Snap just type:
sudo snap install bitwise
Arch
You can use the AUR repository: https://aur.archlinux.org/packages/bitwise/
macOS
MacPorts
sudo port install bitwise

Homebrew
brew install bitwise

Windows
NCurses doesn't support windows. You can use the windows subsystem for Linux as a workaround.
Building from source
Prerequisites

libreadline
libncurses (with forms)
libcunit (only needed for testing)

On Ubuntu/Debian system you can just paste:
sudo apt-get install build-essential
sudo apt-get install libncurses5-dev
sudo apt-get install libreadline-dev
sudo apt-get install libcunit1-dev

On Mac systems:
brew install automake
brew install autoconf
brew install readline
export LDFLAGS=""-L/usr/local/opt/readline/lib""
export CPPFLAGS=""-I/usr/local/opt/readline/include""


Download the latest release

tar xfz RELEASE-FILE.TAR.GZ
cd RELEASE-DIR
./configure
make
sudo make install
Running unit tests by typing
make check
Contribution

Instal prerequisites
Fork the repo
Run ./bootstrap.sh
Follow the building from source section.
commit and send pull request









About

      Terminal based bit manipulator in ncurses
    
Topics



  curses


  c


  bitwise


  bitwise-operation


  linux


  terminal-app



Resources



      Readme
 
License



        GPL-3.0 License
    







    Releases
      14





v0.41

          Latest
 
Dec 18, 2019

 

        + 13 releases







    Packages 0


        No packages published 













    Contributors 10







































Languages










C
54.6%





M4
42.6%





Other
2.8%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# bitwise

> Multi base interactive calculator supporting dynamic base conversion and bit manipulation.
> More information: <https://github.com/mellowcandle/bitwise>.

- Run using interactive mode:

`bitwise`

- Convert from decimal:

`bitwise {{12345}}`

- Convert from hexadecimal:

`bitwise {{0x563d}}`

- Convert a C-style calculation:

`bitwise  {{""0x123 + 0x20 - 30 / 50""}}`
"
rdesktop,,,,"# rdesktop

> Remote Desktop Protocol client.
> It can be used to connect the remote computer using the RDP protocol.

- Connect to a remote computer (default port is 3389):

`rdesktop -u {{username}} -p {{password}} {{host:port}}`

- Simple Examples:

`rdesktop -u Administrator -p passwd123 192.168.1.111:3389`

- Connect to a remote computer with full screen (press `Ctrl + Alt + Enter` to exist):

`rdesktop -u {{username}} -p {{password}} -f {{host:port}}`

- Use the customed resolution (use the letter 'x' between the number):

`rdesktop -u {{username}} -p {{password}} -g 1366x768 {{host:port}}`

- Connect to a remote computer using domain user:

`rdesktop -u {{username}} -p {{password}} -d {{domainname}} {{host:port}}`

- Use the 16 bit color (speed up):

`rdesktop -u {{username}} -p {{password}} -a 16 {{host:port}}`
"
updatedb,,,,"# updatedb

> Create or update the database used by `locate`.
> It is usually run daily by cron.

- Refresh database content:

`sudo updatedb`

- Display file names as soon as they are found:

`sudo updatedb --verbose`
"
silentcast,https://github.com/colinkeenan/silentcast,"













GitHub - colinkeenan/silentcast: Create silent mkv screencast and animated gif.








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















colinkeenan

/

silentcast







    Watch
 
      16
    




      Star


      488
    




          Fork


        20
      





        Create silent mkv screencast and animated gif.
      



            GPL-3.0 License
        




488
        stars
 

20
        forks
 




      Star





    Watch









Code

 



Issues
12
 



Pull requests
0
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














2
branches



23
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit



 
 
Git stats





300
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






lib



git add . and figured out how to move on to next temptoanim function …



Apr 13, 2017







scpkg



more reorganizing files and wrote install and uninstall scripts along…



Apr 16, 2017







src



previous ""more sensible"" algorithm failed due to poor precision so fi…



Oct 28, 2017







.gitignore



more reorganizing files and wrote install and uninstall scripts along…



Apr 16, 2017







COPYING



git add . and figured out how to move on to next temptoanim function …



Apr 13, 2017







README.md



KDE Plasma 5 workaround explained in README.md



Sep 1, 2017







Silencast_v3.02_Screenshot.png



forgot to add screenshot png



Apr 17, 2017







install



removed bashisms from install and uninstall scripts



Apr 17, 2017







makefile



more reorganizing files and wrote install and uninstall scripts along…



Apr 16, 2017







silentcast.svg



more reorganizing files and wrote install and uninstall scripts along…



Apr 16, 2017







tags



more reorganizing files and wrote install and uninstall scripts along…



Apr 16, 2017







uninstall



removed bashisms from install and uninstall scripts



Apr 17, 2017





        View code
      






        README.md
      


Silentcast
This is not a full README (yet) for v3.0 which has a completely different GUI than previous versions.
It's more intuitive than previous versions and explains itself well enough.
It does not support running multiple copies of itself, however, and so cannot record itself the way that
the previous version did: bad things will happen if you try to run Silentcast v3.0 while it is already running.
If you make the mistake of trying to run Silentcast v3.0 while it is already running, make sure you run
pkill -f ffmpeg

when it closes (crashes) so that silentcast/temp.mkv. doesn't take over your hard drive. Due to a bug that
shows on some systems where silencast is unable to kill the ffmpeg process it spawned directly, v3.02 is currently
also killing all instances of ffmpeg so that it's not possible to get a full recording of silentcast in action
using ffmpeg either.
This problem will be fixed in a future release, but other bugs will probably be fixed first because not many
people need to record Silentcast in action.
When ran, you will instantly get a green rectangle surrounding the active window. If that's what you wanted to
record, just press Return to start and then click the minimized Silentcast icon to stop. Here is a screenshot
showing the F1->Rectangle Preferences dialog and green rectangle.

Dependencies

gtk3
ffmpeg
imagemagick

Tiling Window Managers
Starting with v3.05, it is possible to use Silentcast in Tiling Window Managers that can't iconify a window and don't show any windows behind a maximaized window. To make it work, you will have to define 3 new keybindings. The first will make Silentcast a floating window that fills the display. The second will ""iconify"" Silentcast by putting it on an empty workspace (named Silentcast if possible) and putting it back to fullscreen instead of floating (this will trigger Silentcast to begin recording). The third will ""deiconify"" Silentcast by putting back on the original workspace as a floating window that fills the display. This has only been tested in i3wm. I will provide keybindings for other tiling window managers if an issue is opened for it. The following keybindings should be added to ~/.config/i3/config:
# Silentcast Workaround (because i3wm can't iconify)
#
# After copy and pasting this, make sure to change the display size at the end
# of the first definition ($enable_floating_fullscreen) to match your display size
#
# Use these keybindings as follows:
#   1. Start Silentcast
#   2. $mod+Shift+s to make Silentcast a floating window filling the display 
#      (which allows other windows to be seen below it)
#   3. Select the region to be recorded using standard Silentcast controls
#   4. $mod+z to ""iconify"" silentcast to start recording (actually putting it on a
#      workspace named Silencast and making it fullscreen again instead of floating)
#   5. When done recording, $mod+x to ""deiconify"" Silentcast which will stop
#      recording and move on to the next step as usual.
#   

# define what fullscreen means for floating window - have to manually set the display size
set $enable_floating_fullscreen  border none,fullscreen disable,floating enable,move absolute position 0 0,resize set 1920 1080

# more definitions (i3wm doesn't seem to support using $variables in definitions of other $variables)
set $work_in_temp move container to workspace Silentcast,workspace Silentcast

set $return_from_temp move container to workspace back_and_forth,workspace back_and_forth

set $iconify move container to workspace Silentcast,workspace Silentcast,floating disable,fullscreen enable,workspace back_and_forth

set $deiconify workspace Silentcast,border none,fullscreen disable,floating enable,move absolute position 0 0,resize set 1920 1080,move container to workspace back_and_forth,workspace back_and_forth

# change from fullscreen to floating_fullscreen because iw3m won't show other windows under it otherwise
bindsym $mod+Shift+s [class=""Silentcast""] $work_in_temp,$enable_floating_fullscreen,$return_from_temp

# ""iconify""
bindsym $mod+z [class=""Silentcast""] $iconify

# ""deiconify"" to stop ffmpeg and continue
bindsym $mod+x [class=""Silentcast""] $deiconify

#
# End of Silentcast Workaround
#

KDE Plasma 5 - How to stop recording using the keyboard
Plasma 5 previews minimized windows when the mouse is over the icon which is a problem when you're trying to stop a Silentcast recording. To stop Silentcast in Plasma 5 without having to click the minimized icon, define the following keyboard shortcut: System Settings -> (Workspace) Shortcuts -> Global Shortcuts -> KWin -> Setup Window Shortcut -> Global -> Custom and put whatever keys are available for that. I set it to Meta+Space.
For example, if Setup Window Shortcut is set to Meta+Space, and you want to stop the recording with Alt+A, then here are the steps to stopping a Silentcast recording without using the mouse:

Start Silentcast
Meta+Space
Click in the ""Press shortcut"" field in the dialog that pops up in the top left corner
Alt+A
Click on the ""OK"" button in that dialog
Select the area to be recorded and press Return on your keyboard to start the recording
Alt+A to stop the recording
Ctrl+Alt+A to Activate Window Demanding Attention (which is the Silentcast Edit Pngs dialog at this point)
. . .

Something similar can probably be done on other desktops. I will look into it if an issue is raised.
Manual Installation

Install the dependencies, Download Latest Release of Silentcast from github.com, and extract. If extracted in your Downloads directory, this is how you would complete the installation:

$ cd ~/Downloads/silentcast-3.0
$ make
$ sudo ./install

You should then find silentcast in your launcher. You can uninstall it with sudo ./uninstall in the same directory.
You can also test what these scripts do passing a destination directory (that doesn't need to exist already).
For example, install to test, use tree to see what it did, and then uninstall from test. (You will probably need to install tree.)
$ ./install test
$ tree test
test
├── etc
│   ├── silentcast.conf
│   └── silentcast_presets
└── usr
    ├── bin
    │   └── silentcast
    └── share
        ├── applications
        │   └── silentcast.desktop
        ├── doc
        │   └── silentcast
        │       └── README.md
        ├── icons
        │   └── hicolor
        │       ├── 128x128
        │       │   └── apps
        │       │       └── silentcast.png
        │       ├── 24x24
        │       │   └── apps
        │       │       └── silentcast.png
        │       ├── 256x256
        │       │   └── apps
        │       │       └── silentcast.png
        │       ├── 32x32
        │       │   └── apps
        │       │       └── silentcast.png
        │       ├── 48x48
        │       │   └── apps
        │       │       └── silentcast.png
        │       └── 64x64
        │           └── apps
        │               └── silentcast.png
        └── licenses
            └── COPYING

22 directories, 12 files
$./uinstall test
$tree test
test
├── etc
└── usr
    ├── bin
    └── share
        ├── applications
        ├── doc
        ├── icons
        │   └── hicolor
        │       ├── 128x128
        │       │   └── apps
        │       ├── 24x24
        │       │   └── apps
        │       ├── 256x256
        │       │   └── apps
        │       ├── 32x32
        │       │   └── apps
        │       ├── 48x48
        │       │   └── apps
        │       └── 64x64
        │           └── apps
        └── licenses

21 directories, 0 files

Notice that ./uninstall test deleted all the files, but only deleted the one subdirectory named silentcast. Don't forget to specify test when uninstalling, and don't use sudo when not doing a system-wide install or uninstall.








About

      Create silent mkv screencast and animated gif.
    
Resources



      Readme
 
License



        GPL-3.0 License
    







    Releases
      23





v3.07 bug fixes

          Latest
 
Oct 27, 2017

 

        + 22 releases







    Packages 0


        No packages published 













    Contributors 8

































Languages










C
97.6%





Shell
1.9%





Makefile
0.5%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# silentcast

> Silent screencast creator. Saves in `.mkv` and animated gif formats.
> More information: <https://github.com/colinkeenan/silentcast>.

- Launch silentcast:

`silentcast`

- Launch silentcast on a specific display:

`silentcast --display={{display}}`
"
autorandr,,,,"# autorandr

> Automatically change screen layout.

- Save the current screen layout:

`autorandr -s {{profile_name}}`

- Show the saved profiles:

`autorandr`

- Change the profile:

`autorandr -l {{profile_name}}`

- Set the default profile:

`autorandr -d {{profile_name}}`
"
paccache,,,,"# paccache

> A pacman cache cleaning utility.

- Remove all but the 3 most recent package versions from the pacman cache:

`paccache -r`

- Set the number of package versions to keep:

`paccache -rk {{num_versions}}`

- Perform a dry-run and show the number of candidate packages for deletion:

`paccache -d`

- Move candidate packages to a directory instead of deleting them:

`paccache -m {{path/to/directory}}`
"
steghide,https://github.com/StefanoDeVuono/steghide,"













GitHub - StefanoDeVuono/steghide








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















StefanoDeVuono

/

steghide







    Watch
 
      7
    




      Star


      159
    




          Fork


        30
      







            GPL-2.0 License
        




159
        stars
 

30
        forks
 




      Star





    Watch









Code

 



Issues
4
 



Pull requests
1
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



0
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




StefanoDeVuono

first commit



…



8df774d

Oct 25, 2013





first commit


8df774d



Git stats





1
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






doc


 


 







intl


 


 







m4


 


 







po


 


 







src


 


 







tests


 


 







.gitignore


 


 







ABOUT-NLS


 


 







BUGS


 


 







COPYING


 


 







CREDITS


 


 







HISTORY


 


 







INSTALL


 


 







LEAME


 


 







Makefile.am


 


 







Makefile.in


 


 







README


 


 







TODO


 


 







aclocal.m4


 


 







config.guess


 


 







config.h.in


 


 







config.rpath


 


 







config.sub


 


 







configure


 


 







configure.in


 


 







depcomp


 


 







install-sh


 


 







missing


 


 







mkinstalldirs


 


 







steghide.doxygen.in


 


 







steghide.spec.in


 


 





        View code
      







        README
      


Introduction :
==============

Steghide is a steganography program that is able to hide data in various kinds
of image- and audio-files. The color- respectivly sample-frequencies are not
changed thus making the embedding resistant against first-order statistical
tests.

The current version of steghide is 0.5.1

Features:
*) compression of embedded data
*) encryption of embedded data
*) embedding of a checksum to verify the integrity of the extraced data
*) support for JPEG, BMP, WAV and AU files

Steganography :
===============

Steganography literally means covered writing. Its goal is to hide the fact
that communication is taking place. This is often achieved by using a (rather
large) cover file and embedding the (rather short) secret message into this
file. The result is a innocuous looking file (the stego file) that contains
the secret message.

Compilation and Installation :
==============================

Dependencies :
--------------
You should have the following libraries installed to use steghide.

* libmhash
  A library that provides various hash algorithms and cryptographic key
  generation algorithms. Steghide needs this library to convert a passphrase
  into a form that can be used as input for cryptographic and steganographic
  algorithms.
  Available at: http://mhash.sourceforge.net/

* libmcrypt  
  A library that provides a lot of symmetric encryption algorithms. If you
  compile steghide without libmcrypt you will not be able to use steghide to
  encrypt data before embedding nor to extract encrypted data (even if you know
  the correct passphrase).
  Available at: http://mcrypt.sourceforge.net/

* libjpeg
  A library implementing jpeg image compression. Without this library you will
  not be able to embed data in jpeg files nor to extract data from jpeg files.
  Available at: http://www.ijg.org/

* zlib
  A lossless data compression library. If you compile steghide without having
  this library installed you will not be able to use steghide to compress data
  before embedding nor to extract compressed data from a stego-file.
  Available at: http://www.gzip.org/zlib/

Libmhash is absolutely required to compile steghide. While you can compile it
without the other libraries they are highly recommended as major functionality
will not be available without them.

Linux / Unix :
--------------
After unpacking the source distribution, enter the following commands:

1) ./configure 
2) make
3) make check
4) make install (as root)

For more information see the generic installation instructions in the file
INSTALL that came with the distribution.

If any of these commands fails, please send a mail to the steghide development
mailing list (steghide-devel@lists.sourceforge.net) describing the error.
 
Windows :
---------
The easiest way is to download the precompiled binary (including Windows
versions of the necessary libraries) from the steghide website at:
http://steghide.sourceforge.net/index.php

If you want to compile the sources yourself you need a C++ compiler. How you
need to compile the source code depends on the compiler you are using: Please
consult your compiler's documentation.

Steghide can be compiled with gcc in the cygwin environment
(http://www.cygwin.com/) which is a unix emulation layer for Windows using the
procedure mentioned above for the Linux/Unix compilation.

Quick-Start :
=============

Here are some examples of how steghide can be used. Take a look at these to get
a first impression. If you want more detailed information please read the
manpage.

The basic usage is as follows:

  $ steghide embed -cf picture.jpg -ef secret.txt
  Enter passphrase:
  Re-Enter passphrase:
  embedding ""secret.txt"" in ""picture.jpg""... done

This command will embed the file secret.txt in the cover file picture.jpg.

After you have embedded your secret data as shown above you can send the file
picture.jpg to the person who should receive the secret message. The receiver
has to use steghide in the following way:

  $ steghide extract -sf picture.jpg
  Enter passphrase:
  wrote extracted data to ""secret.txt"".

If the supplied passphrase is correct, the contents of the original file
secret.txt will be extracted from the stego file picture.jpg and saved
in the current directory.

If you have received a file that contains embedded data and you want to get
some information about it before extracting it, use the info command:

  $ steghide info received_file.wav
  ""received_file.wav"":
    format: wave audio, PCM encoding
    capacity: 3.5 KB
  Try to get information about embedded data ? (y/n) y
  Enter passphrase:
    embedded file ""secret.txt"":
      size: 1.6 KB
      encrypted: rijndael-128, cbc
      compressed: yes

After printing some general information about the stego file (format, capacity) you will be
asked if steghide should try to get information about the embedded data. If you answer with
yes you have to supply a passphrase. Steghide will then try to extract the embedded data
with that passphrase and - if it succeeds - print some information about it.

Contact :
=========

Website :
---------
You can get the latest version of steghide as well as some additional
information and documentation from the steghide website at:
http://steghide.sourceforge.net/

Mailing Lists :
---------------
If you have found a bug or if you have questions, comments, suggestions, etc.
please send a mail to the development mailing list:
steghide-devel@lists.sourceforge.net
To receive mails sent to this list, subscribe to it at:
http://lists.sourceforge.net/lists/listinfo/steghide-devel

If you want to be informed, when a new version of steghide is released please
subscribe to the steghide announcement mailing list at:
http://lists.sourceforge.net/lists/listinfo/steghide-announce

Anonymous CVS access :
----------------------

You can access the most recent development source code via anonymous cvs. Just
type the following lines:

$ cvs -d:pserver:anonymous@cvs.steghide.sourceforge.net:/cvsroot/steghide login
CVS password:  [ Hit RETURN here ]

$ cvs -z3 -d:pserver:anonymous@cvs.steghide.sourceforge.net:/cvsroot/steghide co steghide

You can also browse the cvs repository on the web:
http://cvs.sourceforge.net/cgi-bin/viewcvs.cgi/steghide/

Author :
--------
You can contact me (Stefan Hetzl) via e-mail: shetzl@chello.at








About

      No description, website, or topics provided.
    
Resources



      Readme
 
License



        GPL-2.0 License
    







    Releases

No releases published






    Packages 0


        No packages published 











Languages











C++
68.5%





C
27.3%





Shell
3.4%





Perl
0.8%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# steghide

> Steganography tool for JPEG, BMP, WAV and AU file formats.
> More information: <https://github.com/StefanoDeVuono/steghide>.

- Embed data in a PNG image, prompting for a passphrase:

`steghide embed --coverfile {{path/to/image.png}} --embedfile {{path/to/data.txt}}`

- Extract data from a WAV audio file:

`steghide extract --stegofile {{path/to/sound.wav}}`

- Display file information, trying to detect an embedded file:

`steghide info {{path/to/file.jpg}}`

- Embed data in a JPEG image, using maximum compression:

`steghide embed --coverfile {{path/to/image.jpg}} --embedfile {{path/to/data.txt}} --compress {{9}}`

- Get the list of supported encryption algorithms and modes:

`steghide encinfo`

- Embed encrypted data in a JPEG image, e.g. with Blowfish in CBC mode:

`steghide embed --coverfile {{path/to/image.jpg}} --embedfile {{path/to/data.txt}} --encryption {{blowfish|...}} {{cbc|...}}`
"
light,,,,"# light

> CLI to control the backlight of your screen.

- Get the current backlight value in percent:

`light`

- Set the backlight value to 50 percent:

`light -S {{50}}`

- Reduce 20 percent from the current backlight value:

`light -U {{20}}`

- Add 20 percent to the current backlight value:

`light -A {{20}}`
"
fc,,,"
BUILTIN(1)		  BSD General Commands Manual		    BUILTIN(1)

NAME
     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,
     breaksw, builtins, case, cd, chdir, command, complete, continue, default,
     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,
     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,
     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,
     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,
     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,
     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,
     telltc, test, then, time, times, trap, true, type, ulimit, umask,
     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,
     where, which, while -- shell built-in commands

SYNOPSIS
     builtin [-options] [args ...]

DESCRIPTION
     Shell builtin commands are commands that can be executed within the run-
     ning shell's process.  Note that, in the case of csh(1) builtin commands,
     the command is executed in a subshell if it occurs as any component of a
     pipeline except the last.

     If a command specified to the shell contains a slash ``/'', the shell
     will not execute a builtin command, even if the last component of the
     specified command matches the name of a builtin command.  Thus, while
     specifying ``echo'' causes a builtin command to be executed under shells
     that support the echo builtin command, specifying ``/bin/echo'' or
     ``./echo'' does not.

     While some builtin commands may exist in more than one shell, their oper-
     ation may be different under each shell which supports them.  Below is a
     table which lists shell builtin commands, the standard shells that sup-
     port them and whether they exist as standalone utilities.

     Only builtin commands for the csh(1) and sh(1) shells are listed here.
     Consult a shell's manual page for details on the operation of its builtin
     commands.	Beware that the sh(1) manual page, at least, calls some of
     these commands ``built-in commands'' and some of them ``reserved words''.
     Users of other shells may need to consult an info(1) page or other
     sources of documentation.

     Commands marked ``No**'' under External do exist externally, but are
     implemented as scripts using a builtin command of the same name.

	   Command	 External    csh(1)    sh(1)
	   !		 No	     No        Yes
	   %		 No	     Yes       No
	   .		 No	     No        Yes
	   :		 No	     Yes       Yes
	   @		 No	     Yes       Yes
	   {		 No	     No        Yes
	   }		 No	     No        Yes
	   alias	 No**	     Yes       Yes
	   alloc	 No	     Yes       No
	   bg		 No**	     Yes       Yes
	   bind 	 No	     No        Yes
	   bindkey	 No	     Yes       No
	   break	 No	     Yes       Yes
	   breaksw	 No	     Yes       No
	   builtin	 No	     No        Yes
	   builtins	 No	     Yes       No
	   case 	 No	     Yes       Yes
	   cd		 No**	     Yes       Yes
	   chdir	 No	     Yes       Yes
	   command	 No**	     No        Yes
	   complete	 No	     Yes       No
	   continue	 No	     Yes       Yes
	   default	 No	     Yes       No
	   dirs 	 No	     Yes       No
	   do		 No	     No        Yes
	   done 	 No	     No        Yes
	   echo 	 Yes	     Yes       Yes
	   echotc	 No	     Yes       No
	   elif 	 No	     No        Yes
	   else 	 No	     Yes       Yes
	   end		 No	     Yes       No
	   endif	 No	     Yes       No
	   endsw	 No	     Yes       No
	   esac 	 No	     No        Yes
	   eval 	 No	     Yes       Yes
	   exec 	 No	     Yes       Yes
	   exit 	 No	     Yes       Yes
	   export	 No	     No        Yes
	   false	 Yes	     No        Yes
	   fc		 No**	     No        Yes
	   fg		 No**	     Yes       Yes
	   filetest	 No	     Yes       No
	   fi		 No	     No        Yes
	   for		 No	     No        Yes
	   foreach	 No	     Yes       No
	   getopts	 No**	     No        Yes
	   glob 	 No	     Yes       No
	   goto 	 No	     Yes       No
	   hash 	 No	     No        Yes
	   hashstat	 No	     Yes       No
	   history	 No	     Yes       No
	   hup		 No	     Yes       No
	   if		 No	     Yes       Yes
	   jobid	 No	     No        Yes
	   jobs 	 No**	     Yes       Yes
	   kill 	 Yes	     Yes       No
	   limit	 No	     Yes       No
	   local	 No	     No        Yes
	   log		 No	     Yes       No
	   login	 Yes	     Yes       No
	   logout	 No	     Yes       No
	   ls-F 	 No	     Yes       No
	   nice 	 Yes	     Yes       No
	   nohup	 Yes	     Yes       No
	   notify	 No	     Yes       No
	   onintr	 No	     Yes       No
	   popd 	 No	     Yes       No
	   printenv	 Yes	     Yes       No
	   pushd	 No	     Yes       No
	   pwd		 Yes	     No        Yes
	   read 	 No**	     No        Yes
	   readonly	 No	     No        Yes
	   rehash	 No	     Yes       No
	   repeat	 No	     Yes       No
	   return	 No	     No        Yes
	   sched	 No	     Yes       No
	   set		 No	     Yes       Yes
	   setenv	 No	     Yes       No
	   settc	 No	     Yes       No
	   setty	 No	     Yes       No
	   setvar	 No	     No        Yes
	   shift	 No	     Yes       Yes
	   source	 No	     Yes       No
	   stop 	 No	     Yes       No
	   suspend	 No	     Yes       No
	   switch	 No	     Yes       No
	   telltc	 No	     Yes       No
	   test 	 Yes	     No        Yes
	   then 	 No	     No        Yes
	   time 	 Yes	     Yes       No
	   times	 No	     No        Yes
	   trap 	 No	     No        Yes
	   true 	 Yes	     No        Yes
	   type 	 No	     No        Yes
	   ulimit	 No	     No        Yes
	   umask	 No**	     Yes       Yes
	   unalias	 No**	     Yes       Yes
	   uncomplete	 No	     Yes       No
	   unhash	 No	     Yes       No
	   unlimit	 No	     Yes       No
	   unset	 No	     Yes       Yes
	   unsetenv	 No	     Yes       No
	   until	 No	     No        Yes
	   wait 	 No**	     Yes       Yes
	   where	 No	     Yes       No
	   which	 Yes	     Yes       No
	   while	 No	     Yes       Yes

SEE ALSO
     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),
     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)

HISTORY
     The builtin manual page first appeared in FreeBSD 3.4.

AUTHORS
     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.

BSD			       February 23, 2005			   BSD
","# fc

> Open the most recent command and edit it.

- Open in the default system editor:

`fc`

- Specify an editor to open with:

`fc -e {{'emacs'}}`

- List recent commands from history:

`fc -l`
"
nmcli-device,,,,"# nmcli device

> Hardware device management with NetworkManager.

- Print the statuses of all network interfaces:

`nmcli device status`

- Print the available Wi-Fi access points:

`nmcli device wifi`

- Connect to the Wi-Fi network with a specified name and password:

`nmcli device wifi connect {{ssid}} password {{password}}`
"
dget,https://manpages.debian.org/dget,"



dget(1) — devscripts — Debian buster — Debian Manpages
















MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / devscripts
     
     
     
     / dget(1)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


CONFIGURATION VARIABLES


EXAMPLES


BUGS AND COMPATIBILITY


AUTHOR


SEE ALSO







other versions




buster 2.19.5+deb10u1


buster-backports 2.20.4~bpo10+1


testing 2.20.4


unstable 2.20.4






other languages




Deutsch


English


français






Scroll to navigation



DGET(1)
 
DGET(1)





NAME¶
dget -- Download Debian source and binary packages


SYNOPSIS¶

dget [options] URL ...

dget [options] [--all]
    package[=version] ...




DESCRIPTION¶
dget downloads Debian packages. In the first form, dget fetches
  the requested URLs. If this is a .dsc or .changes file, then dget acts
  as a source-package aware form of wget: it also fetches any files
  referenced in the .dsc/.changes file. The downloaded source is then checked
  with dscverify and, if successful, unpacked by dpkg-source.
In the second form, dget downloads a binary package
    (i.e., a .deb file) from the Debian mirror configured in
    /etc/apt/sources.list(.d). Unlike apt-get install -d, it does not
    require root privileges, writes to the current directory, and does not
    download dependencies. If a version number is specified, this version of the
    package is requested. With --all, the list of all binaries for the
    source package package is extracted from the output of
    ""apt-cache showsrc package"".
In both cases dget is capable of getting several packages and/or
    URLs at once.
(Note that .udeb packages used by debian-installer are
    located in separate packages files from .deb packages. In order to
    use .udebs with dget, you will need to have configured
    apt to use a packages file for
    component/debian-installer).
Before downloading files listed in .dsc and .changes files, and
    before downloading binary packages, dget checks to see whether any of
    these files already exist. If they do, then their md5sums are compared to
    avoid downloading them again unnecessarily. dget also looks for
    matching files in /var/cache/apt/archives and directories given by
    the --path option or specified in the configuration files (see
    below). Finally, if downloading (.orig).tar.gz or .diff.gz files fails, dget
    consults apt-get source --print-uris. Download backends used are
    curl and wget, looked for in that order.
dget was written to make it easier to retrieve source
    packages from the web for sponsor uploads. For checking the package with
    debdiff, the last binary version is available via dget
package, the last source version via apt-get source
package.


OPTIONS¶

-a, --all
Interpret package as a source package name, and download all
      binaries as found in the output of ""apt-cache showsrc
      package"". If package is arch-qualified, then only
      binary packages which are ""Arch: all"", ""Arch: any"", or
      ""Arch: $arch"" will be downloaded.
-b, --backup
Move files that would be overwritten to ./backup.
-q, --quiet
Suppress wget/curl non-error output.
-d, --download-only
Do not run dpkg-source -x on the downloaded source package. This
      can only be used with the first method of calling dget.
-x, --extract
Run dpkg-source -x on the downloaded source package to unpack it.
      This option is the default and can only be used with the first method of
      calling dget.
-u, --allow-unauthenticated
Do not attempt to verify the integrity of downloaded source packages using
      dscverify.
--build
Run dpkg-buildpackage -b -uc on the downloaded source package.
--path DIR[:DIR ...]
In addition to /var/cache/apt/archives, dget uses the
      colon-separated list given as argument to --path to find files with
      a matching md5sum. For example: ""--path
      /srv/pbuilder/result:/home/cb/UploadQueue"". If DIR is empty (i.e.,
      ""--path ''"" is specified), then any previously listed
      directories or directories specified in the configuration files will be
      ignored. This option may be specified multiple times, and all of the
      directories listed will be searched; hence, the above example could have
      been written as: ""--path /srv/pbuilder/result --path
      /home/cb/UploadQueue"".
--insecure
Allow SSL connections to untrusted hosts.
--no-cache
Bypass server-side HTTP caches by sending a Pragma: no-cache
      header.
-h, --help
Show a help message.
-V, --version
Show version information.



CONFIGURATION VARIABLES¶
The two configuration files /etc/devscripts.conf and ~/.devscripts
  are sourced by a shell in that order to set configuration variables. Command
  line options can be used to override configuration file settings. Environment
  variable settings are ignored for this purpose. The currently recognised
  variable is:

DGET_PATH
This can be set to a colon-separated list of directories in which to
      search for files in addition to the default
      /var/cache/apt/archives. It has the same effect as the
      --path command line option. It is not set by default.
DGET_UNPACK
Set to 'no' to disable extracting downloaded source packages. Default is
      'yes'.
DGET_VERIFY
Set to 'no' to disable checking signatures of downloaded source packages.
      Default is 'yes'.



EXAMPLES¶
Download all .deb files for the previous version of a package and run
  debdiff on them:

  dget --all mypackage=1.2-1
  debdiff --from *_1.2-1_*.deb --to *_1.2-2_*.deb



BUGS AND COMPATIBILITY¶
dget package should be implemented in apt-get install -d.
Before devscripts version 2.10.17, the default was not to extract
    the downloaded source. Set DGET_UNPACK=no to revert to the old
  behaviour.


AUTHOR¶
This program is Copyright (C) 2005-2013 by Christoph Berg
  <myon@debian.org>. Modifications are Copyright (C) 2005-06 by Julian
  Gilbey <jdg@debian.org>.
This program is licensed under the terms of the GPL, either
    version 2 of the License, or (at your option) any later version.


SEE ALSO¶
apt-get(1), curl(1), debcheckout(1), debdiff(1),
  dpkg-source(1), wget(1)




2019-08-04
Debian Utilities









Source file:


dget.1.en.gz (from devscripts 2.19.5+deb10u1)




Source last updated:


2019-08-04T21:15:44Z




Converted to HTML:


2020-08-08T10:08:51Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# dget

> Download Debian packages.
> More information: <https://manpages.debian.org/dget>.

- Download a binary package:

`dget {{package_name}}`

- Download and extract a package source from its .dsc file:

`dget {{http://deb.debian.org/debian/pool/main/h/haskell-tldr/haskell-tldr_0.4.0-2.dsc}}`

- Download a package source tarball from its .dsc file but don't extract it:

`dget -d {{http://deb.debian.org/debian/pool/main/h/haskell-tldr/haskell-tldr_0.4.0-2.dsc}}`
"
rename,,,"
RENAME(2)		    BSD System Calls Manual		     RENAME(2)

NAME
     rename, renameat, renamex_np, renameatx_np -- change the name of a file

SYNOPSIS
     #include <stdio.h>

     int
     rename(const char *old, const char *new);

     int
     renameat(int fromfd, const char *from, int tofd, const char *to);

     int
     renamex_np(const char *from, const char *to, unsigned int flags);

     int
     renameatx_np(int fromfd, const char *from, int tofd, const char *to,
	 unsigned int flags);

DESCRIPTION
     The rename() system call causes the link named old to be renamed as new.
     If new exists, it is first removed.  Both old and new must be of the same
     type (that is, both must be either directories or non-directories) and
     must reside on the same file system.

     The rename() system call guarantees that an instance of new will always
     exist, even if the system should crash in the middle of the operation.

     If the final component of old is a symbolic link, the symbolic link is
     renamed, not the file or directory to which it points.

     The renameat() system call is equivalent to rename() except in the case
     where either from or to specifies a relative path.  If from is a relative
     path, the file to be renamed is located relative to the directory associ-
     ated with the file descriptor fromfd instead of the current working
     directory.  If the to is a relative path, the same happens only relative
     to the directory associated with tofd.  If the renameat() is passed the
     special value AT_FDCWD in the fromfd or tofd parameter, the current work-
     ing directory is used in the determination of the file for the respective
     path parameter.

     The renamex_np() and renameatx_np() system calls are similar to their
     counterparts except that they take a flags argument.  Values for flags
     are constructed with below bits set:

	   RENAME_SWAP	 On file systems that support it (see getattrlist(2)
			 VOL_CAP_INT_RENAME_SWAP), it will cause the source
			 and target to be atomically swapped.  Source and tar-
			 get need not be of the same type, i.e. it is possible
			 to swap a file with a directory.  EINVAL is returned
			 in case of bitwise-inclusive OR with RENAME_EXCL.

	   RENAME_EXCL	 On file systems that support it (see getattrlist(2)
			 VOL_CAP_INT_RENAME_EXCL), it will cause EEXIST to be
			 returned if the destination already exists. EINVAL is
			 returned in case of bitwise-inclusive OR with
			 RENAME_SWAP.

CAVEATS
     The system can deadlock if a loop is present in the file system graph.
     This loop takes the form of an entry in directory `a', say `a/foo', being
     a hard link to directory `b', and an entry in directory `b', say `b/bar',
     being a hard link to directory `a'.  When such a loop exists and two sep-
     arate processes attempt to perform `rename a/foo b/bar' and `rename b/bar
     a/foo', respectively, the system may deadlock attempting to lock both
     directories for modification.

     Whether or not hard links to directories are supported is specific to the
     underlying filesystem implementation.

     It is recommended that any hard links to directories in an underlying
     filesystem should be replaced by symbolic links by the system administra-
     tor to avoid the possibility of deadlocks.

     Moving or renaming a file or directory into a directory with inheritable
     ACLs does not result in ACLs being set on the file or directory. Use
     acl(3) in conjunction with rename() to set ACLs on the file or directory.

RETURN VALUES
     A 0 value is returned if the operation succeeds, otherwise rename()
     returns -1 and the global variable errno indicates the reason for the
     failure.

ERRORS
     The rename() system call will fail and neither of the argument files will
     be affected if:

     [EACCES]		A component of either path prefix denies search per-
			mission.

     [EACCES]		The requested operation requires writing in a direc-
			tory (e.g., new, new/.., or old/..) whose modes disal-
			low this.

     [EDQUOT]		The directory in which the entry for the new name is
			being placed cannot be extended because the user's
			quota of disk blocks on the file system containing the
			directory has been exhausted.

     [EEXIST]		flags has RENAME_EXCL set but new already exists.

     [EFAULT]		Path points outside the process's allocated address
			space.

     [EINVAL]		Old is a parent directory of new, or an attempt is
			made to rename `.' or `..'.  If RENAME_SWAP is used,
			then EINVAL will also be returned if new is a parent
			directory of old.  If both RENAME_SWAP and RENAME_EXCL
			bits are set in flags, then EINVAL will be returned.

     [EINVAL]		flags has an invalid value.

     [EIO]		An I/O error occurs while making or updating a direc-
			tory entry.

     [EISDIR]		new is a directory, but old is not a directory.

     [ELOOP]		Too many symbolic links are encountered in translating
			either pathname.  This is taken to be indicative of a
			looping symbolic link.

     [ENAMETOOLONG]	A component of a pathname exceeds {NAME_MAX} charac-
			ters, or an entire path name exceeds {PATH_MAX} char-
			acters.

     [ENOENT]		A component of the old path does not exist, or a path
			prefix of new does not exist.

     [ENOENT]		flags has RENAME_SWAP set but new does not exist.

     [ENOSPC]		The directory in which the entry for the new name is
			being placed cannot be extended because there is no
			space left on the file system containing the direc-
			tory.

     [ENOTDIR]		A component of either path prefix is not a directory.

     [ENOTDIR]		old is a directory, but new is not a directory.

     [ENOTEMPTY]	New is a directory and is not empty.

     [ENOTSUP]		flags has a value that is not supported by the file
			system.

     [EPERM]		The directory containing old is marked sticky, and
			neither the containing directory nor old are owned by
			the effective user ID.

     [EPERM]		The new file exists, the directory containing new is
			marked sticky, and neither the containing directory
			nor new are owned by the effective user ID.

     [EROFS]		The requested link requires writing in a directory on
			a read-only file system.

     [EXDEV]		The link named by new and the file named by old are on
			different logical devices (file systems).  Note that
			this error code will not be returned if the implemen-
			tation permits cross-device links.

     The renameat() and renameatx_np() calls may also fail with:

     [EBADF]		The from argument does not specify an absolute path
			and the fromfd argument is neither AT_FDCWD nor a
			valid file descriptor open for searching, or the to
			argument does not specify an absolute path and the
			tofd argument is neither AT_FDCWD nor a valid file
			descriptor open for searching.

     [ENOTDIR]		The from argument is not an absolute path and fromfd
			is neither AT_FDCWD nor a file descriptor associated
			with a directory, or the to argument is not an abso-
			lute path and tofd is neither AT_FDCWD nor a file
			descriptor associated with a directory.

CONFORMANCE
     The restriction on renaming a directory whose permissions disallow writ-
     ing is based on the fact that UFS directories contain a "".."" entry.  If
     renaming a directory would move it to another parent directory, this
     entry needs to be changed.

     This restriction has been generalized to disallow renaming of any write-
     disabled directory, even when this would not require a change to the ""..""
     entry.  For consistency, HFS+ directories emulate this behavior.

SEE ALSO
     open(2), symlink(7)

STANDARDS
     The rename() function conforms to IEEE Std 1003.1-1988 (``POSIX.1'').
     The renameat() system call is expected to conform to POSIX.1-2008 .

4.2 Berkeley Distribution     September 18, 2008     4.2 Berkeley Distribution
","# rename

> Rename multiple files.
> NOTE: this page refers to the command from the `util-linux` package.
> For the Perl version, see `file-rename` or `perl-rename`.
> Warning: This command has no safeguards and will overwrite files without prompting.

- Rename files using simple substitutions (substitute 'foo' with 'bar' wherever found):

`rename {{foo}} {{bar}} {{*}}`

- Dry-run - display which renames would occur without performing them:

`rename -vn {{foo}} {{bar}} {{*}}`

- Do not overwrite existing files:

`rename -o {{foo}} {{bar}} {{*}}`

- Change file extensions:

`rename {{.ext}} {{.bak}} {{*.ext}}`

- Prepend ""foo"" to all filenames in the current directory:

`rename {{''}} {{'foo'}} {{*}}`

- Rename a group of increasingly numbered files zero-padding the numbers up to 3 digits:

`rename {{foo}} {{foo00}} {{foo?}} && rename {{foo}} {{foo0}} {{foo??}}`
"
arecord,https://linux.die.net/man/1/arecord,"

arecord(1) - Linux man page
















arecord(1) - Linux man page
Name
arecord, aplay - command-line sound recorder and player for ALSA soundcard driver
Synopsis
arecord [flags] [filename]
aplay [flags] [filename [filename]] ...
Description





arecord is a command-line soundfile recorder for the ALSA soundcard driver. It supports
several file formats and multiple soundcards with multiple devices. If recording with interleaved mode samples the file is automatically split before the 2GB
filesize.
aplay is much the same, only it plays instead of recording. For supported soundfile formats, the sampling rate, bit depth, and so forth can be
automatically determined from the soundfile header.
If filename is not specified, the standard output or input is used. The aplay utility accepts multiple filenames.
Options

-h, --help
Help: show syntax.
--version
Print current version.
-l, --list-devices
List all soundcards and digital audio devices
-L, --list-pcms
List all PCMs defined
-D, --device=NAME
Select PCM by name
-q --quiet
Quiet mode. Suppress messages (not sound :))
-t, --file-type TYPE
File type (voc, wav, raw or au). If this parameter is omitted the WAVE format is used.
-c, --channels=#
The number of channels. The default is one channel. Valid values are 1 through 32.
-f --format=FORMAT
Sample format
Recognized sample formats are: S8 U8 S16_LE S16_BE U16_LE U16_BE S24_LE S24_BE U24_LE U24_BE S32_LE S32_BE U32_LE U32_BE FLOAT_LE FLOAT_BE FLOAT64_LE
FLOAT64_BE IEC958_SUBFRAME_LE IEC958_SUBFRAME_BE MU_LAW A_LAW IMA_ADPCM MPEG GSM SPECIAL S24_3LE S24_3BE U24_3LE U24_3BE S20_3LE S20_3BE U20_3LE U20_3BE
S18_3LE S18_3BE U18_3LE
Some of these may not be available on selected hardware
The available format shortcuts are:-f cd (16 bit little endian, 44100, stereo) [-f S16_LE -c2 -r44100]
-f cdr (16 bit big endian, 44100, stereo) [-f S16_BE -c2 -f44100]
-f dat (16 bit little endian, 48000, stereo) [-f S16_LE -c2 -r48000]
If no format is given U8 is used.
-r, --rate=#<Hz>
Sampling rate in Hertz. The default rate is 8000 Hertz. If the value specified is less than 300, it is taken as the rate in kilohertz. Valid values are
2000 through 192000 Hertz.
-d, --duration=#
Interrupt after # seconds. A value of zero means infinity. The default is zero, so if this option is omitted then the arecord process will run until it is
killed.
-s, --sleep-min=#
Min ticks to sleep. The default is not to sleep.
-M, --mmap
Use memory-mapped (mmap) I/O mode for the audio stream. If this option is not set, the read/write I/O mode will be used.
-N, --nonblock
Open the audio device in non-blocking mode. If the device is busy the program will exit immediately. If this option is not set the program will block until
the audio device is available again.
-F, --period-time=#
Distance between interrupts is # microseconds. If no period time and no period size is given then a quarter of the buffer time is set.
-B, --buffer-time=#
Buffer duration is # microseconds If no buffer time and no buffer size is given then the maximal allowed buffer time but not more than 500ms is set.
--period-size=#
Distance between interrupts is # frames If no period size and no period time is given then a quarter of the buffer size is set.
--buffer-size=#
Buffer duration is # frames If no buffer time and no buffer size is given then the maximal allowed buffer time but not more than 500ms is set.
-A, --avail-min=#
Min available space for wakeup is # microseconds
-R, --start-delay=#
Delay for automatic PCM start is # microseconds (relative to buffer size if <= 0)
-T, --stop-delay=#
Delay for automatic PCM stop is # microseconds from xrun
-v, --verbose
Show PCM structure and setup. This option is accumulative. The VU meter is displayed when this is given twice or three times.
-V, --vumeter=TYPE
Specifies the VU-meter type, either stereo or mono. The stereo VU-meter is available only for 2-channel stereo samples with interleaved
format.
-I, --separate-channels
One file for each channel. This option disables max-file-time and use-strftime, and ignores SIGUSR1. The stereo VU meter is not available with separate
channels.
-P
Playback. This is the default if the program is invoked by typing aplay.
-C
Record. This is the default if the program is invoked by typing arecord.
-i, --interactive
Allow interactive operation via stdin. Currently only pause/resume via space or enter key is implemented.
--disable-resample
Disable automatic rate resample.
--disable-channels
Disable automatic channel conversions.
--disable-format
Disable automatic format conversions.
--disable-softvol
Disable software volume control (softvol).
--test-position
Test ring buffer position.
--test-coef=<coef>
Test coefficient for ring buffer position; default is 8. Expression for validation is: coef * (buffer_size / 2). Minimum value is 1.
--test-nowait
Do not wait for the ring buffer--eats the whole CPU.
--max-file-time
While recording, when the output file has been accumulating sound for this long, close it and open a new output file. Default is the maximum size supported
by the file format: 2 GiB for WAV files. This option has no effect if --separate-channels is specified.
--process-id-file <file name>
aplay writes its process ID here, so other programs can send signals to it.
--use-strftime
When recording, interpret %-codes in the file name parameter using the strftime facility whenever the output file is opened. The important strftime codes
are: %Y is the year, %m month, %d day of the month, %H hour, %M minute and %S second. In addition, %v is the file number, starting at 1. When this option is
specified, intermediate directories for the output file are created automatically. This option has no effect if --separate-channels is specified.
--dump-hw-params
Dump hw_params of the device preconfigured status to stderr. The dump lists capabilities of the selected device such as supported formats, sampling rates,
numbers of channels, period and buffer bytes/sizes/times. For raw device hw:X this option basically lists hardware capabilities of the soundcard.
--fatal-errors
Disables recovery attempts when errors (e.g. xrun) are encountered; the aplay process instead aborts immediately.
Signals
When recording, SIGINT, SIGTERM and SIGABRT will close the output file and exit. SIGUSR1 will close
the output file, open a new one, and continue recording. However, SIGUSR1 does not work with --separate-channels.
Examples

aplay -c 1 -t raw -r 22050 -f mu_law foobar
will play the raw file ""foobar"" as a 22050-Hz, mono, 8-bit, Mu-Law .au file.
arecord -d 10 -f cd -t wav -D copy foobar.wav
will record foobar.wav as a 10-second, CD-quality wave file, using the PCM ""copy"" (which might be defined in the user's .asoundrc file as:pcm.copy {
  type plug
  slave {
    pcm hw
  }
  route_policy copy
}
arecord -t wav --max-file-time 30 mon.wav
Record from the default audio source in monaural, 8,000 samples per second, 8 bits per sample. Start a new file every 30 seconds. File names are
mon-nn.wav, where nn increases from 01. The file after mon-99.wav is mon-100.wav.
arecord -f cd -t wav --max-file-time 3600 --use-strftime %Y/%m/%d/listen-%H-%M-%v.wav
Record in stereo from the default audio source. Create a new file every hour. The files are placed in directories based on their start dates and have names
which include their start times and file numbers.
See Also
alsamixer(1), amixer(1)
Bugs
Note that .aiff files are not currently supported.
Author
arecord and aplay are by Jaroslav Kysela <perex@perex.cz> This document is by
Paul Winkler <zarmzarm@erols.com>. Updated for Alsa 0.9 by James Tappin <james@xena.uklinux.net>










Site Search











Library
linux docs
linux man pages
page load time


Toys
world sunlight
moon phase
trace explorer







",,"# arecord

> Sound recorder for ALSA soundcard driver.
> More information: <https://linux.die.net/man/1/arecord>.

- Record a snippet in ""CD"" quality (finish with Ctrl-C when done):

`arecord -vv --format=cd {{path/to/file.wav}}`

- Record a snippet in ""CD"" quality, with a fixed duration of 10 seconds:

`arecord -vv --format=cd --duration={{10}} {{path/to/file.wav}}`

- Record a snippet and save it as mp3 (finish with Ctrl-C when done):

`arecord -vv --format=cd --file-type raw | lame -r - {{path/to/file.mp3}}`
"
compose,,,,"# compose

> An alias to a `run-mailcap`'s action compose.
> Originally `run-mailcap` is used to mime-type/file.

- Compose action can be used to compose any existing file or new on default mailcap edit tool:

`compose {{filename}}`

- With `run-mailcap`:

`run-mailcap --action=compose {{filename}}`
"
groupmod,,,,"# groupmod

> Modify existing user groups in the system.

- Change the group name:

`groupmod -n {{new_group_name}} {{old_group_name}}`

- Change the group id:

`groupmod -g {{new_group_id}} {{old_group_name}}`
"
btrfs,,,,"# btrfs

> A filesystem based on the copy-on-write (COW) principle for Linux.

- Create subvolume:

`sudo btrfs subvolume create {{path/to/subvolume}}`

- List subvolumes:

`sudo btrfs subvolume list {{path/to/mount_point}}`

- Show space usage information:

`sudo btrfs filesystem df {{path/to/mount_point}}`

- Enable quota:

`sudo btrfs quota enable {{path/to/subvolume}}`

- Show quota:

`sudo btrfs qgroup show {{path/to/subvolume}}`
"
rtcwake,,,,"# rtcwake

> Enter a system sleep state until specified wakeup time relative to your bios clock.

- Show whether an alarm is set or not:

`sudo rtcwake -m show -v`

- Suspend to ram and wakeup after 10 seconds:

`sudo rtcwake -m mem -s {{10}}`

- Suspend to disk (higher power saving) and wakeup 15 minutes later:

`sudo rtcwake -m disk --date +{{15}}min`

- Freeze the system (more efficient than suspend-to-ram but linux > 3.9 required) and wakeup at a given date and time:

`sudo rtcwake -m freeze --date {{YYYYMMDDhhmm}}`

- Disable a previously set alarm:

`sudo rtcwake -m disable`

- Perform a dry run to wakup the computer at a given time. (Press Ctrl + C to abort):

`sudo rtcwake -m on --date {{hh:ss}}`
"
sensors,,,,"# sensors

> Report sensors information.

- Show the current readings of all sensor chips:

`sensors`

- Show temperatures in degrees Fahrenheit:

`sensors --fahrenheit`
"
uuidgen,,,"
UUIDGEN(1)		  BSD General Commands Manual		    UUIDGEN(1)

NAME
     uuidgen -- generates new UUID strings

SYNOPSIS
     uuidgen [-hdr]

DESCRIPTION
     The uuidgen command generates a Universally Unique IDentifier (UUID), a
     128-bit value guaranteed to be unique over both space and time.

     The following options are available:

     -hdr      Emit CoreFoundation CFUUID-based source code for using the uuid
	       in a header.

RETURN VALUE
     The UUID is printed to standard output as a hyphen-punctuated ASCII
     string of the form: EEF45689-BBE5-4FB6-9E80-41B78F6578E2 (in printf(3)
     format ""%08X-%04X-%04X-%04X-%012X""), unless the -hdr option is given, in
     which case a fragment of source code is output.

Mac OS X			 July 1, 2005			      Mac OS X
","# uuidgen

> Generate unique identifiers (UUIDs).

- Create a random UUID:

`uuidgen --random`

- Create a UUID based on the current time:

`uuidgen --time`

- Create a UUID based on the hash of a URL:

`uuidgen --sha1 --namespace {{@url}} --name {{object_name}}`
"
fc-cache,,,"FC-CACHE(1)							   FC-CACHE(1)



NAME
       fc-cache - build font information cache files

SYNOPSIS
       fc-cache  [  -EfrsvVh  ]   [  --error-on-no-fonts  ]   [  --force  ]  [
       --really-force ]  [  [ -y dir ]	[ --sysroot dir ]  ]  [  --system-only
       ]  [ --verbose ]  [ --version ]	[ --help ]  [ dir... ]

DESCRIPTION
       fc-cache  scans	the  font  directories	on  the system and builds font
       information cache files for applications  using	fontconfig  for  their
       font handling.

       If  directory  arguments are not given, fc-cache uses each directory in
       the current font configuration. Each  directory	is  scanned  for  font
       files  readable	by FreeType. A cache is created which contains proper-
       ties of each font and the associated filename.  This cache is  used  to
       speed up application startup when using the fontconfig library.

       Note  that  fc-cache must be executed once per architecture to generate
       font information customized for that architecture.

OPTIONS
       This program follows the usual  GNU  command  line  syntax,  with  long
       options	starting  with	two  dashes  (`-').  A	summary  of options is
       included below.

       -E     Raise an error if there are no fonts in dir  or  directories  in
	      the configuration if not given.

       -f     Force  re-generation of apparently up-to-date cache files, over-
	      riding the timestamp checking.

       -r     Erase all existing cache files and rescan.

       -s     Only scan system-wide directories, omitting the  places  located
	      in the user's home directory.

       -v     Display status information while busy.

       -y     Prepend dir to all paths for scanning.

       -h     Show summary of options.

       -V     Show version of the program and exit.

       dir    Directory to scan for fonts.

RETURN CODES
       fc-cache  returns  zero if the caches successfully generated. otherwise
       non-zero.

FILES
       %cachedir%/*-%arch%.cache-%version%
	      These files are generated by fc-cache and contain maps from file
	      names  to  font  properties.  They  are  read  by the fontconfig
	      library at application startup to locate appropriate fonts.

SEE ALSO
       fc-cat(1) fc-list(1) fc-match(1) fc-pattern(1) fc-query(1) fc-scan(1)

       The fontconfig user's guide, in	HTML  format:  /usr/share/doc/fontcon-
       fig/fontconfig-user.html.

AUTHOR
       This  manual  page was written by Keith Packard <keithp@keithp.com> and
       Josselin Mouette <joss@debian.org>.



				 Aug 13, 2008			   FC-CACHE(1)
","# fc-cache

> Scan font directories in order to build font cache files.

- Generate font cache files:

`fc-cache`

- Force a rebuild of all font cache files, without checking if cache is up-to-date:

`fc-cache -f`

- Erase font cache files, then generate new font cache files:

`fc-cache -r`
"
amixer,,,,"# amixer

> Mixer for ALSA soundcard driver.

- Turn up the master volume by 10%:

`amixer -D pulse sset Master {{10%+}}`

- Turn down the master volume by 10%:

`amixer -D pulse sset Master {{10%-}}`
"
iwconfig,https://linux.die.net/man/8/iwconfig,"

iwconfig(8) - Linux man page
















iwconfig(8) - Linux man page
Name
iwconfig - configure a wireless network interface
Synopsis





iwconfig [interface]
iwconfig interface [essid X] [nwid N] [mode M] [freq F]
[channel C][sens S ][ap A ][nick NN ]
[rate R] [rts RT] [frag FT] [txpower T]
[enc E] [key K] [power P] [retry R]
[modu M] [commit]
iwconfig --help
iwconfig --version
Description
Iwconfig is similar to ifconfig(8), but is dedicated to the wireless interfaces.
It is used to set the parameters of the network interface which are specific to the wireless operation (for example : the frequency). Iwconfig may also
be used to display those parameters, and the wireless statistics (extracted from /proc/net/wireless).
All these parameters and statistics are device dependent. Each driver will provide only some of them depending on hardware support, and the range of values
may change. Please refer to the man page of each device for details.
Parameters

essid
Set the ESSID (or Network Name - in some products it may also be called Domain ID). The ESSID is used to identify cells which are part of the same virtual
network.
As opposed to the AP Address or NWID which define a single cell, the ESSID defines a group of cells connected via repeaters or infrastructure, where the user
may roam transparently.
With some cards, you may disable the ESSID checking (ESSID promiscuous) with off or any (and on to reenable it).
If the ESSID of your network is one of the special keywords (off, on or any), you should use -- to escape it.
Examples :
   iwconfig eth0 essid any
   iwconfig eth0 essid ""My Network""""
   iwconfig eth0 essid -- ""ANY""""
nwid
Set the Network ID. As all adjacent wireless networks share the same medium, this parameter is used to differentiate them (create logical colocated
networks) and identify nodes belonging to the same cell.
This parameter is only used for pre-802.11 hardware, the 802.11 protocol uses the ESSID and AP Address for this function.
With some cards, you may disable the Network ID checking (NWID promiscuous) with off (and on to reenable it).
Examples :
   iwconfig eth0 nwid AB34
   iwconfig eth0 nwid off
nick[name]
Set the nickname, or the station name. Some 802.11 products do define it, but this is not used as far as the protocols (MAC, IP, TCP) are concerned and
completely useless as far as configuration goes. Only some wireless diagnostic tools may use it.
Example :
   iwconfig eth0 nickname ""My Linux Node""""
mode
Set the operating mode of the device, which depends on the network topology. The mode can be Ad-Hoc (network composed of only one cell and without
Access Point), Managed (node connects to a network composed of many Access Points, with roaming), Master (the node is the synchronisation master
or acts as an Access Point), Repeater (the node forwards packets between other wireless nodes), Secondary (the node acts as a backup
master/repeater), Monitor (the node is not associated with any cell and passively monitor all packets on the frequency) or Auto.
Example :
   iwconfig eth0 mode Managed
   iwconfig eth0 mode Ad-Hoc
freq/channel
Set the operating frequency or channel in the device. A value below 1000 indicates a channel number, a value greater than 1000 is a frequency in Hz. You
may append the suffix k, M or G to the value (for example, ""2.46G"" for 2.46 GHz frequency), or add enough '0'.
Channels are usually numbered starting at 1, and you may use iwlist(8) to get the total number of channels, list the available frequencies, and display
the current frequency as a channel. Depending on regulations, some frequencies/channels may not be available.
When using Managed mode, most often the Access Point dictates the channel and the driver may refuse the setting of the frequency. In Ad-Hoc mode, the frequency
setting may only be used at initial cell creation, and may be ignored when joining an existing cell.
You may also use off or auto to let the card pick up the best channel (when supported).
Examples :
   iwconfig eth0 freq 2422000000
   iwconfig eth0 freq 2.422G
   iwconfig eth0 channel 3
   iwconfig eth0 channel auto
ap
Force the card to register to the Access Point given by the address, if it is possible. This address is the cell identity of the Access Point, as reported
by wireless scanning, which may be different from its network MAC address. If the wireless link is point to point, set the address of the other end of the
link. If the link is ad-hoc, set the cell identity of the ad-hoc network.
When the quality of the connection goes too low, the driver may revert back to automatic mode (the card selects the best Access Point in range).
You may also use off to re-enable automatic mode without changing the current Access Point, or you may use any or auto to force the card
to reassociate with the currently best Access Point.
Example :
   iwconfig eth0 ap 00:60:1D:01:23:45
   iwconfig eth0 ap any
   iwconfig eth0 ap off
rate/bit[rate]
For cards supporting multiple bit rates, set the bit-rate in b/s. The bit-rate is the speed at which bits are transmitted over the medium, the user speed
of the link is lower due to medium sharing and various overhead.
You may append the suffix k, M or G to the value (decimal multiplier : 10^3, 10^6 and 10^9 b/s), or add enough '0'. Values below 1000 are card specific,
usually an index in the bit-rate list. Use auto to select automatic bit-rate mode (fallback to lower rate on noisy channels), which is the default for
most cards, and fixed to revert back to fixed setting. If you specify a bit-rate value and append auto, the driver will use all bit-rates lower
and equal than this value.
Examples :
   iwconfig eth0 rate 11M
   iwconfig eth0 rate auto
   iwconfig eth0 rate 5.5M auto
txpower
For cards supporting multiple transmit powers, sets the transmit power in dBm. If W is the power in Watt, the power in dBm is P = 30 +
10.log(W). If the value is postfixed by mW, it will be automatically converted to dBm.
In addition, on and off enable and disable the radio, and auto and fixed enable and disable power control (if those features are
available).
Examples :
   iwconfig eth0 txpower 15
   iwconfig eth0 txpower 30mW
   iwconfig eth0 txpower auto
   iwconfig eth0 txpower off
sens
Set the sensitivity threshold. This define how sensitive is the card to poor operating conditions (low signal, interference). Positive values are assumed
to be the raw value used by the hardware or a percentage, negative values are assumed to be dBm. Depending on the hardware implementation, this parameter may
control various functions.
On modern cards, this parameter usually control handover/roaming threshold, the lowest signal level for which the hardware remains associated with the current
Access Point. When the signal level goes below this threshold the card starts looking for a new/better Access Point. Some cards may use the number of missed
beacons to trigger this. For high density of Access Points, a higher threshold make sure the card is always associated with the best AP, for low density of
APs, a lower threshold minimise the number of failed handoffs.
On more ancient card this parameter usually controls the defer threshold, the lowest signal level for which the hardware considers the channel busy. Signal
levels above this threshold make the hardware inhibits its own transmission whereas signals weaker than this are ignored and the hardware is free to transmit.
This is usually strongly linked to the receive threshold, the lowest signal level for which the hardware attempts packet reception. Proper setting of these
thresholds prevent the card to waste time on background noise while still receiving weak transmissions. Modern designs seems to control those thresholds
automatically.
Example :
   iwconfig eth0 sens -80
   iwconfig eth0 sens 2
retry
Most cards have MAC retransmissions, and some allow to set the behaviour of the retry mechanism.
To set the maximum number of retries, enter limit 'value'. This is an absolute value (without unit), and the default (when nothing is specified). To set
the maximum length of time the MAC should retry, enter lifetime 'value'. By defaults, this value in in seconds, append the suffix m or u to specify
values in milliseconds or microseconds.
You can also add the short, long, min and max modifiers. If the card supports automatic mode, they define the bounds of the limit
or lifetime. Some other cards define different values depending on packet size, for example in 802.11 min limit is the short retry limit (non RTS/CTS
packets).
Examples :
   iwconfig eth0 retry 16
   iwconfig eth0 retry lifetime 300m
   iwconfig eth0 retry short 12
   iwconfig eth0 retry min limit 8
rts[_threshold]
RTS/CTS adds a handshake before each packet transmission to make sure that the channel is clear. This adds overhead, but increases performance in case of
hidden nodes or a large number of active nodes. This parameter sets the size of the smallest packet for which the node sends RTS ; a value equal to the maximum
packet size disables the mechanism. You may also set this parameter to auto, fixed or off.
Examples :
   iwconfig eth0 rts 250
   iwconfig eth0 rts off
frag[mentation_threshold]
Fragmentation allows to split an IP packet in a burst of smaller fragments transmitted on the medium. In most cases this adds overhead, but in a very noisy
environment this reduces the error penalty and allow packets to get through interference bursts. This parameter sets the maximum fragment size which is always
lower than the maximum packet size.
This parameter may also control Frame Bursting available on some cards, the ability to send multiple IP packets together. This mechanism would be enabled if
the fragment size is larger than the maximum packet size.
You may also set this parameter to auto, fixed or off.
Examples :
   iwconfig eth0 frag 512
   iwconfig eth0 frag off
key/enc[ryption]
Used to manipulate encryption or scrambling keys and security mode.
To set the current encryption key, just enter the key in hex digits as XXXX-XXXX-XXXX-XXXX or XXXXXXXX. To set a key other than the current key,
prepend or append [index] to the key itself (this won't change which is the active key). You can also enter the key as an ASCII string by using the
s: prefix. Passphrase is currently not supported.
To change which key is the currently active key, just enter [index] (without entering any key value).
off and on disable and reenable encryption.
The security mode may be open or restricted, and its meaning depends on the card used. With most cards, in open mode no authentication is
used and the card may also accept non-encrypted sessions, whereas in restricted mode only encrypted sessions are accepted and the card will use
authentication if available.
If you need to set multiple keys, or set a key and change the active key, you need to use multiple key directives. Arguments can be put in any order,
the last one will take precedence.
Examples :
   iwconfig eth0 key 0123-4567-89
   iwconfig eth0 key [3] 0123-4567-89
   iwconfig eth0 key s:password [2]
   iwconfig eth0 key [2]
   iwconfig eth0 key open
   iwconfig eth0 key off
   iwconfig eth0 key restricted [3] 0123456789
   iwconfig eth0 key 01-23 key 45-67 [4] key [4]
power
Used to manipulate power management scheme parameters and mode.
To set the period between wake ups, enter period 'value'. To set the timeout before going back to sleep, enter timeout 'value'. To set the
generic level of power saving, enter saving 'value'. You can also add the min and max modifiers. By default, those values are in seconds,
append the suffix m or u to specify values in milliseconds or microseconds. Sometimes, those values are without units (number of beacon periods, dwell,
percentage or similar).
off and on disable and reenable power management. Finally, you may set the power management mode to all (receive all packets),
unicast (receive unicast packets only, discard multicast and broadcast) and multicast (receive multicast and broadcast only, discard unicast
packets).
Examples :
   iwconfig eth0 power period 2
   iwconfig eth0 power 500m unicast
   iwconfig eth0 power timeout 300u all
   iwconfig eth0 power saving 3
   iwconfig eth0 power off
   iwconfig eth0 power min period 2 power max period 4
modu[lation]
Force the card to use a specific set of modulations. Modern cards support various modulations, some which are standard, such as 802.11b or 802.11g, and
some proprietary. This command force the card to only use the specific set of modulations listed on the command line. This can be used to fix interoperability
issues.
The list of available modulations depend on the card/driver and can be displayed using iwlist modulation. Note that some card/driver may not be able to
select each modulation listed independantly, some may come as a group. You may also set this parameter to auto let the card/driver do its best.
Examples :
   iwconfig eth0 modu 11g
   iwconfig eth0 modu CCK OFDMa
   iwconfig eth0 modu auto
commit
Some cards may not apply changes done through Wireless Extensions immediately (they may wait to aggregate the changes or apply it only when the card is
brought up via ifconfig). This command (when available) forces the card to apply all pending changes.
This is normally not needed, because the card will eventually apply the changes, but can be useful for debugging.
Display
For each device which supports wireless extensions, iwconfig will display the name of the
MAC protocol used (name of device for proprietary protocols), the ESSID (Network Name), the NWID, the frequency (or channel), the
sensitivity, the mode of operation, the Access Point address, the bit-rate, the RTS threshold, the fragmentation
threshold, the encryption key and the power management settings (depending on availability).
The parameters displayed have the same meaning and values as the parameters you can set, please refer to the previous part for a detailed explanation of
them.
Some parameters are only displayed in short/abbreviated form (such as encryption). You may use iwlist(8) to get all the details.
Some parameters have two modes (such as bitrate). If the value is prefixed by '=', it means that the parameter is fixed and forced to that value, if it
is prefixed by ':', the parameter is in automatic mode and the current value is shown (and may change).

Access Point/Cell
An address equal to 00:00:00:00:00:00 means that the card failed to associate with an Access Point (most likely a configuration issue). The Access
Point parameter will be shown as Cell in ad-hoc mode (for obvious reasons), but otherwise works the same.
If /proc/net/wireless exists, iwconfig will also display its content. Note that those values will depend on the driver and the hardware
specifics, so you need to refer to your driver documentation for proper interpretation of those values.

Link quality
Overall quality of the link. May be based on the level of contention or interference, the bit or frame error rate, how good the received signal is, some
timing synchronisation, or other hardware metric. This is an aggregate value, and depends totally on the driver and hardware.
Signal level
Received signal strength (RSSI - how strong the received signal is). May be arbitrary units or dBm, iwconfig uses driver meta information to
interpret the raw value given by /proc/net/wireless and display the proper unit or maximum value (using 8 bit arithmetic). In Ad-Hoc mode, this
may be undefined and you should use iwspy.
Noise level
Background noise level (when no packet is transmitted). Similar comments as for Signal level.
Rx invalid nwid
Number of packets received with a different NWID or ESSID. Used to detect configuration problems or adjacent network existence (on the same frequency).
Rx invalid crypt
Number of packets that the hardware was unable to decrypt. This can be used to detect invalid encryption settings.
Rx invalid frag
Number of packets for which the hardware was not able to properly re-assemble the link layer fragments (most likely one was missing).
Tx excessive retries
Number of packets that the hardware failed to deliver. Most MAC protocols will retry the packet a number of times before giving up.
Invalid misc
Other packets lost in relation with specific wireless operations.
Missed beacon
Number of periodic beacons from the Cell or the Access Point we have missed. Beacons are sent at regular intervals to maintain the cell coordination,
failure to receive them usually indicates that the card is out of range.
Author
Jean Tourrilhes - jt@hpl.hp.com
Files
/proc/net/wireless
See Also
ifconfig(8), iwspy(8), iwlist(8),
iwevent(8), iwpriv(8), wireless(7).


Referenced By
iftab(5),
iwgetid(8),
waproamd(8),
wavelan(4),
wicd(8),
wicd-wireless-settings.conf(5)








Site Search











Library
linux docs
linux man pages
page load time


Toys
world sunlight
moon phase
trace explorer







",,"# iwconfig

> Configure and show the parameters of a wireless network interface.
> More information: <https://linux.die.net/man/8/iwconfig>.

- Show the parameters and statistics of all the interfaces:

`iwconfig`

- Show the parameters and statistics of the specified interface:

`iwconfig {{interface}}`

- Set the ESSID (network name) of the specified interface (e.g., eth0 or wlp2s0):

`iwconfig {{interface}} {{new_network_name}}`

- Set the operating mode of the specified interface:

`ifconfig {{interface}} mode {{ad hoc|Managed|Master|Repeater|Secondary|Monitor|Auto}}`
"
emerge,,,,"# emerge

> Gentoo Linux package manager utility.

- Synchronize all packages:

`emerge --sync`

- Update all packages, including dependencies:

`emerge -uDNav @world`

- Resume a failed updated, skipping the failing package:

`emerge --resume --skipfirst`

- Install a new package, with confirmation:

`emerge -av {{package_name}}`

- Remove a package, with confirmation:

`emerge -Cav {{package_name}}`

- Remove orphaned packages (that were installed only as dependencies):

`emerge -avc`

- Search the package database for a keyword:

`emerge -S {{keyword}}`
"
pkgadd,,,,"# pkgadd

> Add a package to a CRUX system.

- Install a local software package:

`pkgadd {{package_name}}`

- Update an already installed package from a local package:

`pkgadd -u {{package_name}}`
"
uprecords,,,,"# uprecords

> Displays a summary of historical uptime records.

- Display a summary of the top 10 historical uptime records:

`uprecords`

- Display the top 25 records:

`uprecords -m {{25}}`

- Display the downtime between reboots instead of the kernel version:

`uprecords -d`

- Show the most recent reboots:

`uprecords -B`

- Don't truncate information:

`uprecords -w`
"
pacman,,,,"# pacman

> Arch Linux package manager utility.

- Synchronize and update all packages:

`pacman -Syu`

- Install a new package:

`pacman -S {{package_name}}`

- Remove a package and its dependencies:

`pacman -Rs {{package_name}}`

- Search the package database for a regular expression or keyword:

`pacman -Ss ""{{search_pattern}}""`

- List installed packages and versions:

`pacman -Q`

- List only the explicitly installed packages and versions:

`pacman -Qe`

- Find which package owns a certain file:

`pacman -Qo {{filename}}`

- Empty package cache to free up space:

`pacman -Scc`
"
colrm,,,"
COLRM(1)		  BSD General Commands Manual		      COLRM(1)

NAME
     colrm -- remove columns from a file

SYNOPSIS
     colrm [start [stop]]

DESCRIPTION
     The colrm utility removes selected columns from the lines of a file.  A
     column is defined as a single character in a line.  Input is read from
     the standard input.  Output is written to the standard output.

     If only the start column is specified, columns numbered less than the
     start column will be written.  If both start and stop columns are speci-
     fied, columns numbered less than the start column or greater than the
     stop column will be written.  Column numbering starts with one, not zero.

     Tab characters increment the column count to the next multiple of eight.
     Backspace characters decrement the column count by one.

ENVIRONMENT
     The LANG, LC_ALL and LC_CTYPE environment variables affect the execution
     of colrm as described in environ(7).

EXIT STATUS
     The colrm utility exits 0 on success, and >0 if an error occurs.

SEE ALSO
     awk(1), column(1), cut(1), paste(1)

HISTORY
     The colrm command appeared in 3.0BSD.

BSD				August 4, 2004				   BSD
","# colrm

> Remove columns from `stdin`.

- Remove first column of `stdin`:

`colrm {{1 1}}`

- Remove from 3rd column till the end of each line:

`colrm {{3}}`

- Remove from the 3rd column till the 5th column of each line:

`colrm {{3 5}}`
"
nemo,https://github.com/linuxmint/nemo,"













GitHub - linuxmint/nemo: File browser for Cinnamon








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















linuxmint

/

nemo







    Watch
 
      77
    




      Star


      613
    




          Fork


        233
      





        File browser for Cinnamon
      



            View license
        




613
        stars
 

233
        forks
 




      Star





    Watch









Code

 



Issues
284
 



Pull requests
4
 



Actions

 



Projects
0
 



Wiki

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Wiki
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














16
branches



117
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 

 




Soapux


   and   mtwebster

Misc cleanup



…



3795d63

Sep 14, 2020





Misc cleanup

Remove autotools INSTALL file.  Cleanup formatting of summary.
Add newline to end of meson_options.txt.

3795d63



Git stats





2,009
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.circleci


 


 







.github


 


 







cut-n-paste-code


 


 







data


 


 







debian


 


 







docs


 


 







eel


 


 







files


 


 







gresources


 


 







install-scripts


 


 







libnemo-extension


 


 







libnemo-private


 


 







po


 


 







src


 


 







test


 


 







utils


 


 







.gitignore


 


 







AUTHORS


 


 







COPYING


 


 







COPYING-DOCS


 


 







COPYING.EXTENSIONS


 


 







COPYING.LIB


 


 







ChangeLog


 


 







NEWS


 


 







README.md


 


 







THANKS


 


 







config.h.meson.in


 


 







generate_additional_file


 


 







makepot


 


 







meson.build


 


 







meson_options.txt


 


 







nemo.pot


 


 







polkit.its


 


 







polkit.loc


 


 





        View code
      







        README.md
      








Nemo
File Manager for Cinnamon
Nemo is the file manager for the Cinnamon desktop environment.








About

      File browser for Cinnamon
    
Resources



      Readme
 
License



        View license
    







    Releases
      117





master.lmde4: Misc cleanup

          Latest
 
Sep 14, 2020

 

        + 116 releases







    Packages 0


        No packages published 













    Contributors 89





 



 



 



 



 



 



 



 



 



 



 



      + 78 contributors





Languages









C
99.1%





Other
0.9%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# nemo

> File manager and graphical shell for Cinnamon.
> More information: <https://github.com/linuxmint/nemo>.

- Open a new window showing the user's home directory:

`nemo`

- Open a new window showing the current directory:

`nemo .`

- Close all open nemo windows:

`nemo --quit`
"
binwalk,https://github.com/ReFirmLabs/binwalk,"













GitHub - ReFirmLabs/binwalk: Firmware Analysis Tool








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















ReFirmLabs

/

binwalk







    Watch
 
      357
    




      Star


      6.5k
    




          Fork


        996
      





        Firmware Analysis Tool
      



            MIT License
        




6.5k
        stars
 

996
        forks
 




      Star





    Watch









Code

 



Issues
78
 



Pull requests
18
 



Actions

 



Projects
0
 



Wiki

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Wiki
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














3
branches



5
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




devttys0

Merge pull request #481 from sviehb/patch-1



…



578e5f7

Sep 17, 2020





Merge pull request #481 from sviehb/patch-1

Update deps.sh for Python 3 jefferson

578e5f7



Git stats





1,150
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






images



Added images/README.md



Dec 23, 2015







src



Added size check for arcadyan decryptor



Aug 11, 2020







testing



Added LZMA tests



Nov 21, 2017







.editorconfig



Added .editorconfig



Nov 29, 2018







.gitignore



Merged multiple .gitignore files into one



Sep 13, 2017







.travis.yml



travis: Update Python versions



Dec 1, 2019







API.md



make API example python3 compliant



Feb 25, 2019







INSTALL.md



Fixed unstuff link in INSTALL.md



Sep 17, 2020







LICENSE



Fix perm messup



Apr 30, 2016







README.md



Update README.md



Jun 14, 2019







deps.sh



Merge pull request #481 from sviehb/patch-1



Sep 17, 2020







setup.py



Merge pull request #387 from bannsec/master



Nov 8, 2019





        View code
      






        README.md
      








Binwalk




Binwalk is a fast, easy to use tool for analyzing, reverse engineering, and extracting firmware images.
Installation and Usage

Installation
API
Supported Platforms
Getting Started
Binwalk Command Line Usage
Binwalk IDA Plugin Usage

More information on Wiki
Binwalk Professional Edition
After years of developing and supporting binwalk as an open source project we have finally sold out to the man and released a cloud-based firmware extraction engine called Binwalk Pro. After all someone needs to pay devttys0 so he can buy more milling equipment and feed his children (in that order). Please consider subscribing and reap the benefits of getting actual customer support for all your firmware extraction needs. Please visit https://www.refirmlabs.com/binwalk-pro/ for more information.








About

      Firmware Analysis Tool
    
Resources



      Readme
 
License



        MIT License
    







    Releases
      5





Binwalk v2.2.0 Release

          Latest
 
Oct 14, 2019

 

        + 4 releases







    Packages 0


        No packages published 







        Used by 244
 




























            + 236
          







    Contributors 61





 



 



 



 



 



 



 



 



 



 



 



      + 50 contributors





Languages









Python
97.4%





Shell
2.6%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# binwalk

> Firmware Analysis Tool.
> More information: <https://github.com/ReFirmLabs/binwalk>.

- Scan a binary file:

`binwalk {{path/to/binary}}`

- Extract files from a binary, specifying the output directory:

`binwalk --extract --directory {{output_directory}} {{path/to/binary}}`

- Recursively extract files from a binary limiting the recursion depth to 2:

`binwalk --extract --matryoshka --depth {{2}} {{path/to/binary}}`

- Extract files from a binary with the specified file signature:

`binwalk --dd '{{png image:png}}' {{path/to/binary}}`

- Analyze the entropy of a binary, saving the plot with the same name as the binary and `.png` extension appended:

`binwalk --entropy --save {{path/to/binary}}`

- Combine entropy, signature and opcodes analysis in a single command:

`binwalk --entropy --signature --opcodes {{path/to/binary}}`
"
cpufreq-aperf,,,,"# cpufreq-aperf

> Calculate the average CPU frequency over a time period.
> Requires root privileges.

- Start calculating, defaulting to all CPU cores and 1 second refresh interval:

`sudo cpufreq-aperf`

- Start calculating for CPU 1 only:

`sudo cpufreq-aperf -c {{1}}`

- Start calculating with a 3 seconds refresh interval for all CPU cores:

`sudo cpufreq-aperf -i {{3}}`

- Calculate only once:

`sudo cpufreq-aperf -o`
"
mkfs.fat,,,,"# mkfs.fat

> Creates an MS-DOS filesystem inside a partition.

- Create a fat filesystem inside partition 1 on device b (`sdb1`):

`mkfs.fat {{/dev/sdb1}}`

- Create filesystem with a volume-name:

`mkfs.fat -n {{volume_name}} {{/dev/sdb1}}`

- Create filesystem with a volume-id:

`mkfs.fat -i {{volume_id}} {{/dev/sdb1}}`

- Use 5 instead of 2 file allocation tables:

`mkfs.fat -f 5 {{/dev/sdb1}}`
"
pdfgrep,,,,"# pdfgrep

> Search text in PDF files.

- Find lines that match pattern in a PDF:

`pdfgrep {{pattern}} {{file.pdf}}`

- Include file name and page number for each matched line:

`pdfgrep --with-filename --page-number {{pattern}} {{file.pdf}}`

- Do a case insensitive search for lines that begin with ""foo"" and return the first 3 matches:

`pdfgrep --max-count {{3}} --ignore-case {{'^foo'}} {{file.pdf}}`

- Find pattern in files with a .pdf extension in the current directory recursively:

`pdfgrep --recursive {{pattern}}`

- Find pattern on files that match a specific glob in the current directory recursively:

`pdfgrep --recursive --include {{'*book.pdf'}} {{pattern}}`
"
e4defrag,,,,"# e4defrag

> Defragment an ext4 filesystem.

- Defragment the filesystem:

`e4defrag {{/dev/sdXN}}`

- See how fragmented a filesystem is:

`e4defrag -c {{/dev/sdXN}}`

- Print errors and the fragmentation count before and after each file:

`e4defrag -v {{/dev/sdXN}}`
"
scrot,,,,"# scrot

> Screen capture utility.

- Capture a screenshot and save it to the current directory with the current date as the filename:

`scrot`

- Capture a screenshot and save it as ""capture.png"":

`scrot {{capture.png}}`

- Capture a screenshot interactively:

`scrot --select`

- Capture a screenshot from the currently focused window:

`scrot --focused`
"
perf,,,,"# perf

> Framework for linux performance counter measurements.

- Display basic performance counter stats for a command:

`perf stat {{gcc hello.c}}`

- Display system-wide real time performance counter profile:

`sudo perf top`

- Run a command and record its profile into ""perf.data"":

`sudo perf record {{command}}`

- Read ""perf.data"" (created by `perf record`) and display the profile:

`sudo perf report`
"
lsblk,,,,"# lsblk

> Lists information about devices.

- List all storage devices in a tree-like format:

`lsblk`

- Also list empty devices:

`lsblk -a`

- Print the SIZE column in bytes rather than in a human-readable format:

`lsblk -b`

- Output info about filesystems:

`lsblk -f`

- Use ASCII characters for tree formatting:

`lsblk -i`

- Output info about block-device topology:

`lsblk -t`

- Exclude the devices specified by the comma-separated list of major device numbers:

`lsblk -e {{1,7}}`
"
mons,https://github.com/Ventto/mons,"













GitHub - Ventto/mons: POSIX Shell script to quickly manage monitors on X








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















Ventto

/

mons







    Watch
 
      7
    




      Star


      422
    




          Fork


        28
      





        POSIX Shell script to quickly manage monitors on X
      



            MIT License
        




422
        stars
 

28
        forks
 




      Star





    Watch









Code

 



Issues
16
 



Pull requests
2
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














2
branches



5
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 

 




mschneiderwng


   and   Ventto

added PREFIX in Makefile



…



375bbba

Mar 20, 2020





added PREFIX in Makefile


375bbba



Git stats





120
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






img



readme: Update img



Apr 17, 2018







libshlist @ 1d0bdb7



git: Update submodule



Oct 7, 2018







.gitignore



make: Remove all artefacts



Apr 17, 2018







.gitmodules



misc: Update submodule



Nov 5, 2017







CONTRIBUTING.md



misc: Add CONTRIBUTING.md



Jan 24, 2017







LICENSE



misc: Update copyright



Apr 17, 2018







Makefile



added PREFIX in Makefile



Mar 20, 2020







README.md



Add FreeBSD installation instructions (#35)



Jan 7, 2020







mons.sh



make: fix non-default install (#34)



Jan 7, 2020





        View code
      






        README.md
      


Mons




""Mons is a Shell script to quickly manage 2-monitors display using xrandr.""
Perks

 No requirement: POSIX-compliant (minimal: xorg-xrandr)
 Useful: Perfectly fit for laptops, quick and daily use
 Well known: Laptop mode, projector mode, duplicate, mirror and extend
 More:  Select one or two monitors over several others
 Extra: Cycle through every mode with only one shortcut
 Auto: Daemon mode to automatically reset display

Installation

Package (AUR)

$ pacaur -S mons


Package (FreeBSD)

# pkg install mons


Manual

$ git clone --recursive https://github.com/Ventto/mons.git
$ cd mons
$ sudo make install

Note: --recursive is needed for git submodule

Usage
Without argument, it prints connected monitors list with their names and ids.
Options are exclusive and can be used in conjunction with extra options.

Information:
  -h    Prints this help and exits.
  -v    Prints version and exits.

Two monitors:
  -o    Primary monitor only.
  -s    Second monitor only.
  -d    Duplicates the primary monitor.
  -m    Mirrors the primary monitor.
  -e <side>
         Extends the primary monitor to the selected side
         [ top | left | right | bottom ].
  -n <side>
         This mode selects the previous ones, one after another. The argument
         sets the side for the extend mode.

More monitors:
  -O <mon>
        Only enables the monitor with a specified id.
  -S <mon1>,<mon2>:<pos>
        Only enables two monitors with specified ids. The specified position
        places the second monitor on the right (R) or at the top (T).

Daemon mode:
  -a    Performs an automatic display if it detects only one monitor.
  -x <script>
        Must be used in conjunction with the -a option. Every time the number
        of connected monitors changes, mons calls the given script with the
        MONS_NUMBER environment variable.

Extra (in-conjunction or alone):
  --dpi <dpi>
        Set the DPI, a strictly positive value within the range [0 ; 27432].
  --primary <mon_name>
        Select a connected monitor as the primary output. Run the script
        without argument to print monitors information, the names are in the
        second column between ids and status. The primary monitor is marked
        by an asterisk.

Examples
Two monitors
Displays monitor list:
$ mons
0: LVDS-1   (enabled)
5: VGA-1

You have an enabled one, you want to extends the second one on the right:
$ mons -e right

You want to only display the second one:
$ mons -s

With the -n option, go through every 2-mons mode consecutively:

Primary monitor only
Second monitor only
Extend mode whose the side is set with -n <side>
Mirror
Duplicate

This mode is useful if you want to switch to every mode with only one shortcut.

# Now in 'Second monitor mode'
$ mons -n right # -> 'Extend mode'
# Now in 'Extend mode'
$ mons -n right # -> 'Mirror mode'
Three monitors (selection mode)
Displays monitor list:
$ mons
Monitors: 3
Mode: Selection
0:* LVDS-1   (enabled)
1: DP-1      (enabled)
5: VGA-1

You may need to display only the third one:
$ mons -O 5

You may need to display the first and the third one on the right:
$ mons -S 0,5:R

Like above but you want to inverse the placement:
$ mons -S 5,0:R

DPI value
You might want to switch mode and set the DPI value.
Use the --dpi <dpi> option in conjunction with all others options.
$ mons [OPTIONS] --dpi <dpi>

Primary monitor
You might choose one of your monitors as the main one.
You can use the --primary <mon_name> option alone or in conjunction with all
others options.
<mon_name> refers to the monitor name that appears in the list of connected
monitors (ex: LVDS-1 or VGA-1):
$ mons
Monitors: 3
Mode: Primary
0:* LVDS-1   (enabled)
5:  VGA-1

The * character means that the monitor is the primary one:
$ mons --primary VGA-1
Monitors: 3
Mode: Primary
0:  LVDS-1   (enabled)
5:* VGA-1

Daemon mode
This mode is useful for laptops. After unplugging all monitors except the last
one, mons's ""daemon"" mode will reset the display and enable the latter.
Use case: ""I connect a monitor to my laptop and I only want to work with that
one, so I disable the native one. After a while, I will unplug the
additional monitor and I need reset my display to re-activate the native one.""

Run it as following:

$ nohup mons -a > /dev/null 2>&1 &  (all shells)
$ mons -a &!                        (zsh)
$ mons -a &; disown                 (bash)

You can handle N-monitors on your own by using the -x option. mons will
export the ${MONS_NUMBER} environment variable and run the given Shell script
everytime the number of connected monitors changes:

$ mons -a -x ""<path>/generic-handler.sh""

# Use it as configuration profiles:
$ mons -a -x ""<path>/home-profile.sh""
$ mons -a -x ""<path>/work-profile.sh""

Example of script.sh:

#!/bin/sh

case ${MONS_NUMBER} in
    1)
        mons -o
        feh --no-fehbg --bg-fill ""${HOME}/wallpapers/a.jpg""
        ;;
    2)
        mons -e top
        feh --no-fehbg --bg-fill ""${HOME}/wallpapers/a.jpg"" \
                       --bg-fill ""${HOME}/wallpapers/b.jpg""
        ;;
    *)
        # Handle it manually
        ;;
esac








About

      POSIX Shell script to quickly manage monitors on X
    
Topics



  xrandr


  manage


  monitor


  screen


  laptop


  display


  arch-linux


  linux


  ubuntu


  posix


  projector



Resources



      Readme
 
License



        MIT License
    







    Releases
      5





v0.8.2

          Latest
 
Jan 9, 2018

 

        + 4 releases







    Packages 0


        No packages published 













    Contributors 7





 



 



 



 



 



 



 





Languages









Shell
94.3%





Makefile
5.7%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# mons

> A tool to quickly manage two displays.
> More information: <https://github.com/Ventto/mons>.

- Enable only the primary monitor:

`mons -o`

- Enable only the secondary monitor:

`mons -s`

- Duplicate the primary monitor onto the secondary monitor, using the resolution of the primary monitor:

`mons -d`

- Mirror the primary monitor onto the secondary monitor, using the resolution of the secondary monitor:

`mons -m`
"
dmidecode,,,,"# dmidecode

> Display the DMI (alternatively known as SMBIOS) table contents in a human-readable format.
> Requires root privileges.

- Show all DMI table contents:

`sudo dmidecode`

- Show the BIOS version:

`sudo dmidecode -s bios-version`

- Show the system's serial number:

`sudo dmidecode -s system-serial-number`

- Show BIOS information:

`sudo dmidecode -t bios`

- Show CPU information:

`sudo dmidecode -t processor`

- Show memory information:

`sudo dmidecode -t memory`
"
apt-cache,,,,"# apt-cache

> Debian and Ubuntu package query tool.

- Search for a package in your current sources:

`apt-cache search {{query}}`

- Show information about a package:

`apt-cache show {{package}}`

- Show whether a package is installed and up to date:

`apt-cache policy {{package}}`

- Show dependencies for a package:

`apt-cache depends {{package}}`

- Show packages that depend on a particular package:

`apt-cache rdepends {{package}}`
"
powertop,,,,"# powertop

> Optimize battery power usage.

- Calibrate power usage measurements:

`sudo powertop --calibrate`

- Generate HTML power usage report in the current directory:

`sudo powertop --html={{power_report.html}}`

- Tune to optimal settings:

`sudo powertop --auto-tune`
"
a2query,https://manpages.debian.org/buster/apache2/a2query.1.en.html,"



a2query(1) — apache2 — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / apache2
     
     
     
     / a2query(1)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


EXIT CODES


SEE ALSO


AUTHOR







other versions




buster 2.4.38-3+deb10u3


buster-backports 2.4.46-1~bpo10+1


testing 2.4.46-1


unstable 2.4.46-1






Scroll to navigation



A2QUERY.IN(1)
User Contributed Perl Documentation
A2QUERY.IN(1)





NAME¶
a2query - retrieve runtime configuration from a local Apache 2 HTTP server


SYNOPSIS¶
a2query [-m [MODULE]] [-s [SITE]] [-c [CONF]] [-a]
  [-v] [-M] [-d] [-h]


DESCRIPTION¶
a2query is a program designed to retrieve configuration values from a
  locally available Apache 2 HTTP web server. It was designed to be as robust as
  possible by returning feasible values even if the Apache 2 syntax validator
  fails.
This program is primarily meant to be used from maintainer
    scripts.


OPTIONS¶

-a
Returns the Apache 2 ""Module Magic Version"" (API version)
      number, the server was compiled with. The returned version does not
      contain any minor versions which are known to be compatible with the major
      version returned.
-c [CONF]
Checks whether the configuration CONF is enabled. If no argument
      was given, all enabled configuration files are being returned. CONF
      is compared by string comparison by ignoring a leading ""mod_""
      prefix and possibly a '.conf' or '.load' suffix.
-h
Displays a brief summary how the program can be called and exits.
-m [MODULE]
Checks whether the module MODULE is enabled, The argument is
      interpreted in the same way, as for configuration files queried by the -c
      switch.
-M
Returns the currently enabled Apache 2 MPM (Multi Processing Module).
-s [SITE]
Checks whether the module SITE is enabled, The argument is
      interpreted in the same way, as for configuration files queried by the -c
      switch.
-v
returns the currently installed Apache 2 HTTP server version
-q
suppress any output. This is useful to invoke a2query from another script.
      This is useful if only the return code is of interest.



EXIT CODES¶
a2query returns with a zero (0) exit status if the requested operation
  was effectuated successfully and with a non-zero status otherwise. In case of
  an error it leaves with error code 32 if a requested module, site or
  configuration was not found and 33 if a module, site or configuration was
  disabled by a maintainer script. However, exit status 1 is returned if the
  module was not found at all


SEE ALSO¶
apache2ctl(8), apache2(8), perl(1)


AUTHOR¶
This manual and a2query was written by Arno Toell <debian@toell.net>.




2019-10-15
perl v5.28.1









Source file:


a2query.1.en.gz (from apache2 2.4.38-3+deb10u3)




Source last updated:


2019-10-15T19:53:42Z




Converted to HTML:


2020-09-01T03:18:55Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# a2query

> Retrieve runtime configuration from Apache on Debian-based OSes.
> More information: <https://manpages.debian.org/buster/apache2/a2query.1.en.html>.

- List enabled Apache modules:

`sudo a2query -m`

- Check if a specific module is installed:

`sudo a2query -m {{module_name}}`

- List enabled virtual hosts:

`sudo a2query -s`

- Display the currently enabled Multi Processing Module:

`sudo a2query -M`

- Display the Apache version:

`sudo a2query -v`
"
xbps,https://github.com/void-linux/xbps,"













GitHub - void-linux/xbps: The X Binary Package System








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















void-linux

/

xbps







    Watch
 
      29
    




      Star


      285
    




          Fork


        57
      





        The X Binary Package System
      



voidlinux.org/xbps/





            View license
        




285
        stars
 

57
        forks
 




      Star





    Watch









Code

 



Issues
37
 



Pull requests
27
 



Actions

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



90
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




Duncaen

tests: new test case for updating ""unpacked"" packages



…



05ff04a

Jul 17, 2020





tests: new test case for updating ""unpacked"" packages


05ff04a



Git stats





3,618
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.github/workflows


 


 







bin


 


 







data


 


 







doc


 


 







include


 


 







lib


 


 







mk


 


 







tests


 


 







.gitignore


 


 







.travis.yml


 


 







3RDPARTY


 


 







AUTHORS


 


 







LICENSE


 


 







LICENSE.3RDPARTY


 


 







Makefile


 


 







NEWS


 


 







README.md


 


 







TODO


 


 







configure


 


 







run-tests


 


 





        View code
      







        README.md
      







XBPS
The X Binary Package System (in short XBPS) is a binary package system
designed and implemented from scratch. Its goal is to be fast, easy to use,
bug-free, featureful and portable as much as possible.
The XBPS code is totally compatible with POSIX/SUSv2/C99 standards, and
released with a Simplified BSD license (2 clause). There is a well
documented API provided by the XBPS Library that is the basis for its frontends
to handle binary packages and repositories. Some highlights:

Supports multiple local/remote repositories (HTTP/HTTPS/FTP).
RSA signed remote repositories (NEW in 0.27).
Supports multiple compression formats for repositories:
gzip (zlib), bzip2, lz4, xz, zstd (default).
Supports multiple compression formats for package archives:
gzip (zlib), bzip2, lz4, xz, zstd (default).
SHA256 hashes for package metadata, files and binary packages.
Supports package states (ala dpkg) to mitigate broken package
installs/updates.
Ability to resume partial package install/updates.
Ability to unpack only files that have been modified in package updates.
Ability to use virtual packages.
Ability to ignore completely any number of packages in dependency resolution.
Ability to check for incompatible shared libraries in reverse
dependencies.
Ability to update reverse dependencies of any number of packages or globally
in a single transaction.
Ability to replace packages.
Ability to put packages on hold (to never update them. NEW in 0.16).
Ability to preserve/update configuration files.
Ability to force reinstallation of any installed package.
Ability to downgrade any installed package.
Ability to execute pre/post install/remove/update scriptlets.
Ability to check package integrity: missing files, hashes, missing or
unresolved (reverse)dependencies, dangling or modified symlinks, etc.

XBPS contains an almost complete test suite, currently with ~200 test cases,
and its number is growing daily! If you find any issue and you can reproduce it,
we will fix it and a new test case will be created. No more regressions!
XBPS is brought to you by:

Juan Romero Pardines (main author)
Enno Boland
Duncan Overbruck

and many other contributors in the free community that have helped improving it.
See the AUTHORS file for a complete list of contributors.
Thanks to all who have contributed.
Build requirements
To build this you'll need:

A C99 compiler (clang, gcc, pcc, tcc)
A POSIX compatible shell
GNU make
pkgconf
zlib
openssl or libressl
libarchive >= 3.3.3 with lz4 and zstd support.

and optionally:

graphviz and doxygen
(--enable-api-docs) to build API documentation.
atf >= 0.15 (--enable-tests) to build the
Kyua test suite.

Building and testing for dummies
$ git clone https://github.com/void-linux/xbps
$ cd xbps
$ ./configure --enable-rpath --prefix=/usr --sysconfdir=/etc
$ make -j$(nproc)
$ make DESTDIR=~/xbps-git install clean
$ export PATH=~/xbps-git/usr/bin:$PATH
$ xbps-query -V
...

Thanks to --enable-rpath you can install it anywhere and it will still use
the libxbps shared library at $ORIGIN/../lib, that means that if xbps
is installed to $HOME/xbps-git/usr, the executables will use
$HOME/xbps-git/usr/lib to locate libxbps.
Happy testing!
Tests
To run the test suite make sure kyua is installed and run the following:
$ ./configure --enable-tests
$ make
$ make check

Build instructions
Standard configure script (not generated by GNU autoconf).
$ ./configure --prefix=/blah
$ make -jX
$ make install

By default PREFIX is set /usr/local and may be changed by setting --prefix
in the configure script. The DESTDIR variable is also supported at the
install stage.
There are some more options that can be tweaked, see them with
./configure --help.
Good luck!
Binaries
Binaries for Linux compiled statically with the musl C library are available:

aarch64
armv6hf
i686
x86_64
mips32

These builds are available on all official void mirrors, along with their
sha256 checksums.
Usage instructions
The xbps package includes the following utilities (among others, not a complete list):

xbps-create (1)      - XBPS utility to create binary packages
xbps-dgraph (1)      - XBPS utility to generate dot(1) graphs
xbps-install (1)     - XBPS utility to install and update packages
xbps-pkgdb (1)       - XBPS utility to report and fix issues in pkgdb
xbps-query (1)       - XBPS utility to query for package and repository information
xbps-reconfigure (1) - XBPS utility to configure installed packages
xbps-remove (1)      - XBPS utility to remove packages
xbps-rindex (1)      - XBPS utility to handle local binary package repositories

In the following sections there will be a brief description of how these utilities currently work.
Package expressions
In the following examples there will be commands accepting an argument such as <package expression>. A package expression is a form to match a pattern; currently XBPS >= 0.19 supports 3 ways to specify them:


by specifying a package name, i.e foo.


by specifying the exact package name and version, i.e foo-1.0_1.


by specifying a package name and version separated by any of the following version comparators:

< less than
> greater than
<= less or equal than
>= greater or equal than

Such example would be foo>=2.0 or blah-foo<=1.0.


Repositories
Repositories can be declared in a configuration file of the configuration or system configuration directories:

<sysconfdir>/xbps.d - The configuration directory (set to /etc/xbps.d)
<sharedir>/xbps.d - The system directory (set to /usr/share/xbps.d)

A configuration file bearing the same filename in /etc/xbps.d overrides the one from <sharedir>/xbps.d.
By default the XBPS package provides only the main Void repository in the /usr/share/xbps.d/00-repository-main.conf file.
Additional repositories can be added by installing any of the following XBPS packages or creating new configuration files manually:
$ xbps-query -Rs void-repo
[*] void-repo-debug-3_1            Void Linux drop-in file for the debug repository
[*] void-repo-multilib-3_1         Void Linux drop-in file for the multilib repository
[*] void-repo-multilib-nonfree-3_1 Void Linux drop-in file for the multilib/nonfree repository
[*] void-repo-nonfree-3_1          Void Linux drop-in file for the nonfree repository
$


Repositories specified in the configuration directory are added to the head of the list, while repositories specified via system configuration directories are appended to the existing list.


If no repositories are found it's possible to declare them manually via the command line option --repository, currently accepted in xbps-install(1) and xbps-query(1).

xbps-query - querying packages and repositories

xbps-query(1) will try to match <package expression> in local packages. This behaviour
can be changed by enabling the -R or --repository option to force repository mode.

To query the list of installed packages:
$ xbps-query -l

To query the list of working repositories:
$ xbps-query -L

To query the list of installed packages that were installed manually (not as dependencies):
$ xbps-query -m

To query the list of packages on hold (won't be upgraded automatically):
$ xbps-query -H

To query the list of installed package orphans (packages that were installed as dependencies but there is not any package currently that requires it):
$ xbps-query -O

To query a package and show its meta information:
$ xbps-query <package expression>


Additionally the -p or --property option can be used to only show a specific key of a package:

$ xbps-query --property=pkgver xbps
xbps-0.19_1
$


Multiple properties can be specified by delimiting them with commas, i.e -p key,key2.

To query a package and show its file list:
$ xbps-query -f <package expression>

To query a package and show required run-time dependencies:
$ xbps-query -x <package expression>

To query a package and show required reverse run-time dependencies:
$ xbps-query -X <package expression>

To query for packages matching a file with specified pattern(s) (ownedby mode):
$ xbps-query -o <pattern>


Where <pattern> is a shell wildcard pattern as explained in fnmatch(3); e.g ""*.png"".


Multiple <patterns> can be specified as arguments.

To query for packages matching pkgname/version/description with specified pattern(s) (search mode):
$ xbps-query -s <pattern>


The same rules explained above in the ownedby mode shall be applied.

xbps-install - installing and updating packages
To synchronize remote repository index files:
$ xbps-install -S


The -S, --sync option can be combined while installing or updating packages, i.e xbps-install -Su.

To install a package:
$ xbps-install <package expression>

To install multiple packages at once:
$ xbps-install <package expression> <package expressions>

To update a single package:
$ xbps-install -u <package expression>

To update all packages (also known as dist-upgrade in Debian/Ubuntu):
$ xbps-install -u


The -n, --dry-run option can be used to print what packages will be updated and/or installed and doesn't need permissions in the target rootdir, which can be useful to list updates.

xbps-remove - removing packages
To remove a package:
$ xbps-remove <package name>

To recursively remove unneeded dependencies that were installed by the target package:
$ xbps-remove -R <package name>

To remove package orphans:
$ xbps-remove -o

To clean the cache directory and remove outdated packages and/or packages with wrong hash:
$ xbps-remove -O


To remove package orphans and clean the cache repository both options can be combined, i.e xbps-remove -Oo.

xbps-reconfigure - configure (or force configuration of) a package
The xbps-reconfigure(1) utility may be used to configure packages that were not previously
(perhaps due to a power outage, process killed, etc) or simply to force package
reconfiguration. By default and unless the -f, --force option is set, only packages that
were not configured will be processed.
Its usage is simple, specify a package name or a, --all for all packages:
$ xbps-reconfigure [-f] <package name> | -a

xbps-pkgdb - checking for errors in packages and pkgdb
The xbps-pkgdb(1) utility may be used to check for errors in packages and in the package database.
It is also used to update the package database format (if there have been changes). It works exactly the
same way as xbps-reconfigure(1) and expects a package name or -a, --all for all packages.
$ xbps-pkgdb <package name> | -a

To put a package on hold mode (won't be upgraded in dist-upgrade mode):
$ xbps-pkgdb -m hold <package name>

To remove a package from hold mode:
$ xbps-pkgdb -m unhold <package name>

To put a package in automatic mode (as it were installed as a dependency):
$ xbps-pkgdb -m auto <package name>

To put a package in manual mode (won't be detected as orphan):
$ xbps-pkgdb -m manual <package name>

To update the pkgdb format to the latest one:
$ xbps-pkgdb -u


NOTE: updating the pkgdb format does not happen too frequently, therefore it's only necessary in rare circumstances.

xbps-rindex - Create, update and administer local repositories
This command only has 3 operation modes:


Add [-a, --all]: adds the specified packages into the specified repository and removes previous entry if found:
 $ xbps-rindex -a /path/to/repository/*.xbps




The -f, --force option can be used to forcefully register a package into the repository index, even if the same version is already registered.



Clean [-c, --clean]: cleans the index of the specified repository by removing outdated or invalid entries (nonexistent packages, unmatched hashes, etc):
 $ xbps-rindex -c /path/to/repository



Remove-obsoletes [-r, --remove-obsoletes]: removes obsolete packages in repository (outdated, broken and unmatched hashes):
 $ xbps-rindex -r /path/to/repository



Examples
Upgrade all packages in the system, without asking for an answer:
# xbps-install -Syu

Clean the cache directory and remove package orphans:
# xbps-remove -Oo

Show information of a package available in repositories:
$ xbps-query -R xbps

Show filelist of a package available in repositories:
$ xbps-query -Rf xbps

Find the packages that own the file /bin/ls in repositories:
$ xbps-query -Ro /bin/ls

Make a package keepable (won't be detected as orphan):
# xbps-pkgdb -m manual xbps

Search for packages in repositories matching the xbps pattern in its pkgver and short_desc objects:
$ xbps-query -Rs xbps

Remove a package and all unnecessary dependencies that were installed:
# xbps-remove -R xbmc

Appending repositories via command line:
$ xbps-query --repository=<url> ...
# xbps-install --repository=<url> ...

Switch an installed package to on hold mode (won't be updated via xbps-install -u):
# xbps-pkgdb -m hold <pkgname>

Switch an installed package to the unhold mode (will be updated if there are updates):
# xbps-pkgdb -m unhold <pkgname>

Check for errors on installed packages and in pkgdb:
# xbps-pkgdb -a

Listing all files not managed by xbps:
#!/bin/sh

tmp=$(mktemp -dt xbps-disownedXXXXXX)
pkg=$tmp/pkg
fs=$tmp/fs

trap ""rm -rf $tmp"" EXIT

xbps-query -o \* | cut -d ' ' -f2 | sort > $pkg
find /boot /etc /opt /usr /var -xdev -type f -print | sort > $fs

comm -23 $fs $pkg








About

      The X Binary Package System
    



voidlinux.org/xbps/


Resources



      Readme
 
License



        View license
    







    Releases



90
tags







    Packages 0


        No packages published 













    Contributors 46





 



 



 



 



 



 



 



 



 



 



      + 35 contributors





Languages












C
73.8%





Shell
19.3%





Roff
5.3%





Makefile
1.4%





C++
0.2%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# xbps

> The X Binary Package System (or xbps) is the binary package system used by Void Linux.
> More information: <https://github.com/void-linux/xbps>.

- Install packages and synchronize them with the remote repository:

`xbps-install --synchronize {{package_name1}} {{package_name2}}`

- Search for a package in the remote repository:

`xbps-query --repository -s {{package_name}}`

- Remove a package, leaving all of its dependencies installed:

`xbps-remove {{package_name}}`

- Remove a package and all of its dependencies recursively that are not required by other packages:

`xbps-remove --recursive {{package_name}}`

- Synchronize your repository databases and update your system and dependencies:

`xbps-install --synchronize -u`

- Remove packages that were installed as dependencies and aren't currently needed:

`xbps-remove --remove-orphans`

- Remove obsolete packages from the cache:

`xbps-remove --clean-cache`
"
a2enconf,https://manpages.debian.org/buster/apache2/a2enconf.8.en.html,"



a2enconf(8) — apache2 — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / apache2
     
     
     
     / a2enconf(8)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


EXIT STATUS


EXAMPLES


FILES


SEE ALSO


AUTHOR







other versions




buster 2.4.38-3+deb10u3


buster-backports 2.4.46-1~bpo10+1


testing 2.4.46-1


unstable 2.4.46-1






Scroll to navigation



A2ENCONF(8)
System Manager's Manual
A2ENCONF(8)




NAME¶
a2enconf, a2disconf - enable or disable an apache2 configuration file


SYNOPSIS¶
a2enconf [ [-q|--quiet] configuration]
a2disconf [ [-q|--quiet] configuration]


DESCRIPTION¶
This manual page documents briefly the a2enconf and a2disconf
  commands.
a2enconf is a script that enables the specified
    configuration file within the apache2 configuration. It does this by
    creating symlinks within /etc/apache2/conf-enabled. Likewise,
    a2disconf disables a specific configuration part by removing those
    symlinks. It is not an error to enable a configuration which is already
    enabled, or to disable one which is already disabled.
Note that many configuration file may have a dependency to
    specific modules. Unlike module dependencies, these are not resolved
    automatically. Configuration fragments stored in the conf-available
    directory are considered non-essential or being installed and manged by
    reverse dependencies (e.g. web scripts).


OPTIONS¶

-q, --quiet
Don't show informative messages.
-m, --maintmode
Enables the maintainer mode, that is the program invocation is effectuated
      automatically by a maintainer script. This switch should not be used by
      end users.
-p, --purge
When disabling a module, purge all traces of the module in the internal
      state data base.



EXIT STATUS¶
a2enconf and a2disconf exit with status 0 if all
  configurations are processed successfully, 1 if errors occur, 2 if an
  invalid option was used.


EXAMPLES¶
a2enconf security

a2disconf charset
Enables Apache security directives stored in the security
    configuration files, and disables the charset configuration.


FILES¶

/etc/apache2/conf-available
Directory with files giving information on available configuration
    files.
/etc/apache2/conf-enabled
Directory with links to the files in conf-available for enabled
      configuration files.



SEE ALSO¶
apache2ctl(8), a2enmod(8), a2dismod(8).


AUTHOR¶
This manual page was written by Arno Toell <debian@toell.net> for the
  Debian GNU/Linux distribution, as it is a Debian-specific script with the
  package.




14 February 2012










Source file:


a2enconf.8.en.gz (from apache2 2.4.38-3+deb10u3)




Source last updated:


2019-10-15T19:53:42Z




Converted to HTML:


2020-09-01T03:18:55Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# a2enconf

> Enable an Apache configuration file on Debian-based OSes.
> More information: <https://manpages.debian.org/buster/apache2/a2enconf.8.en.html>.

- Enable a configuration file:

`sudo a2enconf {{configuration_file}}`

- Don't show informative messages:

`sudo a2enconf --quiet {{configuration_file}}`
"
netselect,https://github.com/apenwarr/netselect,"













GitHub - apenwarr/netselect: A parallelizing combination of ping/traceroute








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















apenwarr

/

netselect







    Watch
 
      8
    




      Star


      95
    




          Fork


        17
      





        A parallelizing combination of ping/traceroute
      



95
        stars
 

17
        forks
 




      Star





    Watch









Code

 



Issues
2
 



Pull requests
2
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



4
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit



 
 
Git stats





10
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






netinet


 


 







.cvsignore


 


 







.gitignore


 


 







HISTORY


 


 







Makefile


 


 







README


 


 







README.OS2


 


 







README.traceroute


 


 







netselect-apt


 


 







netselect-apt.1


 


 







netselect.1


 


 







netselect.c


 


 





        View code
      







        README
      



netselect 0.3
=============

This is netselect, an ultrafast intelligent parallelizing binary-search
implementation of ""ping.""

Now stop laughing and pay attention.

netselect determines several facts about all of the hosts given on the
command line, much faster you would if you manually tried to use ping and
traceroute.  For example, if I type:

	netselect -vv ftp.fceia.unr.edu.ar ftp.kulnet.kuleuven.ac.be \
			ftp.cdrom.com ftp.debian.org ftp.de.debian.org
			
It tells me this:

ftp.fceia.unr.edu.ar                  2792 ms  23 hops  100% ok ( 1/ 1) [ 9213]
ftp.kulnet.kuleuven.ac.be             9999 ms  30 hops    0% ok
ftp.cdrom.com                           94 ms   8 hops  100% ok (10/10) [  169]
ftp.debian.org                          46 ms  15 hops  100% ok (10/10) [  115]
ftp.de.debian.org                     9999 ms  30 hops    0% ok
  115 ftp.debian.org
  
For each host, it figures out the approximate ping time (though not as
accurately as ""ping"" does), the number of network ""hops"" to reach the
target, and the percentage of ping requests that got through successfully. 

The value in brackets is the ""score"" of each operational host based on these
values.  A lower score is better.  The last line shows the server with the
best score.  If we had not used '-vv' on the command line, only this last
line would have been printed.

Note that for ftp.kulnet.kuleuven.ac.be and ftp.de.debian.org in this case,
nothing got through at all.  That indicates that either the host doesn't
exist, or it is down.

For a bigger example, try netselect-apt to build your own sources.list for apt
with the (possibily) fastest debian mirror.


But Why?
========

Why do I want to know about my ping times to computers in Belgium?  Well,
the main reason for netselect -- and its name gives you a hint -- is to help
choose the ""best"" server for you from among a (possibly very large) list.

Starting with version 0.2, netselect can make these decisions for you using
its scoring mechanism.  If you want, however, you can still pass the raw
results and score the servers as you like.  Try this, for example:

	netselect -vv -s 0 $(cat <your_list_of_sites>)
	
The ""-s 0"" option disables printing of scores at the bottom of the list, and
""-vv"" enables printing of the statistics.


How does it work?
=================

First:

 - decode each hostname into an IP address, and stores each IP address into
   a table.  In netselect 0.2, this code was rewritten to resolve hostnames
   much more quickly than before.
   
Now for all hosts at once:
   
 - start firing UDP packets with ""random-guess"" TTL values, much like
   traceroute does.  Actually, the code for this is derived from traceroute.
   
 - if an ""ICMP TTL Expired"" message comes back, then the TTL was too low:
   the host is farther away than that.  Increase TTL next time.  Otherwise,
   a ""Port Unreachable"" message comes back, meaning the TTL was large
   enough.  Try a smaller one.  We do this until we narrow down the TTL. 
   (This is where the ""binary search"" comes in.)
   
 - Meanwhile, collect timing statistics for all packets that reached the
   host.  Packets that don't come back are considered lost.

When all the hosts have had their TTL values narrowed down, and the ""-t""
minimum tries have expired, we're done.  Close the sockets and dump
the statistics to stdout.



Command-line Options
====================

Not much right now.  

	-v	-- verbose mode.  Displays nameserver resolution messages to
		   stderr.  You probably want this so that you don't get
		   bored waiting for a hundred name resolutions to finish.
		   
	-vv	-- very verbose mode.  Displays nameserver resolution and
		   statistics (not just scores) to stderr and stdout.
		   
	-vvv	-- very very verbose mode.  Everything -vv prints, plus
		   print every packet received as it happens.  Good for
		   debugging or trying to figure out how it works.
	
	-vvvv   -- very very very verbose mode. Everything -vvv prints,
		   plus a trace of all packets sent.
		   
	-m #	-- maximum ttl.  Don't accept hosts with more hops than
		   this.
		   
	-t #	-- make sure at least 50% of the hosts get tested with this
		   many packets.  The more packets you use, the more
		   accurate the results... and the longer it takes to run.
		   The default is 10, which is usually okay.
	
	-s #	-- print this many ""top-scoring"" servers at the end of
		   the list.  ""-s 0"" disables printing of high scores.


The Future
==========


Here are some possible improvements:

	- try to estimate line bandwidth somehow.  The 'bing' program does
	  it using two different ping packet sizes.

	- try to improve 'ping time' estimate.  It's a problem right now
	  because netselect writes a lot of packets in a quick stream (for
	  speed reasons).  It's fair to each host, though:  they all put up
	  with an equal amount of lag :)

This program is highly experimental.  Please let me know what you think.

	- Avery Pennarun
	  <apenwarr@gmail.com>








About

      A parallelizing combination of ping/traceroute
    
Resources



      Readme
 






    Releases



4
tags







    Packages 0


        No packages published 











Languages








C
100.0%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# netselect

> Speed test for choosing a fast network server.
> More information: <https://github.com/apenwarr/netselect> .

- Choose the server with the lowest latency:

`sudo netselect {{host_1}} {{host_2}}`

- Display nameserver resolution and statistics:

`sudo netselect -vv {{host_1}} {{host_2}}`

- Define maximum TTL (time to live):

`sudo netselect -m {{10}} {{host_1}} {{host_2}}`

- Print fastest N servers among the hosts:

`sudo netselect -s {{N}} {{host_1}} {{host_2}} {{host_3}}`

- List available options:

`netselect`
"
mkfs.minix,,,,"# mkfs.minix

> Creates a Minix filesystem inside a partition.

- Create a Minix filesystem inside partition 1 on device b (`sdb1`):

`mkfs.minix {{/dev/sdb1}}`
"
debman,,,,"# debman

> Read man pages from uninstalled packages.

- Read a man page for a command that is provided by a specified package name:

`debman -p {{package_name}} {{command_name}}`

- Specify a package version to download:

`debman -p {{package_name}}={{version}} {{command_name}}`

- Read a man page in a .deb file:

`debman -f {{path/to/filename.deb}} {{command_name}}`
"
tlp-stat,,,,"# tlp-stat

> A tool to generate TLP status reports. See also `tlp`.

- Generate status report with configuration and all active settings:

`sudo tlp-stat`

- Show battery information:

`sudo tlp-stat -b`

- Show configuration:

`sudo tlp-stat -c`
"
bpytop,https://github.com/aristocratos/bpytop,"













GitHub - aristocratos/bpytop: Linux/OSX/FreeBSD resource monitor








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















aristocratos

/

bpytop








          Sponsor
        






              Sponsor aristocratos/bpytop
            












    Watch
 
      83
    




      Star


      2.7k
    




          Fork


        88
      





        Linux/OSX/FreeBSD resource monitor
      



            Apache-2.0 License
        




2.7k
        stars
 

88
        forks
 




      Star





    Watch









Code

 



Issues
18
 



Pull requests
0
 



Actions

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



38
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




aristocratos

v1.0.37 Bug fixes



…



c4fa23e

Sep 22, 2020





v1.0.37 Bug fixes


c4fa23e



Git stats





203
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.github



added psutil verion requirement



Aug 3, 2020







Imgs



v1.0.0 First release



Aug 2, 2020







themes



added email/theme name



Sep 10, 2020







.editorconfig



naming...



Aug 2, 2020







.gitignore



Added theme install and path detection



Aug 22, 2020







CHANGELOG.md



v1.0.37 Bug fixes



Sep 22, 2020







CODE_OF_CONDUCT.md



Init



Jul 1, 2020







CONTRIBUTING.md



Added NetBox draw function and added mouse support



Jul 20, 2020







LICENSE



Init



Jul 1, 2020







Makefile



v1.0.0 First release



Aug 2, 2020







README.md



Added mx-linux install instructions



Sep 20, 2020







bpytop-themes



Added theme install and path detection



Aug 22, 2020







bpytop.py



v1.0.37 Bug fixes



Sep 22, 2020







poetry.lock



Add psutil 5.7.2 (^5.7.0)



Aug 22, 2020







pyproject.toml



v1.0.37 Bug fixes



Sep 22, 2020





        View code
      






        README.md
      



















Index

Documents
Description
Features
Themes
Support and funding
Prerequisites
Dependencies
Screenshots
Installation
Configurability
TODO
License

Documents
CHANGELOG.md
CONTRIBUTING.md
CODE_OF_CONDUCT.md
Description
Resource monitor that shows usage and stats for processor, memory, disks, network and processes.
Python port of bashtop.
Features

Easy to use, with a game inspired menu system.
Full mouse support, all buttons with a highlighted key is clickable and mouse scroll works in process list and menu boxes.
Fast and responsive UI with UP, DOWN keys process selection.
Function for showing detailed stats for selected process.
Ability to filter processes, multiple filters can be entered.
Easy switching between sorting options.
Send SIGTERM, SIGKILL, SIGINT to selected process.
UI menu for changing all config file options.
Auto scaling graph for network usage.
Shows message in menu if new version is available
Shows current read and write speeds for disks

Themes
Bpytop uses the same theme files as bashtop so any theme made for bashtop will work.
See themes folder for available themes.
The make install command places the default themes in /usr/local/share/bpytop/themes.
If installed with pip3 the themes will be located in a folder called bpytop-themes in the python3 site-packages folder.
User created themes should be placed in $HOME/.config/bpytop/themes.
Let me know if you want to contribute with new themes.
Support and funding
You can sponsor this project through github, see my sponsors page for options.
Or donate through paypal or ko-fi.
Any support is greatly appreciated!
Prerequisites
Mac Os X
Will not display correctly in the standard terminal!
Recommended alternative iTerm2
Will also need to be run as superuser to display stats for processes not owned by user.
Linux, Mac Os X and FreeBSD
For correct display, a terminal with support for:

24-bit truecolor (See list of terminals with truecolor support)
Wide characters (Are sometimes problematic in web-based terminals)

Also needs a UTF8 locale and a font that covers:

Unicode Block “Braille Patterns” U+2800 - U+28FF
Unicode Block “Geometric Shapes” U+25A0 - U+25FF
Unicode Block ""Box Drawing"" and ""Block Elements"" U+2500 - U+259F

Notice
If you are having problems with the characters in the graphs not looking like they do in the screenshots,
it's likely a problem with your systems configured fallback font not having support for braille characters.
See comments by @sgleizes link and @XenHat link in issue #100 for possible solutions.
Notice
Dropbear seems to not be able to set correct locale. So if accessing bpytop over ssh, OpenSSH is recommended.
Dependencies
Python3 (v3.6 or later)
psutil module (v5.7.0 or later)
Optionals for additional stats
(Optional OSX) coretemp (recommended), or osx-cpu-temp (less accurate) needed to show CPU temperatures.
Screenshots
Main UI showing details for a selected process.

Main UI in mini mode.

Main menu.

Options menu.

Installation
PyPi (will always have latest version)

Install or update to latest version

pip3 install bpytop --upgrade
Arch Linux
Available in the AUR as bpytop
https://aur.archlinux.org/packages/bpytop/
Debian based
Available for debian/ubuntu from Azlux's repository
FreeBSD package
Available in FreeBSD ports

Install pre-built package

sudo pkg install bpytop
Fedora/CentOS 8 package
Available in the Fedora and EPEL-8 repository.

Installation

sudo dnf install bpytop
Gentoo / Calculate Linux
Available from adrien-overlay

Installation

sudo emerge -av sys-process/bpytop
MX Linux
Available in the MX Test Repo as bpytop
Please use MX Package Installer MX Test Repo tab to install.
http://mxrepo.com/mx/testrepo/pool/test/b/bpytop/
Snap package
by @kz6fittycent
https://github.com/kz6fittycent/bpytop-snap

Install the package

sudo snap install bpytop

Give permissions

sudo snap connect bpytop:mount-observe
sudo snap connect bpytop:network-control
sudo snap connect bpytop:hardware-observe
sudo snap connect bpytop:system-observe
sudo snap connect bpytop:process-control
sudo snap connect bpytop:physical-memory-observe
The config folder will be located in ~/snap/bpytop/current/.config/bpytop
Manual installation
Dependencies installation Linux

Install python3 and git with a package manager of you choice


Install psutil python module (sudo might be required)

python3 -m pip install psutil
Dependencies installation OSX

Install homebrew if not already installed

/bin/bash -c ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)""

Install python3 if not already installed

brew install python3 git

Install psutil python module

python3 -m pip install psutil

Install optional dependency coretemp (recommended), or osx-cpu-temp (less accurate)

brew install hacker1024/hacker1024/coretemp
brew install osx-cpu-temp
Dependencies installation FreeBSD

Install with pkg and pip

sudo pkg install git python3 py37-psutil
Manual installation Linux, OSX and FreeBSD

Clone and install

git clone https://github.com/aristocratos/bpytop.git
cd bpytop
sudo make install

to uninstall it

sudo make uninstall
Configurability
All options changeable from within UI.
Config files stored in ""$HOME/.config/bpytop"" folder
bpytop.cfg: (auto generated if not found)
""/etc/bpytop.conf"" will be used as default seed for config file creation if it exists.
#? Config file for bpytop v. 1.0.22

#* Color theme, looks for a .theme file in ""/usr/[local/]share/bpytop/themes"" and ""~/.config/bpytop/themes"", ""Default"" for builtin default theme.
#* Prefix name by a plus sign (+) for a theme located in user themes folder, i.e. color_theme=""+monokai""
color_theme=""Default""

#* If the theme set background should be shown, set to False if you want terminal background transparency
theme_background=False

#* Set bpytop view mode, ""full"" for everything shown, ""proc"" for cpu stats and processes, ""stat"" for cpu, mem, disks and net stats shown.
view_mode=full

#* Update time in milliseconds, increases automatically if set below internal loops processing time, recommended 2000 ms or above for better sample times for graphs.
update_ms=2000

#* Processes sorting, ""pid"" ""program"" ""arguments"" ""threads"" ""user"" ""memory"" ""cpu lazy"" ""cpu responsive"",
#* ""cpu lazy"" updates top process over time, ""cpu responsive"" updates top process directly.
proc_sorting=""cpu lazy""

#* Reverse sorting order, True or False.
proc_reversed=False

#* Show processes as a tree
proc_tree=False

#* Use the cpu graph colors in the process list.
proc_colors=True

#* Use a darkening gradient in the process list.
proc_gradient=True

#* If process cpu usage should be of the core it's running on or usage of the total available cpu power.
proc_per_core=True

#* Show process memory as bytes instead of percent
proc_mem_bytes=True

#* Check cpu temperature, needs ""osx-cpu-temp"" on MacOS X.
check_temp=True

#* Draw a clock at top of screen, formatting according to strftime, empty string to disable.
draw_clock=""%X""

#* Update main ui in background when menus are showing, set this to false if the menus is flickering too much for comfort.
background_update=True

#* Custom cpu model name, empty string to disable.
custom_cpu_name=""""

#* Optional filter for shown disks, should be last folder in path of a mountpoint, ""root"" replaces ""/"", separate multiple values with comma.
#* Begin line with ""exclude="" to change to exclude filter, oterwise defaults to ""most include"" filter. Example: disks_filter=""exclude=boot, home""
disks_filter=""""

#* Show graphs instead of meters for memory values.
mem_graphs=True

#* If swap memory should be shown in memory box.
show_swap=True

#* Show swap as a disk, ignores show_swap value above, inserts itself after first disk.
swap_disk=True

#* If mem box should be split to also show disks info.
show_disks=True

#* Set fixed values for network graphs, default ""10M"" = 10 Mibibytes, possible units ""K"", ""M"", ""G"", append with ""bit"" for bits instead of bytes, i.e ""100mbit""
net_download=""100Mbit""
net_upload=""100Mbit""

#* Start in network graphs auto rescaling mode, ignores any values set above and rescales down to 10 Kibibytes at the lowest.
net_auto=True

#* Sync the scaling for download and upload to whichever currently has the highest scale
net_sync=False

#* If the network graphs color gradient should scale to bandwith usage or auto scale, bandwith usage is based on ""net_download"" and ""net_upload"" values
net_color_fixed=False

#* Show init screen at startup, the init screen is purely cosmetical
show_init=False

#* Enable check for new version from github.com/aristocratos/bpytop at start.
update_check=True

#* Set loglevel for ""~/.config/bpytop/error.log"" levels are: ""ERROR"" ""WARNING"" ""INFO"" ""DEBUG"".
#* The level set includes all lower levels, i.e. ""DEBUG"" will show all logging info.
log_level=WARNING

Command line options:
USAGE: bpytop [argument]

Arguments:
    -f, --full            Start in full mode showing all boxes [default]
    -p, --proc            Start in minimal mode without memory and net boxes
    -s, --stat            Start in minimal mode without process box
    -v, --version         Show version info and exit
    -h, --help            Show this help message and exit
    --debug               Start with loglevel set to DEBUG overriding value set in config

TODO


 Add gpu temp and usage.


 Add cpu and mem stats for docker containers. (If feasible)


 Change process list to line scroll instead of page change.


 Add options for resizing all boxes.


 Add command line argument parsing.


 Miscellaneous optimizations and code cleanup.


LICENSE
Apache License 2.0








About

      Linux/OSX/FreeBSD resource monitor
    
Resources



      Readme
 
License



        Apache-2.0 License
    







    Releases



38
tags





Sponsor this project



 


 Sponsor
        

  Learn more about GitHub Sponsors







    Packages 0


        No packages published 













    Contributors 11





 



 



 



 



 



 



 



 



 



 



 





Languages









Python
99.7%





Makefile
0.3%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# bpytop

> Display dynamic real-time information about running processes with graphs. Similar to `gtop` and `htop`.
> More information: <https://github.com/aristocratos/bpytop>.

- Start bpytop:

`bpytop`

- Start in minimal mode without memory and networking boxes:

`bpytop -m`

- Show version:

`bpytop -v`

- Toggle minimal mode:

`m`

- Search for running programs or processes:

`f`

- Change settings:

`M`
"
losetup,,,,"# losetup

> Set up and control loop devices.

- List loop devices with detailed info:

`losetup -a`

- Attach a file to a given loop device:

`sudo losetup /dev/{{loop}} /{{path/to/file}}`

- Attach a file to a new free loop device and scan the device for partitions:

`sudo losetup --show --partscan -f /{{path/to/file}}`

- Attach a file to a read-only loop device:

`sudo losetup --read-only /dev/{{loop}} /{{path/to/file}}`

- Detach all loop devices:

`sudo losetup -D`

- Detach a given loop device:

`sudo losetup -d /dev/{{loop}}`
"
ldd,,,,"# ldd

> Display shared library dependencies.

- Display shared library dependencies of a binary:

`ldd {{path/to/binary}}`

- Display unused direct dependencies:

`ldd -u {{path/to/binary}}`
"
zgrep,,,"
GREP(1) 		  BSD General Commands Manual		       GREP(1)

NAME
     grep, egrep, fgrep, zgrep, zegrep, zfgrep -- file pattern searcher

SYNOPSIS
     grep [-abcdDEFGHhIiJLlmnOopqRSsUVvwxZ] [-A num] [-B num] [-C[num]]
	  [-e pattern] [-f file] [--binary-files=value] [--color[=when]]
	  [--colour[=when]] [--context[=num]] [--label] [--line-buffered]
	  [--null] [pattern] [file ...]

DESCRIPTION
     The grep utility searches any given input files, selecting lines that
     match one or more patterns.  By default, a pattern matches an input line
     if the regular expression (RE) in the pattern matches the input line
     without its trailing newline.  An empty expression matches every line.
     Each input line that matches at least one of the patterns is written to
     the standard output.

     grep is used for simple patterns and basic regular expressions (BREs);
     egrep can handle extended regular expressions (EREs).  See re_format(7)
     for more information on regular expressions.  fgrep is quicker than both
     grep and egrep, but can only handle fixed patterns (i.e. it does not
     interpret regular expressions).  Patterns may consist of one or more
     lines, allowing any of the pattern lines to match a portion of the input.

     zgrep, zegrep, and zfgrep act like grep, egrep, and fgrep, respectively,
     but accept input files compressed with the compress(1) or gzip(1) com-
     pression utilities.

     The following options are available:

     -A num, --after-context=num
	     Print num lines of trailing context after each match.  See also
	     the -B and -C options.

     -a, --text
	     Treat all files as ASCII text.  Normally grep will simply print
	     ``Binary file ... matches'' if files contain binary characters.
	     Use of this option forces grep to output lines matching the spec-
	     ified pattern.

     -B num, --before-context=num
	     Print num lines of leading context before each match.  See also
	     the -A and -C options.

     -b, --byte-offset
	     The offset in bytes of a matched pattern is displayed in front of
	     the respective matched line.

     -C[num, --context=num]
	     Print num lines of leading and trailing context surrounding each
	     match.  The default is 2 and is equivalent to -A 2 -B 2.  Note:
	     no whitespace may be given between the option and its argument.

     -c, --count
	     Only a count of selected lines is written to standard output.

     --colour=[when, --color=[when]]
	     Mark up the matching text with the expression stored in
	     GREP_COLOR environment variable.  The possible values of when can
	     be `never', `always' or `auto'.

     -D action, --devices=action
	     Specify the demanded action for devices, FIFOs and sockets.  The
	     default action is `read', which means, that they are read as if
	     they were normal files.  If the action is set to `skip', devices
	     will be silently skipped.

     -d action, --directories=action
	     Specify the demanded action for directories.  It is `read' by
	     default, which means that the directories are read in the same
	     manner as normal files.  Other possible values are `skip' to
	     silently ignore the directories, and `recurse' to read them
	     recursively, which has the same effect as the -R and -r option.

     -E, --extended-regexp
	     Interpret pattern as an extended regular expression (i.e. force
	     grep to behave as egrep).

     -e pattern, --regexp=pattern
	     Specify a pattern used during the search of the input: an input
	     line is selected if it matches any of the specified patterns.
	     This option is most useful when multiple -e options are used to
	     specify multiple patterns, or when a pattern begins with a dash
	     (`-').

     --exclude
	     If specified, it excludes files matching the given filename pat-
	     tern from the search.  Note that --exclude patterns take priority
	     over --include patterns, and if no --include pattern is speci-
	     fied, all files are searched that are not excluded.  Patterns are
	     matched to the full path specified, not only to the filename com-
	     ponent.

     --exclude-dir
	     If -R is specified, it excludes directories matching the given
	     filename pattern from the search.	Note that --exclude-dir pat-
	     terns take priority over --include-dir patterns, and if no
	     --include-dir pattern is specified, all directories are searched
	     that are not excluded.

     -F, --fixed-strings
	     Interpret pattern as a set of fixed strings (i.e. force grep to
	     behave as fgrep).

     -f file, --file=file
	     Read one or more newline separated patterns from file.  Empty
	     pattern lines match every input line.  Newlines are not consid-
	     ered part of a pattern.  If file is empty, nothing is matched.

     -G, --basic-regexp
	     Interpret pattern as a basic regular expression (i.e. force grep
	     to behave as traditional grep).

     -H      Always print filename headers with output lines.

     -h, --no-filename
	     Never print filename headers (i.e. filenames) with output lines.

     --help  Print a brief help message.

     -I      Ignore binary files.  This option is equivalent to
	     --binary-file=without-match option.

     -i, --ignore-case
	     Perform case insensitive matching.  By default, grep is case sen-
	     sitive.

     --include
	     If specified, only files matching the given filename pattern are
	     searched.	Note that --exclude patterns take priority over
	     --include patterns.  Patterns are matched to the full path speci-
	     fied, not only to the filename component.

     --include-dir
	     If -R is specified, only directories matching the given filename
	     pattern are searched.  Note that --exclude-dir patterns take pri-
	     ority over --include-dir patterns.

     -J, --bz2decompress
	     Decompress the bzip2(1) compressed file before looking for the
	     text.

     -L, --files-without-match
	     Only the names of files not containing selected lines are written
	     to standard output.  Pathnames are listed once per file searched.
	     If the standard input is searched, the string ``(standard
	     input)'' is written.

     -l, --files-with-matches
	     Only the names of files containing selected lines are written to
	     standard output.  grep will only search a file until a match has
	     been found, making searches potentially less expensive.  Path-
	     names are listed once per file searched.  If the standard input
	     is searched, the string ``(standard input)'' is written.

     --mmap  Use mmap(2) instead of read(2) to read input, which can result in
	     better performance under some circumstances but can cause unde-
	     fined behaviour.

     -m num, --max-count=num
	     Stop reading the file after num matches.

     -n, --line-number
	     Each output line is preceded by its relative line number in the
	     file, starting at line 1.	The line number counter is reset for
	     each file processed.  This option is ignored if -c, -L, -l, or -q
	     is specified.

     --null  Prints a zero-byte after the file name.

     -O      If -R is specified, follow symbolic links only if they were
	     explicitly listed on the command line.  The default is not to
	     follow symbolic links.

     -o, --only-matching
	     Prints only the matching part of the lines.

     -p      If -R is specified, no symbolic links are followed.  This is the
	     default.

     -q, --quiet, --silent
	     Quiet mode: suppress normal output.  grep will only search a file
	     until a match has been found, making searches potentially less
	     expensive.

     -R, -r, --recursive
	     Recursively search subdirectories listed.

     -S      If -R is specified, all symbolic links are followed.  The default
	     is not to follow symbolic links.

     -s, --no-messages
	     Silent mode.  Nonexistent and unreadable files are ignored (i.e.
	     their error messages are suppressed).

     -U, --binary
	     Search binary files, but do not attempt to print them.

     -V, --version
	     Display version information and exit.

     -v, --invert-match
	     Selected lines are those not matching any of the specified pat-
	     terns.

     -w, --word-regexp
	     The expression is searched for as a word (as if surrounded by
	     `[[:<:]]' and `[[:>:]]'; see re_format(7)).

     -x, --line-regexp
	     Only input lines selected against an entire fixed string or regu-
	     lar expression are considered to be matching lines.

     -y      Equivalent to -i.	Obsoleted.

     -Z, -z, --decompress
	     Force grep to behave as zgrep.

     --binary-files=value
	     Controls searching and printing of binary files.  Options are
	     binary, the default: search binary files but do not print them;
	     without-match: do not search binary files; and text: treat all
	     files as text.

     --context[=num]
	     Print num lines of leading and trailing context.  The default is
	     2.

     --line-buffered
	     Force output to be line buffered.	By default, output is line
	     buffered when standard output is a terminal and block buffered
	     otherwise.

     If no file arguments are specified, the standard input is used.

ENVIRONMENT
     GREP_OPTIONS  May be used to specify default options that will be placed
		   at the beginning of the argument list.  Backslash-escaping
		   is not supported, unlike the behavior in GNU grep.

EXIT STATUS
     The grep utility exits with one of the following values:

     0	   One or more lines were selected.
     1	   No lines were selected.
     >1    An error occurred.

EXAMPLES
     To find all occurrences of the word `patricia' in a file:

	   $ grep 'patricia' myfile

     To find all occurrences of the pattern `.Pp' at the beginning of a line:

	   $ grep '^\.Pp' myfile

     The apostrophes ensure the entire expression is evaluated by grep instead
     of by the user's shell.  The caret `^' matches the null string at the
     beginning of a line, and the `\' escapes the `.', which would otherwise
     match any character.

     To find all lines in a file which do not contain the words `foo' or
     `bar':

	   $ grep -v -e 'foo' -e 'bar' myfile

     A simple example of an extended regular expression:

	   $ egrep '19|20|25' calendar

     Peruses the file `calendar' looking for either 19, 20, or 25.

SEE ALSO
     ed(1), ex(1), gzip(1), sed(1), re_format(7)

STANDARDS
     The grep utility is compliant with the IEEE Std 1003.1-2008 (``POSIX.1'')
     specification.

     The flags [-AaBbCDdGHhIJLmoPRSUVwZ] are extensions to that specification,
     and the behaviour of the -f flag when used with an empty pattern file is
     left undefined.

     All long options are provided for compatibility with GNU versions of this
     utility.

     Historic versions of the grep utility also supported the flags [-ruy].
     This implementation supports those options; however, their use is
     strongly discouraged.

HISTORY
     The grep command first appeared in Version 6 AT&T UNIX.

BUGS
     The grep utility does not normalize Unicode input, so a pattern contain-
     ing composed characters will not match decomposed input, and vice versa.

BSD				 July 28, 2010				   BSD
","# zgrep

> Grep text patterns from files within compressed file (equivalent to grep -Z).

- Grep a pattern in a compressed file (case-sensitive):

`zgrep {{pattern}} {{path/to/compressed/file}}`

- Grep a pattern in a compressed file (case-insensitive):

`zgrep -i {{pattern}} {{path/to/compressed/file}}`

- Output count of lines containing matched pattern in a compressed file:

`zgrep -c {{pattern}} {{path/to/compressed/file}}`

- Display the lines which don’t have the pattern present (Invert the search function):

`zgrep -v {{pattern}} {{path/to/compressed/file}}`

- Grep a compressed file for multiple patterns:

`zgrep -e ""{{pattern_1}}"" -e ""{{pattern_2}}"" {{path/to/compressed/file}}`

- Use extended regular expressions (supporting `?`, `+`, `{}`, `()` and `|`):

`zgrep -E {{^regex$}} {{path/to/file}}`

- Print 3 lines of [C]ontext around, [B]efore, or [A]fter each match:

`zgrep -{{C|B|A}} {{3}} {{pattern}} {{path/to/compressed/file}}`
"
ksvgtopng5,,,,"# ksvgtopng5

> Convert SVG files to PNG format.

- Convert an SVG file (should be an absolute path) to PNG:

`ksvgtopng5 {{width}} {{height}} {{path/to/file.svg}} {{output_filename.png}}`
"
collectd,https://collectd.org/,"

Start page – collectd – The system statistics collection daemon











collectd


Homepage
Wiki














Navigation

Start page
Features
News
Download
FAQs
Documentation
Development
Contact
Related sites

[an error occurred while processing this directive]
              
Download

collectd-5.12.0.tar.bz2
collectd-5.11.0.tar.bz2
more …


[an error occurred while processing this directive]
              
Plugins

Apache
APC UPS
Apple Sensors
Ascent
Battery
BIND
ConnTrack
ContextSwitch
CPU
CPUFreq
CSV
cURL
cURL-JSON
cURL-XML
DBI
DF
Disk
DNS
E-Mail
Entropy
Exec
FileCount
FSCache
GenericJMX
gmond
hddtemp
Interface
IPMI
IP-Tables
IPVS
IRQ
Java
libvirt
Load
LogFile
MadWifi
MBMon
memcachec
memcached
Memory
Modbus
Monitorus
Multimeter
MySQL
NetApp
Netlink
Network
NFS
nginx
Notify Desktop
Notify Email
NTPd
NUT
olsrd
OneWire
OpenVPN
OpenVZ
Oracle
Perl
Pinba
Ping
PostgreSQL
PowerDNS
Processes
Protocols
Python
RouterOS
RRDCacheD
RRDtool
Sensors
Serial
SNMP
StatsD
Swap
SysLog
Table
Tail
Tape
tcpconns
TeamSpeak2
TED
thermal
TokyoTyrant
UnixSock
Uptime
Users
UUID
vmem
VServer
Wireless
XMMS
Write HTTP
ZFS ARC


[an error occurred while processing this directive]
              
News

2017-11-21
Version 5.8.0 available.
2017-10-06
Version 5.6.3 available.
2017-06-06
Version 5.7.2 available.
2017-01-23
Version 5.7.1 available.
2016-12-12
Version 5.7.0 available.





collectd – The system statistics collection daemon
collectd is a
              daemon which collects system
              and application performance metrics periodically and provides mechanisms to store the values in a variety
              of ways, for example in
              RRD files.

[an error occurred while processing this directive]

              
Collectd for Windows
http://ssc-serv.com/
High-resolution system metrics. Download free trial version!
Advertisement

What does collectd do?
collectd gathers metrics from various sources, e.g. the operating system,
              applications, logfiles and external devices, and stores this information or makes it available over the
              network.
              Those statistics can be used to monitor systems, find performance bottlenecks (i.e. performance
                analysis) and predict future system load (i.e. capacity planning). Or if you just want
              pretty graphs of your private server and are fed up with some homegrown solution you're at the right
              place, too ;).
A graph can say more than a thousand words, so here's a graph showing the 
              CPU utilization of a system over the last 60 minutes:

Why collectd?
There are other free, open source projects that are similar to
              collectd – a few links are listed on the
              related sites page. So why should you use
              collectd? There are some key differences we think set
              collectd apart. For one, it's written in C for performance and portability,
              allowing it to run on systems without scripting language or cron daemon, such as embedded systems.
              For example, collectd is popular on OpenWrt, a Linux distribution
              for home routers.
              At the same time it includes optimizations and features to handle hundreds of thousands of metrics.
              The daemon comes with
              over 100 plugins which range
              from standard cases to very specialized and advanced topics. It provides powerful networking features and
              is extensible in numerous ways. Last but not least: collectd is actively
              developed and supported and well documented. A more complete
              list of features is available.
Limitations
While collectd
can do a lot for you and your administrative needs,
              there are limits to what it does:

It does not generate graphs. It can write to RRD files, but it cannot generate graphs from these
                files. There's a tiny sample script included
                in contrib/, though. Take a look at
                kcollectd, an
                X frontend, and drraw, a very generic solution, though.
                More utility programs are listed on the
                related projects page.
Monitoring functionality has been added in version 4.3, but is so far limited to simple
                threshold checking. The document
                “Notifications and thresholds” describes
                collectd's monitoring concept and has some details on the limitations,
                too. Also, there's a plugin for Nagios, so it can use the values
                collected by collectd.


Imprint |
                Facebook |
                Github |
                 Google+
(Community) |
                identi.ca |
                Twitter |
                Xing












",,"# collectd

> System statistics collection daemon.
> More information: <https://collectd.org/>.

- Show usage help, including the program version:

`collectd -h`

- Test the configuration file and then exit:

`collectd -t`

- Test plugin data collection functionality and then exit:

`collectd -T`

- Start collectd:

`collectd`

- Specify a custom configuration file location:

`collectd -C {{path/to/file}}`

- Specify a custom PID file location:

`collectd -P {{path/to/file}}`

- Don't fork into the background:

`collectd -f`
"
csplit,,,"
CSPLIT(1)		  BSD General Commands Manual		     CSPLIT(1)

NAME
     csplit -- split files based on context

SYNOPSIS
     csplit [-ks] [-f prefix] [-n number] file args ...

DESCRIPTION
     The csplit utility splits file into pieces using the patterns args.  If
     file is a dash (`-'), csplit reads from standard input.

     The options are as follows:

     -f prefix
	     Give created files names beginning with prefix.  The default is
	     ``xx''.

     -k      Do not remove output files if an error occurs or a HUP, INT or
	     TERM signal is received.

     -n number
	     Use number of decimal digits after the prefix to form the file
	     name.  The default is 2.

     -s      Do not write the size of each output file to standard output as
	     it is created.

     The args operands may be a combination of the following patterns:

     /regexp/[[+|-]offset]
	     Create a file containing the input from the current line to (but
	     not including) the next line matching the given basic regular
	     expression.  An optional offset from the line that matched may be
	     specified.

     %regexp%[[+|-]offset]
	     Same as above but a file is not created for the output.

     line_no
	     Create containing the input from the current line to (but not
	     including) the specified line number.

     {num}   Repeat the previous pattern the specified number of times.  If it
	     follows a line number pattern, a new file will be created for
	     each line_no lines, num times.  The first line of the file is
	     line number 1 for historic reasons.

     After all the patterns have been processed, the remaining input data (if
     there is any) will be written to a new file.

     Requesting to split at a line before the current line number or past the
     end of the file will result in an error.

ENVIRONMENT
     The LANG, LC_ALL, LC_COLLATE and LC_CTYPE environment variables affect
     the execution of csplit as described in environ(7).

EXIT STATUS
     The csplit utility exits 0 on success, and >0 if an error occurs.

EXAMPLES
     Split the mdoc(7) file foo.1 into one file for each section (up to 20):

	   csplit -k foo.1 '%^\.Sh%' '/^\.Sh/' '{20}'

     Split standard input after the first 99 lines and every 100 lines there-
     after:

	   csplit -k - 100 '{19}'

SEE ALSO
     sed(1), split(1), re_format(7)

STANDARDS
     The csplit utility conforms to IEEE Std 1003.1-2001 (``POSIX.1'').

HISTORY
     A csplit command appeared in PWB UNIX.

BUGS
     Input lines are limited to LINE_MAX (2048) bytes in length.

BSD			       January 26, 2005 			   BSD
","# csplit

> Split a file into pieces.
> This generates files named ""xx00"", ""xx01"", and so on.

- Split a file at lines 5 and 23:

`csplit {{file}} {{5}} {{23}}`

- Split a file every 5 lines (this will fail if the total number of lines is not divisible by 5):

`csplit {{file}} {{5}} {*}`

- Split a file every 5 lines, ignoring exact-division error:

`csplit -k {{file}} {{5}} {*}`

- Split a file at line 5 and use a custom prefix for the output files:

`csplit {{file}} {{5}} -f {{prefix}}`

- Split a file at a line matching a regular expression:

`csplit {{file}} /{{regex}}/`
"
unix2dos,,,,"# unix2dos

> Change Unix-style line endings to DOS-style.
> Replaces CR with CRLF.

- Change the line endings of a file:

`unix2dos {{filename}}`

- Create a copy with DOS-style line endings:

`unix2dos -n {{filename}} {{new_filename}}`
"
xterm,,,,"# xterm

> A terminal emulator for the X Window System.

- Open the terminal with a title of `Example`:

`xterm -T {{Example}}`

- Open the terminal in fullscreen mode:

`xterm -fullscreen`

- Open the terminal with a dark blue background and yellow foreground (font color):

`xterm -bg {{darkblue}} -fg {{yellow}}`

- Open the terminal with 100 characters per line and 35 lines, in screen position x=200px, y=20px:

`xterm -geometry {{100}}x{{35}}+{{200}}+{{20}}`

- Open the terminal using a Serif font and a font size equal to 20:

`xterm -fa {{'Serif'}} -fs {{20}}`
"
phpenmod,,,,"# phpenmod

> Enable PHP extensions on Debian-based OSes.

- Enable the json extension for every SAPI of every PHP version:

`sudo phpenmod {{json}}`

- Enable the json extension for PHP 7.3 with the cli SAPI:

`sudo phpenmod -v {{7.3}} -s {{cli}} {{json}}`
"
scriptreplay,,,,"# scriptreplay

> Replay a typescript created by the `script` command to the standard output.

- Replay a typescript at the speed it was recorded:

`scriptreplay {{path/to/timing_file}} {{path/to/typescript}}`

- Replay a typescript at double the original speed:

`scriptreplay {{path/to/timingfile}} {{path/to/typescript}} 2`

- Replay a typescript at half the original speed:

`scriptreplay {{path/to/timingfile}} {{path/to/typescript}} 0.5`
"
disown,,,,"# disown

> Allow sub-processes to live beyond the shell that they are attached to.
> See also the `jobs` command.

- Disown the current job:

`disown`

- Disown a specific job:

`disown %{{job_number}}`

- Disown all jobs:

`disown -a`

- Keep job (do not disown it), but mark it so that no future SIGHUP is received on shell exit:

`disown -h %{{job_number}}`
"
netselect-apt,https://manpages.debian.org/buster/netselect-apt/netselect-apt.1.en.html,"



netselect-apt(1) — netselect-apt — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / netselect-apt
     
     
     
     / netselect-apt(1)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


ENVIRONMENT


LIMITATIONS


SEE ALSO


AUTHOR







other versions




buster 0.3.ds1-28


testing 0.3.ds1-28


unstable 0.3.ds1-28






Scroll to navigation



NETSELECT-APT(1)
General Commands Manual
NETSELECT-APT(1)





NAME¶
netselect-apt - create sources.list for the fastest Debian mirrors



SYNOPSIS¶
netselect-apt [OPTIONS]
  [stable|testing|unstable|experimental|release_codename|sid]



DESCRIPTION¶
netselect-apt automatically creates a sources.list file for using
  with apt for the specified distribution by downloading the list of
  Debian mirrors using wget choosing the fastest servers using
  netselect, and testing the valid servers using curl (if
  available). The output file is written to OUTFILE.
The list of fastest servers is determined by checking through
    netselect, which servers responder faster to ICMP queries. In order
    to determine if the servers are valid a connectiong using the specificied
    protocol (HTTP or FTP) is done using curl.
If netselect is not installed setuid, then
    netselect-apt needs to run as an administrator user (i.e. root). This
    is only required because the network probes done by netselect
    requires these permissions. No changes are done to the system.
If -i INFILE is passed netselect-apt uses
    that rather than downloading another copy to a temporary file. The file will
    be downloaded from http://www.debian.org/mirror/mirrors_full



OPTIONS¶

stable|testing|unstable|experimental|release_codename|sid
Specify which distribution of Debian to use. By default stable is
      used.
-a, --arch ARCH
Use mirrors containing ARCH. By default the architecture of the
      current machine is used as reported by dpkg
-s, --sources
While generating OUTFILE include also deb-src lines to use with
      ``apt-get source'' to obtain Debian source packages.
-i, --infile INFILE
Use INFILE instead of downloading the mirror list to a temporary
      file. The file must be in the same format as mirrors_full.
-o, --outfile OUTFILE
Use OUTFILE instead of sources.list.
-n, --nonfree
Include also non-free section while generating OUTFILE.
-f, --ftp
Use FTP mirrors instead of HTTP and generate OUTFILE
    accordingly.
-O OPTIONS
The OPTIONS provided are added, verbatim, to netselect when
      it is run. Here you can provide a (quoted) list of options for
    netselect.
-t, --tests hosts
Make a short list with the number of hosts provided and use that list to
      test for mirror validity. By default 10 hosts are tested.
-c, --country COUNTRY
Only test the sites found under the country COUNTRY (the value can
      either be an ISO-3166 value or the full name of the language, in English).
      When this value is set the mirror list or the INFILE will be
      filtered and only the sites that are listed under the given country will
      be tested. Note that restricting the search might not give the best
      results, as the ""fastest"" mirror might not even be in the same
      country as the system the program is running in.
    




ENVIRONMENT¶

WANT_SOURCES
setting this to 1 is equivalent to --sources
WANT_NONFREE
setting this to 1 is equivalent to --nonfree
    




LIMITATIONS¶
netselect-apt is unable to work with restricted environments in which
  network filtering is implemented as it relies on netselect being able
  to find a suitable mirror. To do this, the system where the script is run
  needs to have network visibility of the mirrors, as it will probe them using
  ICMP probes.
netselect-apt is also unable to work in environments where
    HTTP or FTP network connections have to be done through a proxy host, as it
    relies on being able to test the validity of the remote mirrors doing direct
    network connections to them.
netselect-apt will not check if the mirror it suggests as
    the ""fastest"" mirror is either valid or up-to-date. It is
    recommended that users that use this tool also validate that the mirrors
    suggested are official mirrors and are also current.




SEE ALSO¶
netselect(1), wget(1), curl(1), apt(8),
  sources.list(5).
For Debian GNU/Linux it is recommended that users review the
    official mirror list at http://www.debian.org/mirror/official as well as the
    mirror checker tool at http://mirror.debian.org/status.html (which provides
    information on the up-to-dateness status of mirrors)



AUTHOR¶
Avery Pennarun <apenwarr@gmail.com>
This manual page and program have been also enhanced by Filippo
    Giunchedi <filippo@esaurito.net> and Javier Fernandez-Sanguino
    <jfs@debian.org>





March 6, 2008
DEBIAN









Source file:


netselect-apt.1.en.gz (from netselect-apt 0.3.ds1-28)




Source last updated:


2016-06-15T00:19:23Z




Converted to HTML:


2020-08-08T10:03:42Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# netselect-apt

> Create a `sources.list` file for a Debian mirror with the lowest latency.
> More information: <https://manpages.debian.org/buster/netselect-apt/netselect-apt.1.en.html>.

- Create `sources.list` using the lowest latency server:

`sudo netselect-apt`

- Specify Debian branch, stable is used by default:

`sudo netselect-apt {{testing}}`

- Include non-free section:

`sudo netselect-apt --non-free`

- Specify a country for the mirror list lookup:

`sudo netselect-apt -c {{India}}`
"
iftop,https://linux.die.net/man/8/iftop,"

iftop(8): bandwidth usage on interface by host - Linux man page
















iftop(8) - Linux man page
Name
iftop - display bandwidth usage on an interface by host
Synopsis
iftop -h | [-nNpblBP] [-i interface] [-f filter code] [-F net/mask] [-G
net6/mask6]
Description





iftop listens to network traffic on a named interface, or on the first interface it can find which looks like an external interface if none is
specified, and displays a table of current bandwidth usage by pairs of hosts. iftop must be run with sufficient permissions to monitor all network
traffic on the interface; see pcap(3) for more information, but on most systems this means that it must be run as root.
By default, iftop will look up the hostnames associated with addresses it finds in packets. This can cause substantial traffic of itself, and may
result in a confusing display. You may wish to suppress display of DNS traffic by using filter code such as not port domain, or switch it off entirely,
by using the -n option or by pressing r when the program is running.
By default, iftop counts all IP packets that pass through the filter, and the direction of the packet is determined according to the direction the
packet is moving across the interface. Using the -F option it is possible to get iftop to show packets entering and leaving a given network. For
example, iftop -F 10.0.0.0/255.0.0.0 will analyse packets flowing in and out of the 10.* network.
Some other filter ideas:

not ether host ff:ff:ff:ff:ff:ff
Ignore ethernet broadcast packets.
port http and not host webcache.example.com
Count web traffic only, unless it is being directed through a local web cache.
icmp
How much bandwidth are users wasting trying to figure out why the network is slow?

Options

-h
Print a summary of usage.

-n
Don't do hostname lookups.

-N
Do not resolve port number to service names

-p
Run in promiscuous mode, so that traffic which does not pass directly through the specified interface is also counted.

-P
Turn on port display.

-l
Display and count datagrams addressed to or from link-local IPv6 addresses. The default is not to display that address category.

-b
Don't display bar graphs of traffic.

-B
Display bandwidth rates in bytes/sec rather than bits/sec.
-i interface
Listen to packets on interface.
-f filter code
Use filter code to select the packets to count. Only IP packets are ever counted, so the specified code is evaluated as (filter
code) and ip.
-F net/mask
Specifies an IPv4 network for traffic analysis. If specified, iftop will only include packets flowing in to or out of the given network, and packet
direction is determined relative to the network boundary, rather than to the interface. You may specify mask as a dotted quad, such as /255.255.255.0,
or as a single number specifying the number of bits set in the netmask, such as /24.
-G net6/mask6
Specifies an IPv6 network for traffic analysis. The value of mask6 can be given as a prefix length or as a numerical address string for more compound
bitmasking.
-c config file
Specifies an alternate config file. If not specified, iftop will use ~/.iftoprc if it exists. See below for a description of config
files

Display
When running, iftop uses the whole screen to display network usage. At the top of the display is a logarithmic scale for the bar graph which gives a
visual indication of traffic.
The main part of the display lists, for each pair of hosts, the rate at which data has been sent and received over the preceding 2, 10 and 40 second
intervals. The direction of data flow is indicated by arrows, <= and =>. For instance,
foo.example.com  =>  bar.example.com      1Kb  500b   100b
                 <=                       2Mb    2Mb    2Mbshows, on the first line, traffic from foo.example.com to bar.example.com; in the preceding 2 seconds, this averaged 1Kbit/s, around half that
amount over the preceding 10s, and a fifth of that over the whole of the last 40s. During each of those intervals, the data sent in the other direction was
about 2Mbit/s. On the actual display, part of each line is inverted to give a visual indication of the 10s average of traffic. You might expect to see
something like this where host foo is making repeated HTTP requests to bar, which is sending data back which saturates a 2Mbit/s link.

By default, the pairs of hosts responsible for the most traffic (10 second average) are displayed at the top of the list.
At the bottom of the display, various totals are shown, including peak traffic over the last 40s, total traffic transferred (after filtering), and total
transfer rates averaged over 2s, 10s and 40s.
SOURCE / DEST AGGREGATION
By pressing s or d while iftop is running, all traffic for each source or destination will be aggregated together. This is most useful
when iftop is run in promiscuous mode, or is run on a gateway machine.
Port Display
S or D toggle the display of source and destination ports respectively. p will toggle port display on/off.
Display Type
t cycles through the four line display modes; the default 2-line display, with sent and received traffic on separate lines, and 3 1-line displays,
with sent, received, or total traffic shown.
Display Order
By default, the display is ordered according to the 10s average (2nd column). By pressing 1, 2 or 3 it is possible to sort by the 1st,
2nd or 3rd column. By pressing < or > the display will be sorted by source or destination hostname respectively.
Display Filtering
l allows you to enter a POSIX extended regular expression that will be used to filter hostnames shown in the display. This is a good way to quickly
limit what is shown on the display. Note that this happens at a much later stage than filter code, and does not affect what is actually captured. Display
filters DO NOT affect the totals at the bottom of the screen.
PAUSE DISPLAY / FREEZE ORDER
P will pause the current display.
o will freeze the current screen order. This has the side effect that traffic between hosts not shown on the screen at the time will not be shown at
all, although it will be included in the totals at the bottom of the screen.
Scroll Display
j and k will scroll the display of hosts. This feature is most useful when the display order is frozen (see above).
Filter Code
f allows you to edit the filter code whilst iftop running. This can lead to some unexpected behaviour.
Config File
iftop can read its configuration from a config file. If the -c option is not specified, iftop will attempt to read its configuration from
~/.iftoprc, if it exists. Any command line options specified will override settings in the config file.
The config file consists of one configuration directive per line. Each directive is a name value pair, for example:
interface: eth0sets the network interface. The following config directives are supported:

interface: if
Sets the network interface to if.
dns-resolution: (yes|no)
Controls reverse lookup of IP addresses.
port-resolution: (yes|no)
Controls conversion of port numbers to service names.
filter-code: bpf
Sets the filter code to bpf.
show-bars: (yes|no)
Controls display of bar graphs.
promiscuous: (yes|no)
Puts the interface into promiscuous mode.
port-display: (off|source-only|destination-only|on)
Controls display of port numbers.
link-local: (yes|no)
Determines displaying of link-local IPv6 addresses.
hide-source: (yes|no)
Hides source host names.
hide-destination: (yes|no)
Hides destination host names.
use-bytes: (yes|no)
Use bytes for bandwidth display, rather than bits.
sort: (2s|10s|40s|source|destination)
Sets which column is used to sort the display.
line-display: (two-line|one-line-both|one-line-sent|one-line-received)
Controls the appearance of each item in the display.
show-totals: (yes|no)
Shows cumulative total for each item.
log-scale: (yes|no)
Use a logarithmic scale for bar graphs.
max-bandwidth: bw
Fixes the maximum for the bar graph scale to bw, e.g. ""10M"". Note that the value has to always be in bits, regardless if the option to display in
bytes has been chosen.
net-filter: net/mask
Defines an IP network boundary for determining packet direction.
net-filter6: net6/mask6
Defines an IPv6 network boundary for determining packet direction.
screen-filter: regexp
Sets a regular expression to filter screen output.

QUIRKS (aka they're features, not bugs)
There are some circumstances in which iftop may not do what you expect. In most cases what it is doing is logical, and we believe it is correct behaviour,
although I'm happy to hear reasoned arguments for alternative behaviour.
Totals don't add up
There are several reasons why the totals may not appear to add up. The most obvious is having a screen filter in effect, or screen ordering frozen. In this
case some captured information is not being shown to you, but is included in the totals.
A more subtle explanation comes about when running in promiscuous mode without specifying a -F option. In this case there is no easy way to assign
the direction of traffic between two third parties. For the purposes of the main display this is done in an arbitrary fashion (by ordering of IP addresses),
but for the sake of totals all traffic between other hosts is accounted as incoming, because that's what it is from the point of view of your interface. The
-F option allows you to specify an arbitrary network boundary, and to show traffic flowing across it.
Peak totals don't add up
Again, this is a feature. The peak sent and peak received didn't necessarily happen at the same time. The peak total is the maximum of sent plus received in
each captured time division.
Changing the filter code doesn't seem to work
Give it time. Changing the filter code affects what is captured from the time that you entered it, but most of what is on the display is based on some
fraction of the last 40s window of capturing. After changing the filter there may be entries on the display that are disallowed by the current filter for up to
40s. DISPLAY FILTERING has immediate effect and does not affect what is captured.
Files
~/.iftoprc

Configuration file for iftop.

See Also
tcpdump(8), pcap(3), driftnet(1).
Author
Paul Warren <pdw@ex-parrot.com>
Version
$Id: iftop.8,v 1.27 2010/11/27 11:06:12 pdw Exp $
Copying
This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software
Foundation; either version 2 of the License, or (at your option) any later version.
This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 675 Mass
Ave, Cambridge, MA 02139, USA.


Referenced By
dstat(1)








Site Search











Library
linux docs
linux man pages
page load time


Toys
world sunlight
moon phase
trace explorer







",,"# iftop

> Show bandwidth usage on an interface by host.
> More information: <https://linux.die.net/man/8/iftop>.

- Show the bandwidth usage:

`sudo iftop`

- Show the bandwidth usage of a given interface:

`sudo iftop -i {{interface}}`

- Show the bandwidth usage with port information:

`sudo iftop -P`

- Do not show bar graphs of traffic:

`sudo iftop -b`

- Do not look up hostnames:

`sudo iftop -n`

- Get help about interactive commands:

`?`
"
equery,,,,"# equery

> View information about Portage packages.

- List all installed packages:

`equery list '*'`

- Search for installed packages in the Portage tree and in overlays:

`equery list -po {{package_name}}`

- List all packages that depend on a given package:

`equery depends {{package_name}}`

- List all packages that a given package depends on:

`equery depgraph {{package_name}}`

- List all files installed by a package:

`equery files --tree {{package_name}}`
"
fuser,,,"FUSER(P)		   POSIX Programmer's Manual		      FUSER(P)



NAME
       fuser  -  list process IDs of all processes that have one or more files
       open

SYNOPSIS
       fuser [ -cfu ] file ...

DESCRIPTION
       The fuser utility shall write to standard output  the  process  IDs  of
       processes running on the local system that have one or more named files
       open. For block special devices, all processes using any file  on  that
       device are listed.

       The  fuser utility shall write to standard error additional information
       about the named files indicating how the file is being used.

       Any output for processes running on remote systems that	have  a  named
       file open is unspecified.

       A user may need appropriate privilege to invoke the fuser utility.

OPTIONS
       The  fuser  utility  shall  conform  to	the Base Definitions volume of
       IEEE Std 1003.1-2001, Section 12.2, Utility Syntax Guidelines.

       The following options shall be supported:

       -c     The file is treated as a	mount  point  and  the	utility  shall
	      report on any files open in the file system.

       -f     The report shall be only for the named files.

       -u     The  user  name, in parentheses, associated with each process ID
	      written to standard output shall be written to standard error.


OPERANDS
       The following operand shall be supported:

       file   A pathname on which the file or file system is to be reported.


STDIN
       Not used.

INPUT FILES
       The user database.

ENVIRONMENT VARIABLES
       The following environment  variables  shall  affect  the  execution  of
       fuser:

       LANG   Provide  a  default value for the internationalization variables
	      that are unset or null. (See  the  Base  Definitions  volume  of
	      IEEE Std 1003.1-2001,  Section  8.2,  Internationalization Vari-
	      ables for the precedence of internationalization variables  used
	      to determine the values of locale categories.)

       LC_ALL If  set  to a non-empty string value, override the values of all
	      the other internationalization variables.

       LC_CTYPE
	      Determine the locale for	the  interpretation  of  sequences  of
	      bytes  of  text  data as characters (for example, single-byte as
	      opposed to multi-byte characters in arguments).

       LC_MESSAGES
	      Determine the locale that should be used to  affect  the	format
	      and contents of diagnostic messages written to standard error.

       NLSPATH
	      Determine the location of message catalogs for the processing of
	      LC_MESSAGES .


ASYNCHRONOUS EVENTS
       Default.

STDOUT
       The fuser utility shall write the process ID  for  each	process  using
       each  file given as an operand to standard output in the following for-
       mat:


	      ""%d"", <process_id>

STDERR
       The fuser utility shall write diagnostic messages to standard error.

       The fuser utility also shall write the following to standard error:

	* The pathname of each named file is written followed immediately by a
	  colon.


	* For  each  process  ID written to standard output, the character 'c'
	  shall be written to standard error if the process is using the  file
	  as  its  current directory and the character 'r' shall be written to
	  standard error if the process is using the file as its  root	direc-
	  tory. Implementations may write other alphabetic characters to indi-
	  cate other uses of files.


	* When the -u option is specified, characters indicating  the  use  of
	  the  file  shall be followed immediately by the user name, in paren-
	  theses, corresponding to the process' real user  ID.	 If  the  user
	  name cannot be resolved from the process' real user ID, the process'
	  real user ID shall be written instead of the user name.


       When standard output and standard error are directed to the same  file,
       the  output  shall  be  interleaved so that the filename appears at the
       start of each line, followed by the process ID and characters  indicat-
       ing  the use of the file. Then, if the -u option is specified, the user
       name or user ID for each process using that file shall be written.

       A <newline> shall be written to standard error after  the  last	output
       described above for each file operand.

OUTPUT FILES
       None.

EXTENDED DESCRIPTION
       None.

EXIT STATUS
       The following exit values shall be returned:

	0     Successful completion.

       >0     An error occurred.


CONSEQUENCES OF ERRORS
       Default.

       The following sections are informative.

APPLICATION USAGE
       None.

EXAMPLES
       The command:


	      fuser -fu .

       writes  to  standard output the process IDs of processes that are using
       the current directory and writes to standard error an indication of how
       those  processes  are using the directory and the user names associated
       with the processes that are using the current directory.

RATIONALE
       The definition of the fuser utility follows existing practice.

FUTURE DIRECTIONS
       None.

SEE ALSO
       None.

COPYRIGHT
       Portions of this text are reprinted and reproduced in  electronic  form
       from IEEE Std 1003.1, 2003 Edition, Standard for Information Technology
       -- Portable Operating System Interface (POSIX),	The  Open  Group  Base
       Specifications  Issue  6,  Copyright  (C) 2001-2003 by the Institute of
       Electrical and Electronics Engineers, Inc and The Open  Group.  In  the
       event of any discrepancy between this version and the original IEEE and
       The Open Group Standard, the original IEEE and The Open Group  Standard
       is  the	referee document. The original Standard can be obtained online
       at http://www.opengroup.org/unix/online.html .



IEEE/The Open Group		     2003			      FUSER(P)
","# fuser

> Display process IDs currently using files or sockets.

- Find which processes are accessing a file or directory:

`fuser {{path/to/file_or_directory}}`

- Show more fields (`USER`, `PID`, `ACCESS` and `COMMAND`):

`fuser --verbose {{path/to/file_or_directory}}`

- Identify processes using a TCP socket:

`fuser --namespace tcp {{port}}`

- Kill all processes accessing a file or directory (sends the `SIGKILL` signal):

`fuser --kill {{path/to/file_or_directory}}`

- Find which processes are accessing the filesystem containing a specific file or directory:

`fuser --mount {{path/to/file_or_directory}}`
"
fdisk,,,"
FDISK(8)		  BSD System Manager's Manual		      FDISK(8)

NAME
     fdisk -- DOS partition maintenance program

SYNOPSIS
     fdisk [-ieu] [-f mbrname] [-c cylinders] [-h heads] [-s sectors]
	   [-S size] [-b size] device

DESCRIPTION
     In order for the BIOS to boot the kernel, certain conventions must be
     adhered to.  Sector 0 of a bootable hard disk must contain boot code, an
     MBR partition table, and a magic number (0xAA55).	These MBR partitions
     (also known as BIOS partitions) can be used to break the disk up into
     several pieces.

     The BIOS loads sector 0 of the boot disk into memory, verifies the magic
     number, and begins executing the code at the first byte.  The normal DOS
     MBR boot code searches the MBR partition table for an ``active'' parti-
     tion (indicated by a `*' in the first column), and if one is found, the
     boot block from that partition is loaded and executed in place of the
     original (MBR) boot block.

     The options are as follows:

     -i      Initialize the MBR sector.

     -a style
	     Specify an automatic partitioning style.

     -e      Edit existing MBR sectors.

     -f mbrname
	     Specifies an alternate MBR template file.

     -u      Update MBR code, preserving existing partition table.

     -y      Do not ask for confirmation before writing.

     -d      Dump partition table in a format readable by the -r option.

     -r      Read a partition table from the standard input.

     -t      Test if the disk is partitioned.

     -c cylinders, -h heads, -s sectors
	     Specifies an alternate BIOS geometry for fdisk to use.

     -S size
	     Specify the disk size in blocks.

     -b size
	     Specify the number of bytes per disk block.

     The DOS fdisk program can be used to divide space on the disk into parti-
     tions and set one active.	This fdisk program serves a similar purpose to
     the DOS program.  When called with no special flags, it prints the MBR
     partition table of the specified device, i.e.,

	 # fdisk fd0
	 Disk: fd0	 geometry: 80/2/18 [2880 sectors]
	 Offset: 0	 Signature: 0xAA55
		  Starting	  Ending
	  #: id  cyl  hd sec -	cyl  hd sec [	  start -	size]
	 ----------------------------------------------------------------------
	 *1: A6    0   0   1 -	 79   1  18 [	      0 -	2880] OpenBSD
	  2: 00    0   0   0 -	  0   0   0 [	      0 -	   0] unused
	  3: A7    0   0   2 -	 79   1  18 [	      1 -	2879] NEXTSTEP
	  4: 00    0   0   0 -	  0   0   0 [	      0 -	   0] unused

     The geometry displayed is a synthetic geometry unless another geometry
     has been selected using the -c, -h, -s, -S, and -b options.  In the
     future, fdisk will read the BIOS geometry from the IOKit registry.

     In this example, the disk is divided into two partitions that happen to
     fill the disk.  The first partition overlaps the third partition.	(Used
     for debugging purposes.)

     #		 Number of partition table entry.  A ``*'' denotes the
		 bootable partition.

     id 	 System identifier.  OpenBSD reserves the magic number 166
		 decimal (A6 in hex).  If no 166 partition is found, it will
		 use an older FreeBSD partition (with a magic number of 165 or
		 A5 in hex).

     cyl/hd/sec  These fields provide the starting and ending address of the
		 partition in BIOS geometry

     start/size  These fields provide the starting sector and size in sectors
		 of the partition in linear block addresses.

     NOTE: The sectors field is ``1 based'', and the start field is ``0
     based''.  The CHS values may need to be in the BIOS's geometry for older
     systems to be able to boot and use the drive correctly; most modern sys-
     tems prefer the starting sector and size in preference to the CHS values.

     The -i flag is used to indicate that the partition data is to be initial-
     ized.  In this mode, fdisk will completely overwrite the primary MBR and
     partition table, either using the default MBR template, or the one speci-
     fied by the -f flag.

     In the default template, partition number 1 will be configured as a Dar-
     win boot partition spanning from cylinder 0, head 1, sector 1, and
     extending for 8 megabytes.  Partition number 2 will be configured as a
     Darwin HFS partition spanning the rest of the disk.  This mode is
     designed to initialize an MBR the very first time, or when it has been
     corrupted beyond repair.

     You can specify other default partition styles with the -a flag.  The
     available styles are:

     boothfs	 Creates an 8Mb boot partition (type AB hex) and makes the
		 rest of the disk a Darwin HFS partition (type AF hex).

     hfs	 Makes the entire disk one HFS+ partition (type AF hex).

     dos	 Makes the entire disk one DOS partition (type 0C hex).

     raid	 Makes the entire disk one type AC hex partition.

     The -u flag is used to update the MBR code on a given drive.  The MBR
     code extends from offset 0x000 to the start of the partition table at
     offset 0x1BE.  It is similar to the -i flag, except the existing parti-
     tion table is preserved. This is useful for writing new MBR code onto an
     existing drive, and is equivalent to the DOS command ``FDISK /MBR''.
     Note that this option will overwrite the NT disk signature, if present.
     The -u and -i flags may not be specified together.

     The flag -e is used to modify a partition table using a interactive edit
     mode of the fdisk program.  This mode is designed to allow you to change
     any partition on the drive you choose, including extended partitions.  It
     is a very powerful mode, but is safe as long as you do not execute the
     write command, or answer in the negative (the default) when fdisk asks
     you about writing out changes.

COMMAND MODE
     When you first enter this mode, you are presented with a prompt, that
     looks like so: fdisk: 0>.	This prompt has two important pieces of infor-
     mation for you.  It will tell you if the in-memory copy of the boot block
     has been modified or not.	If it has been modified, the prompt will
     change to look like: fdisk:*0>.  The second piece of information pertains
     to the number given in the prompt.  This number specifies the disk offset
     of the currently selected boot block you are editing.  This number could
     be something different that zero when you are editing extended parti-
     tions.  The list of commands and their explanations are given below.

     help    Display a list of commands that fdisk understands in the interac-
	     tive edit mode.

     manual  Display this manual page.

     reinit  Initialize the currently selected, in-memory copy of the boot
	     block.

     auto    Partition the disk with one of the automatic partition styles.

     disk    Display the current drive geometry that fdisk has probed.	You
	     are given a chance to edit it if you wish.

     edit    Edit a given table entry in the memory copy of the current boot
	     block.  You may edit either in BIOS geometry mode, or in sector
	     offsets and sizes.

     setpid  Change the partition identifier of the given partition table
	     entry.  This command is particularly useful for reassigning an
	     existing partition to OpenBSD.

     flag    Make the given partition table entry bootable.  Only one entry
	     can be marked bootable.  If you wish to boot from an extended
	     partition, you will need to mark the partition table entry for
	     the extended partition as bootable.

     update  Update the machine code in the memory copy of the currently
	     selected boot block.  Note that this option will overwrite the NT
	     disk signature, if present.

     select  Select and load into memory the boot block pointed to by the
	     extended partition table entry in the current boot block.

     print   Print the currently selected in-memory copy of the boot block and
	     its MBR table to the terminal.

     write   Write the in-memory copy of the boot block to disk.  You will be
	     asked to confirm this operation.

     exit    Exit the current level of fdisk, either returning to the previ-
	     ously selected in-memory copy of a boot block, or exiting the
	     program if there is none.

     quit    Exit the current level of fdisk, either returning to the previ-
	     ously selected in-memory copy of a boot block, or exiting the
	     program if there is none.	Unlike exit it does write the modified
	     block out.

     abort   Quit program without saving current changes.

NOTES
     The automatic calculation of starting cylinder etc. uses a set of figures
     that represent what the BIOS thinks is the geometry of the drive.	These
     figures are by default taken from the in-core disklabel, or values that
     /boot has passed to the kernel, but fdisk gives you an opportunity to
     change them if there is a need to.  This allows the user to create a
     bootblock that can work with drives that use geometry translation under a
     potentially different BIOS.

     If you hand craft your disk layout, please make sure that the OpenBSD
     partition starts on a cylinder boundary.  (This restriction may be
     changed in the future.)

     Editing an existing partition is risky, and may cause you to lose all the
     data in that partition.

     You should run this program interactively once or twice to see how it
     works.  This is completely safe as long as you answer the ``write'' ques-
     tions in the negative.

FILES
     /usr/mdec/mbr  default MBR template

SEE ALSO
     gpt(8), pdisk(8)

BUGS
     There are subtleties fdisk detects that are not explained in this manual
     page.  As well, chances are that some of the subtleties it should detect
     are being steamrolled.  Caveat Emptor.

BSD				January 3, 2002 			   BSD
","# fdisk

> A program for managing partition tables and partitions on a hard disk.

- List partitions:

`fdisk -l`

- Start the partition manipulator:

`fdisk {{/dev/sda}}`
"
edquota,,,"
EDQUOTA(8)		  BSD System Manager's Manual		    EDQUOTA(8)

NAME
     edquota -- edit user quotas

SYNOPSIS
     edquota [-u] [-p proto-username] username ...
     edquota -g [-p proto-groupname] groupname ...
     edquota -t [-u]
     edquota -t -g

DESCRIPTION
     Edquota is a quota editor.  By default, or if the -u flag is specified,
     one or more users may be specified on the command line.  For each user a
     temporary file is created with an ASCII representation of the current
     disk quotas for that user.  The list of filesystems with user quotas is
     determined by scanning the mounted filesystems for a .quota.ops.user file
     located at its root.  An editor is invoked on the ASCII file.  The editor
     invoked is vi(1) unless the environment variable EDITOR specifies other-
     wise.

     The quotas may then be modified, new quotas added, etc.  Setting a quota
     to zero indicates that no quota should be imposed.  Setting a hard limit
     to one indicates that no allocations should be permitted.	Setting a soft
     limit to one with a hard limit of zero indicates that allocations should
     be permitted on only a temporary basis (see -t below).  The current usage
     information in the file is for informational purposes; only the hard and
     soft limits can be changed.

     On leaving the editor, edquota reads the temporary file and modifies the
     binary quota files to reflect the changes made.  The binary quota file,
     .quota.user is stored at the root of the filesystem.  The default file-
     name and root location for the user quotas cannot be overridden.

     If the -p flag is specified, edquota will duplicate the quotas of the
     prototypical user specified for each user specified.  This is the normal
     mechanism used to initialize quotas for groups of users.

     If the -g flag is specified, edquota is invoked to edit the quotas of one
     or more groups specified on the command line.  The list of filesystems
     with group quotas is determined by scanning the mounted filesystems for a
     .quota.ops.group file located at its root.  Similarly, the binary quota
     file, .quota.group is stored at the root of the filesystem.  The default
     filename and root location for group quotas cannot be overridden.	The -p
     flag can be specified in conjunction with the -g flag to specify a proto-
     typical group to be duplicated among the listed set of groups.

     Users are permitted to exceed their soft limits for a grace period that
     may be specified per filesystem.  Once the grace period has expired, the
     soft limit is enforced as a hard limit.  The default grace period for a
     filesystem is specified in /usr/include/sys/quota.h.  The -t flag can be
     used to change the grace period.  By default, or when invoked with the -u
     flag, the grace period is set for each filesystem with a .quota.ops.user
     file located at its root.	When invoked with the -g flag, the grace
     period is set for each filesystem with a .quota.ops.group file located at
     its root.	The grace period may be specified in days, hours, minutes, or
     seconds.  Setting a grace period to zero indicates that the default grace
     period should be imposed.	Setting a grace period to one second indicates
     that no grace period should be granted.

     Only the super-user may edit quotas.

FILES
     Each of the following quota files is located at the root of the mounted
     filesystem.  The mount option files are empty files whose existence indi-
     cates that quotas are to be enabled for that filesystem.  The binary data
     files will be created by edquota, if they don't already exist.

     .quota.user       data file containing user quotas
     .quota.group      data file containing group quotas
     .quota.ops.user   mount option file used to enable user quotas
     .quota.ops.group  mount option file used to enable group quotas

SEE ALSO
     quota(1), quotactl(2), quotacheck(8), quotaon(8), repquota(8)

DIAGNOSTICS
     Various messages about inaccessible files; self-explanatory.

BSD			      September 25, 2020			   BSD
","# edquota

> Edit quotas for a user or group. By default it operates on all file systems with quotas.
> Quota information is stored permanently in the `quota.user` and `quota.group` files in the root of the filesystem.

- Edit quota of the current user:

`edquota --user $(whoami)`

- Edit quota of a specific user:

`sudo edquota --user {{username}}`

- Edit quota for a group:

`sudo edquota --group {{group}}`

- Restrict operations to a given filesystem (by default edquota operates on all filesystems with quotas):

`sudo edquota --file-system {{filesystem}}`

- Edit the default grace period:

`sudo edquota -t`

- Duplicate a quota to other users:

`sudo edquota -p {{reference_user}} {{destination_user1}} {{destination_user2}}`
"
whereis,,,"
WHEREIS(1)		  BSD General Commands Manual		    WHEREIS(1)

NAME
     whereis -- locate programs

SYNOPSIS
     whereis [program ...]

DESCRIPTION
     The whereis utility checks the standard binary directories for the speci-
     fied programs, printing out the paths of any it finds.

     The path searched is the string returned by the sysctl(8) utility for the
     ``user.cs_path'' string.

SEE ALSO
     find(1), locate(1), man(1), which(1), sysctl(8)

COMPATIBILITY
     The historic flags and arguments for the whereis utility are no longer
     available in this version.

HISTORY
     The whereis command appeared in 3.0BSD.

BSD				April 27, 1995				   BSD
","# whereis

> Locate the binary, source, and manual page files for a command.

- Locate binary, source and man pages for ssh:

`whereis {{ssh}}`

- Locate binary and man pages for ls:

`whereis -bm {{ls}}`

- Locate source of gcc and man pages for git:

`whereis -s {{gcc}} -m {{git}}`

- Locate binaries for gcc in /usr/bin/ only:

`whereis -b -B {{/usr/bin/}} -f {{gcc}}`

- Locate unusual binaries (those that have more or less than one binary on the system):

`whereis -u *`

- Locate binaries that have unusual manual entries (binaries that have more or less than one manual installed):

`whereis -u -m *`
"
unset,,,"
BUILTIN(1)		  BSD General Commands Manual		    BUILTIN(1)

NAME
     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,
     breaksw, builtins, case, cd, chdir, command, complete, continue, default,
     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,
     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,
     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,
     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,
     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,
     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,
     telltc, test, then, time, times, trap, true, type, ulimit, umask,
     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,
     where, which, while -- shell built-in commands

SYNOPSIS
     builtin [-options] [args ...]

DESCRIPTION
     Shell builtin commands are commands that can be executed within the run-
     ning shell's process.  Note that, in the case of csh(1) builtin commands,
     the command is executed in a subshell if it occurs as any component of a
     pipeline except the last.

     If a command specified to the shell contains a slash ``/'', the shell
     will not execute a builtin command, even if the last component of the
     specified command matches the name of a builtin command.  Thus, while
     specifying ``echo'' causes a builtin command to be executed under shells
     that support the echo builtin command, specifying ``/bin/echo'' or
     ``./echo'' does not.

     While some builtin commands may exist in more than one shell, their oper-
     ation may be different under each shell which supports them.  Below is a
     table which lists shell builtin commands, the standard shells that sup-
     port them and whether they exist as standalone utilities.

     Only builtin commands for the csh(1) and sh(1) shells are listed here.
     Consult a shell's manual page for details on the operation of its builtin
     commands.	Beware that the sh(1) manual page, at least, calls some of
     these commands ``built-in commands'' and some of them ``reserved words''.
     Users of other shells may need to consult an info(1) page or other
     sources of documentation.

     Commands marked ``No**'' under External do exist externally, but are
     implemented as scripts using a builtin command of the same name.

	   Command	 External    csh(1)    sh(1)
	   !		 No	     No        Yes
	   %		 No	     Yes       No
	   .		 No	     No        Yes
	   :		 No	     Yes       Yes
	   @		 No	     Yes       Yes
	   {		 No	     No        Yes
	   }		 No	     No        Yes
	   alias	 No**	     Yes       Yes
	   alloc	 No	     Yes       No
	   bg		 No**	     Yes       Yes
	   bind 	 No	     No        Yes
	   bindkey	 No	     Yes       No
	   break	 No	     Yes       Yes
	   breaksw	 No	     Yes       No
	   builtin	 No	     No        Yes
	   builtins	 No	     Yes       No
	   case 	 No	     Yes       Yes
	   cd		 No**	     Yes       Yes
	   chdir	 No	     Yes       Yes
	   command	 No**	     No        Yes
	   complete	 No	     Yes       No
	   continue	 No	     Yes       Yes
	   default	 No	     Yes       No
	   dirs 	 No	     Yes       No
	   do		 No	     No        Yes
	   done 	 No	     No        Yes
	   echo 	 Yes	     Yes       Yes
	   echotc	 No	     Yes       No
	   elif 	 No	     No        Yes
	   else 	 No	     Yes       Yes
	   end		 No	     Yes       No
	   endif	 No	     Yes       No
	   endsw	 No	     Yes       No
	   esac 	 No	     No        Yes
	   eval 	 No	     Yes       Yes
	   exec 	 No	     Yes       Yes
	   exit 	 No	     Yes       Yes
	   export	 No	     No        Yes
	   false	 Yes	     No        Yes
	   fc		 No**	     No        Yes
	   fg		 No**	     Yes       Yes
	   filetest	 No	     Yes       No
	   fi		 No	     No        Yes
	   for		 No	     No        Yes
	   foreach	 No	     Yes       No
	   getopts	 No**	     No        Yes
	   glob 	 No	     Yes       No
	   goto 	 No	     Yes       No
	   hash 	 No	     No        Yes
	   hashstat	 No	     Yes       No
	   history	 No	     Yes       No
	   hup		 No	     Yes       No
	   if		 No	     Yes       Yes
	   jobid	 No	     No        Yes
	   jobs 	 No**	     Yes       Yes
	   kill 	 Yes	     Yes       No
	   limit	 No	     Yes       No
	   local	 No	     No        Yes
	   log		 No	     Yes       No
	   login	 Yes	     Yes       No
	   logout	 No	     Yes       No
	   ls-F 	 No	     Yes       No
	   nice 	 Yes	     Yes       No
	   nohup	 Yes	     Yes       No
	   notify	 No	     Yes       No
	   onintr	 No	     Yes       No
	   popd 	 No	     Yes       No
	   printenv	 Yes	     Yes       No
	   pushd	 No	     Yes       No
	   pwd		 Yes	     No        Yes
	   read 	 No**	     No        Yes
	   readonly	 No	     No        Yes
	   rehash	 No	     Yes       No
	   repeat	 No	     Yes       No
	   return	 No	     No        Yes
	   sched	 No	     Yes       No
	   set		 No	     Yes       Yes
	   setenv	 No	     Yes       No
	   settc	 No	     Yes       No
	   setty	 No	     Yes       No
	   setvar	 No	     No        Yes
	   shift	 No	     Yes       Yes
	   source	 No	     Yes       No
	   stop 	 No	     Yes       No
	   suspend	 No	     Yes       No
	   switch	 No	     Yes       No
	   telltc	 No	     Yes       No
	   test 	 Yes	     No        Yes
	   then 	 No	     No        Yes
	   time 	 Yes	     Yes       No
	   times	 No	     No        Yes
	   trap 	 No	     No        Yes
	   true 	 Yes	     No        Yes
	   type 	 No	     No        Yes
	   ulimit	 No	     No        Yes
	   umask	 No**	     Yes       Yes
	   unalias	 No**	     Yes       Yes
	   uncomplete	 No	     Yes       No
	   unhash	 No	     Yes       No
	   unlimit	 No	     Yes       No
	   unset	 No	     Yes       Yes
	   unsetenv	 No	     Yes       No
	   until	 No	     No        Yes
	   wait 	 No**	     Yes       Yes
	   where	 No	     Yes       No
	   which	 Yes	     Yes       No
	   while	 No	     Yes       Yes

SEE ALSO
     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),
     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)

HISTORY
     The builtin manual page first appeared in FreeBSD 3.4.

AUTHORS
     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.

BSD			       February 23, 2005			   BSD
","# unset

> Remove shell variables or functions.

- Remove the variable `foo`, or if the variable doesn't exist, remove the function `foo`:

`unset {{foo}}`

- Remove the variables foo and bar:

`unset -v {{foo}} {{bar}}`

- Remove the function my_func:

`unset -f {{my_func}}`
"
swapon,,,,"# swapon

> Enables device or file for swapping.

- Get swap information:

`swapon -s`

- Enable a given swap partition:

`swapon {{/dev/sdb7}}`

- Enable a given swap file:

`swapon {{path/to/file}}`

- Enable all swap areas:

`swapon -a`

- Enable swap by label of a device or file:

`swapon -L {{swap1}}`
"
faketime,https://manpages.ubuntu.com/manpages/trusty/man1/faketime.1.html,"






Ubuntu Manpage:

       faketime - manipulate the system time for a given command
    


















Menu
Close menu












Jump to main content













Provided by: faketime_0.9.5-2_amd64 
NAME
       faketime - manipulate the system time for a given command

SYNOPSIS
       faketime [options] timestamp program [arguments...]

DESCRIPTION
       The  given  command will be tricked into believing that the current system time is the one
       specified in the timestamp. The wall clock will continue to run from this  date  and  time
       unless  specified otherwise (see advanced options). Actually, faketime is a simple wrapper
       for libfaketime, which uses the  LD_PRELOAD  mechanism  to  load  a  small  library  which
       intercepts  system  calls  to functions such as time(2) and fstat(2). This wrapper exposes
       only a subset of libfaketime's functionality; please refer to the README  file  that  came
       with   faketime   for   more   details   and   advanced   options,   or  have  a  look  at
       http://github.com/wolfcw/libfaketime

OPTIONS
       --help show usage information and quit.

       --version
              show version information and quit.

       -m     use the multi-threading variant of libfaketime.

       -f     use the advanced timestamp specification format.

EXAMPLES
       faketime 'last Friday 5 pm' /bin/date
       faketime '2008-12-24 08:15:42' /bin/date
       faketime -f '+2,5y x10,0' /bin/bash -c 'date; while true; do echo $SECONDS ; sleep 1 ; done'
       faketime -f '+2,5y x0,50' /bin/bash -c 'date; while true; do echo $SECONDS ; sleep 1 ; done'
       faketime -f '+2,5y i2,0' /bin/bash -c 'while true; do date ; sleep 1 ; done'
       In this single case all spawned processes will use the same global clock without restaring it at the start of each process.

       (Please note that it depends on your locale settings whether . or , has to be used for fractional offsets)

ADVANCED TIMESTAMP FORMAT
       The simple timestamp format used by default applies the  /bin/date  -d  command  to  parse
       user-friendly specifications such as 'last friday'. When using the faketime option -f, the
       timestamp specified on the command line is directly passed to libfaketime, which enables a
       couple  of  additional  features  such as speeding the clock up or slowing it down for the
       target program. It is strongly recommended  that  you  have  a  look  at  the  libfaketime
       documentation. Summary:

       Freeze clock at absolute timestamp: ""YYYY-MM-DD hh:mm:ss""
              If you want to specify an absolute point in time, exactly this format must be used.
              Please note that freezing the clock is usually not what you want and may break  the
              application. Only use if you know what you're doing!

       Relative time offset: ""[+/-]123[m/h/d/y], e.g. ""+60m"", ""+2y""
              This  is  the most often used format and specifies the faked time relatively to the
              current real time. The first character of the format string must be a + or a -. The
              numeric  value  by default represents seconds, but the modifiers m, h, d, and y can
              be used to specify minutes, hours, days, or years, respectively. For example, ""-2y""
              means  ""two  years  ago"".  Fractional time offsets can be used, e.g. ""+2,5y"", which
              means ""two and a half years in the future"". Please note that the fraction delimiter
              depends on your locale settings, so if ""+2,5y"" does not work, you might want to try
              ""+2.5y"".

       Start-at timestamps: ""@YYYY-MM-DD hh:mm:ss""
              The wall clock will start counting at the given timestamp for the program. This can
              be used for specifying absolute timestamps without freezing the clock.

ADVANCED USAGE
       When  using  relative  time  offsets or start-at timestamps (see ADVANCED TIMESTAMP FORMAT
       above and option -f), the clock speed can be adjusted, i.e. time may run faster or  slower
       for  the executed program. For example, ""+5y x10"" will set the faked time 5 years into the
       future and make the time pass 10 times as fast (one real second equals 10 seconds measured
       by  the  program). Similarly, the flow of time can be slowed, e.g. using ""-7d x0,2"", which
       will set the faked time 7 days in the past and set the clock speed to 20 percent, i.e.  it
       takes  five real world seconds for one second measured by the program. Again, depending on
       your locale, either ""x2.0"" or ""x2,0"" may be required regarding the delimiter. You can also
       make  faketime  to  advance  the  reported time by a preset interval upon each time() call
       independently from the system's time using ""-7d  i2,0"",  where  ""i""  is  followed  by  the
       increase interval in seconds.

       Faking  times  for  multiple  programs  or  even  system-wide  can  be simplified by using
       ~/.faketimerc files and /etc/faketimerc.  Please  refer  to  the  README  that  came  with
       faketime for warnings and details.

AUTHOR
       Please see the README and NEWS files for contributers.

BUGS
       Due  to  limitations of the LD_PRELOAD mechanism, faketime will not work with suidroot and
       statically linked programs.  While  timestamps  and  time  offsets  will  work  for  child
       processes,  speeding  the  clock  up or slowing it down might not work for child processes
       spawned by the executed program as expected; a new instance of  libfaketime  is  used  for
       each  child  process,  which means that the libfaketime start time, which is used in speed
       adjustments, will also be  re-initialized.  Some  programs  may  dynamically  load  system
       libraries,  such  as  librt,  at run-time and therefore bypass libfaketime. You may report
       programs that do not work with libfaketime, but only if they are available as open source.

REPORTING BUGS
       Please use https://github.com/wolfcw/libfaketime/issues

COPYRIGHT
       Copyright Â© 2003-2013 by the libfaketime authors.

       There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR  A  PARTICULAR  PURPOSE.
       You may redistribute copies of faketime under the terms of the GNU General Public License.
       For more information about these matters, see the file named COPYING.

SEE ALSO
       ld.so(1), time(2), fstat(2)





Powered by the Ubuntu Manpage Repository, file bugs in Launchpad
© 2019 Canonical Ltd. Ubuntu and Canonical are registered trademarks of Canonical Ltd.




",,"# faketime

> Fake the system time for a given command.
> More information: <https://manpages.ubuntu.com/manpages/trusty/man1/faketime.1.html>.

- Fake the time to this evening, before printing the result of `date`:

`faketime '{{today 23:30}}' {{date}}`

- Open a new `bash` shell, which uses yesterday as the current date:

`faketime '{{yesterday}}' {{bash}}`

- Simulate how any program would act next friday night:

`faketime '{{next Friday 1 am}}' {{path/to/any/program}}`
"
diff3,,,"DIFF3(1)			 User Commands			      DIFF3(1)



NAME
       diff3 - compare three files line by line

SYNOPSIS
       diff3 [OPTION]... MYFILE OLDFILE YOURFILE

DESCRIPTION
       Compare three files line by line.

       -e  --ed
	      Output unmerged changes from OLDFILE to YOURFILE into MYFILE.

       -E  --show-overlap
	      Output unmerged changes, bracketing conflicts.

       -A  --show-all
	      Output all changes, bracketing conflicts.

       -x  --overlap-only
	      Output overlapping changes.

       -X     Output overlapping changes, bracketing them.

       -3  --easy-only
	      Output unmerged nonoverlapping changes.

       -m  --merge
	      Output merged file instead of ed script (default -A).

       -L LABEL  --label=LABEL
	      Use LABEL instead of file name.

       -i     Append `w' and `q' commands to ed scripts.

       -a  --text
	      Treat all files as text.

       -T  --initial-tab
	      Make tabs line up by prepending a tab.

       --diff-program=PROGRAM
	      Use PROGRAM to compare files.

       -v  --version
	      Output version info.

       --help Output this help.

       If a FILE is `-', read standard input.

AUTHOR
       Written by Randy Smith.

REPORTING BUGS
       Report bugs to <bug-gnu-utils@gnu.org>.

COPYRIGHT
       Copyright (C) 2002 Free Software Foundation, Inc.

       This  program  comes  with NO WARRANTY, to the extent permitted by law.
       You may redistribute copies of this program under the terms of the  GNU
       General	Public License.  For more information about these matters, see
       the file named COPYING.

SEE ALSO
       The full documentation for diff3 is maintained as a Texinfo manual.  If
       the  info  and  diff3 programs are properly installed at your site, the
       command

	      info diff

       should give you access to the complete manual.



diffutils 2.8.1 		  April 2002			      DIFF3(1)
","# diff3

> Compare three files line by line.

- Compare files:

`diff3 {{file1}} {{file2}} {{file3}}`

- Show all changes, outlining conflicts:

`diff3 --show-all {{file1}} {{file2}} {{file3}}`
"
tshark,,,,"# tshark

> Packet analysis tool, CLI version of wireshark.

- Monitor everything on localhost:

`tshark`

- Only capture packets matching a specific capture filter:

`tshark -f '{{udp port 53}}'`

- Only show packets matching a specific output filter:

`tshark -Y '{{http.request.method == ""GET""}}'`

- Decode a TCP port using a specific protocol (e.g. HTTP):

`tshark -d tcp.port=={{8888}},{{http}}`

- Specify the format of captured output:

`tshark -T {{json|text|ps|…}}`

- Select specific fields to output:

`tshark -T {{fields|ek|json|pdml}} -e {{http.request.method}} -e {{ip.src}}`

- Write captured packet to a file:

`tshark -w {{path/to/file}}`

- Analyze packets from a file:

`tshark -r {{filename}}.pcap`
"
expect,https://linux.die.net/man/1/expect,"

expect(1) - Linux man page















expect(1) - Linux man page
Name
expect - programmed dialogue with interactive programs, Version 5
Synopsis
expect [ -dDinN ] [ -c cmds ] [ [ -[f|b] ]
cmdfile ] [ args ]
Introduction





Expect is a program that ""talks"" to other interactive programs according to a script.
Following the script, Expect knows what can be expected from a program and what the correct response should be. An interpreted language provides
branching and high-level control structures to direct the dialogue. In addition, the user can take control and interact directly when desired, afterward
returning control to the script.
Expectk is a mixture of Expect and Tk. It behaves just like Expect and Tk's wish. Expect can also be used
directly in C or C++ (that is, without Tcl). See libexpect(3).
The name ""Expect"" comes from the idea of send/expect sequences popularized by uucp, kermit and other modem control programs. However unlike uucp,
Expect is generalized so that it can be run as a user-level command with any program and task in mind. Expect can actually talk to several
programs at the same time.
For example, here are some things Expect can do:


Cause your computer to dial you back, so that you can login without paying for the call.
Start a game (e.g., rogue) and if the optimal configuration doesn't appear, restart it (again and again) until it does, then hand over control to you.
Run fsck, and in response to its questions, answer ""yes"", ""no"" or give control back to you, based on predetermined criteria.
Connect to another network or BBS (e.g., MCI Mail, CompuServe) and automatically retrieve your mail so that it appears as if it was originally sent to your
local system.
Carry environment variables, current directory, or any kind of information across rlogin, telnet, tip, su, chgrp, etc.
There are a variety of reasons why the shell cannot perform these tasks. (Try, you'll see.) All are possible with Expect.
In general, Expect is useful for running any program which requires interaction between the program and the user. All that is necessary is that the
interaction can be characterized programmatically. Expect can also give the user back control (without halting the program being controlled) if desired.
Similarly, the user can return control to the script at any time.
Usage
Expect reads cmdfile for a list of commands to execute. Expect may also be
invoked implicitly on systems which support the #! notation by marking the script executable, and making the first line in your script:
#!/usr/local/bin/expect -fOf course, the path must accurately describe where Expect lives. /usr/local/bin is just an example.
The -c flag prefaces a command to be executed before any in the script. The command should be quoted to prevent being broken up by the shell. This
option may be used multiple times. Multiple commands may be executed with a single -c by separating them with semicolons. Commands are executed in the
order they appear. (When using Expectk, this option is specified as -command.)
The -d flag enables some diagnostic output, which primarily reports internal activity of commands such as expect and interact. This
flag has the same effect as ""exp_internal 1"" at the beginning of an Expect script, plus the version of Expect is printed. (The strace command is
useful for tracing statements, and the trace command is useful for tracing variable assignments.) (When using Expectk, this option is specified as
-diag.)
The -D flag enables an interactive debugger. An integer value should follow. The debugger will take control before the next Tcl procedure if the
value is non-zero or if a ^C is pressed (or a breakpoint is hit, or other appropriate debugger command appears in the script). See the README file or SEE ALSO
(below) for more information on the debugger. (When using Expectk, this option is specified as -Debug.)
The -f flag prefaces a file from which to read commands from. The flag itself is optional as it is only useful when using the #! notation (see
above), so that other arguments may be supplied on the command line. (When using Expectk, this option is specified as -file.)
By default, the command file is read into memory and executed in its entirety. It is occasionally desirable to read files one line at a time. For example,
stdin is read this way. In order to force arbitrary files to be handled this way, use the -b flag. (When using Expectk, this option is specified as
-buffer.) Note that stdio-buffering may still take place however this shouldn't cause problems when reading from a fifo or stdin.
If the string ""-"" is supplied as a filename, standard input is read instead. (Use ""./-"" to read from a file actually named ""-"".)
The -i flag causes Expect to interactively prompt for commands instead of reading them from a file. Prompting is terminated via the
exit command or upon EOF. See interpreter (below) for more information. -i is assumed if neither a command file nor -c is used.
(When using Expectk, this option is specified as -interactive.)
-- may be used to delimit the end of the options. This is useful if you want to pass an option-like argument to your script without it being
interpreted by Expect. This can usefully be placed in the #! line to prevent any flag-like interpretation by Expect. For example, the following will
leave the original arguments (including the script name) in the variable argv.
#!/usr/local/bin/expect --Note that the usual getopt(3) and execve(2) conventions must be observed when adding arguments to the #! line.
The file $exp_library/expect.rc is sourced automatically if present, unless the -N flag is used. (When using Expectk, this option is specified as
-NORC.) Immediately after this, the file ~/.expect.rc is sourced automatically, unless the -n flag is used. If the environment variable DOTDIR is
defined, it is treated as a directory and .expect.rc is read from there. (When using Expectk, this option is specified as -norc.) This sourcing occurs
only after executing any -c flags.
-v causes Expect to print its version number and exit. (The corresponding flag in Expectk, which uses long flag names, is -version.)
Optional args are constructed into a list and stored in the variable named argv. argc is initialized to the length of argv.
argv0 is defined to be the name of the script (or binary if no script is used). For example, the following prints out the name of the script and the
first three arguments:send_user ""$argv0 [lrange $argv 0 2]\n""
Commands
Expect uses Tcl (Tool Command Language). Tcl provides control flow (e.g., if, for,
break), expression evaluation and several other features such as recursion, procedure definition, etc. Commands used here but not defined (e.g., set,
if, exec) are Tcl commands (see tcl(3)). Expect supports additional commands, described below. Unless otherwise specified, commands
return the empty string.
Commands are listed alphabetically so that they can be quickly located. However, new users may find it easier to start by reading the descriptions of
spawn, send, expect, and interact, in that order.
Note that the best introduction to the language (both Expect and Tcl) is provided in the book ""Exploring Expect"" (see SEE ALSO below). Examples are included
in this man page but they are very limited since this man page is meant primarily as reference material.
Note that in the text of this man page, ""Expect"" with an uppercase ""E"" refers to the Expect program while ""expect"" with a lower-case ""e"" refers to
the expect command within the Expect program.)

close [-slave] [-onexec 0|1] [-i spawn_id]
closes the connection to the current process. Most interactive programs will detect EOF on their stdin and exit; thus close usually suffices to kill
the process as well. The -i flag declares the process to close corresponding to the named spawn_id.
Both expect and interact will detect when the current process exits and implicitly do a close. But if you kill the process by, say,
""exec kill $pid"", you will need to explicitly call close.
The -onexec flag determines whether the spawn id will be closed in any new spawned processes or if the process is overlayed. To leave a spawn id
open, use the value 0. A non-zero integer value will force the spawn closed (the default) in any new processes.
The -slave flag closes the slave associated with the spawn id. (See ""spawn -pty"".) When the connection is closed, the slave is automatically closed
as well if still open.
No matter whether the connection is closed implicitly or explicitly, you should call wait to clear up the corresponding kernel process slot.
close does not call wait since there is no guarantee that closing a process connection will cause it to exit. See wait below for more
info.
debug [[-now] 0|1]
controls a Tcl debugger allowing you to step through statements, set breakpoints, etc.
With no arguments, a 1 is returned if the debugger is not running, otherwise a 0 is returned.
With a 1 argument, the debugger is started. With a 0 argument, the debugger is stopped. If a 1 argument is preceded by the -now flag, the debugger is
started immediately (i.e., in the middle of the debug command itself). Otherwise, the debugger is started with the next Tcl statement.
The debug command does not change any traps. Compare this to starting Expect with the -D flag (see above).
See the README file or SEE ALSO (below) for more information on the debugger.
disconnect
disconnects a forked process from the terminal. It continues running in the background. The process is given its own process group (if possible). Standard
I/O is redirected to /dev/null.
The following fragment uses
disconnect to continue running the script in the background.if {[fork]!=0} exit
disconnect
. . .
The following script reads a password, and then runs a program every hour that demands a password each time it is run. The script supplies the password so that
you only have to type it once. (See the stty command which demonstrates how to turn off password echoing.)send_user ""password?\ ""
expect_user -re ""(.*)\n""
for {} 1 {} {
    if {[fork]!=0} {sleep 3600;continue}
    disconnect
    spawn priv_prog
    expect Password:
    send ""$expect_out(1,string)\r""
    . . .
    exit
}
An advantage to using disconnect over the shell asynchronous process feature (&) is that Expect can save the terminal parameters prior to
disconnection, and then later apply them to new ptys. With &, Expect does not have a chance to read the terminal's parameters since the terminal is
already disconnected by the time Expect receives control.
exit [-opts] [status]
causes Expect to exit or otherwise prepare to do so.
The -onexit flag causes the next argument to be used as an exit handler. Without an argument, the current exit handler is returned.
The -noexit flag causes Expect to prepare to exit but stop short of actually returning control to the operating system. The user-defined exit
handler is run as well as Expect's own internal handlers. No further Expect commands should be executed. This is useful if you are running Expect with other
Tcl extensions. The current interpreter (and main window if in the Tk environment) remain so that other Tcl extensions can clean up. If Expect's exit is
called again (however this might occur), the handlers are not rerun.
Upon exiting, all connections to spawned processes are closed. Closure will be detected as an EOF by spawned processes. exit takes no other actions
beyond what the normal _exit(2) procedure does. Thus, spawned processes that do not check for EOF may continue to run. (A variety of conditions are important
to determining, for example, what signals a spawned process will be sent, but these are system-dependent, typically documented under exit(3).) Spawned
processes that continue to run will be inherited by init.
status (or 0 if not specified) is returned as the exit status of Expect. exit is implicitly executed if the end of the script is
reached.
exp_continue [-continue_timer]
The command exp_continue allows expect itself to continue executing rather than returning as it normally would. By default
exp_continue resets the timeout timer. The -continue_timer flag prevents timer from being restarted. (See expect for more information.)
exp_internal[-f file] value
causes further commands to send diagnostic information internal to Expect to stderr if value is non-zero. This output is disabled if
value is 0. The diagnostic information includes every character received, and every attempt made to match the current output against the patterns.
If the optional
file is supplied, all normal and debugging output is written to that file (regardless of the value of value). Any previous diagnostic output
file is closed.
The -info flag causes exp_internal to return a description of the most recent non-info arguments given.
exp_open [args] [-i spawn_id]
returns a Tcl file identifier that corresponds to the original spawn id. The file identifier can then be used as if it were opened by Tcl's open
command. (The spawn id should no longer be used. A wait should not be executed.
The -leaveopen flag leaves the spawn id open for access through Expect commands. A wait must be executed on the spawn id.
exp_pid [-i spawn_id]
returns the process id corresponding to the currently spawned process. If the -i flag is used, the pid returned corresponds to that of the given
spawn id.
exp_send
is an alias for send.
exp_send_error
is an alias for send_error.
exp_send_log
is an alias for send_log.
exp_send_tty
is an alias for send_tty.
exp_send_user
is an alias for send_user.
exp_version [[-exit] version]
is useful for assuring that the script is compatible with the current version of Expect.
With no arguments, the current version of
Expect is returned. This version may then be encoded in your script. If you actually know that you are not using features of recent versions, you
can specify an earlier version.
Versions consist of three numbers separated by dots. First
is the major number. Scripts written for versions of Expect with a different major number will almost certainly not work. exp_version returns
an error if the major numbers do not match.
Second is the minor number. Scripts written for a version with a
greater minor number than the current version may depend upon some new feature and might not run. exp_version returns an error if the major numbers
match, but the script minor number is greater than that of the running Expect.
Third is a number that plays no part in the version comparison.
However, it is incremented when the Expect software distribution is changed in any way, such as by additional documentation or optimization. It is
reset to 0 upon each new minor version.
With the
-exit flag, Expect prints an error and exits if the version is out of date.
expect [[-opts] pat1 body1] ... [-opts] patn [bodyn]
waits until one of the patterns matches the output of a spawned process, a specified time period has passed, or an end-of-file is seen. If the final body
is empty, it may be omitted.
Patterns from the most recent
expect_before command are implicitly used before any other patterns. Patterns from the most recent expect_after command are implicitly used
after any other patterns.
If the arguments to the entire
expect statement require more than one line, all the arguments may be ""braced"" into one so as to avoid terminating each line with a backslash. In
this one case, the usual Tcl substitutions will occur despite the braces.
If a pattern is the keyword
eof, the corresponding body is executed upon end-of-file. If a pattern is the keyword timeout, the corresponding body is executed upon
timeout. If no timeout keyword is used, an implicit null action is executed upon timeout. The default timeout period is 10 seconds but may be set, for example
to 30, by the command ""set timeout 30"". An infinite timeout may be designated by the value -1. If a pattern is the keyword default, the corresponding
body is executed upon either timeout or end-of-file.
If a pattern matches, then the corresponding body is executed.
expect returns the result of the body (or the empty string if no pattern matched). In the event that multiple patterns match, the one appearing
first is used to select a body.
Each time new output arrives, it is compared to each pattern in the order
they are listed. Thus, you may test for absence of a match by making the last pattern something guaranteed to appear, such as a prompt. In situations where
there is no prompt, you must use timeout (just like you would if you were interacting manually).
Patterns are specified in three ways. By default,
patterns are specified as with Tcl's string match command. (Such patterns are also similar to C-shell regular expressions usually referred to as
""glob"" patterns). The -gl flag may may be used to protect patterns that might otherwise match expect flags from doing so. Any pattern beginning
with a ""-"" should be protected this way. (All strings starting with ""-"" are reserved for future options.)
For example, the following fragment looks for a successful login.
(Note that abort is presumed to be a procedure defined elsewhere in the script.)expect {
    busy               {puts busy\n ; exp_continue}
    failed             abort
    ""invalid password"" abort
    timeout            abort
    connected
}
Quotes are necessary on the fourth pattern since it contains a space, which would otherwise separate the pattern from the action. Patterns with the same action
(such as the 3rd and 4th) require listing the actions again. This can be avoid by using regexp-style patterns (see below). More information on forming
glob-style patterns can be found in the Tcl manual.
Regexp-style patterns follow the syntax defined by Tcl's
regexp (short for ""regular expression"") command. regexp patterns are introduced with the flag -re. The previous example can be rewritten
using a regexp as:expect {
    busy       {puts busy\n ; exp_continue}
    -re ""failed|invalid password"" abort
    timeout    abort
    connected
}
Both types of patterns are ""unanchored"". This means that patterns do not have to match the entire string, but can begin and end the match anywhere in the
string (as long as everything else matches). Use ^ to match the beginning of a string, and $ to match the end. Note that if you do not wait for the end of a
string, your responses can easily end up in the middle of the string as they are echoed from the spawned process. While still producing correct results, the
output can look unnatural. Thus, use of $ is encouraged if you can exactly describe the characters at the end of a string.
Note that in many editors, the ^ and $ match the beginning and end of lines respectively. However, because expect is not line oriented, these characters
match the beginning and end of the data (as opposed to lines) currently in the expect matching buffer. (Also, see the note below on ""system indigestion."")
The -ex flag causes the pattern to be matched as an ""exact"" string. No interpretation of *, ^, etc is made (although the usual Tcl conventions must
still be observed). Exact patterns are always unanchored.
The
-nocase flag causes uppercase characters of the output to compare as if they were lowercase characters. The pattern is not affected.
While reading output,
more than 2000 bytes can force earlier bytes to be ""forgotten"". This may be changed with the function match_max. (Note that excessively large values
can slow down the pattern matcher.) If patlist is full_buffer, the corresponding body is executed if match_max bytes have been received
and no other patterns have matched. Whether or not the full_buffer keyword is used, the forgotten characters are written to expect_out(buffer).
If patlist is the keyword null, and nulls are allowed (via the remove_nulls command), the corresponding body is executed if a single
ASCII 0 is matched. It is not possible to match 0 bytes via glob or regexp patterns.
Upon matching a pattern (or eof or full_buffer), any matching and previously unmatched output is saved in the variable expect_out(buffer). Up to 9
regexp substring matches are saved in the variables expect_out(1,string) through expect_out(9,string). If the -indices flag is used before
a pattern, the starting and ending indices (in a form suitable for lrange) of the 10 strings are stored in the variables expect_out(X,start) and
expect_out(X,end) where X is a digit, corresponds to the substring position in the buffer. 0 refers to strings which matched the entire pattern and is
generated for glob patterns as well as regexp patterns. For example, if a process has produced output of ""abcdefgh\n"", the result of:expect ""cd""
is as if the following statements had executed:set expect_out(0,string) cd
set expect_out(buffer) abcd
and ""efgh\n"" is left in the output buffer. If a process produced the output ""abbbcabkkkka\n"", the result of:expect -indices -re ""b(b*).*(k+)""
is as if the following statements had executed:set expect_out(0,start) 1
set expect_out(0,end) 10
set expect_out(0,string) bbbcabkkkk
set expect_out(1,start) 2
set expect_out(1,end) 3
set expect_out(1,string) bb
set expect_out(2,start) 10
set expect_out(2,end) 10
set expect_out(2,string) k
set expect_out(buffer) abbbcabkkkk
and ""a\n"" is left in the output buffer. The pattern ""*"" (and -re "".*"") will flush the output buffer without reading any more output from the process.
Normally, the matched output is discarded from Expect's internal buffers.
This may be prevented by prefixing a pattern with the -notransfer flag. This flag is especially useful in experimenting (and can be abbreviated to
""-not"" for convenience while experimenting).
The spawn id associated with the matching output (or eof or full_buffer) is stored in expect_out(spawn_id).
The -timeout flag causes the current expect command to use the following value as a timeout instead of using the value of the timeout variable.
By default, patterns are matched against output from the current process, however the -i flag declares the output from the named spawn_id list be
matched against any following patterns (up to the next -i). The spawn_id list should either be a whitespace separated list of spawn_ids or a variable
referring to such a list of spawn_ids.
For example, the following example waits for ""connected"" from the current process, or ""busy"", ""failed"" or ""invalid password"" from the spawn_id named by
$proc2.expect {
    -i $proc2 busy {puts busy\n ; exp_continue}
    -re ""failed|invalid password"" abort
    timeout abort
    connected
}
The value of the global variable any_spawn_id may be used to match patterns to any spawn_ids that are named with all other -i flags in the
current expect command. The spawn_id from a -i flag with no associated pattern (i.e., followed immediately by another -i) is made
available to any other patterns in the same expect command associated with any_spawn_id.
The -i flag may also name a global variable in which case the variable is read for a list of spawn ids. The variable is reread whenever it changes.
This provides a way of changing the I/O source while the command is in execution. Spawn ids provided this way are called ""indirect"" spawn ids.
Actions such as break and continue cause control structures (i.e., for, proc) to behave in the usual way. The command
exp_continue allows expect itself to continue executing rather than returning as it normally would.
This is useful for avoiding explicit loops or repeated expect statements.
The following example is part of a fragment to automate rlogin. The exp_continue avoids having to write a second expect statement (to look
for the prompt again) if the rlogin prompts for a password.expect {
    Password: {
        stty -echo
        send_user ""password (for $user) on $host: ""
        expect_user -re ""(.*)\n""
        send_user ""\n""
        send ""$expect_out(1,string)\r""
        stty echo
        exp_continue
    } incorrect {
        send_user ""invalid password or account\n""
        exit
    } timeout {
        send_user ""connection to $host timed out\n""
        exit
    } eof {
        send_user \
            ""connection to host failed: $expect_out(buffer)""
        exit
    } -re $prompt
}
For example, the following fragment might help a user guide an interaction that is already totally automated. In this case, the terminal is put into raw mode.
If the user presses ""+"", a variable is incremented. If ""p"" is pressed, several returns are sent to the process, perhaps to poke it in some way, and ""i"" lets
the user interact with the process, effectively stealing away control from the script. In each case, the exp_continue allows the current expect
to continue pattern matching after executing the current action.stty raw -echo
expect_after {
    -i $user_spawn_id
    ""p"" {send ""\r\r\r""; exp_continue}
    ""+"" {incr foo; exp_continue}
    ""i"" {interact; exp_continue}
    ""quit"" exit
}
By default,
exp_continue resets the timeout timer. The timer is not restarted, if exp_continue is called with the -continue_timer flag.
expect_after [expect_args]
works identically to the expect_before except that if patterns from both expect and expect_after can match, the expect pattern
is used. See the expect_before command for more information.
expect_background [expect_args]
takes the same arguments as expect, however it returns immediately. Patterns are tested whenever new input arrives. The pattern timeout and
default are meaningless to expect_background and are silently discarded. Otherwise, the expect_background command uses
expect_before and expect_after patterns just like expect does.
When expect_background actions are being evaluated, background processing for the same spawn id is blocked. Background processing is unblocked when
the action completes. While background processing is blocked, it is possible to do a (foreground) expect on the same spawn id.
It is not possible to execute an expect while an expect_background is unblocked. expect_background for a particular spawn id is deleted
by declaring a new expect_background with the same spawn id. Declaring expect_background with no pattern removes the given spawn id from the ability to
match patterns in the background.
expect_before [expect_args]
takes the same arguments as expect, however it returns immediately. Pattern-action pairs from the most recent expect_before with the same
spawn id are implicitly added to any following expect commands. If a pattern matches, it is treated as if it had been specified in the expect
command itself, and the associated body is executed in the context of the expect command. If patterns from both expect_before and expect
can match, the expect_before pattern is used.
If no pattern is specified, the spawn id is not checked for any patterns.
Unless overridden by a -i flag, expect_before patterns match against the spawn id defined at the time that the expect_before command
was executed (not when its pattern is matched).
The -info flag causes expect_before to return the current specifications of what patterns it will match. By default, it reports on the current spawn
id. An optional spawn id specification may be given for information on that spawn id. For exampleexpect_before -info -i $proc
At most one spawn id specification may be given. The flag -indirect suppresses direct spawn ids that come only from indirect specifications.
Instead of a spawn id specification, the flag ""-all"" will cause ""-info"" to report on all spawn ids.
The output of the -info flag can be reused as the argument to expect_before.
expect_tty [expect_args]
is like expect but it reads characters from /dev/tty (i.e. keystrokes from the user). By default, reading is performed in cooked mode. Thus, lines
must end with a return in order for expect to see them. This may be changed via stty (see the stty command below).
expect_user[expect_args]
is like expect but it reads characters from stdin (i.e. keystrokes from the user). By default, reading is performed in cooked mode. Thus, lines must
end with a return in order for expect to see them. This may be changed via stty (see the stty command below).
fork
creates a new process. The new process is an exact copy of the current Expect process. On success, fork returns 0 to the new (child) process
and returns the process ID of the child process to the parent process. On failure (invariably due to lack of resources, e.g., swap space, memory), fork
returns -1 to the parent process, and no child process is created.
Forked processes exit via the
exit command, just like the original process. Forked processes are allowed to write to the log files. If you do not disable debugging or logging in
most of the processes, the result can be confusing.
Some pty implementations may be confused by multiple readers and writers,
even momentarily. Thus, it is safest to fork before spawning processes.
interact [string1 body1] ... [stringn [bodyn]]
gives control of the current process to the user, so that keystrokes are sent to the current process, and the stdout and stderr of the current process are
returned.
String-body pairs may be specified as arguments, in which case the
body is executed when the corresponding string is entered. (By default, the string is not sent to the current process.) The interpreter command is
assumed, if the final body is missing.
If the arguments to the entire
interact statement require more than one line, all the arguments may be ""braced"" into one so as to avoid terminating each line with a backslash. In
this one case, the usual Tcl substitutions will occur despite the braces.
For example, the following command runs interact with the following
string-body pairs defined: When ^Z is pressed, Expect is suspended. (The -reset flag restores the terminal modes.) When ^A is pressed, the
user sees ""you typed a control-A"" and the process is sent a ^A. When $ is pressed, the user sees the date. When ^C is pressed, Expect exits. If ""foo"" is
entered, the user sees ""bar"". When ~~ is pressed, the Expect interpreter runs interactively.set CTRLZ \032
interact {
    -reset $CTRLZ {exec kill -STOP [pid]}
    \001   {send_user ""you typed a control-A\n"";
            send ""\001""
           }
    $      {send_user ""The date is [clock format [clock seconds]].""}
    \003   exit
    foo    {send_user ""bar""}
    ~~
}
In string-body pairs, strings are matched in the order they are listed
as arguments. Strings that partially match are not sent to the current process in anticipation of the remainder coming. If characters are then entered such
that there can no longer possibly be a match, only the part of the string will be sent to the process that cannot possibly begin another match. Thus, strings
that are substrings of partial matches can match later, if the original strings that was attempting to be match ultimately fails.
By default, string matching is exact with no wild cards. (In contrast,
the expect command uses glob-style patterns by default.) The -ex flag may be used to protect patterns that might otherwise match
interact flags from doing so. Any pattern beginning with a ""-"" should be protected this way. (All strings starting with ""-"" are reserved for future
options.)
The -re flag forces the string to be interpreted as a regexp-style pattern. In this case, matching substrings are stored in the variable
interact_out similarly to the way expect stores its output in the variable expect_out. The -indices flag is similarly supported.
The pattern eof introduces an action that is executed upon end-of-file. A separate eof pattern may also follow the -output flag in
which case it is matched if an eof is detected while writing output. The default eof action is ""return"", so that interact simply returns upon any
EOF.
The pattern timeout introduces a timeout (in seconds) and action that is executed after no characters have been read for a given time. The
timeout pattern applies to the most recently specified process. There is no default timeout. The special variable ""timeout"" (used by the expect
command) has no affect on this timeout.
For example, the following statement could be used to autologout users who have not typed anything for an hour but who still get frequent system
messages:interact -input $user_spawn_id timeout 3600 return -output \
    $spawn_idIf the pattern is the keyword null, and nulls are allowed (via the remove_nulls command), the corresponding body is executed if a single ASCII
0 is matched. It is not possible to match 0 bytes via glob or regexp patterns.
Prefacing a pattern with the flag -iwrite causes the variable interact_out(spawn_id) to be set to the spawn_id which matched the pattern (or
eof).
Actions such as break and continue cause control structures (i.e., for, proc) to behave in the usual way. However return
causes interact to return to its caller, while inter_return causes interact to cause a return in its caller. For example, if ""proc foo"" called
interact which then executed the action inter_return, proc foo would return. (This means that if interact calls interpreter
interactively typing return will cause the interact to continue, while inter_return will cause the interact to return to its caller.)
During
interact, raw mode is used so that all characters may be passed to the current process. If the current process does not catch job control signals,
it will stop if sent a stop signal (by default ^Z). To restart it, send a continue signal (such as by ""kill -CONT <pid>""). If you really want to send a
SIGSTOP to such a process (by ^Z), consider spawning csh first and then running your program. On the other hand, if you want to send a SIGSTOP to Expect
itself, first call interpreter (perhaps by using an escape character), and then press ^Z.
String-body pairs can be used as a shorthand for avoiding having
to enter the interpreter and execute commands interactively. The previous terminal mode is used while the body of a string-body pair is being executed.
For speed, actions execute in raw mode by default. The
-reset flag resets the terminal to the mode it had before interact was executed (invariably, cooked mode). Note that characters entered when
the mode is being switched may be lost (an unfortunate feature of the terminal driver on some systems). The only reason to use -reset is if your action
depends on running in cooked mode.
The
-echo flag sends characters that match the following pattern back to the process that generated them as each character is read. This may be useful
when the user needs to see feedback from partially typed patterns.
If a pattern is being echoed but eventually fails to match,
the characters are sent to the spawned process. If the spawned process then echoes them, the user will see the characters twice. -echo is probably
only appropriate in situations where the user is unlikely to not complete the pattern. For example, the following excerpt is from rftp, the recursive-ftp
script, where the user is prompted to enter ~g, ~p, or ~l, to get, put, or list the current directory recursively. These are so far away from the normal ftp
commands, that the user is unlikely to type ~ followed by anything else, except mistakenly, in which case, they'll probably just ignore the result anyway.interact {
    -echo ~g {getcurdirectory 1}
    -echo ~l {getcurdirectory 0}
    -echo ~p {putcurdirectory}
}
The -nobuffer flag sends characters that match the following pattern on to the output process as characters are read.
This is useful when you wish to let a program echo back the pattern. For example, the following might be used to monitor where a person is dialing (a
Hayes-style modem). Each time ""atd"" is seen the script logs the rest of the line.proc lognumber {} {
    interact -nobuffer -re ""(.*)\r"" return
    puts $log ""[clock format [clock seconds]]: dialed $interact_out(1,string)""
}
interact -nobuffer ""atd"" lognumber
During
interact, previous use of log_user is ignored. In particular, interact will force its output to be logged (sent to the standard
output) since it is presumed the user doesn't wish to interact blindly.
The
-o flag causes any following key-body pairs to be applied to the output of the current process. This can be useful, for example, when dealing with
hosts that send unwanted characters during a telnet session.
By default,
interact expects the user to be writing stdin and reading stdout of the Expect process itself. The -u flag (for ""user"") makes
interact look for the user as the process named by its argument (which must be a spawned id).
This allows two unrelated processes to be joined
together without using an explicit loop. To aid in debugging, Expect diagnostics always go to stderr (or stdout for certain logging and debugging
information). For the same reason, the interpreter command will read interactively from stdin.
For example, the following fragment creates a login process.
Then it dials the user (not shown), and finally connects the two together. Of course, any process may be substituted for login. A shell, for example, would
allow the user to work without supplying an account and password.spawn login
set login $spawn_id
spawn tip modem
# dial back out to user
# connect user to login
interact -u $login
To send output to multiple processes, list each spawn id list prefaced by a -output flag. Input for a group of output spawn ids may be determined by a
spawn id list prefaced by a -input flag. (Both -input and -output may take lists in the same form as the -i flag in the
expect command, except that any_spawn_id is not meaningful in interact.) All following flags and strings (or patterns) apply to this input until
another -input flag appears. If no -input appears, -output implies ""-input $user_spawn_id -output"". (Similarly, with patterns that do not have
-input.) If one -input is specified, it overrides $user_spawn_id. If a second -input is specified, it overrides $spawn_id. Additional
-input flags may be specified.
The two implied input processes default to having their outputs specified as $spawn_id and $user_spawn_id (in reverse). If a -input flag appears with
no -output flag, characters from that process are discarded.
The -i flag introduces a replacement for the current spawn_id when no other -input or -output flags are used. A -i flag implies a -o
flag.
It is possible to change the processes that are being interacted with by using indirect spawn ids. (Indirect spawn ids are described in the section on the
expect command.) Indirect spawn ids may be specified with the -i, -u, -input, or -output flags.
interpreter "" [args]""
causes the user to be interactively prompted for Expect and Tcl commands. The result of each command is printed.
Actions such as
break and continue cause control structures (i.e., for, proc) to behave in the usual way. However return causes
interpreter to return to its caller, while inter_return causes interpreter to cause a return in its caller. For example, if ""proc foo"" called
interpreter which then executed the action inter_return, proc foo would return. Any other command causes interpreter to continue
prompting for new commands.
By default, the prompt contains two integers.
The first integer describes the depth of the evaluation stack (i.e., how many times Tcl_Eval has been called). The second integer is the Tcl history
identifier. The prompt can be set by defining a procedure called ""prompt1"" whose return value becomes the next prompt. If a statement has open quotes, parens,
braces, or brackets, a secondary prompt (by default ""+> "") is issued upon newline. The secondary prompt may be set by defining a procedure called ""prompt2"".
During
interpreter, cooked mode is used, even if the its caller was using raw mode.
If stdin is closed,
interpreter will return unless the -eof flag is used, in which case the subsequent argument is invoked.
log_file[args] [[-a] file]
If a filename is provided, log_file will record a transcript of the session (beginning at that point) in the file. log_file will stop
recording if no argument is given. Any previous log file is closed.
Instead of a filename, a Tcl file identifier may be provided by using the -open or -leaveopen flags. This is similar to the spawn
command. (See spawn for more info.)
The -a flag forces output to be logged that was suppressed by the log_user command.
By default, the log_file command appends to old files rather than truncating them, for the convenience of being able to turn logging off and
on multiple times in one session. To truncate files, use the -noappend flag.
The -info flag causes log_file to return a description of the most recent non-info arguments given.
log_user -info|0|1
By default, the send/expect dialogue is logged to stdout (and a logfile if open). The logging to stdout is disabled by the command ""log_user 0"" and
reenabled by ""log_user 1"". Logging to the logfile is unchanged.
The -info flag causes log_user to return a description of the most recent non-info arguments given.
match_max [-d] [-i spawn_id] [size]
defines the size of the buffer (in bytes) used internally by expect. With no size argument, the current size is returned.
With the
-d flag, the default size is set. (The initial default is 2000.) With the -i flag, the size is set for the named spawn id, otherwise it is
set for the current process.
overlay [-# spawn_id] [-# spawn_id] [...] program [args]
executes program args in place of the current Expect program, which terminates. A bare hyphen argument forces a hyphen in front of the
command name as if it was a login shell. All spawn_ids are closed except for those named as arguments. These are mapped onto the named file identifiers.
Spawn_ids are mapped to file identifiers for the new program to inherit.
For example, the following line runs chess and allows it to be controlled by the current process - say, a chess master.overlay -0 $spawn_id -1 $spawn_id -2 $spawn_id chess
This is more efficient than ""interact -u"", however, it sacrifices the ability to do programmed interaction since the Expect process is no longer in
control.
Note that no controlling terminal is provided. Thus, if you
disconnect or remap standard input, programs that do job control (shells, login, etc) will not function properly.
parity [-d] [-i spawn_id] [value]
defines whether parity should be retained or stripped from the output of spawned processes. If value is zero, parity is stripped, otherwise it is
not stripped. With no value argument, the current value is returned.
With the
-d flag, the default parity value is set. (The initial default is 1, i.e., parity is not stripped.) With the -i flag, the parity value is set
for the named spawn id, otherwise it is set for the current process.
remove_nulls [-d] [-i spawn_id] [value]
defines whether nulls are retained or removed from the output of spawned processes before pattern matching or storing in the variable expect_out or
interact_out. If value is 1, nulls are removed. If value is 0, nulls are not removed. With no value argument, the current value is
returned.
With the
-d flag, the default value is set. (The initial default is 1, i.e., nulls are removed.) With the -i flag, the value is set for the named
spawn id, otherwise it is set for the current process.
Whether or not nulls are removed, Expect will record null bytes to the log and stdout.
send [-flags] string
Sends string to the current process. For example, the commandsend ""hello world\r""
sends the characters, h e l l o <blank> w o r l d <return> to the current process. (Tcl includes a printf-like command (called format) which
can build arbitrarily complex strings.)
Characters are sent immediately although programs with line-buffered input
will not read the characters until a return character is sent. A return character is denoted ""\r"".
The -- flag forces the next argument to be interpreted as a string rather than a flag. Any string can be preceded by ""--"" whether or not it actually
looks like a flag. This provides a reliable mechanism to specify variable strings without being tripped up by those that accidentally look like flags. (All
strings starting with ""-"" are reserved for future options.)
The -i flag declares that the string be sent to the named spawn_id. If the spawn_id is user_spawn_id, and the terminal is in raw mode,
newlines in the string are translated to return-newline sequences so that they appear as if the terminal was in cooked mode. The -raw flag disables this
translation.
The -null flag sends null characters (0 bytes). By default, one null is sent. An integer may follow the -null to indicate how many nulls to
send.
The -break flag generates a break condition. This only makes sense if the spawn id refers to a tty device opened via ""spawn -open"". If you have
spawned a process such as tip, you should use tip's convention for generating a break.
The -s flag forces output to be sent ""slowly"", thus avoid the common situation where a computer outtypes an input buffer that was designed for a
human who would never outtype the same buffer. This output is controlled by the value of the variable ""send_slow"" which takes a two element list. The first
element is an integer that describes the number of bytes to send atomically. The second element is a real number that describes the number of seconds by which
the atomic sends must be separated. For example, ""set send_slow {10 .001}"" would force ""send -s"" to send strings with 1 millisecond in between each 10
characters sent.
The -h flag forces output to be sent (somewhat) like a human actually typing. Human-like delays appear between the characters. (The algorithm is
based upon a Weibull distribution, with modifications to suit this particular application.) This output is controlled by the value of the variable ""send_human""
which takes a five element list. The first two elements are average interarrival time of characters in seconds. The first is used by default. The second is
used at word endings, to simulate the subtle pauses that occasionally occur at such transitions. The third parameter is a measure of variability where .1 is
quite variable, 1 is reasonably variable, and 10 is quite invariable. The extremes are 0 to infinity. The last two parameters are, respectively, a minimum and
maximum interarrival time. The minimum and maximum are used last and ""clip"" the final time. The ultimate average can be quite different from the given average
if the minimum and maximum clip enough values.
As an example, the following command emulates a fast and consistent typist:set send_human {.1 .3 1 .05 2}
send -h ""I'm hungry.  Let's do lunch.""
while the following might be more suitable after a hangover:set send_human {.4 .4 .2 .5 100}
send -h ""Goodd party lash night!""
Note that errors are not simulated, although you can set up error correction situations yourself by embedding mistakes and corrections in a send argument.
The flags for sending null characters, for sending breaks, for forcing slow output and for human-style output are mutually exclusive. Only the one specified
last will be used. Furthermore, no string argument can be specified with the flags for sending null characters or breaks.
It is a good idea to precede the first send to a process by an expect. expect will wait for the process to start, while send
cannot. In particular, if the first send completes before the process starts running, you run the risk of having your data ignored. In situations where
interactive programs offer no initial prompt, you can precede send by a delay as in:# To avoid giving hackers hints on how to break in,
# this system does not prompt for an external password.
# Wait for 5 seconds for exec to complete
spawn telnet very.secure.gov
sleep 5
send password\r
exp_send is an alias for send. If you are using Expectk or some other variant of Expect in the Tk environment, send is defined by
Tk for an entirely different purpose. exp_send is provided for compatibility between environments. Similar aliases are provided for other Expect's other
send commands.
send_error[-flags] string
is like send, except that the output is sent to stderr rather than the current process.
send_log [--] string
is like send, except that the string is only sent to the log file (see log_file.) The arguments are ignored if no log file is open.
send_tty [-flags] string
is like send, except that the output is sent to /dev/tty rather than the current process.
send_user[-flags] string
is like send, except that the output is sent to stdout rather than the current process.
sleep seconds
causes the script to sleep for the given number of seconds. Seconds may be a decimal number. Interrupts (and Tk events if you are using Expectk) are
processed while Expect sleeps.
spawn[args] program [args]
creates a new process running program args. Its stdin, stdout and stderr are connected to Expect, so that they may be read and written by other
Expect commands. The connection is broken by close or if the process itself closes any of the file identifiers.
When a process is started by
spawn, the variable spawn_id is set to a descriptor referring to that process. The process described by spawn_id is considered the
current process. spawn_id may be read or written, in effect providing job control.
user_spawn_id
is a global variable containing a descriptor which refers to the user. For example, when spawn_id is set to this value, expect behaves like
expect_user.
error_spawn_id is a global variable containing a descriptor which refers to the standard error. For example, when spawn_id is set to this
value, send behaves like send_error.
tty_spawn_id
is a global variable containing a descriptor which refers to /dev/tty. If /dev/tty does not exist (such as in a cron, at, or batch script), then
tty_spawn_id is not defined. This may be tested as:if {[info vars tty_spawn_id]} {
    # /dev/tty exists
} else {
    # /dev/tty doesn't exist
    # probably in cron, batch, or at script
}
spawn
returns the UNIX process id. If no process is spawned, 0 is returned. The variable spawn_out(slave,name) is set to the name of the pty slave device.
By default,
spawn echoes the command name and arguments. The -noecho flag stops spawn from doing this.
The
-console flag causes console output to be redirected to the spawned process. This is not supported on all systems.
Internally, spawn uses a pty, initialized the same way as the user's tty. This is further initialized so that all settings are ""sane"" (according to
stty(1)). If the variable stty_init is defined, it is interpreted in the style of stty arguments as further configuration. For example, ""set
stty_init raw"" will cause further spawned processes's terminals to start in raw mode. -nottycopy skips the initialization based on the user's tty.
-nottyinit skips the ""sane"" initialization.
Normally,
spawn takes little time to execute. If you notice spawn taking a significant amount of time, it is probably encountering ptys that are wedged. A
number of tests are run on ptys to avoid entanglements with errant processes. (These take 10 seconds per wedged pty.) Running Expect with the -d option
will show if Expect is encountering many ptys in odd states. If you cannot kill the processes to which these ptys are attached, your only recourse may
be to reboot.
If program cannot be spawned successfully because exec(2) fails (e.g. when program doesn't exist), an error message will be returned by
the next interact or expect command as if program had run and produced the error message as output. This behavior is a natural consequence
of the implementation of spawn. Internally, spawn forks, after which the spawned process has no way to communicate with the original Expect
process except by communication via the spawn_id.
The -open flag causes the next argument to be interpreted as a Tcl file identifier (i.e., returned by open.) The spawn id can then be used as
if it were a spawned process. (The file identifier should no longer be used.) This lets you treat raw devices, files, and pipelines as spawned processes
without using a pty. 0 is returned to indicate there is no associated process. When the connection to the spawned process is closed, so is the Tcl file
identifier. The -leaveopen flag is similar to -open except that -leaveopen causes the file identifier to be left open even after the spawn
id is closed.
The -pty flag causes a pty to be opened but no process spawned. 0 is returned to indicate there is no associated process. Spawn_id is set as usual.
The variable spawn_out(slave,fd) is set to a file identifier corresponding to the pty slave. It can be closed using ""close -slave"".
The -ignore flag names a signal to be ignored in the spawned process. Otherwise, signals get the default behavior. Signals are named as in the
trap command, except that each signal requires a separate flag.
strace level
causes following statements to be printed before being executed. (Tcl's trace command traces variables.) level indicates how far down in the call
stack to trace. For example, the following command runs Expect while tracing the first 4 levels of calls, but none below that.expect -c ""strace 4"" script.expThe -info flag causes strace to return a description of the most recent non-info arguments given.
stty args
changes terminal modes similarly to the external stty command.
By default, the controlling terminal is accessed. Other terminals can be accessed by appending ""< /dev/tty..."" to the command. (Note that the arguments
should not be grouped into a single argument.)
Requests for status return it as the result of the command. If no status is requested and the controlling terminal is accessed, the previous status of the
raw and echo attributes are returned in a form which can later be used by the command.
For example, the arguments raw or -cooked put the terminal into raw mode. The arguments -raw or cooked put the terminal into
cooked mode. The arguments echo and -echo put the terminal into echo and noecho mode respectively.
The following example illustrates how to temporarily disable echoing.
This could be used in otherwise-automatic scripts to avoid embedding passwords in them. (See more discussion on this under EXPECT HINTS below.)stty -echo
send_user ""Password: ""
expect_user -re ""(.*)\n""
set password $expect_out(1,string)
stty echo
system args
gives args to sh(1) as input, just as if it had been typed as a command from a terminal. Expect waits until the shell terminates. The
return status from sh is handled the same way that exec handles its return status.
In contrast to
exec which redirects stdin and stdout to the script, system performs no redirection (other than that indicated by the string itself). Thus,
it is possible to use programs which must talk directly to /dev/tty. For the same reason, the results of system are not recorded in the log.
timestamp [args]
returns a timestamp. With no arguments, the number of seconds since the epoch is returned.
The -format flag introduces a string which is returned but with substitutions made according to the POSIX rules for strftime. For example %a is
replaced by an abbreviated weekday name (i.e., Sat). Others are:%a      abbreviated weekday name
%A      full weekday name
%b      abbreviated month name
%B      full month name
%c      date-time as in: Wed Oct  6 11:45:56 1993
%d      day of the month (01-31)
%H      hour (00-23)
%I      hour (01-12)
%j      day (001-366)
%m      month (01-12)
%M      minute (00-59)
%p      am or pm
%S      second (00-61)
%u      day (1-7, Monday is first day of week)
%U      week (00-53, first Sunday is first day of week one)
%V      week (01-53, ISO 8601 style)
%w      day (0-6)
%W      week (00-53, first Monday is first day of week one)
%x      date-time as in: Wed Oct  6 1993
%X      time as in: 23:59:59
%y      year (00-99)
%Y      year as in: 1993
%Z      timezone (or nothing if not determinable)
%%      a bare percent sign
Other % specifications are undefined. Other characters will be passed through untouched. Only the C locale is supported.
The -seconds flag introduces a number of seconds since the epoch to be used as a source from which to format. Otherwise, the current time is used.
The -gmt flag forces timestamp output to use the GMT timezone. With no flag, the local timezone is used.
trap [[command] signals]
causes the given command to be executed upon future receipt of any of the given signals. The command is executed in the global scope. If
command is absent, the signal action is returned. If command is the string SIG_IGN, the signals are ignored. If command is the string
SIG_DFL, the signals are result to the system default. signals is either a single signal or a list of signals. Signals may be specified numerically or
symbolically as per signal(3). The ""SIG"" prefix may be omitted.
With no arguments (or the argument -number), trap returns the signal number of the trap command currently being executed.
The -code flag uses the return code of the command in place of whatever code Tcl was about to return when the command originally started running.
The -interp flag causes the command to be evaluated using the interpreter active at the time the command started running rather than when the trap
was declared.
The -name flag causes the trap command to return the signal name of the trap command currently being executed.
The -max flag causes the trap command to return the largest signal number that can be set.
For example, the command ""trap {send_user ""Ouch!""} SIGINT"" will print ""Ouch!"" each time the user presses ^C.
By default, SIGINT (which can usually be generated by pressing ^C) and SIGTERM cause Expect to exit. This is due to the following trap, created by default
when Expect starts.trap exit {SIGINT SIGTERM}
If you use the -D flag to start the debugger, SIGINT is redefined to start the interactive debugger. This is due to the following trap:trap {exp_debug 1} SIGINT
The debugger trap can be changed by setting the environment variable EXPECT_DEBUG_INIT to a new trap command.
You can, of course, override both of these just by adding trap commands to your script. In particular, if you have your own ""trap exit SIGINT"", this will
override the debugger trap. This is useful if you want to prevent users from getting to the debugger at all.
If you want to define your own trap on SIGINT but still trap to the debugger when it is running, use:if {![exp_debug]} {trap mystuff SIGINT}
Alternatively, you can trap to the debugger using some other signal.
trap will not let you override the action for SIGALRM as this is used internally to Expect. The disconnect command sets SIGALRM to SIG_IGN
(ignore). You can reenable this as long as you disable it during subsequent spawn commands.
See signal(3) for more info.
wait [args]
delays until a spawned process (or the current process if none is named) terminates.
wait
normally returns a list of four integers. The first integer is the pid of the process that was waited upon. The second integer is the corresponding spawn
id. The third integer is -1 if an operating system error occurred, or 0 otherwise. If the third integer was 0, the fourth integer is the status returned by the
spawned process. If the third integer was -1, the fourth integer is the value of errno set by the operating system. The global variable errorCode is also set.
Additional elements may appear at the end of the return value from wait. An optional fifth element identifies a class of information. Currently, the
only possible value for this element is CHILDKILLED in which case the next two values are the C-style signal name and a short textual description.
The
-i flag declares the process to wait corresponding to the named spawn_id (NOT the process id). Inside a SIGCHLD handler, it is possible to wait for
any spawned process by using the spawn id -1.
The -nowait flag causes the wait to return immediately with the indication of a successful wait. When the process exits (later), it will
automatically disappear without the need for an explicit wait.
The wait command may also be used wait for a forked process using the arguments ""-i -1"". Unlike its use with spawned processes, this command can be
executed at any time. There is no control over which process is reaped. However, the return value can be checked for the process id.
Libraries
Expect automatically knows about two built-in libraries for Expect scripts. These are defined by
the directories named in the variables exp_library and exp_exec_library. Both are meant to contain utility files that can be used by other scripts.
exp_library contains architecture-independent files. exp_exec_library contains architecture-dependent files. Depending on your system, both directories may
be totally empty. The existence of the file $exp_exec_library/cat-buffers describes whether your /bin/cat buffers by default.
Pretty-printing
A vgrind definition is available for pretty-printing Expect scripts. Assuming the
vgrind definition supplied with the Expect distribution is correctly installed, you can use it as:vgrind -lexpect file
Examples
It many not be apparent how to put everything together that the man page describes. I encourage
you to read and try out the examples in the example directory of the Expect distribution. Some of them are real programs. Others are simply illustrative
of certain techniques, and of course, a couple are just quick hacks. The INSTALL file has a quick overview of these programs.
The Expect papers (see SEE ALSO) are also useful. While some papers use syntax corresponding to earlier versions of Expect, the accompanying
rationales are still valid and go into a lot more detail than this man page.
Caveats
Extensions may collide with Expect's command names. For example, send is defined by Tk for
an entirely different purpose. For this reason, most of the Expect commands are also available as ""exp_XXXX"". Commands and variables beginning with
""exp"", ""inter"", ""spawn"", and ""timeout"" do not have aliases. Use the extended command names if you need this compatibility between environments.
Expect takes a rather liberal view of scoping. In particular, variables read by commands specific to the Expect program will be sought first
from the local scope, and if not found, in the global scope. For example, this obviates the need to place ""global timeout"" in every procedure you write that
uses expect. On the other hand, variables written are always in the local scope (unless a ""global"" command has been issued). The most common problem
this causes is when spawn is executed in a procedure. Outside the procedure, spawn_id no longer exists, so the spawned process is no longer accessible
simply because of scoping. Add a ""global spawn_id"" to such a procedure.
If you cannot enable the multispawning capability (i.e., your system supports neither select (BSD *.*), poll (SVR>2), nor something equivalent),
Expect will only be able to control a single process at a time. In this case, do not attempt to set spawn_id, nor should you execute processes
via exec while a spawned process is running. Furthermore, you will not be able to expect from multiple processes (including the user as one) at the same
time.
Terminal parameters can have a big effect on scripts. For example, if a script is written to look for echoing, it will misbehave if echoing is turned off.
For this reason, Expect forces sane terminal parameters by default. Unfortunately, this can make things unpleasant for other programs. As an example, the emacs
shell wants to change the ""usual"" mappings: newlines get mapped to newlines instead of carriage-return newlines, and echoing is disabled. This allows one to
use emacs to edit the input line. Unfortunately, Expect cannot possibly guess this.
You can request that Expect not override its default setting of terminal parameters, but you must then be very careful when writing scripts for such
environments. In the case of emacs, avoid depending upon things like echoing and end-of-line mappings.
The commands that accepted arguments braced into a single list (the expect variants and interact) use a heuristic to decide if the list is
actually one argument or many. The heuristic can fail only in the case when the list actually does represent a single argument which has multiple embedded \n's
with non-whitespace characters between them. This seems sufficiently improbable, however the argument ""-nobrace"" can be used to force a single argument to be
handled as a single argument. This could conceivably be used with machine-generated Expect code. Similarly, -brace forces a single argument to be handle as
multiple patterns/actions.
Bugs
It was really tempting to name the program ""sex"" (for either ""Smart EXec"" or ""Send-EXpect""), but good
sense (or perhaps just Puritanism) prevailed.
On some systems, when a shell is spawned, it complains about not being able to access the tty but runs anyway. This means your system has a mechanism for
gaining the controlling tty that Expect doesn't know about. Please find out what it is, and send this information back to me.
Ultrix 4.1 (at least the latest versions around here) considers timeouts of above 1000000 to be equivalent to 0.
Digital UNIX 4.0A (and probably other versions) refuses to allocate ptys if you define a SIGCHLD handler. See grantpt page for more info.
IRIX 6.0 does not handle pty permissions correctly so that if Expect attempts to allocate a pty previously used by someone else, it fails. Upgrade to IRIX
6.1.
Telnet (verified only under SunOS 4.1.2) hangs if TERM is not set. This is a problem under cron, at and in cgi scripts, which do not define TERM. Thus, you
must set it explicitly - to what type is usually irrelevant. It just has to be set to something! The following probably suffices for most cases.set env(TERM) vt100Tip (verified only under BSDI BSD/OS 3.1 i386) hangs if SHELL and HOME are not set. This is a problem under cron, at and in cgi scripts, which do not define
these environment variables. Thus, you must set them explicitly - to what type is usually irrelevant. It just has to be set to something! The following
probably suffices for most cases.set env(SHELL) /bin/sh
set env(HOME) /usr/local/binSome implementations of ptys are designed so that the kernel throws away any unread output after 10 to 15 seconds (actual number is
implementation-dependent) after the process has closed the file descriptor. Thus Expect programs such asspawn date
sleep 20
expect
will fail. To avoid this, invoke non-interactive programs with exec rather than spawn. While such situations are conceivable, in practice I have
never encountered a situation in which the final output of a truly interactive program would be lost due to this behavior.
On the other hand, Cray UNICOS ptys throw away any unread output immediately after the process has closed the file descriptor. I have reported this to Cray
and they are working on a fix.
Sometimes a delay is required between a prompt and a response, such as when a tty interface is changing UART settings or matching baud rates by looking for
start/stop bits. Usually, all this is require is to sleep for a second or two. A more robust technique is to retry until the hardware is ready to receive
input. The following example uses both strategies:send ""speed 9600\r"";
sleep 1
expect {
    timeout {send ""\r""; exp_continue}
    $prompt
}trap -code will not work with any command that sits in Tcl's event loop, such as sleep. The problem is that in the event loop, Tcl discards the return codes
from async event handlers. A workaround is to set a flag in the trap code. Then check the flag immediately after the command (i.e., sleep).
The expect_background command ignores -timeout arguments and has no concept of timeouts in general.
Expect Hints
There are a couple of things about Expect that may be non-intuitive. This section
attempts to address some of these things with a couple of suggestions.
A common expect problem is how to recognize shell prompts. Since these are customized differently by differently people and different shells, portably
automating rlogin can be difficult without knowing the prompt. A reasonable convention is to have users store a regular expression describing their prompt (in
particular, the end of it) in the environment variable EXPECT_PROMPT. Code like the following can be used. If EXPECT_PROMPT doesn't exist, the code still has a
good chance of functioning correctly.set prompt ""(%|#|\\$) $""          ;# default prompt
catch {set prompt $env(EXPECT_PROMPT)}
expect -re $prompt
I encourage you to write expect patterns that include the end of whatever you expect to see. This avoids the possibility of answering a question before
seeing the entire thing. In addition, while you may well be able to answer questions before seeing them entirely, if you answer early, your answer may appear
echoed back in the middle of the question. In other words, the resulting dialogue will be correct but look scrambled.
Most prompts include a space character at the end. For example, the prompt from ftp is 'f', 't', 'p', '>' and <blank>. To match this prompt, you
must account for each of these characters. It is a common mistake not to include the blank. Put the blank in explicitly.
If you use a pattern of the form X*, the * will match all the output received from the end of X to the last thing received. This sounds intuitive but can be
somewhat confusing because the phrase ""last thing received"" can vary depending upon the speed of the computer and the processing of I/O both by the kernel and
the device driver.
In particular, humans tend to see program output arriving in huge chunks (atomically) when in reality most programs produce output one line at a time.
Assuming this is the case, the * in the pattern of the previous paragraph may only match the end of the current line even though there seems to be more,
because at the time of the match that was all the output that had been received.
expect has no way of knowing that further output is coming unless your pattern specifically accounts for it.
Even depending on line-oriented buffering is unwise. Not only do programs rarely make promises about the type of buffering they do, but system indigestion
can break output lines up so that lines break at seemingly random places. Thus, if you can express the last few characters of a prompt when writing patterns,
it is wise to do so.
If you are waiting for a pattern in the last output of a program and the program emits something else instead, you will not be able to detect that with the
timeout keyword. The reason is that expect will not timeout - instead it will get an eof indication. Use that instead. Even better, use
both. That way if that line is ever moved around, you won't have to edit the line itself.
Newlines are usually converted to carriage return, linefeed sequences when output by the terminal driver. Thus, if you want a pattern that explicitly
matches the two lines, from, say, printf(""foo\nbar""), you should use the pattern ""foo\r\nbar"".
A similar translation occurs when reading from the user, via expect_user. In this case, when you press return, it will be translated to a newline. If
Expect then passes that to a program which sets its terminal to raw mode (like telnet), there is going to be a problem, as the program expects a true
return. (Some programs are actually forgiving in that they will automatically translate newlines to returns, but most don't.) Unfortunately, there is no way to
find out that a program put its terminal into raw mode.
Rather than manually replacing newlines with returns, the solution is to use the command ""stty raw"", which will stop the translation. Note, however, that
this means that you will no longer get the cooked line-editing features.
interact implicitly sets your terminal to raw mode so this problem will not arise then.
It is often useful to store passwords (or other private information) in Expect scripts. This is not recommended since anything that is stored on a
computer is susceptible to being accessed by anyone. Thus, interactively prompting for passwords from a script is a smarter idea than embedding them literally.
Nonetheless, sometimes such embedding is the only possibility.
Unfortunately, the UNIX file system has no direct way of creating scripts which are executable but unreadable. Systems which support setgid shell scripts
may indirectly simulate this as follows:
Create the Expect script (that contains the secret data) as usual. Make its permissions be 750 (-rwxr-x---) and owned by a trusted group, i.e., a
group which is allowed to read it. If necessary, create a new group for this purpose. Next, create a /bin/sh script with permissions 2751 (-rwxr-s--x) owned by
the same group as before.
The result is a script which may be executed (and read) by anyone. When invoked, it runs the Expect script.
See Also
Tcl(3), libexpect(3)
""Exploring Expect: A Tcl-Based Toolkit for Automating Interactive Programs"" by Don Libes, pp. 602, ISBN 1-56592-090-2, O'Reilly and Associates, 1995.
""expect: Curing Those Uncontrollable Fits of Interactivity"" by Don Libes, Proceedings of the Summer 1990 USENIX Conference, Anaheim, California, June 11-15,
1990.
""Using expect to Automate System Administration Tasks"" by Don Libes, Proceedings of the 1990 USENIX Large Installation Systems Administration
Conference, Colorado Springs, Colorado, October 17-19, 1990.
""Tcl: An Embeddable Command Language"" by John Ousterhout, Proceedings of the Winter 1990 USENIX Conference, Washington, D.C., January 22-26, 1990.
""expect: Scripts for Controlling Interactive Programs"" by Don Libes, Computing Systems, Vol. 4, No. 2, University of California Press Journals, November
1991.
""Regression Testing and Conformance Testing Interactive Programs"", by Don Libes, Proceedings of the Summer 1992 USENIX Conference, pp. 135-144, San Antonio,
TX, June 12-15, 1992.
""Kibitz - Connecting Multiple Interactive Programs Together"", by Don Libes, Software - Practice & Experience, John Wiley & Sons, West Sussex, England,
Vol. 23, No. 5, May, 1993.
""A Debugger for Tcl Applications"", by Don Libes, Proceedings of the 1993 Tcl/Tk Workshop, Berkeley, CA, June 10-11, 1993.
Author
Don Libes, National Institute of Standards and Technology
Acknowledgments
Thanks to John Ousterhout for Tcl, and Scott Paisley for inspiration. Thanks to Rob
Savoye for Expect's autoconfiguration code.
The HISTORY file documents much of the evolution of expect. It makes interesting reading and might give you further insight to this software. Thanks
to the people mentioned in it who sent me bug fixes and gave other assistance.
Design and implementation of Expect was paid for in part by the U.S. government and is therefore in the public domain. However the author and NIST
would like credit if this program and documentation or portions of them are used.


Referenced By
clogin(1),
kibitz(1),
pty(7),
shellout(3),
x3270-script(1),
x3270if(1),
xkibitz(1)








Site Search











Library
linux docs
linux man pages
page load time


Toys
world sunlight
moon phase
trace explorer







","EXPECT(1)							     EXPECT(1)



NAME
       expect - programmed dialogue with interactive programs, Version 5

SYNOPSIS
       expect [ -dDinN ] [ -c cmds ] [ [ -[f|b] ] cmdfile ] [ args ]

INTRODUCTION
       Expect  is a program that ""talks"" to other interactive programs accord-
       ing to a script.  Following  the  script,  Expect  knows  what  can  be
       expected  from  a  program and what the correct response should be.  An
       interpreted language provides branching and high-level  control	struc-
       tures  to  direct the dialogue.	In addition, the user can take control
       and interact directly when desired, afterward returning control to  the
       script.

       Expectk is a mixture of Expect and Tk.  It behaves just like Expect and
       Tk's wish.  Expect can also be used directly in	C  or  C++  (that  is,
       without Tcl).  See libexpect(3).

       The name ""Expect"" comes from the idea of send/expect sequences popular-
       ized by uucp, kermit and other modem control programs.  However	unlike
       uucp,  Expect is generalized so that it can be run as a user-level com-
       mand with any program and task in mind.	Expect can  actually  talk  to
       several programs at the same time.

       For example, here are some things Expect can do:

	      o   Cause  your computer to dial you back, so that you can login
		  without paying for the call.

	      o   Start a game (e.g., rogue) and if the optimal  configuration
		  doesn't  appear, restart it (again and again) until it does,
		  then hand over control to you.

	      o   Run fsck, and in response to its  questions,	answer	""yes"",
		  ""no""	or  give  control  back to you, based on predetermined
		  criteria.

	      o   Connect to another network or  BBS  (e.g.,  MCI  Mail,  Com-
		  puServe)  and  automatically	retrieve  your mail so that it
		  appears as if it was originally sent to your local system.

	      o   Carry environment variables, current directory, or any  kind
		  of information across rlogin, telnet, tip, su, chgrp, etc.

       There  are  a  variety  of  reasons  why the shell cannot perform these
       tasks.  (Try, you'll see.)  All are possible with Expect.

       In general, Expect is useful for running  any  program  which  requires
       interaction between the program and the user.  All that is necessary is
       that the interaction can be characterized programmatically.  Expect can
       also give the user back control (without halting the program being con-
       trolled) if desired.  Similarly, the user can  return  control  to  the
       script at any time.

USAGE
       Expect  reads  cmdfile  for  a list of commands to execute.  Expect may
       also be invoked implicitly on systems which support the #! notation  by
       marking	the  script  executable,  and  making  the  first line in your
       script:

	   #!/usr/local/bin/expect -f

       Of course, the  path  must  accurately  describe  where	Expect	lives.
       /usr/local/bin is just an example.

       The -c flag prefaces a command to be executed before any in the script.
       The command should be quoted to prevent being broken up by  the	shell.
       This  option may be used multiple times.  Multiple commands may be exe-
       cuted with a single -c by separating them  with	semicolons.   Commands
       are  executed  in  the  order  they  appear.  (When using Expectk, this
       option is specified as -command.)

       The -d flag enables some diagnostic  output,  which  primarily  reports
       internal  activity  of commands such as expect and interact.  This flag
       has the same effect as ""exp_internal 1"" at the beginning of  an	Expect
       script,	plus the version of Expect is printed.	(The strace command is
       useful for tracing statements, and the  trace  command  is  useful  for
       tracing	variable  assignments.)   (When  using Expectk, this option is
       specified as -diag.)

       The -D flag enables an interactive debugger.  An integer  value	should
       follow.	 The  debugger will take control before the next Tcl procedure
       if the value is non-zero or if a ^C is pressed (or a breakpoint is hit,
       or  other appropriate debugger command appears in the script).  See the
       README file or SEE ALSO (below) for more information on	the  debugger.
       (When using Expectk, this option is specified as -Debug.)

       The -f flag prefaces a file from which to read commands from.  The flag
       itself is optional as it is only useful when using the #! notation (see
       above),	so  that  other arguments may be supplied on the command line.
       (When using Expectk, this option is specified as -file.)

       By default, the command file is read into memory and  executed  in  its
       entirety.   It  is  occasionally  desirable to read files one line at a
       time.  For example, stdin is read this way.  In order  to  force  arbi-
       trary  files  to  be  handled  this  way, use the -b flag.  (When using
       Expectk, this option is specified as  -buffer.)Notethatstdio-buffering-
       maystilltakeplacehoweverthisshouldn'tcauseproblemswhenreadingfromafi-
       foorstdin.

       If the string ""-"" is supplied as a filename,  standard  input  is  read
       instead.  (Use ""./-"" to read from a file actually named ""-"".)

       The  -i flag causes Expect to interactively prompt for commands instead
       of reading them from a file.  Prompting is terminated via the exit com-
       mand or upon EOF.  See interpreter (below) for more information.  -i is
       assumed if neither a command file nor -c is used.  (When using Expectk,
       this option is specified as -interactive.)

       --  may	be  used to delimit the end of the options.  This is useful if
       you want to pass an option-like argument  to  your  script  without  it
       being  interpreted  by  Expect.	 This can usefully be placed in the #!
       line to prevent any flag-like interpretation by Expect.	 For  example,
       the  following  will leave the original arguments (including the script
       name) in the variable argv.

	   #!/usr/local/bin/expect --

       Note that  the  usual  getopt(3)  and  execve(2)  conventions  must  be
       observed when adding arguments to the #! line.

       The  file  $exp_library/expect.rc  is sourced automatically if present,
       unless the -N flag is used.  (When using Expectk, this option is speci-
       fied  as  -NORC.)   Immediately	after  this,  the file ~/.expect.rc is
       sourced automatically, unless the -n flag is used.  If the  environment
       variable DOTDIR is defined, it is treated as a directory and .expect.rc
       is read from there.  (When using Expectk, this option is  specified  as
       -norc.)	This sourcing occurs only after executing any -c flags.

       -v  causes  Expect  to  print its version number and exit.  (The corre-
       sponding flag in Expectk, which uses long flag names, is -version.)

       Optional args are constructed into a list and stored  in  the  variable
       named argv.  argc is initialized to the length of argv.

       argv0  is  defined to be the name of the script (or binary if no script
       is used).  For example, the following prints out the name of the script
       and the first three arguments:

	   send_user ""$argv0 [lrange $argv 0 2]\n""


COMMANDS
       Expect  uses  Tcl  (Tool  Command Language).  Tcl provides control flow
       (e.g., if, for, break), expression evaluation and  several  other  fea-
       tures such as recursion, procedure definition, etc.  Commands used here
       but not defined (e.g., set, if, exec) are Tcl  commands	(see  tcl(3)).
       Expect supports additional commands, described below.  Unless otherwise
       specified, commands return the empty string.

       Commands are listed alphabetically so that they can be quickly located.
       However,  new users may find it easier to start by reading the descrip-
       tions of spawn, send, expect, and interact, in that order.

       Note that the best introduction to the language (both Expect  and  Tcl)
       is provided in the book ""Exploring Expect"" (see SEE ALSO below).  Exam-
       ples are included in this man page but they are very limited since this
       man page is meant primarily as reference material.

       Note  that in the text of this man page, ""Expect"" with an uppercase ""E""
       refers to the Expect program  while  ""expect""  with  a  lower-case  ""e""
       refers to the expect command within the Expect program.)

       close [-slave] [-onexec 0|1] [-i spawn_id]
	     closes  the  connection to the current process.  Most interactive
	     programs will detect EOF on their stdin and exit; thus close usu-
	     ally  suffices to kill the process as well.  The -i flag declares
	     the process to close corresponding to the named spawn_id.

	     Both expect and interact will detect  when  the  current  process
	     exits and implicitly do a close.  But if you kill the process by,
	     say, ""exec kill $pid"", you will need to explicitly call close.

	     The -onexec flag determines whether the spawn id will  be	closed
	     in  any new spawned processes or if the process is overlayed.  To
	     leave a spawn id open, use the value 0.  A non-zero integer value
	     will force the spawn closed (the default) in any new processes.

	     The  -slave  flag	closes the slave associated with the spawn id.
	     (See ""spawn -pty"".)  When the connection is closed, the slave  is
	     automatically closed as well if still open.

	     No  matter whether the connection is closed implicitly or explic-
	     itly, you should call wait to clear up the  corresponding	kernel
	     process slot.  close does not call wait since there is no guaran-
	     tee that closing a process connection will cause it to exit.  See
	     wait below for more info.

       debug [[-now] 0|1]
	     controls  a Tcl debugger allowing you to step through statements,
	     set breakpoints, etc.

	     With no arguments, a 1 is returned if the debugger  is  not  run-
	     ning, otherwise a 0 is returned.

	     With  a  1 argument, the debugger is started.  With a 0 argument,
	     the debugger is stopped.  If a 1 argument is preceded by the -now
	     flag, the debugger is started immediately (i.e., in the middle of
	     the debug command itself).  Otherwise, the  debugger  is  started
	     with the next Tcl statement.

	     The  debug  command  does	not change any traps.  Compare this to
	     starting Expect with the -D flag (see above).

	     See the README file or SEE ALSO (below) for more  information  on
	     the debugger.

       disconnect
	     disconnects  a  forked  process  from the terminal.  It continues
	     running in the background.  The process is given its own  process
	     group (if possible).  Standard I/O is redirected to /dev/null.

	     The  following  fragment  uses disconnect to continue running the
	     script in the background.

		 if {[fork]!=0} exit
		 disconnect
		 . . .

	     The following script reads a password, and then  runs  a  program
	     every  hour  that	demands  a  password each time it is run.  The
	     script supplies the password so that you only  have  to  type  it
	     once.   (See  the stty command which demonstrates how to turn off
	     password echoing.)

		 send_user ""password?\ ""
		 expect_user -re ""(.*)\n""
		 for {} 1 {} {
		     if {[fork]!=0} {sleep 3600;continue}
		     disconnect
		     spawn priv_prog
		     expect Password:
		     send ""$expect_out(1,string)\r""
		     . . .
		     exit
		 }

	     An advantage to using  disconnect	over  the  shell  asynchronous
	     process  feature (&) is that Expect can save the terminal parame-
	     ters prior to disconnection, and then later  apply  them  to  new
	     ptys.   With  &, Expect does not have a chance to read the termi-
	     nal's parameters since the terminal is  already  disconnected  by
	     the time Expect receives control.

       exit [-opts] [status]
	     causes Expect to exit or otherwise prepare to do so.

	     The  -onexit  flag causes the next argument to be used as an exit
	     handler.  Without	an  argument,  the  current  exit  handler  is
	     returned.

	     The  -noexit flag causes Expect to prepare to exit but stop short
	     of actually returning control to the operating system.  The user-
	     defined exit handler is run as well as Expect's own internal han-
	     dlers.  No further Expect commands should be executed.   This  is
	     useful  if you are running Expect with other Tcl extensions.  The
	     current interpreter (and main window if in  the  Tk  environment)
	     remain  so  that  other Tcl extensions can clean up.  If Expect's
	     exit is called again (however this might occur), the handlers are
	     not rerun.

	     Upon  exiting,  all  connections to spawned processes are closed.
	     Closure will be detected as an EOF by  spawned  processes.   exit
	     takes  no other actions beyond what the normal _exit(2) procedure
	     does.  Thus, spawned processes that do not check for EOF may con-
	     tinue  to	run.  (A variety of conditions are important to deter-
	     mining, for example, what signals a spawned process will be sent,
	     but   these  are  system-dependent,  typically  documented  under
	     exit(3).)	Spawned processes that continue to run will be	inher-
	     ited by init.

	     status  (or 0 if not specified) is returned as the exit status of
	     Expect.  exit is implicitly executed if the end of the script  is
	     reached.

       exp_continue [-continue_timer]
	     The command exp_continue allows expect itself to continue execut-
	     ing rather than  returning  as  it  normally  would.  By  default
	     exp_continue  resets  the timeout timer. The -continue_timer flag
	     prevents timer from being restarted. (See expect for more	infor-
	     mation.)

       exp_internal [-f file] value
	     causes  further  commands to send diagnostic information internal
	     to Expect to stderr if value is non-zero.	This  output  is  dis-
	     abled  if	value is 0.  The diagnostic information includes every
	     character received, and every attempt made to match  the  current
	     output against the patterns.

	     If the optional file is supplied, all normal and debugging output
	     is written to that file (regardless of the value of value).   Any
	     previous diagnostic output file is closed.

	     The -info flag causes exp_internal to return a description of the
	     most recent non-info arguments given.

       exp_open [args] [-i spawn_id]
	     returns a Tcl file identifier that corresponds  to  the  original
	     spawn  id.   The  file  identifier can then be used as if it were
	     opened by Tcl's open command.  (The spawn id should no longer  be
	     used.  A wait should not be executed.

	     The  -leaveopen  flag leaves the spawn id open for access through
	     Expect commands.  A wait must be executed on the spawn id.

       exp_pid [-i spawn_id]
	     returns the process id corresponding  to  the  currently  spawned
	     process.  If the -i flag is used, the pid returned corresponds to
	     that of the given spawn id.

       exp_send
	     is an alias for send.

       exp_send_error
	     is an alias for send_error.

       exp_send_log
	     is an alias for send_log.

       exp_send_tty
	     is an alias for send_tty.

       exp_send_user
	     is an alias for send_user.

       exp_version [[-exit] version]
	     is useful for assuring that the script  is  compatible  with  the
	     current version of Expect.

	     With  no  arguments,  the	current version of Expect is returned.
	     This version may then be encoded in your script.  If you actually
	     know  that you are not using features of recent versions, you can
	     specify an earlier version.

	     Versions consist of three numbers separated by  dots.   First  is
	     the  major number.  Scripts written for versions of Expect with a
	     different major number will almost certainly not work.   exp_ver-
	     sion returns an error if the major numbers do not match.

	     Second is the minor number.  Scripts written for a version with a
	     greater minor number than the current  version  may  depend  upon
	     some new feature and might not run.  exp_version returns an error
	     if the major numbers  match,  but	the  script  minor  number  is
	     greater than that of the running Expect.

	     Third  is	a number that plays no part in the version comparison.
	     However, it is incremented when the Expect software  distribution
	     is  changed  in  any  way, such as by additional documentation or
	     optimization.  It is reset to 0 upon each new minor version.

	     With the -exit flag, Expect prints an error and exits if the ver-
	     sion is out of date.

       expect [[-opts] pat1 body1] ... [-opts] patn [bodyn]
	     waits  until  one of the patterns matches the output of a spawned
	     process, a specified time period has passed, or an end-of-file is
	     seen.  If the final body is empty, it may be omitted.

	     Patterns  from  the most recent expect_before command are implic-
	     itly used before any other  patterns.   Patterns  from  the  most
	     recent  expect_after  command are implicitly used after any other
	     patterns.

	     If the arguments to the entire expect statement require more than
	     one  line,  all  the  arguments may be ""braced"" into one so as to
	     avoid terminating each line with a backslash.  In this one  case,
	     the usual Tcl substitutions will occur despite the braces.

	     If  a  pattern is the keyword eof, the corresponding body is exe-
	     cuted upon end-of-file.  If a pattern is the keyword timeout, the
	     corresponding  body is executed upon timeout.  If no timeout key-
	     word is used, an implicit null action is executed	upon  timeout.
	     The  default  timeout  period  is	10 seconds but may be set, for
	     example to 30, by the command  ""set  timeout  30"".   An  infinite
	     timeout  may  be designated by the value -1.  If a pattern is the
	     keyword default, the corresponding body is executed  upon	either
	     timeout or end-of-file.

	     If  a  pattern  matches, then the corresponding body is executed.
	     expect returns the result of the body (or the empty string if  no
	     pattern matched).	In the event that multiple patterns match, the
	     one appearing first is used to select a body.

	     Each time new output arrives, it is compared to each  pattern  in
	     the  order  they are listed.  Thus, you may test for absence of a
	     match by making the last pattern something guaranteed to  appear,
	     such  as  a  prompt.  In situations where there is no prompt, you
	     must use timeout (just like you would  if	you  were  interacting
	     manually).

	     Patterns  are  specified in three ways.  By default, patterns are
	     specified as with Tcl's string match command.  (Such patterns are
	     also  similar  to C-shell regular expressions usually referred to
	     as ""glob"" patterns).  The -gl flag may may  be  used  to  protect
	     patterns  that  might otherwise match expect flags from doing so.
	     Any pattern beginning with a ""-"" should be  protected  this  way.
	     (All  strings starting with ""-"" are reserved for future options.)


	     For example, the following fragment looks for a successful login.
	     (Note  that abort is presumed to be a procedure defined elsewhere
	     in the script.)

		 expect {
		     busy		{puts busy\n ; exp_continue}
		     failed		abort
		     ""invalid password"" abort
		     timeout		abort
		     connected
		 }

	     Quotes are necessary on the fourth pattern since  it  contains  a
	     space,  which  would  otherwise  separate	the  pattern  from the
	     action.  Patterns with the same action (such as the 3rd and  4th)
	     require  listing  the  actions again.  This can be avoid by using
	     regexp-style patterns (see below).  More information  on  forming
	     glob-style patterns can be found in the Tcl manual.

	     Regexp-style  patterns  follow the syntax defined by Tcl's regexp
	     (short for ""regular expression"") command.	 regexp  patterns  are
	     introduced  with  the  flag  -re.	 The  previous	example can be
	     rewritten using a regexp as:

		 expect {
		     busy	{puts busy\n ; exp_continue}
		     -re ""failed|invalid password"" abort
		     timeout	abort
		     connected
		 }

	     Both types of patterns are ""unanchored"".  This  means  that  pat-
	     terns  do	not have to match the entire string, but can begin and
	     end the match anywhere in the string (as long as everything  else
	     matches).	 Use  ^  to  match the beginning of a string, and $ to
	     match the end.  Note that if you do not wait for  the  end  of  a
	     string,  your  responses  can  easily end up in the middle of the
	     string as they are echoed from the spawned process.  While  still
	     producing	correct results, the output can look unnatural.  Thus,
	     use of $ is encouraged if you can exactly describe the characters
	     at the end of a string.

	     Note  that  in  many editors, the ^ and $ match the beginning and
	     end of lines respectively. However, because expect  is  not  line
	     oriented,	these  characters  match  the beginning and end of the
	     data (as opposed to  lines)  currently  in  the  expect  matching
	     buffer.  (Also, see the note below on ""system indigestion."")

	     The  -ex  flag  causes  the  pattern  to be matched as an ""exact""
	     string.  No interpretation of *, ^, etc  is  made	(although  the
	     usual  Tcl  conventions  must still be observed).	Exact patterns
	     are always unanchored.


	     The -nocase flag causes uppercase characters  of  the  output  to
	     compare as if they were lowercase characters.  The pattern is not
	     affected.

	     While reading output, more than  2000  bytes  can	force  earlier
	     bytes  to	be ""forgotten"".  This may be changed with the function
	     match_max.  (Note that excessively large values can slow down the
	     pattern  matcher.)   If patlist is full_buffer, the corresponding
	     body is executed if match_max bytes have  been  received  and  no
	     other patterns have matched.  Whether or not the full_buffer key-
	     word  is  used,  the  forgotten   characters   are   written   to
	     expect_out(buffer).

	     If  patlist  is  the keyword null, and nulls are allowed (via the
	     remove_nulls command), the corresponding body is  executed  if  a
	     single  ASCII  0 is matched.  It is not possible to match 0 bytes
	     via glob or regexp patterns.

	     Upon matching a pattern (or eof or full_buffer), any matching and
	     previously   unmatched   output   is   saved   in	 the  variable
	     expect_out(buffer).  Up to 9 regexp substring matches  are  saved
	     in      the      variables      expect_out(1,string)      through
	     expect_out(9,string).  If the -indices flag is used before a pat-
	     tern,  the  starting  and	ending indices (in a form suitable for
	     lrange)  of  the  10  strings  are  stored   in   the   variables
	     expect_out(X,start)  and  expect_out(X,end)  where  X is a digit,
	     corresponds to the substring position in the buffer.  0 refers to
	     strings  which  matched  the  entire pattern and is generated for
	     glob patterns as well as regexp  patterns.   For  example,  if  a
	     process has produced output of ""abcdefgh\n"", the result of:

		 expect ""cd""

	     is as if the following statements had executed:

		 set expect_out(0,string) cd
		 set expect_out(buffer) abcd

	     and ""efgh\n"" is left in the output buffer.  If a process produced
	     the output ""abbbcabkkkka\n"", the result of:

		 expect -indices -re ""b(b*).*(k+)""

	     is as if the following statements had executed:

		 set expect_out(0,start) 1
		 set expect_out(0,end) 10
		 set expect_out(0,string) bbbcabkkkk
		 set expect_out(1,start) 2
		 set expect_out(1,end) 3
		 set expect_out(1,string) bb
		 set expect_out(2,start) 10
		 set expect_out(2,end) 10
		 set expect_out(2,string) k
		 set expect_out(buffer) abbbcabkkkk

	     and ""a\n"" is left in the output buffer.  The pattern ""*"" (and -re
	     "".*"")  will flush the output buffer without reading any more out-
	     put from the process.

	     Normally, the matched output is discarded from Expect's  internal
	     buffers.	This  may be prevented by prefixing a pattern with the
	     -notransfer flag.	This flag is especially useful in  experiment-
	     ing  (and	can  be  abbreviated  to  ""-not"" for convenience while
	     experimenting).

	     The spawn id associated with  the	matching  output  (or  eof  or
	     full_buffer) is stored in expect_out(spawn_id).

	     The  -timeout  flag  causes the current expect command to use the
	     following value as a timeout instead of using the	value  of  the
	     timeout variable.

	     By  default, patterns are matched against output from the current
	     process, however the -i flag declares the output from  the  named
	     spawn_id  list  be  matched against any following patterns (up to
	     the next -i).  The spawn_id list should either  be  a  whitespace
	     separated	list  of  spawn_ids  or a variable referring to such a
	     list of spawn_ids.

	     For example, the following example waits for ""connected"" from the
	     current  process,	or ""busy"", ""failed"" or ""invalid password"" from
	     the spawn_id named by $proc2.

		 expect {
		     -i $proc2 busy {puts busy\n ; exp_continue}
		     -re ""failed|invalid password"" abort
		     timeout abort
		     connected
		 }

	     The value of the global variable  any_spawn_id  may  be  used  to
	     match  patterns to any spawn_ids that are named with all other -i
	     flags in the current expect command.  The spawn_id from a -i flag
	     with no associated pattern (i.e., followed immediately by another
	     -i) is made available to any other patterns in  the  same	expect
	     command associated with any_spawn_id.

	     The  -i  flag  may  also name a global variable in which case the
	     variable is read for a list of spawn ids.	The variable is reread
	     whenever  it  changes.   This  provides a way of changing the I/O
	     source while the command is in  execution.   Spawn  ids  provided
	     this way are called ""indirect"" spawn ids.

	     Actions  such  as	break  and  continue  cause control structures
	     (i.e., for, proc) to  behave  in  the  usual  way.   The  command
	     exp_continue  allows  expect  itself to continue executing rather
	     than returning as it normally would.

	     This is useful for avoiding explicit  loops  or  repeated	expect
	     statements.  The following example is part of a fragment to auto-
	     mate rlogin.  The exp_continue avoids having to  write  a	second
	     expect  statement	(to  look  for the prompt again) if the rlogin
	     prompts for a password.

		 expect {
		     Password: {
			 stty -echo
			 send_user ""password (for $user) on $host: ""
			 expect_user -re ""(.*)\n""
			 send_user ""\n""
			 send ""$expect_out(1,string)\r""
			 stty echo
			 exp_continue
		     } incorrect {
			 send_user ""invalid password or account\n""
			 exit
		     } timeout {
			 send_user ""connection to $host timed out\n""
			 exit
		     } eof {
			 send_user \
			     ""connection to host failed: $expect_out(buffer)""
			 exit
		     } -re $prompt
		 }

	     For example, the following fragment might help a  user  guide  an
	     interaction that is already totally automated.  In this case, the
	     terminal is put into raw mode.  If the user presses ""+"", a  vari-
	     able is incremented.  If ""p"" is pressed, several returns are sent
	     to the process, perhaps to poke it in some way, and ""i"" lets  the
	     user interact with the process, effectively stealing away control
	     from the script.  In each case, the exp_continue allows the  cur-
	     rent expect to continue pattern matching after executing the cur-
	     rent action.

		 stty raw -echo
		 expect_after {
		     -i $user_spawn_id
		     ""p"" {send ""\r\r\r""; exp_continue}
		     ""+"" {incr foo; exp_continue}
		     ""i"" {interact; exp_continue}
		     ""quit"" exit
		 }


	     By default, exp_continue resets the timeout timer.  The timer  is
	     not restarted, if exp_continue is called with the -continue_timer
	     flag.

       expect_after [expect_args]
	     works identically to the expect_before except  that  if  patterns
	     from  both  expect and expect_after can match, the expect pattern
	     is used.  See the expect_before command for more information.

       expect_background [expect_args]
	     takes the same arguments as expect, however  it  returns  immedi-
	     ately.  Patterns are tested whenever new input arrives.  The pat-
	     tern timeout and default are meaningless to expect_background and
	     are silently discarded.  Otherwise, the expect_background command
	     uses expect_before and expect_after  patterns  just  like	expect
	     does.

	     When  expect_background  actions  are being evaluated, background
	     processing for the same spawn id is blocked.  Background process-
	     ing  is  unblocked  when  the action completes.  While background
	     processing is blocked, it is possible to do a (foreground) expect
	     on the same spawn id.

	     It  is  not  possible  to execute an expect while an expect_back-
	     ground is unblocked.  expect_background for a particular spawn id
	     is  deleted  by  declaring  a new expect_background with the same
	     spawn id.	Declaring expect_background with  no  pattern  removes
	     the  given  spawn	id  from  the ability to match patterns in the
	     background.

       expect_before [expect_args]
	     takes the same arguments as expect, however  it  returns  immedi-
	     ately.   Pattern-action  pairs from the most recent expect_before
	     with the same spawn id are  implicitly  added  to	any  following
	     expect  commands.	 If  a pattern matches, it is treated as if it
	     had been specified in the expect command itself, and the  associ-
	     ated  body  is executed in the context of the expect command.  If
	     patterns from  both  expect_before  and  expect  can  match,  the
	     expect_before pattern is used.

	     If  no  pattern is specified, the spawn id is not checked for any
	     patterns.

	     Unless overridden by a  -i  flag,	expect_before  patterns  match
	     against  the  spawn id defined at the time that the expect_before
	     command was executed (not when its pattern is matched).

	     The -info flag causes expect_before to return the current	speci-
	     fications of what patterns it will match.	By default, it reports
	     on the current spawn id.  An optional spawn id specification  may
	     be given for information on that spawn id.  For example

		 expect_before -info -i $proc

	     At most one spawn id specification may be given.  The flag -indi-
	     rect suppresses direct spawn ids that  come  only	from  indirect
	     specifications.

	     Instead  of  a spawn id specification, the flag ""-all"" will cause
	     ""-info"" to report on all spawn ids.

	     The output of the -info flag can be reused  as  the  argument  to
	     expect_before.

       expect_tty [expect_args]
	     is  like  expect but it reads characters from /dev/tty (i.e. key-
	     strokes from the user).  By  default,  reading  is  performed  in
	     cooked  mode.   Thus,  lines  must end with a return in order for
	     expect to see them.  This may be changed via stty (see  the  stty
	     command below).

       expect_user [expect_args]
	     is  like  expect  but  it	reads characters from stdin (i.e. key-
	     strokes from the user).  By  default,  reading  is  performed  in
	     cooked  mode.   Thus,  lines  must end with a return in order for
	     expect to see them.  This may be changed via stty (see  the  stty
	     command below).

       fork  creates  a  new process.  The new process is an exact copy of the
	     current Expect process.  On success, fork returns 0  to  the  new
	     (child)  process  and returns the process ID of the child process
	     to the parent process.  On failure (invariably  due  to  lack  of
	     resources, e.g., swap space, memory), fork returns -1 to the par-
	     ent process, and no child process is created.

	     Forked processes exit via the exit command, just like the	origi-
	     nal  process.   Forked  processes are allowed to write to the log
	     files.  If you do not disable debugging or logging in most of the
	     processes, the result can be confusing.

	     Some  pty implementations may be confused by multiple readers and
	     writers, even momentarily.  Thus, it is  safest  to  fork	before
	     spawning processes.

       interact [string1 body1] ... [stringn [bodyn]]
	     gives  control  of  the current process to the user, so that key-
	     strokes are sent to the  current  process,  and  the  stdout  and
	     stderr of the current process are returned.

	     String-body  pairs  may  be specified as arguments, in which case
	     the body is executed when the corresponding  string  is  entered.
	     (By  default,  the  string  is  not sent to the current process.)
	     The interpreter command is assumed, if the final body is missing.

	     If  the  arguments  to the entire interact statement require more
	     than one line, all the arguments may be ""braced"" into one	so  as
	     to  avoid	terminating  each  line with a backslash.  In this one
	     case, the usual Tcl substitutions will occur despite the  braces.

	     For example, the following command runs interact with the follow-
	     ing string-body pairs defined:  When ^Z  is  pressed,  Expect  is
	     suspended.   (The -reset flag restores the terminal modes.)  When
	     ^A is pressed, the user sees ""you	typed  a  control-A""  and  the
	     process is sent a ^A.  When $ is pressed, the user sees the date.
	     When ^C is pressed, Expect exits.	If ""foo"" is entered, the  user
	     sees  ""bar"".   When  ~~  is  pressed, the Expect interpreter runs
	     interactively.

		 set CTRLZ \032
		 interact {
		     -reset $CTRLZ {exec kill -STOP [pid]}
		     \001   {send_user ""you typed a control-A\n"";
			     send ""\001""
			    }
		     $	    {send_user ""The date is [clock format [clock seconds]].""}
		     \003   exit
		     foo    {send_user ""bar""}
		     ~~
		 }


	     In string-body pairs, strings are matched in the order  they  are
	     listed  as  arguments.  Strings that partially match are not sent
	     to the current process in anticipation of the  remainder  coming.
	     If characters are then entered such that there can no longer pos-
	     sibly be a match, only the part of the string will be sent to the
	     process  that cannot possibly begin another match.  Thus, strings
	     that are substrings of partial matches can match  later,  if  the
	     original  strings	that  was  attempting  to  be match ultimately
	     fails.

	     By default, string matching is exact with	no  wild  cards.   (In
	     contrast,	 the   expect  command	uses  glob-style  patterns  by
	     default.)	The -ex flag may be  used  to  protect	patterns  that
	     might  otherwise match interact flags from doing so.  Any pattern
	     beginning with a  ""-""  should  be	protected  this  way.	  (All
	     strings starting with ""-"" are reserved for future options.)

	     The  -re  flag  forces  the string to be interpreted as a regexp-
	     style pattern.  In this case, matching substrings are  stored  in
	     the  variable interact_out similarly to the way expect stores its
	     output in the variable expect_out.  The -indices  flag  is  simi-
	     larly supported.

	     The  pattern  eof introduces an action that is executed upon end-
	     of-file.  A separate eof pattern may also follow the -output flag
	     in  which	case it is matched if an eof is detected while writing
	     output.  The default eof action is  ""return"",  so	that  interact
	     simply returns upon any EOF.

	     The  pattern timeout introduces a timeout (in seconds) and action
	     that is executed after no characters have been read for  a  given
	     time.  The timeout pattern applies to the most recently specified
	     process.  There is no  default  timeout.	The  special  variable
	     ""timeout""	(used  by  the	expect	command) has no affect on this
	     timeout.

	     For example, the following statement could be used to  autologout
	     users  who  have not typed anything for an hour but who still get
	     frequent system messages:

		 interact -input $user_spawn_id timeout 3600 return -output \
		     $spawn_id


	     If the pattern is the keyword null, and nulls  are  allowed  (via
	     the  remove_nulls command), the corresponding body is executed if
	     a single ASCII 0 is matched.  It is not possible to match 0 bytes
	     via glob or regexp patterns.

	     Prefacing	a  pattern  with  the flag -iwrite causes the variable
	     interact_out(spawn_id) to be set to the  spawn_id	which  matched
	     the pattern (or eof).

	     Actions  such  as	break  and  continue  cause control structures
	     (i.e., for, proc) to behave in the  usual	way.   However	return
	     causes  interact  to  return  to  its  caller, while inter_return
	     causes interact to cause a return in its caller.  For example, if
	     ""proc  foo""  called  interact  which  then  executed  the	action
	     inter_return, proc foo would return.  (This means that if	inter-
	     act  calls interpreter interactively typing return will cause the
	     interact to continue, while inter_return will cause the  interact
	     to return to its caller.)

	     During  interact,	raw mode is used so that all characters may be
	     passed to the current process.  If the current process  does  not
	     catch job control signals, it will stop if sent a stop signal (by
	     default ^Z).  To restart it, send a continue signal (such	as  by
	     ""kill  -CONT  <pid>"").   If  you really want to send a SIGSTOP to
	     such a process (by ^Z), consider spawning csh first and then run-
	     ning  your  program.   On	the  other hand, if you want to send a
	     SIGSTOP to Expect itself,	first  call  interpreter  (perhaps  by
	     using an escape character), and then press ^Z.

	     String-body  pairs can be used as a shorthand for avoiding having
	     to enter the interpreter and execute commands interactively.  The
	     previous  terminal  mode  is used while the body of a string-body
	     pair is being executed.

	     For speed, actions execute in raw mode by	default.   The	-reset
	     flag  resets  the terminal to the mode it had before interact was
	     executed (invariably, cooked mode).  Note that characters entered
	     when  the mode is being switched may be lost (an unfortunate fea-
	     ture of the terminal driver on some systems).  The only reason to
	     use -reset is if your action depends on running in cooked mode.

	     The  -echo flag sends characters that match the following pattern
	     back to the process that generated  them  as  each  character  is
	     read.   This  may	be  useful when the user needs to see feedback
	     from partially typed patterns.

	     If a pattern is being echoed but eventually fails to  match,  the
	     characters  are  sent  to	the  spawned  process.	If the spawned
	     process then echoes them, the user will see the characters twice.
	     -echo  is	probably only appropriate in situations where the user
	     is unlikely to not complete the pattern.  For example,  the  fol-
	     lowing  excerpt is from rftp, the recursive-ftp script, where the
	     user is prompted to enter ~g, ~p, or ~l, to get, put, or list the
	     current  directory  recursively.	These are so far away from the
	     normal ftp commands, that the user is unlikely to type ~ followed
	     by anything else, except mistakenly, in which case, they'll prob-
	     ably just ignore the result anyway.

		 interact {
		     -echo ~g {getcurdirectory 1}
		     -echo ~l {getcurdirectory 0}
		     -echo ~p {putcurdirectory}
		 }

	     The -nobuffer flag sends characters that match the following pat-
	     tern on to the output process as characters are read.

	     This  is useful when you wish to let a program echo back the pat-
	     tern.  For example, the following might be used to monitor  where
	     a	person	is  dialing (a Hayes-style modem).  Each time ""atd"" is
	     seen the script logs the rest of the line.

		 proc lognumber {} {
		     interact -nobuffer -re ""(.*)\r"" return
		     puts $log ""[clock format [clock seconds]]: dialed $interact_out(1,string)""
		 }

		 interact -nobuffer ""atd"" lognumber


	     During interact, previous use of log_user is ignored.  In partic-
	     ular,  interact  will  force its output to be logged (sent to the
	     standard output) since it is presumed the user  doesn't  wish  to
	     interact blindly.

	     The  -o flag causes any following key-body pairs to be applied to
	     the output of the current process.  This can be useful, for exam-
	     ple, when dealing with hosts that send unwanted characters during
	     a telnet session.

	     By default, interact expects the user to  be  writing  stdin  and
	     reading  stdout  of  the Expect process itself.  The -u flag (for
	     ""user"") makes interact look for the user as the process named  by
	     its argument (which must be a spawned id).

	     This allows two unrelated processes to be joined together without
	     using an explicit loop.  To aid in debugging, Expect  diagnostics
	     always  go to stderr (or stdout for certain logging and debugging
	     information).  For the same reason, the interpreter command  will
	     read interactively from stdin.

	     For  example,  the  following  fragment  creates a login process.
	     Then it dials the user (not shown), and finally connects the  two
	     together.	 Of  course, any process may be substituted for login.
	     A shell, for example, would allow the user to work  without  sup-
	     plying an account and password.

		 spawn login
		 set login $spawn_id
		 spawn tip modem
		 # dial back out to user
		 # connect user to login
		 interact -u $login

	     To  send  output  to  multiple processes, list each spawn id list
	     prefaced by a -output flag.  Input for a group  of  output  spawn
	     ids  may  be  determined  by a spawn id list prefaced by a -input
	     flag.  (Both -input and -output may take lists in the  same  form
	     as the -i flag in the expect command, except that any_spawn_id is
	     not meaningful in interact.)  All following flags and strings (or
	     patterns)	apply to this input until another -input flag appears.
	     If no -input  appears,  -output  implies  ""-input	$user_spawn_id
	     -output"".	 (Similarly,  with  patterns that do not have -input.)
	     If one -input is specified, it overrides  $user_spawn_id.	 If  a
	     second  -input  is specified, it overrides $spawn_id.  Additional
	     -input flags may be specified.

	     The two implied input processes default to having	their  outputs
	     specified	as  $spawn_id  and  $user_spawn_id (in reverse).  If a
	     -input flag appears with no -output flag,	characters  from  that
	     process are discarded.

	     The  -i  flag  introduces	a replacement for the current spawn_id
	     when no other -input or  -output  flags  are  used.   A  -i  flag
	     implies a -o flag.

	     It  is possible to change the processes that are being interacted
	     with by using  indirect  spawn  ids.   (Indirect  spawn  ids  are
	     described	in the section on the expect command.)	Indirect spawn
	     ids may be specified with the -i, -u, -input, or -output flags.

       interpreter  [args]
	     causes the user to be interactively prompted for Expect  and  Tcl
	     commands.	The result of each command is printed.

	     Actions  such  as	break  and  continue  cause control structures
	     (i.e., for, proc) to behave in the  usual	way.   However	return
	     causes  interpreter  to  return to its caller, while inter_return
	     causes interpreter to cause a return in its caller.  For example,
	     if  ""proc	foo"" called interpreter which then executed the action
	     inter_return, proc foo would return.  Any	other  command	causes
	     interpreter to continue prompting for new commands.

	     By  default, the prompt contains two integers.  The first integer
	     describes the depth of the evaluation stack (i.e., how many times
	     Tcl_Eval has been called).  The second integer is the Tcl history
	     identifier.  The prompt can be set by defining a procedure called
	     ""prompt1""	whose  return  value  becomes  the  next prompt.  If a
	     statement has open quotes, parens, braces, or  brackets,  a  sec-
	     ondary  prompt  (by  default  ""+> "") is issued upon newline.  The
	     secondary prompt may  be  set  by	defining  a  procedure	called
	     ""prompt2"".

	     During  interpreter,  cooked mode is used, even if the its caller
	     was using raw mode.

	     If stdin is closed, interpreter will return unless the -eof  flag
	     is used, in which case the subsequent argument is invoked.

       log_file [args] [[-a] file]
	     If  a  filename is provided, log_file will record a transcript of
	     the session (beginning at that point) in the file.  log_file will
	     stop recording if no argument is given.  Any previous log file is
	     closed.

	     Instead of a filename, a Tcl file identifier may be  provided  by
	     using  the  -open	or  -leaveopen	flags.	This is similar to the
	     spawn command.  (See spawn for more info.)

	     The -a flag forces output to be logged that was suppressed by the
	     log_user command.

	     By default, the log_file command appends to old files rather than
	     truncating them, for the convenience of being able to  turn  log-
	     ging  off	and  on  multiple  times  in one session.  To truncate
	     files, use the -noappend flag.

	     The -info flag causes log_file to return  a  description  of  the
	     most recent non-info arguments given.

       log_user -info|0|1
	     By  default,  the send/expect dialogue is logged to stdout (and a
	     logfile if open).	The logging to stdout is disabled by the  com-
	     mand  ""log_user 0"" and reenabled by ""log_user 1"".	Logging to the
	     logfile is unchanged.

	     The -info flag causes log_user to return  a  description  of  the
	     most recent non-info arguments given.

       match_max [-d] [-i spawn_id] [size]
	     defines  the  size  of  the  buffer (in bytes) used internally by
	     expect.  With no size argument, the current size is returned.

	     With the -d flag, the default size is set.  (The initial  default
	     is  2000.)  With the -i flag, the size is set for the named spawn
	     id, otherwise it is set for the current process.

       overlay [-# spawn_id] [-# spawn_id] [...] program [args]
	     executes program args in place of	the  current  Expect  program,
	     which  terminates.   A  bare  hyphen  argument forces a hyphen in
	     front of the command name as  if  it  was	a  login  shell.   All
	     spawn_ids	are closed except for those named as arguments.  These
	     are mapped onto the named file identifiers.

	     Spawn_ids are mapped to file identifiers for the new  program  to
	     inherit.	For  example, the following line runs chess and allows
	     it to be controlled by the current process - say, a chess master.

		 overlay -0 $spawn_id -1 $spawn_id -2 $spawn_id chess

	     This is more efficient than ""interact -u"", however, it sacrifices
	     the ability to do programmed interaction since the Expect process
	     is no longer in control.

	     Note that no controlling terminal is provided.  Thus, if you dis-
	     connect or remap standard input, programs	that  do  job  control
	     (shells, login, etc) will not function properly.

       parity [-d] [-i spawn_id] [value]
	     defines  whether  parity  should be retained or stripped from the
	     output of	spawned  processes.   If  value  is  zero,  parity  is
	     stripped,	otherwise it is not stripped.  With no value argument,
	     the current value is returned.

	     With the -d flag, the default parity value is set.  (The  initial
	     default  is  1, i.e., parity is not stripped.)  With the -i flag,
	     the parity value is set for the named spawn id, otherwise	it  is
	     set for the current process.

       remove_nulls [-d] [-i spawn_id] [value]
	     defines  whether nulls are retained or removed from the output of
	     spawned processes before pattern matching or storing in the vari-
	     able  expect_out  or  interact_out.   If  value  is  1, nulls are
	     removed.  If value is 0, nulls are not removed.   With  no  value
	     argument, the current value is returned.

	     With the -d flag, the default value is set.  (The initial default
	     is 1, i.e., nulls are removed.)  With the -i flag, the  value  is
	     set  for  the named spawn id, otherwise it is set for the current
	     process.

	     Whether or not nulls are removed, Expect will record  null  bytes
	     to the log and stdout.

       send [-flags] string
	     Sends string to the current process.  For example, the command

		 send ""hello world\r""

	     sends the characters, h e l l o <blank> w o r l d <return> to the
	     current process.  (Tcl includes  a  printf-like  command  (called
	     format) which can build arbitrarily complex strings.)

	     Characters  are  sent  immediately  although  programs with line-
	     buffered input will not read the characters until a return  char-
	     acter is sent.  A return character is denoted ""\r"".

	     The  --  flag  forces  the  next  argument to be interpreted as a
	     string rather than a flag.  Any string can be  preceded  by  ""--""
	     whether  or  not  it actually looks like a flag.  This provides a
	     reliable mechanism to  specify  variable  strings	without  being
	     tripped  up  by  those  that  accidentally look like flags.  (All
	     strings starting with ""-"" are reserved for future options.)

	     The -i flag declares  that  the  string  be  sent	to  the  named
	     spawn_id.	 If the spawn_id is user_spawn_id, and the terminal is
	     in raw mode, newlines in the string are translated to return-new-
	     line  sequences  so  that	they  appear as if the terminal was in
	     cooked mode.  The -raw flag disables this translation.

	     The -null flag sends null characters (0 bytes).  By default,  one
	     null  is  sent.   An integer may follow the -null to indicate how
	     many nulls to send.

	     The -break flag generates a break	condition.   This  only  makes
	     sense  if	the  spawn id refers to a tty device opened via ""spawn
	     -open"".  If you have spawned a process such as  tip,  you	should
	     use tip's convention for generating a break.

	     The  -s  flag  forces  output to be sent ""slowly"", thus avoid the
	     common situation where a computer outtypes an input  buffer  that
	     was designed for a human who would never outtype the same buffer.
	     This  output  is  controlled  by  the  value  of	the   variable
	     ""send_slow"" which takes a two element list.  The first element is
	     an integer that describes the number of bytes to send atomically.
	     The  second element is a real number that describes the number of
	     seconds by which the atomic sends must be separated.   For  exam-
	     ple,  ""set  send_slow  {10  .001}""  would force ""send -s"" to send
	     strings with 1 millisecond in between each 10 characters sent.

	     The -h flag forces output to be  sent  (somewhat)	like  a  human
	     actually  typing.	 Human-like  delays appear between the charac-
	     ters.  (The algorithm is based upon a Weibull distribution,  with
	     modifications  to suit this particular application.)  This output
	     is controlled by the value of  the  variable  ""send_human""  which
	     takes  a  five  element list.  The first two elements are average
	     interarrival time of characters in seconds.  The first is used by
	     default.	The  second  is  used at word endings, to simulate the
	     subtle pauses that occasionally occur at such  transitions.   The
	     third  parameter  is  a  measure of variability where .1 is quite
	     variable, 1 is reasonably variable, and 10 is  quite  invariable.
	     The  extremes  are  0  to infinity.  The last two parameters are,
	     respectively, a minimum and maximum interarrival time.  The mini-
	     mum  and  maximum	are  used last and ""clip"" the final time.  The
	     ultimate average can be quite different from the given average if
	     the minimum and maximum clip enough values.

	     As  an example, the following command emulates a fast and consis-
	     tent typist:

		 set send_human {.1 .3 1 .05 2}
		 send -h ""I'm hungry.  Let's do lunch.""

	     while the following might be more suitable after a hangover:

		 set send_human {.4 .4 .2 .5 100}
		 send -h ""Goodd party lash night!""

	     Note that errors are not simulated, although you can set up error
	     correction  situations yourself by embedding mistakes and correc-
	     tions in a send argument.

	     The flags for sending null characters, for  sending  breaks,  for
	     forcing  slow  output  and  for  human-style  output are mutually
	     exclusive. Only the one specified last will be used. Furthermore,
	     no  string  argument  can be specified with the flags for sending
	     null characters or breaks.

	     It is a good idea to precede the first send to a  process	by  an
	     expect.   expect  will  wait for the process to start, while send
	     cannot.  In particular, if the first send	completes  before  the
	     process  starts  running,	you  run  the risk of having your data
	     ignored.  In situations where interactive programs offer no  ini-
	     tial prompt, you can precede send by a delay as in:

		 # To avoid giving hackers hints on how to break in,
		 # this system does not prompt for an external password.
		 # Wait for 5 seconds for exec to complete
		 spawn telnet very.secure.gov
		 sleep 5
		 send password\r

	     exp_send  is an alias for send.  If you are using Expectk or some
	     other variant of Expect in the Tk environment, send is defined by
	     Tk  for  an entirely different purpose.  exp_send is provided for
	     compatibility between environments.  Similar aliases are provided
	     for other Expect's other send commands.

       send_error [-flags] string
	     is  like  send,  except  that the output is sent to stderr rather
	     than the current process.

       send_log [--] string
	     is like send, except that the string is only sent to the log file
	     (see  log_file.)	The  arguments	are  ignored if no log file is
	     open.

       send_tty [-flags] string
	     is like send, except that the output is sent to  /dev/tty	rather
	     than the current process.

       send_user [-flags] string
	     is  like  send,  except  that the output is sent to stdout rather
	     than the current process.

       sleep seconds
	     causes the script to sleep for the given number of seconds.  Sec-
	     onds  may	be a decimal number.  Interrupts (and Tk events if you
	     are using Expectk) are processed while Expect sleeps.

       spawn [args] program [args]
	     creates a new process running program args.   Its	stdin,	stdout
	     and  stderr are connected to Expect, so that they may be read and
	     written by other Expect commands.	The connection	is  broken  by
	     close  or	if  the  process itself closes any of the file identi-
	     fiers.

	     When a process is started by spawn, the variable spawn_id is  set
	     to a descriptor referring to that process.  The process described
	     by spawn_id is considered the current process.  spawn_id  may  be
	     read or written, in effect providing job control.

	     user_spawn_id  is a global variable containing a descriptor which
	     refers to the user.  For example, when spawn_id is  set  to  this
	     value, expect behaves like expect_user.

	     error_spawn_id is a global variable containing a descriptor which
	     refers to the standard error.  For example, when spawn_id is  set
	     to this value, send behaves like send_error.

	     tty_spawn_id  is  a global variable containing a descriptor which
	     refers to /dev/tty.  If /dev/tty does not exist  (such  as  in  a
	     cron,  at,  or  batch  script), then tty_spawn_id is not defined.
	     This may be tested as:

		 if {[info vars tty_spawn_id]} {
		     # /dev/tty exists
		 } else {
		     # /dev/tty doesn't exist
		     # probably in cron, batch, or at script
		 }


	     spawn returns the UNIX process id.  If no process is  spawned,  0
	     is  returned.   The  variable spawn_out(slave,name) is set to the
	     name of the pty slave device.

	     By default, spawn echoes the command  name  and  arguments.   The
	     -noecho flag stops spawn from doing this.

	     The  -console  flag causes console output to be redirected to the
	     spawned process.  This is not supported on all systems.

	     Internally, spawn uses a pty, initialized the  same  way  as  the
	     user's tty.  This is further initialized so that all settings are
	     ""sane"" (according to stty(1)).   If  the  variable  stty_init  is
	     defined, it is interpreted in the style of stty arguments as fur-
	     ther configuration.  For example, ""set stty_init raw"" will  cause
	     further  spawned  processes's  terminals  to  start  in raw mode.
	     -nottycopy skips the initialization  based  on  the  user's  tty.
	     -nottyinit skips the ""sane"" initialization.

	     Normally,	spawn  takes  little  time  to execute.  If you notice
	     spawn taking a significant amount of time, it is probably encoun-
	     tering  ptys  that are wedged.  A number of tests are run on ptys
	     to avoid entanglements with errant  processes.   (These  take  10
	     seconds  per wedged pty.)	Running Expect with the -d option will
	     show if Expect is encountering many ptys in odd states.   If  you
	     cannot  kill the processes to which these ptys are attached, your
	     only recourse may be to reboot.

	     If program cannot be spawned successfully because	exec(2)  fails
	     (e.g.  when  program  doesn't  exist),  an  error message will be
	     returned by the next interact or expect command as if program had
	     run and produced the error message as output.  This behavior is a
	     natural consequence of the implementation of spawn.   Internally,
	     spawn forks, after which the spawned process has no way to commu-
	     nicate with the original Expect process except  by  communication
	     via the spawn_id.

	     The  -open  flag  causes the next argument to be interpreted as a
	     Tcl file identifier (i.e., returned by open.)  The spawn  id  can
	     then  be used as if it were a spawned process.  (The file identi-
	     fier should no longer be used.)  This lets you treat raw devices,
	     files, and pipelines as spawned processes without using a pty.  0
	     is returned to indicate there is no associated process.  When the
	     connection  to  the spawned process is closed, so is the Tcl file
	     identifier.  The -leaveopen flag is similar to -open except  that
	     -leaveopen  causes the file identifier to be left open even after
	     the spawn id is closed.

	     The -pty flag causes a pty to be opened but no  process  spawned.
	     0	is  returned  to  indicate  there  is  no  associated process.
	     Spawn_id is set as usual.

	     The variable spawn_out(slave,fd) is set to a file identifier cor-
	     responding  to  the  pty  slave.	It  can be closed using ""close
	     -slave"".

	     The -ignore flag names a signal to  be  ignored  in  the  spawned
	     process.	Otherwise,  signals get the default behavior.  Signals
	     are named as  in  the  trap  command,  except  that  each	signal
	     requires a separate flag.

       strace level
	     causes  following statements to be printed before being executed.
	     (Tcl's trace command traces variables.)  level indicates how  far
	     down in the call stack to trace.  For example, the following com-
	     mand runs Expect while tracing the first 4 levels of  calls,  but
	     none below that.

		 expect -c ""strace 4"" script.exp


	     The  -info flag causes strace to return a description of the most
	     recent non-info arguments given.

       stty args
	     changes terminal modes similarly to the external stty command.

	     By default, the controlling terminal is accessed.	 Other	termi-
	     nals can be accessed by appending ""< /dev/tty..."" to the command.
	     (Note that the arguments should not  be  grouped  into  a	single
	     argument.)

	     Requests  for  status return it as the result of the command.  If
	     no status is requested and the controlling terminal is  accessed,
	     the  previous  status of the raw and echo attributes are returned
	     in a form which can later be used by the command.

	     For example, the arguments raw or -cooked put the	terminal  into
	     raw  mode.   The  arguments  -raw or cooked put the terminal into
	     cooked mode.  The arguments echo and -echo put the terminal  into
	     echo and noecho mode respectively.

	     The  following  example  illustrates  how	to temporarily disable
	     echoing.  This could be used in  otherwise-automatic  scripts  to
	     avoid  embedding passwords in them.  (See more discussion on this
	     under EXPECT HINTS below.)

		 stty -echo
		 send_user ""Password: ""
		 expect_user -re ""(.*)\n""
		 set password $expect_out(1,string)
		 stty echo


       system args
	     gives args to sh(1) as input, just as if it had been typed  as  a
	     command  from  a  terminal.   Expect waits until the shell termi-
	     nates.  The return status from sh is handled the  same  way  that
	     exec handles its return status.

	     In  contrast  to  exec  which  redirects  stdin and stdout to the
	     script, system performs no redirection (other than that indicated
	     by  the  string  itself).	 Thus,	it is possible to use programs
	     which must talk directly to /dev/tty.  For the same  reason,  the
	     results of system are not recorded in the log.

       timestamp [args]
	     returns  a  timestamp.   With no arguments, the number of seconds
	     since the epoch is returned.

	     The -format flag introduces a string which is returned  but  with
	     substitutions  made  according  to  the POSIX rules for strftime.
	     For example %a is replaced by an abbreviated weekday name	(i.e.,
	     Sat).  Others are:
		 %a	 abbreviated weekday name
		 %A	 full weekday name
		 %b	 abbreviated month name
		 %B	 full month name
		 %c	 date-time as in: Wed Oct  6 11:45:56 1993
		 %d	 day of the month (01-31)
		 %H	 hour (00-23)
		 %I	 hour (01-12)
		 %j	 day (001-366)
		 %m	 month (01-12)
		 %M	 minute (00-59)
		 %p	 am or pm
		 %S	 second (00-61)
		 %u	 day (1-7, Monday is first day of week)
		 %U	 week (00-53, first Sunday is first day of week one)
		 %V	 week (01-53, ISO 8601 style)
		 %w	 day (0-6)
		 %W	 week (00-53, first Monday is first day of week one)
		 %x	 date-time as in: Wed Oct  6 1993
		 %X	 time as in: 23:59:59
		 %y	 year (00-99)
		 %Y	 year as in: 1993
		 %Z	 timezone (or nothing if not determinable)
		 %%	 a bare percent sign

	     Other  %  specifications are undefined.  Other characters will be
	     passed through untouched.	Only the C locale is supported.

	     The -seconds flag introduces a number of seconds since the  epoch
	     to be used as a source from which to format.  Otherwise, the cur-
	     rent time is used.

	     The -gmt flag forces timestamp output to use  the	GMT  timezone.
	     With no flag, the local timezone is used.

       trap [[command] signals]
	     causes  the  given  command to be executed upon future receipt of
	     any of the given signals.	The command is executed in the	global
	     scope.   If command is absent, the signal action is returned.  If
	     command is the string SIG_IGN, the signals are ignored.  If  com-
	     mand  is the string SIG_DFL, the signals are result to the system
	     default.  signals is either a single signal or a list of signals.
	     Signals  may be specified numerically or symbolically as per sig-
	     nal(3).  The ""SIG"" prefix may be omitted.

	     With no arguments (or the argument  -number),  trap  returns  the
	     signal number of the trap command currently being executed.

	     The  -code  flag  uses the return code of the command in place of
	     whatever code Tcl was about to return when the command originally
	     started running.

	     The  -interp  flag  causes  the command to be evaluated using the
	     interpreter active at the time the command started running rather
	     than when the trap was declared.

	     The  -name flag causes the trap command to return the signal name
	     of the trap command currently being executed.

	     The -max flag causes the trap command to return the largest  sig-
	     nal number that can be set.

	     For  example,  the command ""trap {send_user ""Ouch!""} SIGINT"" will
	     print ""Ouch!""  each time the user presses ^C.

	     By default, SIGINT (which can usually be  generated  by  pressing
	     ^C) and SIGTERM cause Expect to exit.  This is due to the follow-
	     ing trap, created by default when Expect starts.

		 trap exit {SIGINT SIGTERM}

	     If you use the -D flag to start the debugger, SIGINT is redefined
	     to  start the interactive debugger.  This is due to the following
	     trap:

		 trap {exp_debug 1} SIGINT

	     The debugger trap can be changed by setting the environment vari-
	     able EXPECT_DEBUG_INIT to a new trap command.

	     You  can,	of  course, override both of these just by adding trap
	     commands to your script.  In particular, if  you  have  your  own
	     ""trap  exit  SIGINT"", this will override the debugger trap.  This
	     is useful if you want to prevent users from getting to the debug-
	     ger at all.

	     If  you  want to define your own trap on SIGINT but still trap to
	     the debugger when it is running, use:

		 if {![exp_debug]} {trap mystuff SIGINT}

	     Alternatively, you can trap to the debugger using some other sig-
	     nal.

	     trap  will not let you override the action for SIGALRM as this is
	     used internally to Expect.  The disconnect command  sets  SIGALRM
	     to  SIG_IGN  (ignore).  You can reenable this as long as you dis-
	     able it during subsequent spawn commands.

	     See signal(3) for more info.

       wait [args]
	     delays until a spawned process (or the current process if none is
	     named) terminates.

	     wait normally returns a list of four integers.  The first integer
	     is the pid of the process that was waited upon.  The second inte-
	     ger is the corresponding spawn id.  The third integer is -1 if an
	     operating system error occurred, or 0 otherwise.	If  the  third
	     integer  was  0, the fourth integer is the status returned by the
	     spawned process.  If the third integer was -1, the fourth integer
	     is  the  value  of errno set by the operating system.  The global
	     variable errorCode is also set.

	     Additional elements may appear at the end	of  the  return  value
	     from  wait.   An  optional  fifth	element  identifies a class of
	     information.  Currently, the only possible value for this element
	     is  CHILDKILLED in which case the next two values are the C-style
	     signal name and a short textual description.

	     The -i flag declares the process to  wait	corresponding  to  the
	     named  spawn_id  (NOT the process id).  Inside a SIGCHLD handler,
	     it is possible to wait for any spawned process by using the spawn
	     id -1.

	     The  -nowait  flag causes the wait to return immediately with the
	     indication of a successful wait.  When the process exits (later),
	     it  will automatically disappear without the need for an explicit
	     wait.

	     The wait command may also be used wait for a forked process using
	     the  arguments  ""-i  -1"".	Unlike its use with spawned processes,
	     this command can be executed at any time.	There  is  no  control
	     over  which  process is reaped.  However, the return value can be
	     checked for the process id.


LIBRARIES
       Expect automatically knows about  two  built-in	libraries  for	Expect
       scripts.   These  are defined by the directories named in the variables
       exp_library and exp_exec_library.  Both are meant  to  contain  utility
       files that can be used by other scripts.

       exp_library  contains architecture-independent files.  exp_exec_library
       contains architecture-dependent files.  Depending on your system,  both
       directories   may   be  totally	empty.	 The  existence  of  the  file
       $exp_exec_library/cat-buffers describes whether your  /bin/cat  buffers
       by default.

PRETTY-PRINTING
       A  vgrind  definition  is available for pretty-printing Expect scripts.
       Assuming the vgrind definition supplied with the Expect distribution is
       correctly installed, you can use it as:

	   vgrind -lexpect file


EXAMPLES
       It  many  not  be  apparent how to put everything together that the man
       page describes.	I encourage you to read and try out  the  examples  in
       the  example  directory	of  the Expect distribution.  Some of them are
       real programs.  Others are simply illustrative of  certain  techniques,
       and  of	course, a couple are just quick hacks.	The INSTALL file has a
       quick overview of these programs.

       The Expect papers (see SEE ALSO) are also useful.   While  some	papers
       use  syntax corresponding to earlier versions of Expect, the accompany-
       ing rationales are still valid and go into a lot more detail than  this
       man page.

CAVEATS
       Extensions  may collide with Expect's command names.  For example, send
       is defined by Tk for an entirely different purpose.  For  this  reason,
       most of the Expect commands are also available as ""exp_XXXX"".  Commands
       and variables beginning with ""exp"", ""inter"", ""spawn"", and ""timeout""  do
       not have aliases.  Use the extended command names if you need this com-
       patibility between environments.

       Expect takes a rather liberal view of scoping.	In  particular,  vari-
       ables  read  by	commands specific to the Expect program will be sought
       first from the local scope, and if not found, in the global scope.  For
       example, this obviates the need to place ""global timeout"" in every pro-
       cedure you write that uses expect.  On the other hand, variables  writ-
       ten  are  always in the local scope (unless a ""global"" command has been
       issued).  The most common problem this causes is when spawn is executed
       in  a  procedure.  Outside the procedure, spawn_id no longer exists, so
       the spawned process is no longer accessible simply because of  scoping.
       Add a ""global spawn_id"" to such a procedure.

       If  you	cannot	enable the multispawning capability (i.e., your system
       supports neither select (BSD *.*), poll (SVR>2), nor something  equiva-
       lent),  Expect will only be able to control a single process at a time.
       In this case, do not attempt to set spawn_id, nor  should  you  execute
       processes  via  exec  while a spawned process is running.  Furthermore,
       you will not be able to expect from multiple processes  (including  the
       user as one) at the same time.

       Terminal  parameters can have a big effect on scripts.  For example, if
       a script is written to look for echoing, it will misbehave  if  echoing
       is turned off.  For this reason, Expect forces sane terminal parameters
       by default.  Unfortunately, this can make things unpleasant  for  other
       programs.   As  an example, the emacs shell wants to change the ""usual""
       mappings: newlines get mapped to newlines  instead  of  carriage-return
       newlines,  and  echoing	is  disabled.  This allows one to use emacs to
       edit the input line.  Unfortunately, Expect cannot possibly guess this.

       You  can request that Expect not override its default setting of termi-
       nal parameters, but you must then be very careful when writing  scripts
       for  such  environments.   In  the  case of emacs, avoid depending upon
       things like echoing and end-of-line mappings.

       The commands that accepted arguments braced into  a  single  list  (the
       expect  variants and interact) use a heuristic to decide if the list is
       actually one argument or many.  The heuristic can fail only in the case
       when  the list actually does represent a single argument which has mul-
       tiple embedded \n's with non-whitespace characters between them.   This
       seems  sufficiently  improbable, however the argument ""-nobrace"" can be
       used to force a single argument to be handled  as  a  single  argument.
       This  could  conceivably  be  used  with machine-generated Expect code.
       Similarly, -brace forces a single argument to  be  handle  as  multiple
       patterns/actions.


BUGS
       It  was	really	tempting  to name the program ""sex"" (for either ""Smart
       EXec"" or ""Send-EXpect""), but good sense (or  perhaps  just  Puritanism)
       prevailed.

       On  some systems, when a shell is spawned, it complains about not being
       able to access the tty but runs anyway.	This means your system	has  a
       mechanism  for  gaining	the  controlling  tty that Expect doesn't know
       about.  Please find out what it is, and send this information  back  to
       me.

       Ultrix  4.1  (at least the latest versions around here) considers time-
       outs of above 1000000 to be equivalent to 0.

       Digital UNIX 4.0A (and probably other  versions)  refuses  to  allocate
       ptys  if you define a SIGCHLD handler.  See grantpt page for more info.

       IRIX 6.0 does not handle pty permissions correctly so  that  if	Expect
       attempts  to  allocate a pty previously used by someone else, it fails.
       Upgrade to IRIX 6.1.

       Telnet (verified only under SunOS 4.1.2) hangs  if  TERM  is  not  set.
       This  is  a  problem  under  cron,  at and in cgi scripts, which do not
       define TERM.  Thus, you must set it explicitly - to what type  is  usu-
       ally  irrelevant.   It  just has to be set to something!  The following
       probably suffices for most cases.

	   set env(TERM) vt100


       Tip (verified only under BSDI BSD/OS 3.1 i386) hangs if SHELL and  HOME
       are  not  set.	This  is  a problem under cron, at and in cgi scripts,
       which do not define these environment variables.  Thus,	you  must  set
       them  explicitly  - to what type is usually irrelevant.	It just has to
       be set to something!  The following probably suffices for most cases.

	   set env(SHELL) /bin/sh
	   set env(HOME) /usr/local/bin



       Some implementations of ptys are designed so  that  the	kernel	throws
       away  any unread output after 10 to 15 seconds (actual number is imple-
       mentation-dependent) after the process has closed the file  descriptor.
       Thus Expect programs such as

	   spawn date
	   sleep 20
	   expect

       will  fail.   To  avoid this, invoke non-interactive programs with exec
       rather than spawn.  While such situations are conceivable, in  practice
       I  have	never  encountered  a situation in which the final output of a
       truly interactive program would be lost due to this behavior.

       On the other hand, Cray UNICOS ptys throw away any unread output  imme-
       diately	after  the  process  has  closed  the file descriptor.	I have
       reported this to Cray and they are working on a fix.

       Sometimes a delay is required between a prompt and a response, such  as
       when  a	tty interface is changing UART settings or matching baud rates
       by looking for start/stop bits.	Usually, all this  is  require	is  to
       sleep  for  a second or two.  A more robust technique is to retry until
       the hardware is ready to receive input.	 The  following  example  uses
       both strategies:

	   send ""speed 9600\r"";
	   sleep 1
	   expect {
	       timeout {send ""\r""; exp_continue}
	       $prompt
	   }


       trap  -code  will  not  work  with any command that sits in Tcl's event
       loop, such as sleep.  The problem is that in the event loop,  Tcl  dis-
       cards  the  return codes from async event handlers.  A workaround is to
       set a flag in the trap code.  Then check the flag immediately after the
       command (i.e., sleep).

       The  expect_background  command	ignores  -timeout arguments and has no
       concept of timeouts in general.


EXPECT HINTS
       There are a couple of things about Expect that  may  be	non-intuitive.
       This  section attempts to address some of these things with a couple of
       suggestions.

       A common expect problem is how to recognize shell prompts.  Since these
       are  customized differently by differently people and different shells,
       portably automating rlogin can be difficult without knowing the prompt.
       A  reasonable  convention  is  to have users store a regular expression
       describing their prompt (in particular, the end of it) in the  environ-
       ment  variable EXPECT_PROMPT.  Code like the following can be used.  If
       EXPECT_PROMPT doesn't exist, the code still has a good chance of  func-
       tioning correctly.

	   set prompt ""(%|#|\\$) $""	     ;# default prompt
	   catch {set prompt $env(EXPECT_PROMPT)}

	   expect -re $prompt

       I  encourage you to write expect patterns that include the end of what-
       ever you expect to see.	This avoids the  possibility  of  answering  a
       question  before  seeing  the entire thing.  In addition, while you may
       well be able to answer questions before seeing them  entirely,  if  you
       answer  early,  your answer may appear echoed back in the middle of the
       question.  In other words, the resulting dialogue will be  correct  but
       look scrambled.

       Most  prompts  include  a space character at the end.  For example, the
       prompt from ftp is 'f', 't', 'p',  '>'  and  <blank>.   To  match  this
       prompt,	you must account for each of these characters.	It is a common
       mistake not to include the blank.  Put the blank in explicitly.

       If you use a pattern of the form X*, the * will match  all  the	output
       received  from  the  end  of X to the last thing received.  This sounds
       intuitive but can be somewhat confusing because the phrase ""last  thing
       received""  can  vary  depending	upon the speed of the computer and the
       processing of I/O both by the kernel and the device driver.

       In particular, humans tend to  see  program  output  arriving  in  huge
       chunks  (atomically)  when  in reality most programs produce output one
       line at a time.	Assuming this is the case, the * in the pattern of the
       previous  paragraph  may  only  match  the end of the current line even
       though there seems to be more, because at the time of  the  match  that
       was all the output that had been received.

       expect  has no way of knowing that further output is coming unless your
       pattern specifically accounts for it.

       Even depending on line-oriented buffering is unwise.  Not only do  pro-
       grams  rarely  make  promises  about the type of buffering they do, but
       system indigestion can break output lines up so	that  lines  break  at
       seemingly random places.  Thus, if you can express the last few charac-
       ters of a prompt when writing patterns, it is wise to do so.

       If you are waiting for a pattern in the last output of  a  program  and
       the  program  emits  something  else  instead,  you will not be able to
       detect that with the timeout keyword.  The reason is that  expect  will
       not timeout - instead it will get an eof indication.  Use that instead.
       Even better, use both.  That way if that line is ever moved around, you
       won't have to edit the line itself.

       Newlines  are  usually converted to carriage return, linefeed sequences
       when output by the terminal driver.  Thus, if you want a  pattern  that
       explicitly  matches  the  two lines, from, say, printf(""foo\nbar""), you
       should use the pattern ""foo\r\nbar"".

       A  similar  translation	occurs	when  reading  from  the   user,   via
       expect_user.   In  this	case, when you press return, it will be trans-
       lated to a newline.  If Expect then passes that to a program which sets
       its terminal to raw mode (like telnet), there is going to be a problem,
       as the program expects a true return.  (Some programs are actually for-
       giving  in  that they will automatically translate newlines to returns,
       but most don't.)  Unfortunately, there is no way to  find  out  that  a
       program put its terminal into raw mode.

       Rather  than  manually replacing newlines with returns, the solution is
       to use the command ""stty raw"", which will stop the translation.	 Note,
       however,  that  this means that you will no longer get the cooked line-
       editing features.

       interact implicitly sets your terminal to raw mode so this problem will
       not arise then.

       It is often useful to store passwords (or other private information) in
       Expect scripts.	This is not recommended since anything that is	stored
       on a computer is susceptible to being accessed by anyone.  Thus, inter-
       actively prompting for passwords from a script is a smarter  idea  than
       embedding them literally.  Nonetheless, sometimes such embedding is the
       only possibility.

       Unfortunately, the UNIX file system  has  no  direct  way  of  creating
       scripts	which  are  executable	but unreadable.  Systems which support
       setgid shell scripts may indirectly simulate this as follows:

       Create the Expect script (that contains	the  secret  data)  as	usual.
       Make  its permissions be 750 (-rwxr-x---) and owned by a trusted group,
       i.e., a group which is allowed to read it.  If necessary, create a  new
       group for this purpose.	Next, create a /bin/sh script with permissions
       2751 (-rwxr-s--x) owned by the same group as before.

       The result is a script which may be  executed  (and  read)  by  anyone.
       When invoked, it runs the Expect script.

SEE ALSO
       Tcl(3), libexpect(3)
       ""Exploring  Expect: A Tcl-Based Toolkit for Automating Interactive Pro-
       grams"" by Don Libes, pp. 602, ISBN 1-56592-090-2,  O'Reilly  and  Asso-
       ciates, 1995.
       ""expect:  Curing  Those	Uncontrollable	Fits  of Interactivity"" by Don
       Libes, Proceedings of the Summer 1990 USENIX Conference, Anaheim, Cali-
       fornia, June 11-15, 1990.
       ""Using  expect  to  Automate System Administration Tasks"" by Don Libes,
       Proceedings of the 1990 USENIX Large Installation  Systems  Administra-
       tion Conference, Colorado Springs, Colorado, October 17-19, 1990.
       ""Tcl:  An  Embeddable Command Language"" by John Ousterhout, Proceedings
       of the Winter 1990 USENIX Conference, Washington, D.C., January	22-26,
       1990.
       ""expect:  Scripts  for  Controlling Interactive Programs"" by Don Libes,
       Computing Systems, Vol. 4, No. 2, University of California Press  Jour-
       nals, November 1991.
       ""Regression  Testing  and Conformance Testing Interactive Programs"", by
       Don Libes, Proceedings  of  the	Summer	1992  USENIX  Conference,  pp.
       135-144, San Antonio, TX, June 12-15, 1992.
       ""Kibitz	-  Connecting  Multiple Interactive Programs Together"", by Don
       Libes, Software - Practice & Experience, John Wiley & Sons,  West  Sus-
       sex, England, Vol. 23, No. 5, May, 1993.
       ""A  Debugger  for  Tcl  Applications"", by Don Libes, Proceedings of the
       1993 Tcl/Tk Workshop, Berkeley, CA, June 10-11, 1993.

AUTHOR
       Don Libes, National Institute of Standards and Technology

ACKNOWLEDGMENTS
       Thanks to John Ousterhout for Tcl, and Scott Paisley  for  inspiration.
       Thanks to Rob Savoye for Expect's autoconfiguration code.

       The  HISTORY  file documents much of the evolution of expect.  It makes
       interesting reading and might give you further insight  to  this  soft-
       ware.   Thanks  to the people mentioned in it who sent me bug fixes and
       gave other assistance.

       Design and implementation of Expect was paid for in part  by  the  U.S.
       government  and	is therefore in the public domain.  However the author
       and NIST would like credit if this program and  documentation  or  por-
       tions of them are used.



			       29 December 1994 		     EXPECT(1)
","# expect

> Script executor that interacts with other programs that require user input.
> More information: <https://linux.die.net/man/1/expect>.

- Execute an expect script from a file:

`expect {{path/to/file}}`

- Execute a specified expect script:

`expect -c ""{{commands}}""`

- Enter an interactive REPL (use `exit` or Ctrl + D to exit):

`expect -i`
"
dockerd,https://docs.docker.com/engine/reference/commandline/dockerd/,"
































dockerd | Docker Documentation





































Toggle navigation
























dockerd

Estimated reading time: 
  
  
    55 minutes
  


daemon
Usage: dockerd COMMAND

A self-sufficient runtime for containers.

Options:
      --add-runtime runtime                   Register an additional OCI compatible runtime (default [])
      --allow-nondistributable-artifacts list Allow push of nondistributable artifacts to registry
      --api-cors-header string                Set CORS headers in the Engine API
      --authorization-plugin list             Authorization plugins to load
      --bip string                            Specify network bridge IP
  -b, --bridge string                         Attach containers to a network bridge
      --cgroup-parent string                  Set parent cgroup for all containers
      --cluster-advertise string              Address or interface name to advertise
      --cluster-store string                  URL of the distributed storage backend
      --cluster-store-opt map                 Set cluster store options (default map[])
      --config-file string                    Daemon configuration file (default ""/etc/docker/daemon.json"")
      --containerd string                     containerd grpc address
      --cpu-rt-period int                     Limit the CPU real-time period in microseconds
      --cpu-rt-runtime int                    Limit the CPU real-time runtime in microseconds
      --cri-containerd                        start containerd with cri
      --data-root string                      Root directory of persistent Docker state (default ""/var/lib/docker"")
  -D, --debug                                 Enable debug mode
      --default-address-pool pool-options     Default address pools for node specific local networks
      --default-gateway ip                    Container default gateway IPv4 address
      --default-gateway-v6 ip                 Container default gateway IPv6 address
      --default-ipc-mode string               Default mode for containers ipc (""shareable"" | ""private"") (default ""private"")
      --default-runtime string                Default OCI runtime for containers (default ""runc"")
      --default-shm-size bytes                Default shm size for containers (default 64MiB)
      --default-ulimit ulimit                 Default ulimits for containers (default [])
      --dns list                              DNS server to use
      --dns-opt list                          DNS options to use
      --dns-search list                       DNS search domains to use
      --exec-opt list                         Runtime execution options
      --exec-root string                      Root directory for execution state files (default ""/var/run/docker"")
      --experimental                          Enable experimental features
      --fixed-cidr string                     IPv4 subnet for fixed IPs
      --fixed-cidr-v6 string                  IPv6 subnet for fixed IPs
  -G, --group string                          Group for the unix socket (default ""docker"")
      --help                                  Print usage
  -H, --host list                             Daemon socket(s) to connect to
      --icc                                   Enable inter-container communication (default true)
      --init                                  Run an init in the container to forward signals and reap processes
      --init-path string                      Path to the docker-init binary
      --insecure-registry list                Enable insecure registry communication
      --ip ip                                 Default IP when binding container ports (default 0.0.0.0)
      --ip-forward                            Enable net.ipv4.ip_forward (default true)
      --ip-masq                               Enable IP masquerading (default true)
      --iptables                              Enable addition of iptables rules (default true)
      --ipv6                                  Enable IPv6 networking
      --label list                            Set key=value labels to the daemon
      --live-restore                          Enable live restore of docker when containers are still running
      --log-driver string                     Default driver for container logs (default ""json-file"")
  -l, --log-level string                      Set the logging level (""debug""|""info""|""warn""|""error""|""fatal"") (default ""info"")
      --log-opt map                           Default log driver options for containers (default map[])
      --max-concurrent-downloads int          Set the max concurrent downloads for each pull (default 3)
      --max-concurrent-uploads int            Set the max concurrent uploads for each push (default 5)
      --metrics-addr string                   Set default address and port to serve the metrics api on
      --mtu int                               Set the containers network MTU
      --network-control-plane-mtu int         Network Control plane MTU (default 1500)
      --no-new-privileges                     Set no-new-privileges by default for new containers
      --node-generic-resource list            Advertise user-defined resource
      --oom-score-adjust int                  Set the oom_score_adj for the daemon (default -500)
  -p, --pidfile string                        Path to use for daemon PID file (default ""/var/run/docker.pid"")
      --raw-logs                              Full timestamps without ANSI coloring
      --registry-mirror list                  Preferred Docker registry mirror
      --rootless                              Enable rootless mode; typically used with RootlessKit (experimental)
      --seccomp-profile string                Path to seccomp profile
      --selinux-enabled                       Enable selinux support
      --shutdown-timeout int                  Set the default shutdown timeout (default 15)
  -s, --storage-driver string                 Storage driver to use
      --storage-opt list                      Storage driver options
      --swarm-default-advertise-addr string   Set default address or interface for swarm advertised address
      --tls                                   Use TLS; implied by --tlsverify
      --tlscacert string                      Trust certs signed only by this CA (default ""~/.docker/ca.pem"")
      --tlscert string                        Path to TLS certificate file (default ""~/.docker/cert.pem"")
      --tlskey string                         Path to TLS key file (default ""~/.docker/key.pem"")
      --tlsverify                             Use TLS and verify the remote
      --userland-proxy                        Use userland proxy for loopback traffic (default true)
      --userland-proxy-path string            Path to the userland proxy binary
      --userns-remap string                   User/Group setting for user namespaces
  -v, --version                               Print version information and quit

Options with [] may be specified multiple times.
Description
dockerd is the persistent process that manages containers. Docker
uses different binaries for the daemon and client. To run the daemon you
type dockerd.
To run the daemon with debug output, use dockerd -D or add ""debug"": true to
the daemon.json file.

Enabling experimental features
Enable experimental features by starting dockerd with the --experimental
flag or adding ""experimental"": true to the daemon.json file.

Environment variables
For easy reference, the following list of environment variables are supported
by the dockerd command line:

DOCKER_DRIVER The graph driver to use.
DOCKER_NOWARN_KERNEL_VERSION Prevent warnings that your Linux kernel is
unsuitable for Docker.
DOCKER_RAMDISK If set this will disable âpivot_rootâ.
DOCKER_TMPDIR Location for temporary Docker files.
MOBY_DISABLE_PIGZ Do not use unpigz to
decompress layers in parallel when pulling images, even if it is installed.

Examples
Daemon socket option
The Docker daemon can listen for Docker Engine API
requests via three different types of Socket: unix, tcp, and fd.
By default, a unix domain socket (or IPC socket) is created at
/var/run/docker.sock, requiring either root permission, or docker group
membership.
If you need to access the Docker daemon remotely, you need to enable the tcp
Socket. Beware that the default setup provides un-encrypted and
un-authenticated direct access to the Docker daemon - and should be secured
either using the built in HTTPS encrypted socket, or by
putting a secure web proxy in front of it. You can listen on port 2375 on all
network interfaces with -H tcp://0.0.0.0:2375, or on a particular network
interface using its IP address: -H tcp://192.168.59.103:2375. It is
conventional to use port 2375 for un-encrypted, and port 2376 for encrypted
communication with the daemon.

Note
If youâre using an HTTPS encrypted socket, keep in mind that only
TLS1.0 and greater are supported. Protocols SSLv3 and under are not
supported anymore for security reasons.

On Systemd based systems, you can communicate with the daemon via
Systemd socket activation,
use dockerd -H fd://. Using fd:// will work perfectly for most setups but
you can also specify individual sockets: dockerd -H fd://3. If the
specified socket activated files arenât found, then Docker will exit. You can
find examples of using Systemd socket activation with Docker and Systemd in the
Docker source tree.
You can configure the Docker daemon to listen to multiple sockets at the same
time using multiple -H options:
# listen using the default unix socket, and on 2 specific IP addresses on this host.

$ sudo dockerd -H unix:///var/run/docker.sock -H tcp://192.168.59.106 -H tcp://10.10.10.2

The Docker client will honor the DOCKER_HOST environment variable to set the
-H flag for the client. Use one of the following commands:
$ docker -H tcp://0.0.0.0:2375 ps

$ export DOCKER_HOST=""tcp://0.0.0.0:2375""

$ docker ps

Setting the DOCKER_TLS_VERIFY environment variable to any value other than
the empty string is equivalent to setting the --tlsverify flag. The following
are equivalent:
$ docker --tlsverify ps
# or
$ export DOCKER_TLS_VERIFY=1
$ docker ps

The Docker client will honor the HTTP_PROXY, HTTPS_PROXY, and NO_PROXY
environment variables (or the lowercase versions thereof). HTTPS_PROXY takes
precedence over HTTP_PROXY.
Starting with Docker 18.09, the Docker client supports connecting to a remote
daemon via SSH:
$ docker -H ssh://me@example.com:22 ps
$ docker -H ssh://me@example.com ps
$ docker -H ssh://example.com ps

To use SSH connection, you need to set up ssh so that it can reach the
remote host with public key authentication. Password authentication is not
supported. If your key is protected with passphrase, you need to set up
ssh-agent.
Also, you need to have docker binary 18.09 or later on the daemon host.
Bind Docker to another host/port or a Unix socket

Warning:
Changing the default docker daemon binding to a
TCP port or Unix docker user group will increase your security risks
by allowing non-root users to gain root access on the host. Make sure
you control access to docker. If you are binding
to a TCP port, anyone with access to that port has full Docker access;
so it is not advisable on an open network.

With -H it is possible to make the Docker daemon to listen on a
specific IP and port. By default, it will listen on
unix:///var/run/docker.sock to allow only local connections by the
root user. You could set it to 0.0.0.0:2375 or a specific host IP
to give access to everybody, but that is not recommended because
then it is trivial for someone to gain root access to the host where the
daemon is running.
Similarly, the Docker client can use -H to connect to a custom port.
The Docker client will default to connecting to unix:///var/run/docker.sock
on Linux, and tcp://127.0.0.1:2376 on Windows.
-H accepts host and port assignment in the following format:
tcp://[host]:[port][path] or unix://path

For example:

tcp:// -> TCP connection to 127.0.0.1 on either port 2376 when TLS encryption
is on, or port 2375 when communication is in plain text.
tcp://host:2375 -> TCP connection on
host:2375
tcp://host:2375/path -> TCP connection on
host:2375 and prepend path to all requests
unix://path/to/socket -> Unix socket located
at path/to/socket

-H, when empty, will default to the same value as
when no -H was passed in.
-H also accepts short form for TCP bindings: host: or host:port or :port
Run Docker in daemon mode:
$ sudo <path to>/dockerd -H 0.0.0.0:5555 &

Download an ubuntu image:
$ docker -H :5555 pull ubuntu

You can use multiple -H, for example, if you want to listen on both
TCP and a Unix socket
# Run docker in daemon mode
$ sudo <path to>/dockerd -H tcp://127.0.0.1:2375 -H unix:///var/run/docker.sock &
# Download an ubuntu image, use default Unix socket
$ docker pull ubuntu
# OR use the TCP port
$ docker -H tcp://127.0.0.1:2375 pull ubuntu

Daemon storage-driver
On Linux, the Docker daemon has support for several different image layer storage
drivers: aufs, devicemapper, btrfs, zfs, overlay and overlay2.
The aufs driver is the oldest, but is based on a Linux kernel patch-set that
is unlikely to be merged into the main kernel. These are also known to cause
some serious kernel crashes. However aufs allows containers to share
executable and shared library memory, so is a useful choice when running
thousands of containers with the same program or libraries.
The devicemapper driver uses thin provisioning and Copy on Write (CoW)
snapshots. For each devicemapper graph location â typically
/var/lib/docker/devicemapper â a thin pool is created based on two block
devices, one for data and one for metadata. By default, these block devices
are created automatically by using loopback mounts of automatically created
sparse files. Refer to Devicemapper options below
for a way how to customize this setup.
~jpetazzo/Resizing Docker containers with the Device Mapper plugin
article explains how to tune your existing setup without the use of options.
The btrfs driver is very fast for docker build - but like devicemapper
does not share executable memory between devices. Use
dockerd -s btrfs -g /mnt/btrfs_partition.
The zfs driver is probably not as fast as btrfs but has a longer track record
on stability. Thanks to Single Copy ARC shared blocks between clones will be
cached only once. Use dockerd -s zfs. To select a different zfs filesystem
set zfs.fsname option as described in ZFS options.
The overlay is a very fast union filesystem. It is now merged in the main
Linux kernel as of 3.18.0. overlay
also supports page cache sharing, this means multiple containers accessing
the same file can share a single page cache entry (or entries), it makes
overlay as efficient with memory as aufs driver. Call dockerd -s overlay
to use it.
The overlay2 uses the same fast union filesystem but takes advantage of
additional features added in Linux
kernel 4.0 to avoid excessive inode consumption. Call dockerd -s overlay2
to use it.

Note
The overlay storage driver can cause excessive inode consumption (especially
as the number of images grows). We recommend using the overlay2 storage
driver instead.


Note
Both overlay and overlay2 are currently unsupported on btrfs
or any Copy on Write filesystem and should only be used over ext4 partitions.

On Windows, the Docker daemon supports a single image layer storage driver
depending on the image platform: windowsfilter for Windows images, and
lcow for Linux containers on Windows.
Options per storage driver
Particular storage-driver can be configured with options specified with
--storage-opt flags. Options for devicemapper are prefixed with dm,
options for zfs start with zfs, options for btrfs start with btrfs
and options for lcow start with lcow.
Devicemapper options
This is an example of the configuration file for devicemapper on Linux:
{
  ""storage-driver"": ""devicemapper"",
  ""storage-opts"": [
    ""dm.thinpooldev=/dev/mapper/thin-pool"",
    ""dm.use_deferred_deletion=true"",
    ""dm.use_deferred_removal=true""
  ]
}

dm.thinpooldev
Specifies a custom block storage device to use for the thin pool.
If using a block device for device mapper storage, it is best to use lvm
to create and manage the thin-pool volume. This volume is then handed to Docker
to exclusively create snapshot volumes needed for images and containers.
Managing the thin-pool outside of Engine makes for the most feature-rich
method of having Docker utilize device mapper thin provisioning as the
backing storage for Docker containers. The highlights of the lvm-based
thin-pool management feature include: automatic or interactive thin-pool
resize support, dynamically changing thin-pool features, automatic thinp
metadata checking when lvm activates the thin-pool, etc.
As a fallback if no thin pool is provided, loopback files are
created. Loopback is very slow, but can be used without any
pre-configuration of storage. It is strongly recommended that you do
not use loopback in production. Ensure your Engine daemon has a
--storage-opt dm.thinpooldev argument provided.
Example:
$ sudo dockerd --storage-opt dm.thinpooldev=/dev/mapper/thin-pool

dm.directlvm_device
As an alternative to providing a thin pool as above, Docker can setup a block
device for you.
Example:
$ sudo dockerd --storage-opt dm.directlvm_device=/dev/xvdf

dm.thinp_percent
Sets the percentage of passed in block device to use for storage.
Example:
$ sudo dockerd --storage-opt dm.thinp_percent=95

dm.thinp_metapercent
Sets the percentage of the passed in block device to use for metadata storage.
Example:
$ sudo dockerd --storage-opt dm.thinp_metapercent=1

dm.thinp_autoextend_threshold
Sets the value of the percentage of space used before lvm attempts to
autoextend the available space [100 = disabled]
Example:
$ sudo dockerd --storage-opt dm.thinp_autoextend_threshold=80

dm.thinp_autoextend_percent
Sets the value percentage value to increase the thin pool by when lvm
attempts to autoextend the available space [100 = disabled]
Example:
$ sudo dockerd --storage-opt dm.thinp_autoextend_percent=20

dm.basesize
Specifies the size to use when creating the base device, which limits the
size of images and containers. The default value is 10G. Note, thin devices
are inherently âsparseâ, so a 10G device which is mostly empty doesnât use
10 GB of space on the pool. However, the filesystem will use more space for
the empty case the larger the device is.
The base device size can be increased at daemon restart which will allow
all future images and containers (based on those new images) to be of the
new base device size.
Examples
$ sudo dockerd --storage-opt dm.basesize=50G

This will increase the base device size to 50G. The Docker daemon will throw an
error if existing base device size is larger than 50G. A user can use
this option to expand the base device size however shrinking is not permitted.
This value affects the system-wide âbaseâ empty filesystem
that may already be initialized and inherited by pulled images. Typically,
a change to this value requires additional steps to take effect:
$ sudo service docker stop

$ sudo rm -rf /var/lib/docker

$ sudo service docker start

dm.loopdatasize

Note
This option configures devicemapper loopback, which should not
be used in production.

Specifies the size to use when creating the loopback file for the
âdataâ device which is used for the thin pool. The default size is
100G. The file is sparse, so it will not initially take up this
much space.
Example
$ sudo dockerd --storage-opt dm.loopdatasize=200G

dm.loopmetadatasize

Note
This option configures devicemapper loopback, which should not
be used in production.

Specifies the size to use when creating the loopback file for the
âmetadataâ device which is used for the thin pool. The default size
is 2G. The file is sparse, so it will not initially take up
this much space.
Example
$ sudo dockerd --storage-opt dm.loopmetadatasize=4G

dm.fs
Specifies the filesystem type to use for the base device. The supported
options are âext4â and âxfsâ. The default is âxfsâ
Example
$ sudo dockerd --storage-opt dm.fs=ext4

dm.mkfsarg
Specifies extra mkfs arguments to be used when creating the base device.
Example
$ sudo dockerd --storage-opt ""dm.mkfsarg=-O ^has_journal""

dm.mountopt
Specifies extra mount options used when mounting the thin devices.
Example
$ sudo dockerd --storage-opt dm.mountopt=nodiscard

dm.datadev
(Deprecated, use dm.thinpooldev)
Specifies a custom blockdevice to use for data for the thin pool.
If using a block device for device mapper storage, ideally both datadev and
metadatadev should be specified to completely avoid using the loopback
device.
Example
$ sudo dockerd \
      --storage-opt dm.datadev=/dev/sdb1 \
      --storage-opt dm.metadatadev=/dev/sdc1

dm.metadatadev
(Deprecated, use dm.thinpooldev)
Specifies a custom blockdevice to use for metadata for the thin pool.
For best performance the metadata should be on a different spindle than the
data, or even better on an SSD.
If setting up a new metadata pool it is required to be valid. This can be
achieved by zeroing the first 4k to indicate empty metadata, like this:
$ dd if=/dev/zero of=$metadata_dev bs=4096 count=1

Example
$ sudo dockerd \
      --storage-opt dm.datadev=/dev/sdb1 \
      --storage-opt dm.metadatadev=/dev/sdc1

dm.blocksize
Specifies a custom blocksize to use for the thin pool. The default
blocksize is 64K.
Example
$ sudo dockerd --storage-opt dm.blocksize=512K

dm.blkdiscard
Enables or disables the use of blkdiscard when removing devicemapper
devices. This is enabled by default (only) if using loopback devices and is
required to resparsify the loopback file on image/container removal.
Disabling this on loopback can lead to much faster container removal
times, but will make the space used in /var/lib/docker directory not be
returned to the system for other use when containers are removed.
Examples
$ sudo dockerd --storage-opt dm.blkdiscard=false

dm.override_udev_sync_check
Overrides the udev synchronization checks between devicemapper and udev.
udev is the device manager for the Linux kernel.
To view the udev sync support of a Docker daemon that is using the
devicemapper driver, run:
$ docker info
[...]
Udev Sync Supported: true
[...]

When udev sync support is true, then devicemapper and udev can
coordinate the activation and deactivation of devices for containers.
When udev sync support is false, a race condition occurs between
thedevicemapper and udev during create and cleanup. The race condition
results in errors and failures. (For information on these failures, see
docker#4036)
To allow the docker daemon to start, regardless of udev sync not being
supported, set dm.override_udev_sync_check to true:
$ sudo dockerd --storage-opt dm.override_udev_sync_check=true

When this value is true, the  devicemapper continues and simply warns
you the errors are happening.

Note
The ideal is to pursue a docker daemon and environment that does
support synchronizing with udev. For further discussion on this
topic, see docker#4036.
Otherwise, set this flag for migrating existing Docker daemons to
a daemon with a supported environment.

dm.use_deferred_removal
Enables use of deferred device removal if libdm and the kernel driver
support the mechanism.
Deferred device removal means that if device is busy when devices are
being removed/deactivated, then a deferred removal is scheduled on
device. And devices automatically go away when last user of the device
exits.
For example, when a container exits, its associated thin device is removed.
If that device has leaked into some other mount namespace and canât be
removed, the container exit still succeeds and this option causes the
system to schedule the device for deferred removal. It does not wait in a
loop trying to remove a busy device.
Example
$ sudo dockerd --storage-opt dm.use_deferred_removal=true

dm.use_deferred_deletion
Enables use of deferred device deletion for thin pool devices. By default,
thin pool device deletion is synchronous. Before a container is deleted,
the Docker daemon removes any associated devices. If the storage driver
can not remove a device, the container deletion fails and daemon returns.
Error deleting container: Error response from daemon: Cannot destroy container

To avoid this failure, enable both deferred device deletion and deferred
device removal on the daemon.
$ sudo dockerd \
      --storage-opt dm.use_deferred_deletion=true \
      --storage-opt dm.use_deferred_removal=true

With these two options enabled, if a device is busy when the driver is
deleting a container, the driver marks the device as deleted. Later, when
the device isnât in use, the driver deletes it.
In general it should be safe to enable this option by default. It will help
when unintentional leaking of mount point happens across multiple mount
namespaces.
dm.min_free_space
Specifies the min free space percent in a thin pool require for new device
creation to succeed. This check applies to both free data space as well
as free metadata space. Valid values are from 0% - 99%. Value 0% disables
free space checking logic. If user does not specify a value for this option,
the Engine uses a default value of 10%.
Whenever a new a thin pool device is created (during docker pull or during
container creation), the Engine checks if the minimum free space is
available. If sufficient space is unavailable, then device creation fails
and any relevant docker operation fails.
To recover from this error, you must create more free space in the thin pool
to recover from the error. You can create free space by deleting some images
and containers from the thin pool. You can also add more storage to the thin
pool.
To add more space to a LVM (logical volume management) thin pool, just add
more storage to the volume group container thin pool; this should automatically
resolve any errors. If your configuration uses loop devices, then stop the
Engine daemon, grow the size of loop files and restart the daemon to resolve
the issue.
Example
$ sudo dockerd --storage-opt dm.min_free_space=10%

dm.xfs_nospace_max_retries
Specifies the maximum number of retries XFS should attempt to complete
IO when ENOSPC (no space) error is returned by underlying storage device.
By default XFS retries infinitely for IO to finish and this can result
in unkillable process. To change this behavior one can set
xfs_nospace_max_retries to say 0 and XFS will not retry IO after getting
ENOSPC and will shutdown filesystem.
Example
$ sudo dockerd --storage-opt dm.xfs_nospace_max_retries=0

dm.libdm_log_level
Specifies the maxmimum libdm log level that will be forwarded to the
dockerd log (as specified by --log-level). This option is primarily
intended for debugging problems involving libdm. Using values other than the
defaults may cause false-positive warnings to be logged.
Values specified must fall within the range of valid libdm log levels. At the
time of writing, the following is the list of libdm log levels as well as
their corresponding levels when output by dockerd.



libdm Level
Value
--log-level




_LOG_FATAL
2
error


_LOG_ERR
3
error


_LOG_WARN
4
warn


_LOG_NOTICE
5
info


_LOG_INFO
6
info


_LOG_DEBUG
7
debug



Example
$ sudo dockerd \
      --log-level debug \
      --storage-opt dm.libdm_log_level=7

ZFS options
zfs.fsname
Set zfs filesystem under which docker will create its own datasets.
By default docker will pick up the zfs filesystem where docker graph
(/var/lib/docker) is located.
Example
$ sudo dockerd -s zfs --storage-opt zfs.fsname=zroot/docker

Btrfs options
btrfs.min_space
Specifies the minimum size to use when creating the subvolume which is used
for containers. If user uses disk quota for btrfs when creating or running
a container with --storage-opt size option, docker should ensure the
size cannot be smaller than btrfs.min_space.
Example
$ sudo dockerd -s btrfs --storage-opt btrfs.min_space=10G

Overlay2 options
overlay2.override_kernel_check
Overrides the Linux kernel version check allowing overlay2. Support for
specifying multiple lower directories needed by overlay2 was added to the
Linux kernel in 4.0.0. However, some older kernel versions may be patched
to add multiple lower directory support for OverlayFS. This option should
only be used after verifying this support exists in the kernel. Applying
this option on a kernel without this support will cause failures on mount.
overlay2.size
Sets the default max size of the container. It is supported only when the
backing fs is xfs and mounted with pquota mount option. Under these
conditions the user can pass any size less then the backing fs size.
Example
$ sudo dockerd -s overlay2 --storage-opt overlay2.size=1G

Windowsfilter options
size
Specifies the size to use when creating the sandbox which is used for containers.
Defaults to 20G.
Example
C:\> dockerd --storage-opt size=40G

LCOW (Linux Containers on Windows) options
lcow.globalmode
Specifies whether the daemon instantiates utility VM instances as required
(recommended and default if omitted), or uses single global utility VM (better
performance, but has security implications and not recommended for production
deployments).
Example
C:\> dockerd --storage-opt lcow.globalmode=false

lcow.kirdpath
Specifies the folder path to the location of a pair of kernel and initrd files
used for booting a utility VM. Defaults to %ProgramFiles%\Linux Containers.
Example
C:\> dockerd --storage-opt lcow.kirdpath=c:\path\to\files

lcow.kernel
Specifies the filename of a kernel file located in the lcow.kirdpath path.
Defaults to bootx64.efi.
Example
C:\> dockerd --storage-opt lcow.kernel=kernel.efi

lcow.initrd
Specifies the filename of an initrd file located in the lcow.kirdpath path.
Defaults to initrd.img.
Example
C:\> dockerd --storage-opt lcow.initrd=myinitrd.img

lcow.bootparameters
Specifies additional boot parameters for booting utility VMs when in kernel/
initrd mode. Ignored if the utility VM is booting from VHD. These settings
are kernel specific.
Example
C:\> dockerd --storage-opt ""lcow.bootparameters='option=value'""

lcow.vhdx
Specifies a custom VHDX to boot a utility VM, as an alternate to kernel
and initrd booting. Defaults to uvm.vhdx under lcow.kirdpath.
Example
C:\> dockerd --storage-opt lcow.vhdx=custom.vhdx

lcow.timeout
Specifies the timeout for utility VM operations in seconds. Defaults
to 300.
Example
C:\> dockerd --storage-opt lcow.timeout=240

lcow.sandboxsize
Specifies the size in GB to use when creating the sandbox which is used for
containers. Defaults to 20. Cannot be less than 20.
Example
C:\> dockerd --storage-opt lcow.sandboxsize=40

Docker runtime execution options
The Docker daemon relies on a
OCI compliant runtime
(invoked via the containerd daemon) as its interface to the Linux
kernel namespaces, cgroups, and SELinux.
By default, the Docker daemon automatically starts containerd. If you want to
control containerd startup, manually start containerd and pass the path to
the containerd socket using the --containerd flag. For example:
$ sudo dockerd --containerd /var/run/dev/docker-containerd.sock

Runtimes can be registered with the daemon either via the
configuration file or using the --add-runtime command line argument.
The following is an example adding 2 runtimes via the configuration:
{
	""default-runtime"": ""runc"",
	""runtimes"": {
		""runc"": {
			""path"": ""runc""
		},
		""custom"": {
			""path"": ""/usr/local/bin/my-runc-replacement"",
			""runtimeArgs"": [
				""--debug""
			]
		}
	}
}

This is the same example via the command line:
$ sudo dockerd --add-runtime runc=runc --add-runtime custom=/usr/local/bin/my-runc-replacement


Note
Defining runtime arguments via the command line is not supported.

Options for the runtime
You can configure the runtime using options specified
with the --exec-opt flag. All the flagâs options have the native prefix. A
single native.cgroupdriver option is available.
The native.cgroupdriver option specifies the management of the containerâs
cgroups. You can only specify cgroupfs or systemd. If you specify
systemd and it is not available, the system errors out. If you omit the
native.cgroupdriver option, cgroupfs is used.
This example sets the cgroupdriver to systemd:
$ sudo dockerd --exec-opt native.cgroupdriver=systemd

Setting this option applies to all containers the daemon launches.
Also Windows Container makes use of --exec-opt for special purpose. Docker user
can specify default container isolation technology with this, for example:
> dockerd --exec-opt isolation=hyperv

Will make hyperv the default isolation technology on Windows. If no isolation
value is specified on daemon start, on Windows client, the default is
hyperv, and on Windows server, the default is process.
Daemon DNS options
To set the DNS server for all Docker containers, use:
$ sudo dockerd --dns 8.8.8.8

To set the DNS search domain for all Docker containers, use:
$ sudo dockerd --dns-search example.com

Allow push of nondistributable artifacts
Some images (e.g., Windows base images) contain artifacts whose distribution is
restricted by license. When these images are pushed to a registry, restricted
artifacts are not included.
To override this behavior for specific registries, use the
--allow-nondistributable-artifacts option in one of the following forms:

--allow-nondistributable-artifacts myregistry:5000 tells the Docker daemon
to push nondistributable artifacts to myregistry:5000.
--allow-nondistributable-artifacts 10.1.0.0/16 tells the Docker daemon to
push nondistributable artifacts to all registries whose resolved IP address
is within the subnet described by the CIDR syntax.

This option can be used multiple times.
This option is useful when pushing images containing nondistributable artifacts
to a registry on an air-gapped network so hosts on that network can pull the
images without connecting to another server.

Warning: Nondistributable artifacts typically have restrictions on how
and where they can be distributed and shared. Only use this feature to push
artifacts to private registries and ensure that you are in compliance with
any terms that cover redistributing nondistributable artifacts.

Insecure registries
Docker considers a private registry either secure or insecure. In the rest of
this section, registry is used for private registry, and myregistry:5000
is a placeholder example for a private registry.
A secure registry uses TLS and a copy of its CA certificate is placed on the
Docker host at /etc/docker/certs.d/myregistry:5000/ca.crt. An insecure
registry is either not using TLS (i.e., listening on plain text HTTP), or is
using TLS with a CA certificate not known by the Docker daemon. The latter can
happen when the certificate was not found under
/etc/docker/certs.d/myregistry:5000/, or if the certificate verification
failed (i.e., wrong CA).
By default, Docker assumes all, but local (see local registries below),
registries are secure. Communicating with an insecure registry is not possible
if Docker assumes that registry is secure. In order to communicate with an
insecure registry, the Docker daemon requires --insecure-registry in one of
the following two forms:

--insecure-registry myregistry:5000 tells the Docker daemon that
myregistry:5000 should be considered insecure.
--insecure-registry 10.1.0.0/16 tells the Docker daemon that all registries
whose domain resolve to an IP address is part of the subnet described by the
CIDR syntax, should be considered insecure.

The flag can be used multiple times to allow multiple registries to be marked
as insecure.
If an insecure registry is not marked as insecure, docker pull,
docker push, and docker search will result in an error message prompting
the user to either secure or pass the --insecure-registry flag to the Docker
daemon as described above.
Local registries, whose IP address falls in the 127.0.0.0/8 range, are
automatically marked as insecure as of Docker 1.3.2. It is not recommended to
rely on this, as it may change in the future.
Enabling --insecure-registry, i.e., allowing un-encrypted and/or untrusted
communication, can be useful when running a local registry.  However,
because its use creates security vulnerabilities it should ONLY be enabled for
testing purposes.  For increased security, users should add their CA to their
systemâs list of trusted CAs instead of enabling --insecure-registry.
Legacy Registries
Starting with Docker 17.12, operations against registries supporting only the
legacy v1 protocol are no longer supported. Specifically, the daemon will not
attempt push, pull and login to v1 registries. The exception to this is
search which can still be performed on v1 registries.
The disable-legacy-registry configuration option has been removed and, when
used, will produce an error on daemon startup.
Running a Docker daemon behind an HTTPS_PROXY
When running inside a LAN that uses an HTTPS proxy, the Docker Hub
certificates will be replaced by the proxyâs certificates. These certificates
need to be added to your Docker hostâs configuration:

Install the ca-certificates package for your distribution
Ask your network admin for the proxyâs CA certificate and append them to
/etc/pki/tls/certs/ca-bundle.crt
Then start your Docker daemon with HTTPS_PROXY=http://username:password@proxy:port/ dockerd.
The username: and password@ are optional - and are only needed if your
proxy is set up to require authentication.

This will only add the proxy and authentication to the Docker daemonâs requests -
your docker builds and running containers will need extra configuration to
use the proxy
Default ulimit settings
--default-ulimit allows you to set the default ulimit options to use for
all containers. It takes the same options as --ulimit for docker run. If
these defaults are not set, ulimit settings will be inherited, if not set on
docker run, from the Docker daemon. Any --ulimit options passed to
docker run will overwrite these defaults.
Be careful setting nproc with the ulimit flag as nproc is designed by Linux to
set the maximum number of processes available to a user, not to a container. For details
please check the run reference.
Node discovery
The --cluster-advertise option specifies the host:port or interface:port
combination that this particular daemon instance should use when advertising
itself to the cluster. The daemon is reached by remote hosts through this value.
If you  specify an interface, make sure it includes the IP address of the actual
Docker host. For Engine installation created through docker-machine, the
interface is typically eth1.
The daemon uses libkv to advertise
the node within the cluster. Some key-value backends support mutual
TLS. To configure the client TLS settings used by the daemon can be configured
using the --cluster-store-opt flag, specifying the paths to PEM encoded
files. For example:
$ sudo dockerd \
    --cluster-advertise 192.168.1.2:2376 \
    --cluster-store etcd://192.168.1.2:2379 \
    --cluster-store-opt kv.cacertfile=/path/to/ca.pem \
    --cluster-store-opt kv.certfile=/path/to/cert.pem \
    --cluster-store-opt kv.keyfile=/path/to/key.pem

The currently supported cluster store options are:



Option
Description




discovery.heartbeat
Specifies the heartbeat timer in seconds which is used by the daemon as a keepalive mechanism to make sure discovery module treats the node as alive in the cluster. If not configured, the default value is 20 seconds.


discovery.ttl
Specifies the TTL (time-to-live) in seconds which is used by the discovery module to timeout a node if a valid heartbeat is not received within the configured ttl value. If not configured, the default value is 60 seconds.


kv.cacertfile
Specifies the path to a local file with PEM encoded CA certificates to trust.


kv.certfile
Specifies the path to a local file with a PEM encoded certificate. This certificate is used as the client cert for communication with the Key/Value store.


kv.keyfile
Specifies the path to a local file with a PEM encoded private key. This private key is used as the client key for communication with the Key/Value store.


kv.path
Specifies the path in the Key/Value store. If not configured, the default value is âdocker/nodesâ.



Access authorization
Dockerâs access authorization can be extended by authorization plugins that your
organization can purchase or build themselves. You can install one or more
authorization plugins when you start the Docker daemon using the
--authorization-plugin=PLUGIN_ID option.
$ sudo dockerd --authorization-plugin=plugin1 --authorization-plugin=plugin2,...

The PLUGIN_ID value is either the pluginâs name or a path to its specification
file. The pluginâs implementation determines whether you can specify a name or
path. Consult with your Docker administrator to get information about the
plugins available to you.
Once a plugin is installed, requests made to the daemon through the
command line or Dockerâs Engine API are allowed or denied by the plugin.
If you have multiple plugins installed, each plugin, in order, must
allow the request for it to complete.
For information about how to create an authorization plugin, see authorization
plugin section in the Docker extend section of this documentation.
Daemon user namespace options
The Linux kernel
user namespace support
provides additional security by enabling a process, and therefore a container,
to have a unique range of user and group IDs which are outside the traditional
user and group range utilized by the host system. Potentially the most important
security improvement is that, by default, container processes running as the
root user will have expected administrative privilege (with some restrictions)
inside the container but will effectively be mapped to an unprivileged uid on
the host.
For details about how to use this feature, as well as limitations, see
Isolate containers with a user namespace.
Miscellaneous options
IP masquerading uses address translation to allow containers without a public
IP to talk to other machines on the Internet. This may interfere with some
network topologies and can be disabled with --ip-masq=false.
Docker supports softlinks for the Docker data directory (/var/lib/docker) and
for /var/lib/docker/tmp. The DOCKER_TMPDIR and the data directory can be
set like this:
DOCKER_TMPDIR=/mnt/disk2/tmp /usr/local/bin/dockerd -D -g /var/lib/docker -H unix:// > /var/lib/docker-machine/docker.log 2>&1
# or
export DOCKER_TMPDIR=/mnt/disk2/tmp
/usr/local/bin/dockerd -D -g /var/lib/docker -H unix:// > /var/lib/docker-machine/docker.log 2>&1

Default cgroup parent
The --cgroup-parent option allows you to set the default cgroup parent
to use for containers. If this option is not set, it defaults to /docker for
fs cgroup driver and system.slice for systemd cgroup driver.
If the cgroup has a leading forward slash (/), the cgroup is created
under the root cgroup, otherwise the cgroup is created under the daemon
cgroup.
Assuming the daemon is running in cgroup daemoncgroup,
--cgroup-parent=/foobar creates a cgroup in
/sys/fs/cgroup/memory/foobar, whereas using --cgroup-parent=foobar
creates the cgroup in /sys/fs/cgroup/memory/daemoncgroup/foobar
The systemd cgroup driver has different rules for --cgroup-parent. Systemd
represents hierarchy by slice and the name of the slice encodes the location in
the tree. So --cgroup-parent for systemd cgroups should be a slice name. A
name can consist of a dash-separated series of names, which describes the path
to the slice from the root slice. For example, --cgroup-parent=user-a-b.slice
means the memory cgroup for the container is created in
/sys/fs/cgroup/memory/user.slice/user-a.slice/user-a-b.slice/docker-<id>.scope.
This setting can also be set per container, using the --cgroup-parent
option on docker create and docker run, and takes precedence over
the --cgroup-parent option on the daemon.
Daemon metrics
The --metrics-addr option takes a tcp address to serve the metrics API.
This feature is still experimental, therefore, the daemon must be running in experimental
mode for this feature to work.
To serve the metrics API on localhost:9323 you would specify --metrics-addr 127.0.0.1:9323,
allowing you to make requests on the API at 127.0.0.1:9323/metrics to receive metrics in the
prometheus format.
Port 9323 is the default port associated with Docker
metrics
to avoid collisions with other prometheus exporters and services.
If you are running a prometheus server you can add this address to your scrape configs
to have prometheus collect metrics on Docker.  For more information
on prometheus refer to the prometheus website.
scrape_configs:
  - job_name: 'docker'
    static_configs:
      - targets: ['127.0.0.1:9323']

Please note that this feature is still marked as experimental as metrics and metric
names could change while this feature is still in experimental.  Please provide
feedback on what you would like to see collected in the API.
Node Generic Resources
The --node-generic-resources option takes a list of key-value
pair (key=value) that allows you to advertise user defined resources
in a swarm cluster.
The current expected use case is to advertise NVIDIA GPUs so that services
requesting NVIDIA-GPU=[0-16] can land on a node that has enough GPUs for
the task to run.
Example of usage:
{
  ""node-generic-resources"": [""NVIDIA-GPU=UUID1"", ""NVIDIA-GPU=UUID2""]
}

Daemon configuration file
The --config-file option allows you to set any configuration option
for the daemon in a JSON format. This file uses the same flag names as keys,
except for flags that allow several entries, where it uses the plural
of the flag name, e.g., labels for the label flag.
The options set in the configuration file must not conflict with options set
via flags. The docker daemon fails to start if an option is duplicated between
the file and the flags, regardless their value. We do this to avoid
silently ignore changes introduced in configuration reloads.
For example, the daemon fails to start if you set daemon labels
in the configuration file and also set daemon labels via the --label flag.
Options that are not present in the file are ignored when the daemon starts.
On Linux
The default location of the configuration file on Linux is
/etc/docker/daemon.json. The --config-file flag can be used to specify a
 non-default location.
This is a full example of the allowed configuration options on Linux:
{
  ""authorization-plugins"": [],
  ""data-root"": """",
  ""dns"": [],
  ""dns-opts"": [],
  ""dns-search"": [],
  ""exec-opts"": [],
  ""exec-root"": """",
  ""experimental"": false,
  ""features"": {},
  ""storage-driver"": """",
  ""storage-opts"": [],
  ""labels"": [],
  ""live-restore"": true,
  ""log-driver"": ""json-file"",
  ""log-opts"": {
    ""max-size"": ""10m"",
    ""max-file"":""5"",
    ""labels"": ""somelabel"",
    ""env"": ""os,customer""
  },
  ""mtu"": 0,
  ""pidfile"": """",
  ""cluster-store"": """",
  ""cluster-store-opts"": {},
  ""cluster-advertise"": """",
  ""max-concurrent-downloads"": 3,
  ""max-concurrent-uploads"": 5,
  ""default-shm-size"": ""64M"",
  ""shutdown-timeout"": 15,
  ""debug"": true,
  ""hosts"": [],
  ""log-level"": """",
  ""tls"": true,
  ""tlsverify"": true,
  ""tlscacert"": """",
  ""tlscert"": """",
  ""tlskey"": """",
  ""swarm-default-advertise-addr"": """",
  ""api-cors-header"": """",
  ""selinux-enabled"": false,
  ""userns-remap"": """",
  ""group"": """",
  ""cgroup-parent"": """",
  ""default-ulimits"": {
    ""nofile"": {
      ""Name"": ""nofile"",
      ""Hard"": 64000,
      ""Soft"": 64000
    }
  },
  ""init"": false,
  ""init-path"": ""/usr/libexec/docker-init"",
  ""ipv6"": false,
  ""iptables"": false,
  ""ip-forward"": false,
  ""ip-masq"": false,
  ""userland-proxy"": false,
  ""userland-proxy-path"": ""/usr/libexec/docker-proxy"",
  ""ip"": ""0.0.0.0"",
  ""bridge"": """",
  ""bip"": """",
  ""fixed-cidr"": """",
  ""fixed-cidr-v6"": """",
  ""default-gateway"": """",
  ""default-gateway-v6"": """",
  ""icc"": false,
  ""raw-logs"": false,
  ""allow-nondistributable-artifacts"": [],
  ""registry-mirrors"": [],
  ""seccomp-profile"": """",
  ""insecure-registries"": [],
  ""no-new-privileges"": false,
  ""default-runtime"": ""runc"",
  ""oom-score-adjust"": -500,
  ""node-generic-resources"": [""NVIDIA-GPU=UUID1"", ""NVIDIA-GPU=UUID2""],
  ""runtimes"": {
    ""cc-runtime"": {
      ""path"": ""/usr/bin/cc-runtime""
    },
    ""custom"": {
      ""path"": ""/usr/local/bin/my-runc-replacement"",
      ""runtimeArgs"": [
        ""--debug""
      ]
    }
  },
  ""default-address-pools"":[
    {""base"":""172.80.0.0/16"",""size"":24},
    {""base"":""172.90.0.0/16"",""size"":24}
  ]
}


Note:
You cannot set options in daemon.json that have already been set on
daemon startup as a flag.
On systems that use systemd to start the Docker daemon, -H is already set, so
you cannot use the hosts key in daemon.json to add listening addresses.
See https://docs.docker.com/engine/admin/systemd/#custom-docker-daemon-options for how
to accomplish this task with a systemd drop-in file.

On Windows
The default location of the configuration file on Windows is
 %programdata%\docker\config\daemon.json. The --config-file flag can be
 used to specify a non-default location.
This is a full example of the allowed configuration options on Windows:
{
  ""authorization-plugins"": [],
  ""data-root"": """",
  ""dns"": [],
  ""dns-opts"": [],
  ""dns-search"": [],
  ""exec-opts"": [],
  ""experimental"": false,
  ""features"":{},
  ""storage-driver"": """",
  ""storage-opts"": [],
  ""labels"": [],
  ""log-driver"": """",
  ""mtu"": 0,
  ""pidfile"": """",
  ""cluster-store"": """",
  ""cluster-advertise"": """",
  ""max-concurrent-downloads"": 3,
  ""max-concurrent-uploads"": 5,
  ""shutdown-timeout"": 15,
  ""debug"": true,
  ""hosts"": [],
  ""log-level"": """",
  ""tlsverify"": true,
  ""tlscacert"": """",
  ""tlscert"": """",
  ""tlskey"": """",
  ""swarm-default-advertise-addr"": """",
  ""group"": """",
  ""default-ulimits"": {},
  ""bridge"": """",
  ""fixed-cidr"": """",
  ""raw-logs"": false,
  ""allow-nondistributable-artifacts"": [],
  ""registry-mirrors"": [],
  ""insecure-registries"": []
}

Feature options
The optional field features in daemon.json allows users to enable or disable specific
daemon features. For example, {""features"":{""buildkit"": true}} enables buildkit as the
default docker image builder.
The list of currently supported feature options:

buildkit: It enables buildkit as default builder when set to true or disables it by
false. Note that if this option is not explicitly set in the daemon config file, then it
is up to the cli to determine which builder to invoke.

Configuration reload behavior
Some options can be reconfigured when the daemon is running without requiring
to restart the process. We use the SIGHUP signal in Linux to reload, and a global event
in Windows with the key Global\docker-daemon-config-$PID. The options can
be modified in the configuration file but still will check for conflicts with
the provided flags. The daemon fails to reconfigure itself
if there are conflicts, but it wonât stop execution.
The list of currently supported options that can be reconfigured is this:

debug: it changes the daemon to debug mode when set to true.
cluster-store: it reloads the discovery store with the new address.
cluster-store-opts: it uses the new options to reload the discovery store.
cluster-advertise: it modifies the address advertised after reloading.
labels: it replaces the daemon labels with a new set of labels.
live-restore: Enables keeping containers alive during daemon downtime.
max-concurrent-downloads: it updates the max concurrent downloads for each pull.
max-concurrent-uploads: it updates the max concurrent uploads for each push.
default-runtime: it updates the runtime to be used if not is
specified at container creation. It defaults to âdefaultâ which is
the runtime shipped with the official docker packages.
runtimes: it updates the list of available OCI runtimes that can
be used to run containers.
authorization-plugin: it specifies the authorization plugins to use.
allow-nondistributable-artifacts: Replaces the set of registries to which the daemon will push nondistributable artifacts with a new set of registries.
insecure-registries: it replaces the daemon insecure registries with a new set of insecure registries. If some existing insecure registries in daemonâs configuration are not in newly reloaded insecure resgitries, these existing ones will be removed from daemonâs config.
registry-mirrors: it replaces the daemon registry mirrors with a new set of registry mirrors. If some existing registry mirrors in daemonâs configuration are not in newly reloaded registry mirrors, these existing ones will be removed from daemonâs config.
shutdown-timeout: it replaces the daemonâs existing configuration timeout with a new timeout for shutting down all containers.
features: it explicitly enables or disables specific features.

Updating and reloading the cluster configurations such as --cluster-store,
--cluster-advertise and --cluster-store-opts will take effect only if
these configurations were not previously configured. If --cluster-store
has been provided in flags and cluster-advertise not, cluster-advertise
can be added in the configuration file without accompanied by --cluster-store.
Configuration reload will log a warning message if it detects a change in
previously configured cluster configurations.
Run multiple daemons

Note: Running multiple daemons on a single host is considered as âexperimentalâ. The user should be aware of
unsolved problems. This solution may not work properly in some cases. Solutions are currently under development
and will be delivered in the near future.

This section describes how to run multiple Docker daemons on a single host. To
run multiple daemons, you must configure each daemon so that it does not
conflict with other daemons on the same host. You can set these options either
by providing them as flags, or by using a daemon configuration file.
The following daemon options must be configured for each daemon:
-b, --bridge=                          Attach containers to a network bridge
--exec-root=/var/run/docker            Root of the Docker execdriver
--data-root=/var/lib/docker            Root of persisted Docker data
-p, --pidfile=/var/run/docker.pid      Path to use for daemon PID file
-H, --host=[]                          Daemon socket(s) to connect to
--iptables=true                        Enable addition of iptables rules
--config-file=/etc/docker/daemon.json  Daemon configuration file
--tlscacert=""~/.docker/ca.pem""         Trust certs signed only by this CA
--tlscert=""~/.docker/cert.pem""         Path to TLS certificate file
--tlskey=""~/.docker/key.pem""           Path to TLS key file

When your daemons use different values for these flags, you can run them on the same host without any problems.
It is very important to properly understand the meaning of those options and to use them correctly.

The -b, --bridge= flag is set to docker0 as default bridge network. It is created automatically when you install Docker.
If you are not using the default, you must create and configure the bridge manually or just set it to ânoneâ: --bridge=none
--exec-root is the path where the container state is stored. The default value is /var/run/docker. Specify the path for
your running daemon here.
--data-root is the path where persisted data such as images, volumes, and
cluster state are stored. The default value is /var/lib/docker. To avoid any
conflict with other daemons, set this parameter separately for each daemon.
-p, --pidfile=/var/run/docker.pid is the path where the process ID of the daemon is stored. Specify the path for your
pid file here.
--host=[] specifies where the Docker daemon will listen for client connections. If unspecified, it defaults to /var/run/docker.sock.
--iptables=false prevents the Docker daemon from adding iptables rules. If
multiple daemons manage iptables rules, they may overwrite rules set by another
daemon. Be aware that disabling this option requires you to manually add
iptables rules to expose container ports. If you prevent Docker from adding
iptables rules, Docker will also not add IP masquerading rules, even if you set
--ip-masq to true. Without IP masquerading rules, Docker containers will not be
able to connect to external hosts or the internet when using network other than
default bridge.
--config-file=/etc/docker/daemon.json is the path where configuration file is stored. You can use it instead of
daemon flags. Specify the path for each daemon.
--tls* Docker daemon supports --tlsverify mode that enforces encrypted and authenticated remote connections.
The --tls* options enable use of specific certificates for individual daemons.

Example script for a separate âbootstrapâ instance of the Docker daemon without network:
$ sudo dockerd \
        -H unix:///var/run/docker-bootstrap.sock \
        -p /var/run/docker-bootstrap.pid \
        --iptables=false \
        --ip-masq=false \
        --bridge=none \
        --data-root=/var/lib/docker-bootstrap \
        --exec-root=/var/run/docker-bootstrap


container, daemon, runtime






















 Edit this
                                                page
 Request
                                                docs changes



















On this page:

Description

Environment variables


Examples

Daemon socket option
Daemon storage-driver
Options per storage driver
Docker runtime execution options
Daemon DNS options
Allow push of nondistributable artifacts
Insecure registries
Running a Docker daemon behind an HTTPS_PROXY
Default ulimit settings
Node discovery
Access authorization
Daemon user namespace options
Miscellaneous options
Daemon configuration file
Run multiple daemons
















Why Docker?
What is a Container?




Products
Docker Desktop
Docker Hub
Features
Container Runtime
Developer Tools
Kubernetes




Developers
Use Cases
Play with Docker
Community
Open Source
Docker Captains




Company
About Us
Blog
Customers
Partners
Newsroom
Careers
Contact Us






Status
Security
Legal
Contact







                    Copyright © 2013-2020 Docker Inc. All rights reserved. 



Twitter
Youtube
GitHub
Linkedin
Facebook
Slideshare
Reddit


















",,"# dockerd

> A persistent process to start and manage docker containers.
> More information: <https://docs.docker.com/engine/reference/commandline/dockerd/>.

- Run docker daemon:

`dockerd`

- Run docker daemon and config it to listen to specific sockets(unix,tcp):

`dockerd --host unix://{{path/to/tmp.sock}} --host tcp://{{ip}}`

- Run with specific daemon PID file:

`dockerd --pidfile {{path/to/pid_file}}`

- Run in debug mode:

`dockerd --debug`

- Run and set a specific log level:

`dockerd --log-level={{debug|info|warn|error|fatal}}`
"
mkfs.cramfs,,,,"# mkfs.cramfs

> Creates a ROM filesystem inside a partition.

- Create a ROM filesystem inside partition 1 on device b (`sdb1`):

`mkfs.cramfs {{/dev/sdb1}}`

- Create a ROM filesystem with a volume-name:

`mkfs.cramfs -n {{volume_name}} {{/dev/sdb1}}`
"
smbclient,,,,"# smbclient

> FTP-like client to access SMB/CIFS resources on servers.

- Connect to a share (user will be prompted for password; `exit` to quit the session):

`smbclient {{//server/share}}`

- Connect with a different username:

`smbclient {{//server/share}} --user {{username}}`

- Connect with a different workgroup:

`smbclient {{//server/share}} --workgroup {{domain}} --user {{username}}`

- Connect with a username and password:

`smbclient {{//server/share}} --user {{username%password}}`

- Download a file from the server:

`smbclient {{//server/share}} --directory {{path/to/directory}} --command ""get {{file.txt}}""`

- Upload a file to the server:

`smbclient {{//server/share}} --directory {{path/to/directory}} --command ""put {{file.txt}}""`
"
cryptsetup,,,,"# cryptsetup

> Manage plain dm-crypt and LUKS (Linux Unified Key Setup) encrypted volumes.

- Initialize a LUKS volume (overwrites all data on the partition):

`cryptsetup luksFormat {{/dev/sda1}}`

- Open a LUKS volume and create a decrypted mapping at /dev/mapper/{{target}}:

`cryptsetup luksOpen {{/dev/sda1}} {{target}}`

- Remove an existing mapping:

`cryptsetup luksClose {{target}}`

- Change the LUKS volume's passphrase:

`cryptsetup luksChangeKey {{/dev/sda1}}`
"
userdel,,,,"# userdel

> Remove a user.

- Remove a user and their home directory:

`userdel -r {{name}}`
"
logcat,https://developer.android.com/studio/command-line/logcat,"





















Logcat command-line tool  |  Android Developers




































  Platform




  Android Studio




  Google Play




  Jetpack




  Kotlin




  Docs




  News





















Language

        English
      

        Bahasa Indonesia
      

        Deutsch
      

        Español
      

        Español – América Latina
      

        Français
      

        Português – Brasil
      

        Tiếng Việt
      

        Türkçe
      

        Русский
      

        ภาษาไทย
      

        中文 – 简体
      

        中文 – 繁體
      

        日本語
      

        한국어
      














    
        Android Studio
      
  









  Download




  What's new




  User guide




  Preview
































      Platform
   





      Android Studio
   





      Download
   





      What's new
   







      User guide
   







      Preview
   









      Google Play
   





      Jetpack
   





      Kotlin
   





      Docs
   





      News
   







Meet Android StudioOverviewInstall Android StudioMigrate to Android StudioConfigure the IDEKeyboard shortcutsAccessibility featuresUpdate the IDE and tools
Workflow basics

Manage your projectOverviewCreate a projectAbout Play Feature Delivery
Add C and C++ codeOverviewInstall NDK and CMakeConfigure the NDK for AGPConfigure CMakeLink GradleCreate an Android librarySet up continuous integration

Write your appOverviewAdd code from a templateFind sample codeAdd a module for a new deviceCreate a Java class or typeUse Java 8 language featuresJava 8 language support tableAdd app resourcesBuild a UI with Layout EditorBuild animation with Motion EditorManage your app's UI resourcesDesign app themesAdd multi-density vector graphicsCreate icons with Image Asset StudioCreate resizable bitmaps (9-Patch)Create WebP imagesLocalize the UIAdd Android app linksConnect to FirebaseImprove your code with lint checksImprove code inspection with annotationsTools attributes reference

Build and run your appOverview
Run apps on the emulatorOverviewCreate and manage virtual devicesStart the emulator from the command lineSend emulator console commandsSet up emulator networkingConfigure hardware accelerationEmulator feature comparisonTroubleshoot emulator
Run apps on a hardware deviceOverviewInstall OEM USB driversGet the Google USB driverCreate run/debug configurationsBuild your app from the command line

Configure your buildOverviewSet the application IDAdd build dependenciesUsing native dependenciesOptimize your build speedTroubleshoot build performanceUse the build cacheConfigure build variantsBuild multiple APKsMerge multiple manifestsInject build variables into the manifestShrink your appEnable multidexInspect artifacts with APK AnalyzerUse the Maven Publish pluginGradle tips and recipes

Debug your appOverviewConfigure developer optionsWrite and view logsAnalyze a stack traceDebug your layout with Layout InspectorView on-device filesDebug pre-built APKsTake a screenshotRecord a videoCapture and read bug reports

Test your appOverviewTest from the command lineCreate UI tests with Espresso Test RecorderUI/App Exerciser Monkey
monkeyrunner referenceOverviewMonkeyDeviceMonkeyImageMonkeyRunner

Profile your appOverviewMeasure app performance
Benchmark your appOverviewBuild benchmarks without GradleRun benchmarks in Continuous IntegrationProfile pre-built APKs
Inspect CPU activityOverviewGenerate trace logs by instrumenting your appView the heap and memory allocationsInspect network activityInspect energy use

Publish your appOverviewPrepare for releaseVersion your appSign your appUpload your app

Command line toolsOverviewaapt2adbapkanalyzerapksigneravdmanagerbmgrbundletoold8dmtracedumpdumpsysetc1tooljobbjetifier-standalonelogcatmksdcardsdkmanagersystraceperfettozipalignEnvironment variables
Troubleshoot
Known issues
Report a bug














 Google is committed to advancing racial equity for Black communities. See how.







    
        Android Developers
      
  




    
        Android Studio
      
  




    
        User guide
      
  





Logcat command-line tool



Logcat is a command-line tool that dumps a log of system messages, including stack traces when the
device throws an error and messages that you have written from your app with the
Log class.
This page is about the command-line logcat tool, but you can also view log
messages from the Logcat window in Android Studio. For
information about viewing and filtering logs from Android Studio,
see Write and View Logs with
Logcat.
Logging system overview

    The Android logging system is a set of structured circular buffers maintained by the system
    process logd. The set of available buffers is fixed and defined by the
    system. The most relevant ones are: main, which stores most application logs,
    system, which stores messages originating from the Android OS, and
    crash, which stores crash logs. Each log entry has a priority
    (one of VERBOSE, DEBUG, INFO, WARNING,
    ERROR or FATAL), a tag that identifies the origin of the log,
    and the actual log message.
  

    The primary interface to the logging system is the shared library liblog
    and its header <android/log.h>.
    All language-specific logging facilities eventually call the function
    __android_log_write. By default, it calls the function
    __android_log_logd_logger, which sends the log entry to logd
    using a socket. Starting with API level 30, the logging function can be changed by calling
    __android_set_log_writer. More information is available in the
    NDK documentation.
  

    Logs displayed by adb logcat undergo four levels of filtering:
  

Compile-time filtering: depending on compilation settings, some logs may be completely
      removed from the binary. For example, Proguard can be configured to remove calls to
      Log.d from Java code.
System property filtering: liblog queries a set of system properties to
      determine the minimum severity level to be sent to logd. If your logs have
      the tag MyApp, the following properties are checked, and are expected to contain
      the first letter of the minimum severity (V, D, I,
      W, E, or S to disable all logs):

log.tag.MyApp
persist.log.tag.MyApp
log.tag
persist.log.tag

Application filtering: If none of the properties are set, liblog uses
      the minimum priority set by __android_log_set_minimum_priority.
      The default setting is INFO.
Display filtering: adb logcat supports additional filters that can reduce
      the amount of logs shown from logd.
      See below for details.
Command-line syntax

    To run logcat through the adb shell, the general usage is:
  

[adb] logcat [<option>] ... [<filter-spec>] ...

You can run logcat as an adb command or directly in a shell prompt
  of your emulator or connected device. To view log output using adb, navigate to your SDK
  platform-tools/ directory and execute:

adb logcat


For logcat online help, start a device and then execute:


adb logcat --help

You can create a shell connection to a device and execute:

$ adb shell
# logcat

Options
The following table describes the command line options of logcat.


Option
Description


-b <buffer>
Load an alternate log buffer for viewing, such as events or
        radio. The main, system, and crash buffer
        set is used by default. See Viewing Alternative Log Buffers.


-c, --clear
Clear (flush) the selected buffers and exit. The default buffer set is main,
        system and crash. To clear all of the buffers, use
        -b all -c.
      


-e <expr>, --regex=<expr>
Only print lines where the log message matches <expr>
          where <expr> is a regular expression.


-m <count>, --max-count=<count>
Quit after printing <count> number of lines. This is meant to be
        paired with --regex, but will work on its own.


--print
Paired with --regex and --max-count
        to let content bypass the regex filter, but still stop at the
        right number of matches.


-d
Dump the log to the screen and exits.


-f <filename>
Write log message output to <filename>. The default is
      stdout.


-g, --buffer-size
Print the size of the specified log buffer and exits.


-n <count>
Set the maximum number of rotated logs to <count>. The default value
      is 4. Requires the -r option.


-r <kbytes>
Rotate the log file every <kbytes> of output. The default value is
      16. Requires the -f option.


-s
Equivalent to the filter expression '*:S', which sets priority for all tags
      to silent, and is used to precede a list of filter expressions that add content. To learn more,
      go to the section about filtering log output.
      


-v <format>
Set the output format for log messages. The default is threadtime format. For a
      list of supported formats, go to the section about the Control log
      output format.
      


-D, --dividers
Print dividers between each log buffer.


-c
Flush (clear) the entire log and exit.


-t <count> 
Print only the most recent number of lines. This option includes -d
        functionality.


-t '<time>' 
Print the most recent lines since the specified time. This option includes
        -d functionality. See the -P option for
        information about quoting parameters with embedded spaces.

        adb logcat -t '01-26 20:52:41.820'



-T <count> 
Print the most recent number of lines since the specified time. This option does not
        include -d functionality 


-T '<time>' 
Print the most recent lines since the specified time. This option does not include
        include -d functionality. See the -P option for
      information about quoting parameters with embedded spaces.

        adb logcat -t '01-26 20:52:41.820'



-L, -last
Dump the logs prior to the last reboot.


-B, --binary
Output the log in binary.


-S, --statistics
Include statistics in the output to help you identify and target log spammers.


-G <size> 
Set the size of the log ring buffer. Can add
        K or M at the end to indicate
        kilobytes or megabytes.


-p, --prune

         Print (read) the current allow (white) and deny (black) lists and
         takes no arguments, as follows:


adb logcat -p





-P '<list> ...'
          --prune '<list> ...'
          -P '<white_and_black_list>'


        Write (set) the allow (white) and deny (black) lists to adjust the
        logging content for a specific purpose. You provide a mixed content of allowed
        (<white>) and denied (~<black>) list entries, where
        <white> or <black> can be a UID, UID/PID or /PID. With
        guidance from the logcat statistics (logcat -S), one can consider adjustments
        to the allow (white) and deny (black) lists for purposes such as:

Give the highest longevity to specific logging content through UID selections.
Prevent someone (UID) or something (PID) from consuming these resources to help increase the
    logspan so you can have more visibility into the problems you are diagnosing.


  By default the logging system automatically prevents the worst offender in the log statistics
  dynamically to make space for new log messages. Once it has exhausted the heuristics, the system
  prunes the oldest entries to make space for the new messages.


    Adding an allowlist (whitelist) protects your Android Identification number (AID),
    which becomes the processes' AID and GID from being declared an offender, and adding a denylist
    helps free up space before the worst offenders are considered. You can choose how active the
    pruning is, and you can turn pruning off so it only removes content from the oldest entries in
    each log buffer.
  
Quotes

adb logcat does not preserve the quotes, so the syntax for specifying allow
  (white) and deny (black) lists is as follows:


$ adb logcat -P '""<white_and_blacklist>""'

or

adb shell
$ logcat -P '<white_and_blacklist>'


  The following example specifies an allow (white) list with PID 32676 and UID 675, and
  a deny (black) list with PID 32677 and UID 897. PID 32677 on the denylist is
  weighted for faster pruning.


adb logcat -P '""/32676 675 ~/32677 897""'


  Other allow (white) and deny (black) list command variations you can use
  are as follows:
  

~! worst uid blacklist
~1000/! worst pid in system (1000)




--pid=<pid> ...
Only print logs from the given PID.


--wrap
Sleep for 2 hours or when the buffer is about to wrap whichever
          comes first. Improves efficiency of polling by providing
          an about-to-wrap wakeup.


Filtering log output

The tag of a log message is a short string indicating the system component from which the
    message originates (for example, ""View"" for the view system).
The priority is one of the following character values, ordered from lowest to highest
    priority:


V: Verbose (lowest priority)
D: Debug
I: Info
W: Warning
E: Error
F: Fatal
S: Silent (highest priority, on which nothing is ever printed)



You can obtain a list of tags used in the system, with priorities, by running
  logcat and observing the first two columns of each message, given as
  <priority>/<tag>.

    The following is an example of brief logcat output obtained with the
    logcat -v brief output command. It shows that the message relates to priority
    level ""I"" and tag ""ActivityManager"":
  

I/ActivityManager(  585): Starting activity: Intent { action=android.intent.action...}

To reduce the log output to a manageable level, you can restrict log output using filter
  expressions. Filter expressions let you indicate to the system the tags-priority
  combinations that you are interested in — the system suppresses other messages for the
  specified tags.
A filter expression follows this format tag:priority ..., where tag
  indicates the tag of interest and priority indicates the minimum level of
  priority to report for that tag. Messages for that tag at or above the specified priority are
  written to the log. You can supply any number of tag:priority specifications in a
  single filter expression. The series of specifications is whitespace-delimited.
Here's an example of a filter expression that suppresses all log messages except those with
  the tag ""ActivityManager"", at priority ""Info"" or above, and all log messages with tag ""MyApp"",
  with priority ""Debug"" or above:

adb logcat ActivityManager:I MyApp:D *:S

The final element in the above expression, *:S, sets the priority level for all
  tags to ""silent"", thus ensuring only log messages with ""ActivityManager"" and ""MyApp"" are displayed. Using
  *:S is an excellent way to ensure that log output is restricted to the filters that
  you have explicitly specified — it lets your filters serve as an allowlist for log
  output.
The following filter expression displays all log messages with priority level ""warning"" and higher, on all tags:

adb logcat *:W

If you're running logcat from your development computer (versus running it on a
  remote adb shell), you can also set a default filter expression by exporting a value for the
  environment variable ANDROID_LOG_TAGS:

export ANDROID_LOG_TAGS=""ActivityManager:I MyApp:D *:S""

Note that ANDROID_LOG_TAGS filter is not exported to the emulator/device
  instance, if you are running logcat from a remote shell or using adb shell
  logcat.
Control log output format
Log messages contain a number of metadata fields, in addition to the tag and priority. You can
  modify the output format for messages so that they display a specific metadata field. To do so,
  you use the -v option and specify one of the supported output formats listed
    below.

  
brief: Display priority, tag, and PID of the process issuing the
    message.
long: Display all metadata fields and separate messages with blank
    lines.
process: Display PID only.
raw: Display the raw log message with no other metadata fields.
tag: Display the priority and tag only.
thread: A legacy format that shows priority, PID, and TID of the
      thread issuing the message.
threadtime (default): Display the date, invocation time, priority,
        tag, PID, and TID of the thread issuing the message.
time: Display the date, invocation time, priority, tag, and PID of the
    process issuing the message.

When starting logcat, you can specify the output format you want by using the
  -v option:

[adb] logcat [-v <format>]

Here's an example that shows how to generate messages in thread output
  format:

adb logcat -v thread

Note that you can only specify one output format with the -v option, but you
    can specify as many modifiers that make sense. Logcat ignores modifiers that do not make sense.
Format modifiers

    Format modifiers change the logcat output in terms of any combination of one or more of
    the following modifiers. To specify a format modifier, use the -v option, as
    follows:
  

adb logcat -b all -v color -d

Every Android log message has a tag and a priority associated with it.
  You can combine any format modifier with any one of the following format options: brief,
      long, process, raw, tag,
      thread, threadtime, and time.


  You can get the format modifier details by typing logcat -v --help at the command line.
  

color: Show each priority level with a different color.
descriptive: Show log buffer event descriptions. This modifier affects event
      log buffer messages only, and has no effect on the other non-binary buffers. The event
      descriptions come from the event-log-tags database.
epoch: Display time in seconds starting from Jan 1, 1970.
monotonic: Display time in CPU seconds starting from the last boot.
printable: Ensure that any binary logging content is escaped.
uid: If permitted by access controls, display the UID or Android ID of the
      logged process.
usec: Display the time with precision down to microseconds.
UTC: Display time as UTC.
year:  Add the year to the displayed time.
zone: Add the local time zone to the displayed time.

Viewing alternative log buffers
The Android logging system keeps multiple circular buffers for log messages, and not all of
  the log messages are sent to the default circular buffer. To see additional log messages, you can
  run the logcat command with the -b option, to request viewing of an
  alternate circular buffer. You can view any of these alternate buffers:

radio: View the buffer that contains radio/telephony related
    messages.
events: View the interpreted binary system event buffer messages.
main: View the main log buffer (default) does not contain
      system and crash log messages.
system: View the system log buffer (default).
crash: View the crash log buffer (default).
all: View all buffers.
default: Reports main, system, and
      crash buffers.
  

      The usage of the -b option is:

[adb] logcat [-b <buffer>]


    Here is an example of how to view a log buffer containing radio and telephony messages:
  

adb logcat -b radio


    You can also specify multiple -b flags for all of the buffers you want to print,
    as follows:
  

logcat -b main -b radio -b events


    You can specify a single -b flag with a comma-separated list of buffers,
    for example:
  

logcat -b main,radio,events

Logging from code
The Log class allows you to create log entries in your code that display
  in the logcat tool. Common logging methods include:

Log.v(String, String) (verbose)
Log.d(String, String) (debug)
Log.i(String, String) (information)
Log.w(String, String) (warning)
Log.e(String, String) (error)

For example, using the following call:

Kotlin

Log.i(""MyActivity"", ""MyClass.getView() — get item number $position"")

Java

Log.i(""MyActivity"", ""MyClass.getView() — get item number "" + position);



The logcat outputs something like:

I/MyActivity( 1557): MyClass.getView() — get item number 1







Content and code samples on this page are subject to the licenses described in the Content License. Java is a registered trademark of Oracle and/or its affiliates.
Last updated 2020-08-25 UTC.









        
        Twitter
      
Follow @AndroidDev on Twitter




        
        YouTube
      
Check out Android Developers on YouTube








More Android



          
            Android
          
          



          
            Enterprise
          
          



          
            Security
          
          



          
            Source
          
          




Support



          
            Report platform bug
          
          



          
            Report documentation bug
          
          



          
            Google Play support
          
          



          
            Join research studies
          
          




Documentation



          
            Developer guides
          
          



          
            Design guides
          
          



          
            API reference
          
          



          
            Samples
          
          



          
            Android Studio
          
          















          Android
        



          Chrome
        



          Firebase
        



          Google Cloud Platform
        



          All products
        







          Privacy
        



          License
        



          Brand guidelines
        


Get news and tips by email

          Subscribe
        





Language

        English
      

        Bahasa Indonesia
      

        Deutsch
      

        Español
      

        Español – América Latina
      

        Français
      

        Português – Brasil
      

        Tiếng Việt
      

        Türkçe
      

        Русский
      

        ภาษาไทย
      

        中文 – 简体
      

        中文 – 繁體
      

        日本語
      

        한국어
      



















",,"# logcat

> Dump a log of system messages.
> Native Android CLI tool.
> More information: <https://developer.android.com/studio/command-line/logcat>.

- Display system logs:

`logcat`

- Write system logs to a file:

`logcat -f {{path/to/file}}`

- Display lines that match a regex:

`logcat --regex {{regex}}`
"
resize2fs,,,,"# resize2fs

> Resize an ext2, ext3 or ext4 filesystem.
> Does not resize the underlying partition, and the filesystem must be unmounted.

- Automatically resize a filesystem:

`resize2fs {{/dev/sdXN}}`

- Resize the filesystem to a size of 40G, displaying a progress bar:

`resize2fs -p {{/dev/sdXN}} {{40G}}`

- Shrink the filesystem to its minimum possible size:

`resize2fs -M {{/dev/sdXN}}`
"
service,,,,"# service

> Manage services by running init scripts.
> The full script path should be omitted (/etc/init.d/ is assumed).

- Start/Stop/Restart/Reload service (start/stop should always be available):

`service {{init_script}} {{start|stop|restart|reload}}`

- Do a full restart (runs script twice with start and stop):

`service {{init_script}} --full-restart`

- Show the current status of a service:

`service {{init_script}} status`

- List the status of all services:

`service --status-all`
"
ac,,,"
AC(8)			  BSD System Manager's Manual			 AC(8)

NAME
     ac -- display connect-time accounting

SYNOPSIS
     ac [-d] [-p] [-w file] [users ...]

DESCRIPTION
     A record of individual login and logout times are written to the system
     log by login(8) and launchd(8), respectively.  The program ac examines
     these records and writes the accumulated connect time (in decimal hours)
     for all logins to the standard output.

     Options available:

     -d      Display the connect times in 24 hour chunks.

     -p      Display individual user totals.

     -w file
	     Read raw connect time data from file, instead of the system log.

     users ...
	     Display totals for the given individuals only.

     If no arguments are given, ac displays the total amount of login time for
     all active accounts on the system.

SEE ALSO
     login(1), utmpx(5), launchd(8), sa(8)

HISTORY
     An ac command appeared in Version 6 AT&T UNIX.

4th Berkeley Distribution	April 19, 1994	     4th Berkeley Distribution
","# ac

> Print statistics on how long users have been connected.

- Print how long the current user has been connected in hours:

`ac`

- Print how long users have been connected in hours:

`ac --individual-totals`

- Print how long a particular user has been connected in hours:

`ac --individual-totals {{username}}`

- Print how long a particular user has been connected in hours per day (with total):

`ac --daily-totals --individual-totals {{username}}`
"
pacaur,,,,"# pacaur

> A utility for Arch Linux to build and install packages from the Arch User Repository.

- Synchronize and update all packages (includes AUR):

`pacaur -Syu`

- Synchronize and update only AUR packages:

`pacaur -Syua`

- Install a new package (includes AUR):

`pacaur -S {{package_name}}`

- Remove a package and its dependencies (includes AUR packages):

`pacaur -Rs {{package_name}}`

- Search the package database for a keyword (includes AUR):

`pacaur -Ss {{keyword}}`

- List all currently installed packages (includes AUR packages):

`pacaur -Qs`
"
yay,,,,"# yay

> Yet Another Yogurt: A utility for Arch Linux to build and install packages from the Arch User Repository.
> Also see `pacman`.

- Interactively search and install packages from the repos and AUR:

`yay {{package_name|search_term}}`

- Synchronize and update all packages from the repos and AUR:

`yay`

- Synchronize and update only AUR packages:

`yay -Sua`

- Install a new package from the repos and AUR:

`yay -S {{package_name}}`

- Search the package database for a keyword from the repos and AUR:

`yay -Ss {{keyword}}`

- Show statistics for installed packages and system health:

`yay -Ps`
"
pwgen,,,,"# pwgen

> Generate pronounceable passwords.

- Generate random password with s[y]mbols:

`pwgen -y {{length}}`

- Generate secure, hard-to-memorize passwords:

`pwgen -s {{length}}`

- Generate password with at least one capital letter in them:

`pwgen -c {{length}}`
"
newgrp,,,"
NEWGRP(1)		  BSD General Commands Manual		     NEWGRP(1)

NAME
     newgrp -- change to a new group

SYNOPSIS
     newgrp [-l] [group]

DESCRIPTION
     The newgrp utility creates a new shell execution environment with modi-
     fied real and effective group IDs.

     The options are as follows:

     -l      Simulate a full login.  The environment and umask are set to what
	     would be expected if the user actually logged in again.

     If the group operand is present, a new shell is started with the speci-
     fied effective and real group IDs.  The user will be prompted for a pass-
     word if they are not a member of the specified group.

     Otherwise, the real, effective and supplementary group IDs are restored
     to those from the current user's password database entry.

EXIT STATUS
     The newgrp utility attempts to start the shell regardless of whether
     group IDs were successfully changed.

     If an error occurs and the shell cannot be started, newgrp exits >0.
     Otherwise, the exit status of newgrp is the exit status of the shell.

SEE ALSO
     csh(1), groups(1), login(1), sh(1), su(1), umask(1), group(5), passwd(5),
     environ(7)

STANDARDS
     The newgrp utility conforms to IEEE Std 1003.1-2001 (``POSIX.1'').

HISTORY
     A newgrp utility appeared in Version 6 AT&T UNIX.

BUGS
     Group passwords are inherently insecure as there is no way to stop users
     obtaining the crypted passwords from the group database.  Their use is
     discouraged.

BSD				 May 23, 2002				   BSD
","# newgrp

> Switch primary group membership.

- Change user's primary group membership:

`newgrp {{group_name}}`

- Reset primary group membership to user's default group in /etc/passwd:

`newgrp`
"
genie,https://github.com/arkane-systems/genie,"













GitHub - arkane-systems/genie: A quick way into a systemd ""bottle"" for WSL








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















arkane-systems

/

genie








          Sponsor
        






              Sponsor arkane-systems/genie
            












    Watch
 
      17
    




      Star


      493
    




          Fork


        29
      





        A quick way into a systemd ""bottle"" for WSL
      



            View license
        




493
        stars
 

29
        forks
 




      Star





    Watch









Code

 



Issues
5
 



Pull requests
0
 



Actions

 



Wiki

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Wiki
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














2
branches



18
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




cerebrate

Merge branch 'master' of https://github.com/arkane-systems/genie into…



…



97f89c0

Sep 21, 2020





Merge branch 'master' of https://github.com/arkane-systems/genie into…

… master

* 'master' of https://github.com/arkane-systems/genie:
  Update readme.md

97f89c0



Git stats





188
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






.github



Update stale.yml



Jun 21, 2020







arch



Ready to add arch build.



Sep 21, 2020







genie



Merge branch 'master' of https://github.com/arkane-systems/genie into…



Sep 21, 2020







.gitignore



Hack shlibs for buster compat.



Sep 2, 2020







CONTENTS



Added contents file.



Aug 13, 2020







LICENSE



Remade source tree and makefile for debuild.



Aug 12, 2020







Makefile



Ready to add arch build.



Sep 21, 2020







PBUILDER.md



Added description of pbuilder environment.



Aug 19, 2020







README.md



Remade source tree and makefile for debuild.



Aug 12, 2020





        View code
      






        README.md
      


genie

A quick way into a systemd ""bottle"" for WSL
What does that even mean?
Well, this gives you a way to run systemd as pid 1, with all the trimmings, inside WSL 2. It does this by creating a pid namespace, the eponymous poor-man's-container ""bottle"", starting up systemd in there, and entering it, and providing some helpful shortcuts to do so.
If you want to try it, please read this entire document first, especially the BUGS section.
NOTE: WSL 2 ONLY
Note: it is only possible to run systemd (and thus genie ) under WSL 2; WSL 1 does not support the system calls required to do so. If you are running inside a distro configured as WSL 1, even if your system supports WSL 2, genie will fail to operate properly.
INSTALLATION
If there is a package available for your distribution, this is the recommended method of installing genie.
Debian
Dependent packages on Debian are daemonize, dbus, dotnet-runtime-3.1, policykit-1, and systemd . For the most part, these are either already installed or in the distro and able to be installed automatically. You need debhelper and dotnet-sdk-3.1 (and optionally pbuilder) to build the Debian package, but not to simply build genie or install locally.
The chief exception is dotnet-runtime-3.1 , for which you will need to follow the installation instructions here:
https://dotnet.microsoft.com/download/
To install, add the wsl-translinux repository here by issueing the following command, or by following the instructions here (https://packagecloud.io/arkane-systems/wsl-translinux):
curl -s https://packagecloud.io/install/repositories/arkane-systems/wsl-translinux/script.deb.sh | sudo bash
then install genie using the command:
sudo apt install -y systemd-genie
PLEASE NOTE
The wsl-translinux repository is hosted by packagecloud.io, whose free plan allows for 250 MB of downloads per month. Due to the unexpected popularity of genie, we are currently skating right at the edge of this level of usage, and my poor indie developer budget does not stretch to the $75/mo. required for a ""Small"" plan. As such, if it won't download for you, you may need to either download the .deb file from the Releases page and install manually using dpkg -i, or wait for the usage counter to reset on the 12th of the month.
We apologize for the inconvenience. Anyone wishing to be this project's sugar daddy is welcome to apply.
Other Distros
Debian is the ""native"" distribution for genie , for which read, ""what the author uses"". Specifically, Debian stretch+, with usrmerge installed. If you're using anything else, you may need to tweak the configuration file (see below) accordingly.
Other
We're actively looking for maintainers for everything else. If you can use .deb packages (especially if your distro is a Debian derivative), the Debian package may work for you. Otherwise, manually installing from the .tar.gz is probably the best I can suggest.
I am unable to support distributions which there are not prebuilt packages for. I am actively seeking maintainers for these packages.
...OR BUILD IT YOURSELF
It is possible to build your own version of genie and install it locally. To do so, you will require build-essential and dotnet-sdk-3.1 in addition to the other dependencies, all of which must be installed manually.
After cloning the repository, run
sudo make local

This will build genie and install it under /usr/local .
CONFIGURATION FILE
That would be the file /etc/genie.ini. This defines the secure path (i.e., those directories in which genie will look for the utilities it depends on), and also the explicit path to unshare(1), required by daemonize(1). Normally, it looks like this:
[genie]
secure-path=/lib/systemd:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
unshare=/usr/bin/unshare
update-hostname=true

The secure-path setting should be generic enough to cover all but the weirdest Linux filesystem layouts, but on the off-chance that yours stores binaries somewhere particularly idiosyncratic, you can change it here. Meanwhile, the unshare setting is much more likely to be system-dependent; if you are getting errors running genie, please replace this with the output of which unshare before trying anything else.
The update-hostname setting controls whether or not genie updates the WSL hostname when creating the bottle. By default, genie updates a hostname foo to foo-wsl, to prevent hostname clashes between the host Windows machine and the WSL distribution, especially when communicating back and forth between the two. However, as recent Insider builds allow the hostname of the WSL distributions to be set in _.wslconfig, this option has been provided to disable genie's intervention and keep the original hostname.
USAGE
genie:
  Handles transitions to the ""bottle"" namespace for systemd under WSL.

Usage:
  genie [options] [command]

Options:
  -v, --verbose <VERBOSE>    Display verbose progress messages
  --version                  Display version information

Commands:
  -i, --initialize           Initialize the bottle (if necessary) only.
  -s, --shell                Initialize the bottle (if necessary), and run a shell in it.
  -c, --command <COMMAND>    Initialize the bottle (if necessary), and run the specified command in it.
  --shutdown, -u             Shut down systemd and exit the bottle.

So, it has three modes, all of which will set up the bottle and run systemd in it if it isn't already running for simplicity of use.
genie -i will set up the bottle - including changing the WSL hostname by suffixing -wsl, to distinguish it from the Windows host -  run systemd, and then exit. This is intended for use if you want services running all the time in the background, or to preinitialize things so you needn't worry about startup time later on, and for this purpose is ideally run from Task Scheduler on logon.
genie -s runs your login shell inside the bottle; basically, Windows-side, wsl genie -s is your substitute for just wsl to get started, or for the shortcut you get to start a shell in the distro. It follows login semantics, and as such does not preserve the current working directory.
genie -c [command] runs command inside the bottle, then exits. The return code is the return code of the command. It follows sudo semantics, and so does preserve the cwd.
Meanwhile, genie -u , run from outside the bottle, will shut down systemd cleanly and exit the bottle. This uses the systemctl poweroff command to simulate a normal Linux system shutting down. It is suggested that this be used before shutting down Windows or restarting the Linux distribution to ensure a clean shutdown of systemd services.
While not compulsory, it is recommended that you shut down and restart the WSL distro before using genie again after you have used genie -u. See BUGS, below, for more details.
RECOMMENDATIONS
Once you have this up and running, I suggest disabling via systemctl the getty@tty1 service (since logging on and using WSL is done via ptsen, not ttys).
Further tips on usage from other genie users can be found on the wiki for this repo.
BUGS


This breaks pstree and other /proc-walking tools that count on everything being a child of pid 1, because entering the namespace with a shell or other process leaves that process with a ppid of 0. To the best of my knowledge, I can't set the ppid of a process, and if I'm wrong about that, please send edification and pull requests to be gratefully accepted.


It is considerably clunkier than I'd like it to be, inasmuch as you have to invoke genie every time to get inside the bottle, either manually (replacing, for example, wsl [command] with wsl genie -c [command]), or by using your own shortcut in place of the one WSL gives you for the distro, using which will put you outside the bottle. Pull requests, etc.


There is a race condition that means that if you start a genie session too quickly after initializing the bottle (very likely if you use genie -c or genie -s without having running genie -i first, meaning that they will auto-initialize the bottle on first run), you may not get a systemd-logind login session or the functionality supplied by that, such as a systemd user instance. Using genie -i is strongly recommended to avoid this issue. Please see https://github.com/arkane-systems/genie/issues/70 for more details.


genie is not idempotent; i.e., it is possible that changes made by genie or by systemd inside the bottle will not be perftectly reverted when the genie bottle is shut down with genie -u . As such, it is recommended that you terminate the entire wsl session with wsl -t  or wsl --shutdown in between stopping and restarting the bottle, or errors may occur.










About

      A quick way into a systemd ""bottle"" for WSL
    
Resources



      Readme
 
License



        View license
    







    Releases
      18





1.28 - bug fixes and hostname updateless edition

          Latest
 
Sep 5, 2020

 

        + 17 releases





Sponsor this project



 





ko-fi.com/arkanesystems




  Learn more about GitHub Sponsors







    Packages 0


        No packages published 













    Contributors 9





 



 



 



 



 



 



 



 



 





Languages











C#
61.8%





Makefile
19.5%





Roff
17.5%





Shell
1.2%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# genie

> Set up and use a ""bottle"" namespace to run systemd under WSL (Windows Subsystem for Linux).
> To run these from Windows rather than an already-running distribution, precede them with `wsl`.
> More information: <https://github.com/arkane-systems/genie>.

- Initialize the bottle (run once, at start):

`genie -i`

- Run a login shell inside the bottle:

`genie -s`

- Run a specified command inside the bottle:

`genie -c {{command}}`
"
apport-bug,https://wiki.ubuntu.com/Apport,"



Apport - Ubuntu Wiki


























 Partners 
 Support 
 Community 
 Ubuntu.com 


 Ubuntu Wiki 





Search:










Immutable PageInfoAttachments


More Actions:

Raw Text
Print View
Render as Docbook
Delete Cache
------------------------
Check Spelling
Like Pages
Local Site Map
------------------------
Rename Page
Copy Page
Delete Page
------------------------
Subscribe User
------------------------
Remove Spam
Revert to this revision
Package Pages
Sync Pages
------------------------
Load
Save
SlideShow







Ubuntu Wiki
Login
Help







Apport




Available languages:Italiano,  Contents
What is this all about?
What does it look like for users?
Why is apport disabled by default?
How to enable apport
I'm a developer. How do I use these crash reports?
Report format
Fields
Tools
How does it work internally?
Crash interception
Example
Backend
Frontend invocation
Launchpad-based auto-retracer
Per-package Apport Hooks
Use the source, Luke!
Future plans
Further links


What is this all about?
Debugging program crashes without any automated tools has been pretty time consuming and hard for both developers and users. Many program crashes remain unreported or unfixed because: Many crashes are not easily reproducible. End users do not know how to prepare a report that is really useful for developers, like building a package with debug symbols, operating gdb, etc. A considerable part of bug triage is spent with collecting relevant information about the crash itself, package versions, hardware architecture, operating system version, etc. There is no easy frontend which allow users to submit detailed problem reports. Existing solutions like bug-buddy or krash are specific to a particular desktop environment, are nontrivial to adapt to the needs of a distribution developer, do not work for crashes of background servers (like a database or an email server), and do not integrate well with existing debug packages that a distribution might provide. Apport is a system which: intercepts crashes right when they happen the first time, gathers potentially useful information about the crash and the OS environment, can be automatically invoked for unhandled exceptions in other programming languages (e. g. in Ubuntu this is done for Python), can be automatically invoked for other problems that can be automatically detected (e. g. Ubuntu automatically detects and reports package installation/upgrade failures from update-manager), presents a UI that informs the user about the crash and instructs them on how to proceed, and is able to file non-crash bug reports about software, so that developers still get information about package versions, OS version etc. We are sure that this will lead to a much better level of quality assurance in the future. If you want to make crash reports of your software even more useful when being reported through apport, please see /DeveloperHowTo. 
What does it look like for users?
The user side of apport is designed to be extremely simple and as unannoying as possible. If any process in the system dies due to a signal that is commonly referred to as a 'crash' (segmentation violation, bus error, floating point exception, etc.), or e. g. a packaged Python application raises an uncaught exception, the apport backend is automatically invoked. It produces an initial crash report in a file in /var/crash/ (the file name is composed from the name of the crashed executable and the user id). If the crashed process belongs to the user who is currently logged in, or it belongs to a system process and the user is an administrator, apport informs the user about the crash and offers to report the problem:  You can click on ""Show Details..."" to see what data it collected:  If the user leaves the ""Send error report"" checkbox enabled, Apport uploads the collected information to the bug tracking system. After that it opens the packages' bug filing page with a sensible default bug title and leaves the rest of bug filing process to the web UI. 
Why is apport disabled by default?
Apport is not enabled by default in stable releases, even if it is installed. The automatic crash interception component of apport is disabled by default in stable releases for a number of reasons: Apport collects potentially sensitive data, such as core dumps, stack traces, and log files. They can contain passwords, credit card numbers, serial numbers, and other private material. This is mitigated by the fact that it presents you what will be sent to the bug tracker, and that all crash report bugs are private by default, limited to the Ubuntu bug triaging team. We can reasonably expect developers and technically savvy users, who run the development release, to be aware of this and judge whether it is appropriate to file a crash report. But we shouldn't assume that every Ubuntu user of stable releases is able to do so. In 12.04 and up this is transparently handled by whoopsie, see ErrorTracker. During the development release we already collect thousands of crash reports, much more than we can ever fix. Continuing to collect those for stable releases is not really useful, since The most important crashes have already been discovered in the development release. The less important ones are not suitable for getting fixed in stable releases (see https://wiki.ubuntu.com/StableReleaseUpdates Asking users to send crash reports to us is insincere, since we can't possibly answer and deal with all of them. Data collection from apport takes a nontrivial amount of CPU and I/O resources, which slow down the computer and don't allow you to restart the crashed program for several seconds. Note apport does not trap SIGABRT signals. If you are getting such a signal, then please see DebuggingProgramCrash. 
How to enable apport
Apport itself is running at all times because it collects crash data for whoopsie (see ErrorTracker). However, the crash interception component is still disabled. To enable it permanently, do: sudo nano /etc/apport/crashdb.conf... and add a hash symbol # in the beginning of the following line:         'problem_types': ['Bug', 'Package'],To disable crash reporting just remove the hash symbol. 
I'm a developer. How do I use these crash reports?

Report format
apport internally uses the standard Debian control syntax for reports, i. e. keeps everything in a flat file that looks like this: DistroRelease: Ubuntu 12.04
ExecutablePath: /usr/bin/gcalctool
Package: gcalctool 5.8.24-0ubuntu2
ProcCmdline: gcalctool
ProcEnviron:
 SHELL=/bin/bash
 PATH=/usr/sbin:/usr/bin:/sbin:/bin:/usr/bin/X11:/usr/games
 LANG=de_DE.UTF-8
StackTrace:
 [...]
 #0  0x00002ae577bb37bf in poll () from /lib/libc.so.6
 No symbol table info available.
 #1  0x00002ae57786991e in g_main_context_check () from /usr/lib64/libglib-2.0.so.0
 No symbol table info available.
 [...]
CoreDump: base64
 eJzsXQmcFMXV7+XGA0dBREVoDxSPXQYEB...Only a tiny subset of the available fields are shown here. Apport reports include a core dump in a compressed and encoded format, which is useful for post-mortem debugging and post-mortem generation of a symbolic stack trace. However, when uploading the data to a bug tracking system, a different format can be used. e. g. when using Launchpad, the data is uploaded in Multipart/MIME format so that the small parts land directly in the bug summary and the big parts become separate bug attachments. 
Fields
Some fields warrant further details: SegvAnalysis: when examining a Segmentation Fault (signal 11), Apport attempts to review the exact machine instruction that caused the fault, and checks the program counter, source, and destination addresses, looking for any virtual memory address (VMA) that is outside an allocated range (as reported in the ProcMaps attachment). SegvReason: a VMA can be read from, written to, or executed.  On a SegFault, one of these 3 CPU actions has taken place at a given VMA that either not allocated, or lacks permissions to perform the action.  For example: SegvReason: reading NULL VMA would mean that a NULL pointer was most likely dereferenced while reading a value. SegvReason: writing unknown VMA would mean that something was attempting to write to the destination of a pointer aimed outside of allocated memory.  (This is sometimes a security issue.) SegvReason: executing writable VMA [stack] would mean that something was causing code on the stack to be executed, but the stack (correctly) lacked execute permissions.  (This is almost always a security issue.)  
Tools
There are several tools available for working with a crash report: Ubuntu Bug Patterns: These are patterns for packages (writable by Ubuntu Bug Control) that prevent bugs from being filed by apport.  Complete details are found in the README. apport-unpack: Unpack a report into single files (one per attribute). This is most useful for extracting the core dump. Please see the manpage for further details. This tool is not necessary when working with Launchpad, since it already splits the parts into separate attachments. apport-retrace: Regenerate stack traces of a report. If you supply the -g option, this tool will automatically download available debug symbol packages and use them to generate a symbolic stack trace. The manpage explains the functionality and all available options in detail. python-problem-report: This package ships a Python module problem_report which provides general dictionary access to a crash report and loading/saving methods (not specific to apport reports). python-apport: This ships a Python package apport which encapsulates core functionality of apport and is specific to crash and bug reports. You can use it to implement your own frontends and backends. apport-collect: This checks the source package(s) of an existing Launchpad bug, runs apport hooks for them, and uploads their collected information back to the bug report. 
How does it work internally?

Crash interception
Apport uses /proc/sys/kernel/core_pattern to directly pipe the core dump into apport: $ cat /proc/sys/kernel/core_pattern
|/usr/share/apport/apport %p %s %c
$ Note that even if ulimit is set to disabled core files (by specyfing a core file size of zero using ulimit -c 0), apport will still capture the crash. For intercepting Python crashes it installs a /etc/python*/sitecustomize.py to call apport on unhandled exceptions. 
Example
Apport is even able to capture core files if PID 1 (Upstart) dies: If Upstart detects an internal inconsistency, it raises the SIGABRT signal. The Upstart crash handler is called on SIGABRT. Upstart crash handler forks a child process. The Upstart child process re-raises the signal which results in the child exiting abnormally. The kernel detects the child process has exited abnormally and calls apport, piping the core file to apports standard input (due to /proc/sys/kernel/core_pattern). apport writes the core file to disk in /var/crash/. PID 1 waits for its child to terminate (which only happens once apport has finished writing the core file). PID 1 exits. kernel panics. On next boot, Whoopsie will detect the crash file and process it. 
Backend
In order to keep the delay and CPU/IO impact as low as possible, /usr/share/apport/apport only collects data which has to be acquired while the crashed process still exists: information from /proc/pid, the core dump, the executable path, and the signal number. The report is written to /var/crash/executable_path.uid.crash. 
Frontend invocation
In Gnome, update-notifier keeps an inotify watch on /var/crash. Whenever there is something new, it calls /usr/share/apport/apport-checkreports. If there are new reports, it calls /usr/share/apport/apport-gtk, which is the frontend shown in the screenshots above. The frontend then collects additional information like package versions, package file checksums, or OS version, and calls all matching package hooks. To disable this, you can run gsettings set com.ubuntu.update-notifier show-apport-crashes false (as your ordinary desktop user). 
Launchpad-based auto-retracer
The Canonical data center runs a service which automatically retrace bugs with apport. By tagging the bugs according to architecture in Launchpad, a retrace will be done and the tag will be removed. Tags that are used are need-i386-retrace or need-amd64-retrace. See the announcement. 
Per-package Apport Hooks
It is possible for packages to specify information gathered from the system and included in the bug report.  These are done by apport hooks contained in packages.  For some useful examples see: source_xorg.py - adds additional log files and hardware details to bug reports usplash - ignores crashes in specific code paths source_totem.py - asks the reporter questions and gathers different information based on responses in /usr/share/apport/package-hooks.  There is also a list of packages providing apport hooks. Please see /DeveloperHowTo for further information. If a crash or bug report is submitted through apport, the relevant hooks will be run automatically. If you have an already reported bug that was filed without apport, and you are interested in the information from those hooks, you can ask the bug reporter to use apport-collect bugnumber (see #Tools). 
Use the source, Luke!
You can download the upstream tarball from the Launchpad project page, or the Ubuntu source tarball from the Ubuntu archive. apport is developed with the bazaar RCS on Launchpad. If you want to contribute to it or develop your own system based on it, you can get your own branch with bzr branch lp:apport for trunk, or debcheckout -a apport for the Ubuntu packaging branch. You can also browse it online. 
Future plans
Various improvements to performance, better tools to work with reports, and integration of more languages (Mono/Python stack traces, assertion messages, etc.) See the relevant specification. 
Further links
The report file data format specification. Original specifications: apport design, User interface Ubuntu apport bug patterns Whoopsie is a newer Ubuntu crash submission system that doesn't require any input from the user and integrates with Apport Please do not hesitate to report bugs and feature requests to the bug tracker. See Bugs/ApportRetraces for additional documentation for those triaging Apport-generated bug reports in LaunchPad, based on a MOTU/School session by EmmetHikory . Brian Murray gave a class at Ubuntu Developer week regarding writing package hooks. Integration using LaunchpadIntegration: https://wiki.ubuntu.com/UbuntuDevelopment/Internationalisation/Coding#LPI  




Apport  (last edited 2017-05-25 20:03:48 by penalvch)










 The material on this wiki is available under a free license, see 
	Copyright / License for details.
        



",,"# apport-bug

> File a bug report on Ubuntu.
> More information: <https://wiki.ubuntu.com/Apport>.

- Report a bug about the whole system:

`apport-bug`

- Report a bug about a specific package:

`apport-bug {{package}}`

- Report a bug about a specific executable:

`apport-bug {{path/to/executable}}`

- Report a bug about a specific process:

`apport-bug {{PID}}`
"
uvcdynctrl,,,,"# uvcdynctrl

> A libwebcam command line tool to manage dynamic controls in uvcvideo.

- List all available cameras:

`uvcdynctrl -l`

- Specify the device to use (defaults to `video0`):

`uvcdynctrl -d {{device_name}}`

- List available controls:

`uvcdynctrl -c`

- Set a new control value (for negative values, add -- before {{-value}}):

`uvcdynctrl -s {{control_name}} {{value}}`

- Get the current control value:

`uvcdynctrl -g {{control_name}}`

- Save the state of the current controls to a file:

`uvcdynctrl -W {{filename}}`

- Load the state of the controls from a file:

`uvcdynctrl -L {{filename}}`
"
tree,,,"TREE(1) 							       TREE(1)



NAME
       tree - list contents of directories in a tree-like format.

SYNOPSIS
       tree  [-acdfghilnpqrstuvxACDFQNSUX]  [-L  level [-R]] [-H baseHREF] [-T
       title] [-o filename] [--nolinks] [-P pattern] [-I  pattern]  [--inodes]
       [--device] [--noreport] [--dirsfirst] [--version] [--help] [--filelimit
       #] [--si] [--prune] [--du] [--timefmt  format]  [--matchdirs]  [--from-
       file] [--] [directory ...]


DESCRIPTION
       Tree  is  a  recursive  directory listing program that produces a depth
       indented listing of files, which is  colorized  ala  dircolors  if  the
       LS_COLORS  environment  variable  is set and output is to tty.  With no
       arguments, tree lists the files in the current directory.  When	direc-
       tory  arguments	are given, tree lists all the files and/or directories
       found in the given directories each in turn.  Upon completion of  list-
       ing all files/directories found, tree returns the total number of files
       and/or directories listed.

       By default, when a symbolic link is encountered, the path that the sym-
       bolic  link refers to is printed after the name of the link in the for-
       mat:

	   name -> real-path

       If the `-l' option is given and the symbolic link refers to  an	actual
       directory, then tree will follow the path of the symbolic link as if it
       were a real directory.


OPTIONS
       Tree understands the following command line switches:


LISTING OPTIONS
       -a     All files are printed.  By default tree does  not  print	hidden
	      files  (those  beginning with a dot `.').  In no event does tree
	      print the file system constructs	`.'  (current  directory)  and
	      `..' (previous directory).


       -d     List directories only.


       -l     Follows  symbolic links if they point to directories, as if they
	      were directories. Symbolic links that will result  in  recursion
	      are avoided when detected.


       -f     Prints the full path prefix for each file.


       -x     Stay on the current file-system only.  Ala find -xdev.


       -L level
	      Max display depth of the directory tree.


       -R     Recursively  cross  down the tree each level directories (see -L
	      option), and at each of  them  execute  tree  again  adding  `-o
	      00Tree.html' as a new option.


       -P pattern
	      List  only  those files that match the wild-card pattern.  Note:
	      you must use the -a option to also consider those  files	begin-
	      ning with a dot `.'  for matching.  Valid wildcard operators are
	      `*' (any zero or more characters), `?' (any  single  character),
	      `[...]'  (any single character listed between brackets (optional
	      - (dash) for character  range  may  be  used:  ex:  [A-Z]),  and
	      `[^...]'	(any  single character not listed in brackets) and `|'
	      separates alternate patterns.


       -I pattern
	      Do not list those files that match the wild-card pattern.


       --ignore-case
	      If a match pattern is specified by the -P  or  -I  option,  this
	      will  cause  the pattern to match without regards to the case of
	      each letter.


       --matchdirs
	      If a match pattern is specified by  the  -P  option,  this  will
	      cause  the pattern to be applied to directory names (in addition
	      to filenames).  In the event of a match on the  directory  name,
	      matching	is  disabled  for  the	directory's  contents.	If the
	      --prune option is used, empty folders  that  match  the  pattern
	      will not be pruned.


       --prune
	      Makes  tree prune empty directories from the output, useful when
	      used in conjunction with -P or -I.  See BUGS AND NOTES below for
	      more information on this option.


       --noreport
	      Omits  printing  of  the file and directory report at the end of
	      the tree listing.


       --charset charset
	      Set the character set to use when outputting HTML and  for  line
	      drawing.


       --filelimit #
	      Do not descend directories that contain more than # entries.


       --timefmt format
	      Prints (implies -D) and formats the date according to the format
	      string which uses the strftime(3) syntax.


       -o filename
	      Send output to filename.



FILE OPTIONS
       -q     Print non-printable characters in filenames  as  question  marks
	      instead of the default.


       -N     Print non-printable characters as is instead of as escaped octal
	      numbers.


       -Q     Quote the names of files in double quotes.


       -p     Print the file type and permissions for each  file  (as  per  ls
	      -l).


       -u     Print the username, or UID # if no username is available, of the
	      file.


       -g     Print the group name, or GID # if no group name is available, of
	      the file.


       -s     Print the size of each file in bytes along with the name.


       -h     Print  the  size	of each file but in a more human readable way,
	      e.g. appending a size letter for kilobytes (K),  megabytes  (M),
	      gigabytes (G), terabytes (T), petabytes (P) and exabytes (E).


       --si   Like -h but use SI units (powers of 1000) instead.


       --du   For  each directory report its size as the accumulation of sizes
	      of all its files and sub-directories (and their  files,  and  so
	      on).   The total amount of used space is also given in the final
	      report (like the 'du -c' command.) This option requires tree  to
	      read  the entire directory tree before emitting it, see BUGS AND
	      NOTES below.  Implies -s.


       -D     Print the date of the last modification time or if -c  is  used,
	      the last status change time for the file listed.


       -F     Append  a `/' for directories, a `=' for socket files, a `*' for
	      executable files, a `>'  for  doors  (Solaris)  and  a  `|'  for
	      FIFO's, as per ls -F


       --inodes
	      Prints the inode number of the file or directory


       --device
	      Prints the device number to which the file or directory belongs



SORTING OPTIONS
       -v     Sort the output by version.


       -t     Sort  the output by last modification time instead of alphabeti-
	      cally.


       -c     Sort the output by last status change instead of alphabetically.
	      Modifies the -D option (if used) to print the last status change
	      instead of modification time.


       -U     Do not sort.  Lists files in directory order.  Disables  --dirs-
	      first.


       -r     Sort  the  output  in  reverse  order.  This is a meta-sort that
	      alter the above sorts.  This option is disabled when -U is used.


       --dirsfirst
	      List  directories  before files. This is a meta-sort that alters
	      the above sorts.	This option is disabled when -U is used.


       --sort[=]type
	      Sort the output by type instead of name.	Possible  values  are:
	      ctime (-c), mtime (-t), size, or version (-v).


GRAPHICS OPTIONS
       -i     Makes  tree not print the indentation lines, useful when used in
	      conjunction with the -f option.  Also removes as much whitespace
	      as possible when used with the -J or -x options.


       -A     Turn  on	ANSI  line graphics hack when printing the indentation
	      lines.


       -S     Turn on CP437 line graphics (useful  when  using	Linux  console
	      mode fonts). This option is now equivalent to `--charset=IBM437'
	      and may eventually be depreciated.


       -n     Turn colorization off always, over-ridden by the -C option.


       -C     Turn colorization on always, using built-in  color  defaults  if
	      the  LS_COLORS or TREE_COLORS environment variables are not set.
	      Useful to colorize output to a pipe.



XML/JSON/HTML OPTIONS
       -X     Turn on XML output. Outputs the directory tree as an XML format-
	      ted file.


       -J     Turn  on JSON output. Outputs the directory tree as an JSON for-
	      matted array.


       -H baseHREF
	      Turn on HTML output, including HTTP references. Useful  for  ftp
	      sites.   baseHREF  gives	the  base ftp location when using HTML
	      output. That is, the local directory  may  be  `/local/ftp/pub',
	      but   it	 must	be   referenced  as  `ftp://hostname.organiza-
	      tion.domain/pub' (baseHREF should  be  `ftp://hostname.organiza-
	      tion.domain').  Hint: don't use ANSI lines with this option, and
	      don't give more than one directory in the directory list. If you
	      wish  to	use  colors  via CSS style-sheet, use the -C option in
	      addition to this option to force color output.


       -T title
	      Sets the title and H1 header string in HTML output mode.


       --nolinks
	      Turns off hyperlinks in HTML output.



INPUT OPTIONS
       --fromfile Reads a directory listing from a file rather than the  file-
       system.	 Paths	provided  on  the  command line are files to read from
       rather than directories to search.  The	dot  (.)  directory  indicates
       that tree should read paths from standard input.


MISC OPTIONS
       --help Outputs a verbose usage listing.


       --version
	      Outputs the version of tree.


       --     Option  processing  terminator.  No further options will be pro-
	      cessed after this.



FILES
       /etc/DIR_COLORS		System color database.
       ~/.dircolors	   Users color database.


ENVIRONMENT
       LS_COLORS      Color information created by dircolors
       TREE_COLORS    Uses this for color information over LS_COLORS if it  is
       set.
       TREE_CHARSET   Character set for tree to use in HTML mode.
       CLICOLOR       Enables colorization even if TREE_COLORS or LS_COLORS is
       not set.
       CLICOLOR_FORCE Always enables colorization (effectively -C)
       LC_CTYPE       Locale for filename output.
       LC_TIME	      Locale for timefmt output, see strftime(3).
       TZ	 Timezone for timefmt output, see strftime(3).


AUTHOR
       Steve Baker (ice@mama.indstate.edu)
       HTML output hacked by Francesc Rocher (rocher@econ.udg.es)
       Charsets and OS/2 support by Kyosuke Tokoro (NBG01720@nifty.ne.jp)


BUGS AND NOTES
       Tree does not prune ""empty"" directories when the -P and -I options  are
       used by default. Use the --prune option.

       The -h and --si options round to the nearest whole number unlike the ls
       implementations which rounds up always.

       Pruning files and directories with the -I, -P and  --filelimit  options
       will lead to incorrect file/directory count reports.

       The  --prune  and --du options cause tree to accumulate the entire tree
       in memory before emitting it. For large directory trees this can  cause
       a significant delay in output and the use of large amounts of memory.

       The  timefmt  expansion	buffer	is limited to a ridiculously large 255
       characters.  Output of time strings longer than this will be undefined,
       but are guaranteed to not exceed 255 characters.

       XML/JSON trees are not colored, which is a bit of a shame.

       Probably more.


SEE ALSO
       dircolors(1), ls(1), find(1), du(1), strftime(3)



Tree 1.8.0							       TREE(1)
","# tree

> Show the contents of the current directory as a tree.

- Print files and directories up to 'num' levels of depth (where 1 means the current directory):

`tree -L {{num}}`

- Print directories only:

`tree -d`

- Print hidden files too:

`tree -a`

- Print the tree without indentation lines, showing the full path instead (use `-N` to not escape whitespace and special characters):

`tree -i -f`

- Print the size of each node next to it, in human-readable format:

`tree -s -h`

- Filter the tree using a wildcard (glob) pattern:

`tree -P {{*.txt}}`

- Ignore entries that match a wildcard (glob) pattern:

`tree -I {{*.txt}}`

- Print the tree ignoring the given directories:

`tree -I '{{directory_name1|directory_name2}}'`
"
a2dismod,https://manpages.debian.org/buster/apache2/a2dismod.8.en.html,"



a2dismod(8) — apache2 — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / apache2
     
     
     
     / a2dismod(8)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


EXIT STATUS


EXAMPLES


FILES


SEE ALSO


AUTHOR







other versions




buster 2.4.38-3+deb10u3


buster-backports 2.4.43-1~bpo10+1


testing 2.4.43-1


unstable 2.4.43-1






Scroll to navigation



A2ENMOD(8)
System Manager's Manual
A2ENMOD(8)




NAME¶
a2enmod, a2dismod - enable or disable an apache2 module


SYNOPSIS¶
a2enmod [ [-q|--quiet] module]
a2dismod [ [-q|--quiet] module]


DESCRIPTION¶
This manual page documents briefly the a2enmod and a2dismod
  commands.
a2enmod is a script that enables the specified module
    within the apache2 configuration. It does this by creating symlinks
    within /etc/apache2/mods-enabled. Likewise, a2dismod disables
    a module by removing those symlinks. It is not an error to enable a module
    which is already enabled, or to disable one which is already disabled.
Note that many modules have, in addition to a .load file, an
    associated .conf file. Enabling the module puts the configuration directives
    in the .conf file as directives into the main server context of
    apache2.


OPTIONS¶

-q, --quiet
Don't show informative messages.
-m, --maintmode
Enables the maintainer mode, that is the program invocation is effectuated
      automatically by a maintainer script. This switch should not be used by
      end users.
-p, --purge
When disabling a module, purge all traces of the module in the internal
      state data base.



EXIT STATUS¶
a2enmod and a2dismod exit with status 0 if all modules are
  processed successfully, 1 if errors occur, 2 if an invalid option was used.


EXAMPLES¶
a2enmod imagemap

a2dismod mime_magic
Enables the mod_imagemap module, and disables the
    mod_mime_magic module.


FILES¶

/etc/apache2/mods-available
Directory with files giving information on available modules.
/etc/apache2/mods-enabled
Directory with links to the files in mods-available for enabled
      modules.



SEE ALSO¶
apache2ctl(8), a2enconf(8), a2disconf(8).


AUTHOR¶
This manual page was written by Daniel Stone <daniel@sfarc.net> for the
  Debian GNU/Linux distribution, as it is a Debian-specific script with the
  package.




12 October 2006










Source file:


a2dismod.8.en.gz (from apache2 2.4.38-3+deb10u3)




Source last updated:


2019-04-07T18:15:40Z




Converted to HTML:


2020-08-08T10:05:56Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# a2dismod

> Disable an Apache module on Debian-based OSes.
> More information: <https://manpages.debian.org/buster/apache2/a2dismod.8.en.html>.

- Disable a module:

`sudo a2dismod {{module}}`

- Don't show informative messages:

`sudo a2dismod --quiet {{module}}`
"
lvresize,,,,"# lvresize

> Change the size of a logical volume.

- Change a volume's size to 120GB:

`lvresize -L {{120G}} {{logical_volume}}`

- Reduce a volume's size by 120GB as well as the underlying filesystem:

`lvresize --size -{{120G}} -r {{logical_volume}}`

- Increase a volume's size to 100% of the free phyiscal volume space:

`lvresize --size {{100}}%FREE {{logical_volume}}`
"
yank,,,,"# yank

> Read input from `stdin` and display a selection interface that allows a field to be selected and copied to the clipboard.

- Yank using the default delimiters (\f, \n, \r, \s, \t):

`{{sudo dmesg}} | yank`

- Yank an entire line:

`{{sudo dmesg}} | yank -l`

- Yank using a specific delimiter:

`{{echo hello=world}} | yank -d {{=}}`

- Only yank fields matching a specific pattern:

`{{ps ux}} | yank -g {{""[0-9]+""}}`
"
dpkg,,,,"# dpkg

> Debian package manager.

- Install a package:

`dpkg -i {{path/to/file.deb}}`

- Remove a package:

`dpkg -r {{package_name}}`

- List installed packages:

`dpkg -l {{pattern}}`

- List package contents:

`dpkg -L {{package_name}}`

- List contents of a local package file:

`dpkg -c {{path/to/file.deb}}`

- Find out which package owns a file:

`dpkg -S {{filename}}`
"
mountpoint,,,,"# mountpoint

> Test if a directory is a filesystem mountpoint.

- Check if a directory is a mountpoint:

`mountpoint {{path/to/directory}}`

- Check if a directory is a mountpoint without showing any output:

`mountpoint -q {{path/to/directory}}`

- Show major/minor numbers of a mountpoint's filesystem:

`mountpoint --fs-devno {{path/to/directory}}`
"
edit,,,,"# edit

> An alias to a `run-mailcap`'s action edit.
> Originally `run-mailcap` is used to process/edit mime-type/file.

- Edit action can be used to view any file on default mailcap explorer:

`edit {{filename}}`

- With `run-mailcap`:

`run-mailcap --action=edit {{filename}}`
"
apt-get,,,,"# apt-get

> Debian and Ubuntu package management utility.
> Search for packages using `apt-cache`.

- Update the list of available packages and versions (it's recommended to run this before other `apt-get` commands):

`apt-get update`

- Install a package, or update it to the latest available version:

`apt-get install {{package}}`

- Remove a package:

`apt-get remove {{package}}`

- Remove a package and its configuration files:

`apt-get purge {{package}}`

- Upgrade all installed packages to their newest available versions:

`apt-get upgrade`

- Clean the local repository - removing package files (.deb) from interrupted downloads that can no longer be downloaded:

`apt-get autoclean`

- Remove all packages that are no longer needed:

`apt-get autoremove`

- Upgrade installed packages (like `upgrade`), but remove obsolete packages and install additional packages to meet new dependencies:

`apt-get dist-upgrade`
"
kpartx,,,,"# kpartx

> Create device maps from partition tables.

- Add partition mappings:

`kpartx -a {{whole_disk.img}}`

- Delete partition mappings:

`kpartx -d {{whole_disk.img}}`

- List partition mappings:

`kpartx -l {{whole_disk.img}}`
"
hardinfo,,,,"# hardinfo

> Show hardware information in GUI window.

- Start hardinfo:

`hardinfo`

- Print report to standard output:

`hardinfo -r`

- Save report to HTML file:

`hardinfo -r -f html > hardinfo.html`
"
strace,,,,"# strace

> Troubleshooting tool for tracing system calls.

- Start tracing a specific process by its PID:

`strace -p {{pid}}`

- Trace a process and filter output by system call:

`strace -p {{pid}} -e {{system_call_name}}`

- Count time, calls, and errors for each system call and report a summary on program exit:

`strace -p {{pid}} -c`

- Show the time spent in every system call:

`strace -p {{pid}} -T`

- Start tracing a program by executing it:

`strace {{program}}`

- Start tracing file operations of a program:

`strace -e trace=file {{program}}`
"
avahi-browse,https://www.avahi.org/,"

avahi - mDNS/DNS-SD


Welcome to Avahi
Quick Links

doxygen documentation
download: avahi 0.8
download: avahi 0.7
github: lathiat/avahi (bug reports & pull requests)
github: lathiat/nss-mdns (bug reports & pull requests)
mailing list

What is Avahi?
Avahi is a system which facilitates service discovery on a local network via the mDNS/DNS-SD protocol suite. This enables you to plug your laptop or computer into a network and instantly be able to view other people who you can chat with, find printers to print to or find files being shared. Compatible technology is found in Apple MacOS X (branded ""Bonjour"" and sometimes ""Zeroconf"").
Avahi is primarily targetted at Linux systems and ships by default in most distributions.  It is not ported to Windows at this stage, but will run on many other BSD-like systems.  The primary API is D-Bus and is required for usage of most of Avahi, however services can be published using an XML service definition placed in /etc/avahi/services.
See also the nss-mdns project, which allows hostname lookup of *.local hostnames via mDNS in all system programs using nsswitch
Definition at Wikipedia
News
February 2020
 * 2020-02-18: We have released Avahi 0.8! This release has a number of new features and a D-Bus/avahi-core API change related to racing signals with D-Bus object creation.  For full details of all bug fixes, changes and new features check out the release page or docs/NEWS!
July 2017
 * 2017-07-10: We have released Avahi 0.7! The main new feature of this release is the ability to encode binary (non-text) TXT records into XML service definitions (/etc/avahi/services).  For full details of all bug fixes, changes and new features check the release page
February 2016
 * 2016-02-16: We have released Avahi 0.6.32! This is a bugfix release with a couple of minor new configuration options or default changes.  Full details and downloads at the link.  Please file any issues or pull requests through github.com/lathiat/avahi
October 2015
 * 2015-10-10: We have a release candidate, 0.6.32-rc! This is mostly a bugfix release, see the NEWS (Change Log).  This is intended for release soon, please file any issues you notice through github.com/lathiat/avahi.

February 2012
 * 2012-02-15: We have released Avahi 0.6.31! This is a bugfix release.

April 2011
 * 2011-04-04: We have released Avahi 0.6.30! This is a bugfix release.

March 2011
 * 2011-03-09: We have released Avahi 0.6.29! This is a bugfix release and fixes a minor security issue.

August 2010
 * 2010-10-05: We have released Avahi 0.6.28! This is a bugfix release.

July 2010
 * 2010-07-13: We have released Avahi 0.6.27! This is a bugfix release. 

June 2010
 * 2010-06-29: We have released Avahi 0.6.26! This is a bugfix release and fixes a minor security issue.


",,"# avahi-browse

> Displays services and hosts exposed on the local network via mDNS/DNS-SD.
> Avahi is compatible with Bonjour (Zeroconf) found in Apple devices.
> More information: <https://www.avahi.org/>.

- List all services available on the local network along with their addresses and ports while ignoring local ones:

`avahi-browse --all --resolve --ignore-local`

- List all domains:

`avahi-browse --browse-domains`

- Limit the search to a particular domain:

`avahi-browse --all --domain={{domain}}`
"
chfn,,,"
CHPASS(1)		  BSD General Commands Manual		     CHPASS(1)

NAME
     chpass, chfn, chsh -- add or change user database information

SYNOPSIS
     chpass [-l location] [-u authname] [-s newshell] [user]

DESCRIPTION
     The chpass utility allows editing of the user database information asso-
     ciated with user or, by default, the current user.

     The chpass utility cannot change the user's password on Open Directory
     systems.  Use the passwd(1) utility instead.

     The chfn, and chsh utilities behave identically to chpass.  (There is
     only one program.)

     The information is formatted and supplied to an editor for changes.

     Only the information that the user is allowed to change is displayed.

     The options are as follows:

     -l location
	     If not specified, chpass will perform a search for the user
	     record on all available Open Directory nodes.  When specified,
	     chpass will edit the user record on the directory node at the
	     given location.

     -u authname
	     The user name to use when authenticating to the directory node
	     containing the user.

     -s newshell
	     Attempt to change the user's shell to newshell.

     Possible display items are as follows:

	   Login:	       user's login name
	   Uid: 	       user's login
	   Gid: 	       user's login group
	   Generated uid:      user's UUID
	   Full Name:	       user's real name
	   Office Location:    user's office location
	   Office Phone:       user's office phone
	   Home Phone:	       user's home phone
	   Home Directory:     user's home directory
	   Shell:	       user's login shell

     The login field is the user name used to access the computer account.

     The uid field is the number associated with the login field.  Both of
     these fields should be unique across the system (and often across a group
     of systems) as they control file access.

     While it is possible to have multiple entries with identical login names
     and/or identical user id's, it is usually a mistake to do so.  Routines
     that manipulate these files will often return only one of the multiple
     entries, and that one by random selection.

     The group field is the group that the user will be placed in at login.
     Since BSD supports multiple groups (see groups(1)) this field currently
     has little special meaning.  This field may be filled in with either a
     number or a group name (see group(5)).

     The generated uid field is the globally unique identifier (UUID) for the
     user.  The full name field contains the full name of the user.

     The user's home directory is the full UNIX path name where the user will
     be placed at login.

     The shell field is the command interpreter the user prefers.  If the
     shell field is empty, the Bourne shell, /bin/sh, is assumed.  When alter-
     ing a login shell, and not the super-user, the user may not change from a
     non-standard shell or to a non-standard shell.  Non-standard is defined
     as a shell not found in /etc/shells.

     The picture field is the path to a picture to be displayed for the user.

OPEN DIRECTORY
     User database entries are under the control of DirectoryService(8) and
     may be physically located in many different places, including the local
     Directory Service node, and remote LDAP servers.  This version of chpass
     uses Open Directory to change user database information.  It does not
     interact with the historic flat file database /etc/master.passwd

ENVIRONMENT
     The vi(1) editor will be used unless the environment variable EDITOR is
     set to an alternate editor.  When the editor terminates, the information
     is re-read and used to update the user database itself.  Only the user,
     or the super-user, may edit the information associated with the user.

FILES
     /etc/chpass.XXXXXX  temporary copy of the data to edit
     /etc/shells	 the list of approved shells

SEE ALSO
     login(1), passwd(1), getusershell(3), passwd(5)

     Robert Morris and Ken Thompson, UNIX Password security.

HISTORY
     The chpass utility appeared in 4.3BSD-Reno.

BSD			       December 30, 1993			   BSD
","# chfn

> Update `finger` info for a user.

- Update a user's ""Name"" field in the output of `finger`:

`chfn -f {{new_display_name}} {{username}}`

- Update a user's ""Office Room Number"" field for the output of `finger`:

`chfn -o {{new_office_room_number}} {{username}}`

- Update a user's ""Office Phone Number"" field for the output of `finger`:

`chfn -p {{new_office_telephone_number}} {{username}}`

- Update a user's ""Home Phone Number"" field for the output of `finger`:

`chfn -h {{new_home_telephone_number}} {{username}}`
"
tlp,,,,"# tlp

> Advanced power management for Linux. See `tlp-stat` page for additional information.

- Apply settings (according to the actual power source):

`sudo tlp start`

- Apply battery settings (ignoring the actual power source):

`sudo tlp bat`

- Apply AC settings (ignoring the actual power source):

`sudo tlp ac`
"
shutdown,,,"
SHUTDOWN(8)		  BSD System Manager's Manual		   SHUTDOWN(8)

NAME
     shutdown -- close down the system at a given time

SYNOPSIS
     shutdown [-] [-h [-u] | -r | -s | -k] [-o [-n]] time
	      [warning-message ...]

DESCRIPTION
     The shutdown utility provides an automated shutdown procedure for super-
     users to nicely notify users when the system is shutting down, saving
     them from system administrators, hackers, and gurus, who would otherwise
     not bother with such niceties.

     The following options are available:

     -h      The system is halted at the specified time.

     -k      Kick everybody off.  The -k option does not actually halt the
	     system, but leaves the system multi-user with logins disabled
	     (for all but super-user).

     -n      If the -o is specified, prevent the file system cache from being
	     flushed by passing -n option to halt(8) or reboot(8).  This
	     option should probably not be used.

     -o      If -h or -r is specified, shutdown will execute halt(8) or
	     reboot(8) instead of sending a signal to launchd(8).

     -r      The system is rebooted at the specified time.

     -s      The system is put to sleep at the specified time.

     -u      The system is halted up until the point of removing system power,
	     but waits before removing power for 5 minutes so that an external
	     UPS (uninterruptible power supply) can forcibly remove power.
	     This simulates a dirty shutdown to permit a later automatic power
	     on. OS X uses this mode automatically with supported UPSs in
	     emergency shutdowns.

     time    Time is the time at which shutdown will bring the system down and
	     may be the word now (indicating an immediate shutdown) or specify
	     a future time in one of two formats: +number, or yymmddhhmm,
	     where the year, month, and day may be defaulted to the current
	     system values.  The first form brings the system down in number
	     minutes and the second at the absolute time specified.

     warning-message
	     Any other arguments comprise the warning message that is broad-
	     cast to users currently logged into the system.

     -	     If `-' is supplied as an option, the warning message is read from
	     the standard input.

     At intervals, becoming more frequent as apocalypse approaches and start-
     ing at ten hours before shutdown, warning messages are displayed on the
     terminals of all users logged in.

     At shutdown time a message is written to the system log, containing the
     time of shutdown, the person who initiated the shutdown and the reason.
     Corresponding signal is then sent to launchd(8) to respectively halt,
     reboot or bring the system down to single-user state (depending on the
     above options).

     A scheduled shutdown can be canceled by killing the shutdown process (a
     SIGTERM should suffice).

SIGTERM TO SIGKILL INTERVAL
     Upon shutdown, all running processes are sent a SIGTERM followed by a
     SIGKILL.  The SIGKILL will follow the SIGTERM by an intentionally inde-
     terminate period of time.	Programs are expected to take only enough time
     to flush all dirty data and exit.	Developers are encouraged to file a
     bug with the OS vendor, should they encounter an issue with this func-
     tionality.

SEE ALSO
     kill(1), login(1), wall(1), halt(8), launchd(8), reboot(8)

BACKWARD COMPATIBILITY
     The hours and minutes in the second time format may be separated by a
     colon (``:'') for backward compatibility.

HISTORY
     The shutdown utility appeared in 4.0BSD.

BSD			       December 11, 1998			   BSD
","# shutdown

> Shutdown and reboot the system.

- Power off (halt) immediately:

`shutdown -h now`

- Reboot immediately:

`shutdown -r now`

- Reboot in 5 minutes:

`shutdown -r +{{5}} &`

- Shutdown at 1:00 pm (Uses 24h clock):

`shutdown -h 13:00`

- Cancel a pending shutdown/reboot operation:

`shutdown -c`
"
phpquery,,,,"# phpquery

> PHP extension manager for Debian-based OSes.

- List available PHP versions:

`sudo phpquery -V`

- List available SAPIs for PHP 7.3:

`sudo phpquery -v {{7.3}} -S`

- List enabled extensions for PHP 7.3 with the cli SAPI:

`sudo phpquery -v {{7.3}} -s {{cli}} -M`

- Check if the json extension is enabled for PHP 7.3 with the apache2 SAPI:

`sudo phpquery -v {{7.3}} -s {{apache2}} -m {{json}}`
"
ul,,,"
UL(1)			  BSD General Commands Manual			 UL(1)

NAME
     ul -- do underlining

SYNOPSIS
     ul [-i] [-t terminal] [file ...]

DESCRIPTION
     The ul utility reads the named files (or standard input if none are
     given) and translates occurrences of underscores to the sequence which
     indicates underlining for the terminal in use, as specified by the envi-
     ronment variable TERM.  The file /etc/termcap is read to determine the
     appropriate sequences for underlining.  If the terminal is incapable of
     underlining, but is capable of a standout mode then that is used instead.
     If the terminal can overstrike, or handles underlining automatically, ul
     degenerates to cat(1).  If the terminal cannot underline, underlining is
     ignored.

     The following options are available:

     -i      Underlining is indicated by a separate line containing appropri-
	     ate dashes `-'; this is useful when you want to look at the
	     underlining which is present in an nroff(1) output stream on a
	     crt-terminal.

     -t terminal
	     Overrides the terminal type specified in the environment with
	     terminal.

ENVIRONMENT
     The LANG, LC_ALL, LC_CTYPE and TERM environment variables affect the exe-
     cution of ul as described in environ(7).

EXIT STATUS
     The ul utility exits 0 on success, and >0 if an error occurs.

SEE ALSO
     colcrt(1), man(1), nroff(1)

HISTORY
     The ul command appeared in 3.0BSD.

BUGS
     The nroff(1) command usually outputs a series of backspaces and under-
     lines intermixed with the text to indicate underlining.  No attempt is
     made to optimize the backward motion.

BSD				August 4, 2004				   BSD
","# ul

> Performs the underlining of a text.
> Each character in a given string must be underlined separately.

- Display the contents of the file with underlines where applicable:

`ul {{file.txt}}`

- Display the contents of the file with underlines made of dashes `-`:

`ul -i {{file.txt}}`
"
wmctrl,,,,"# wmctrl

> CLI for X Window Manager.

- List all windows, managed by the window manager:

`wmctrl -l`

- Switch to the first window whose (partial) title matches:

`wmctrl -a {{window_title}}`

- Move a window to the current workspace, raise it and give it focus:

`wmctrl -R {{window_title}}`

- Switch to a workspace:

`wmctrl -s {{workspace_number}}`

- Select a window and toggle fullscreen:

`wmctrl -r {{window_title}} -b toggle,fullscreen`

- Select a window a move it to a workspace:

`wmctrl -r {{window_title}} -t {{workspace_number}}`
"
wall,,,"
WALL(1) 		  BSD General Commands Manual		       WALL(1)

NAME
     wall -- write a message to users

SYNOPSIS
     wall [-g group] [file]

DESCRIPTION
     The wall utility displays the contents of file or, by default, its stan-
     dard input, on the terminals of all currently logged in users.

     Only the super-user can write on the terminals of users who have chosen
     to deny messages or are using a program which automatically denies mes-
     sages.

     -g      Send messages to users in this group.  This option may be speci-
	     fied multiple times, and any user in any of the specified groups
	     will receive the message.

SEE ALSO
     mesg(1), talk(1), write(1), shutdown(8)

HISTORY
     A wall command appeared in PWB UNIX.

BUGS
     The sender's LC_CTYPE setting is used to determine which characters are
     safe to write to a terminal, not the receiver's (which wall has no way of
     knowing).

     The wall utility does not recognize multibyte characters.

BSD				 July 17, 2004				   BSD
","# wall

> Write a message on the terminals of users currently logged in.

- Send a message:

`echo ""{{message}}"" | wall`

- Send a message from a file:

`wall {{file}}`

- Send a message with timeout (default 300):

`wall -t {{seconds}} {{file}}`
"
runuser,,,,"# runuser

> Run commands as a specific user and group without asking for password (needs root privileges).

- Run command as a different user:

`runuser {{user}} -c '{{command}}'`

- Run command as a different user and group:

`runuser {{user}} -g {{group}} -c '{{command}}'`

- Start a login shell as a specific user:

`runuser {{user}} -l`

- Specify a shell for running instead of the default shell (also works for login):

`runuser {{user}} -s {{/bin/sh}}`

- Preserve the entire environment of root (only if `--login` is not specified):

`runuser {{user}} --preserve-environment -c '{{command}}'`
"
zenity,,,,"# zenity

> Display dialogs from the command line/shell scripts.
> Return user-inserted values or 1 if error.

- Display the default question dialog:

`zenity --question`

- Display an info dialog displaying the text ""Hello!"":

`zenity --info --text=""{{Hello!}}""`

- Display a name/password form and output the data separated by "";"":

`zenity --forms --add-entry=""{{Name}}"" --add-password=""{{Password}}"" --separator=""{{;}}""`

- Display a file selection form in which the user can only select directories:

`zenity --file-selection --directory`

- Display a progress bar which updates its message every second and show a progress percent:

`{{(echo ""#1""; sleep 1; echo ""50""; echo ""#2""; sleep 1; echo ""100"")}} | zenity --progress`
"
pulseaudio,,,,"# pulseaudio

> The pulseaudio sound system daemon and manager.

- Check if pulseaudio is running (a non-zero exit code means it is not running):

`pulseaudio --check`

- Start the pulseaudio daemon in the background:

`pulseaudio --start`

- Kill the running pulseaudio daemon:

`pulseaudio --kill`

- List available modules:

`pulseaudio --dump-modules`

- Load a module into the currently running daemon with the specified arguments:

`pulseaudio --load=""{{module_name}} {{arguments}}""`
"
taskset,,,,"# taskset

> Get or set a process' CPU affinity or start a new process with a defined CPU affinity.

- Get a running process' CPU affinity by PID:

`taskset --pid --cpu-list {{pid}}`

- Set a running process' CPU affinity by PID:

`taskset --pid --cpu-list {{cpu_id}} {{pid}}`

- Start a new process with affinity for a single CPU:

`taskset --cpu-list {{cpu_id}} {{command}}`

- Start a new process with affinity for multiple non-sequential CPUs:

`taskset --cpu-list {{cpu_id_1}} {{cpu_id_2}} {{cpu_id_3}}`

- Start a new process with affinity for CPUs 1 through 4:

`taskset --cpu-list {{cpu_id_1}},{{cpu_id_4}}`
"
check-support-status,https://manpages.debian.org/buster/debian-security-support/check-support-status.1.en.html,"



check-support-status(1) — debian-security-support — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / debian-security-support
     
     
     
     / check-support-status(1)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


VERSION


SYNOPSIS


OPTIONS


BUGS


AUTHOR


COPYRIGHT &amp; LICENSE







other versions




buster 2020.06.21~deb10u1


testing 2020.07.12


unstable 1:11+2020.09.12






Scroll to navigation



CHECK-SUPPORT-STAT(1)
 
CHECK-SUPPORT-STAT(1)




NAME¶
check-support-status - check installed packages for security support
  (debian-security-support)


VERSION¶
Version 2020.06.21~deb10u1


SYNOPSIS¶
Search for packages whose support is limited, has already ended or will end
  earlier than the distribution’s end of life:

    check-support-status

Search for packages with ended support from a custom list,
    reporting each package only once:

    check-support-status \
        --type ended \
        --status-db /path/to/status-db \
        --list /path/to/security-support-ended



OPTIONS¶
--list FILE
Use the given file as the database of packages whose
  support ends at a particular date or that is limited by specific conditions.
  The file format is plain text in columns, separated by one or more whitespace
  characters.
For --type earlyend:

•source package name

•last package version that will be supported

•the date support will end

•the rest (optional): details, and/or a URL for
  further information.
For --type ended:

•source package name

•last package version that is supported

•the date support was ended

•the rest (optional): details, and/or a URL for
  further information.
For --type limited:

•source package name

•the rest (optional): details, and/or a URL for
  further information.
If no ""--list"" is provided, the script is run for
    limited and date-defined end of support, using the lists shipped in the
    package.
By default, check-support-status evaluates the status of the
    packages according to the Debian version where it runs upon. This behavior
    can be modified using the DEBIAN_VERSION environment variable, e.g.


DEBIAN_VERSION=9 check-support-status



--no-heading
Skips printing a headline.
--status-db FILE
Use the given file to record alerts so each affected
  package is reported only once.
Default: No records, any affected package will be reported every
    time.

--except PACKAGES
Do not alert for the given binary packages
  (comma-separated list).
Default: Alert for all packages (no exceptions).

--type TYPE
One of the following:

•""earlyend"": Alert for packages whose
  support will end earlier than the distribution’s.

•""ended"": Alert for packages where
  security support has ended.

•""limited"": Alert for packages where
  security support is limited.

--version, --Version, -V
Show the version number and exit.


BUGS¶
Installations with mixed distributions like half-stable, half-testing are not
  supported.


AUTHOR¶
Christoph Biedl <debian.axhn@manchmal.in-ulm.de>


COPYRIGHT & LICENSE¶

Copyright (C) 2014 Christoph Biedl <debian.axhn@manchmal.in-ulm.de>
This package is free software; you can redistribute it and/or
modify it under the terms of the GNU General Public License
version 2 as published by the Free Software Foundation.
This package is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
You should have received a copy of the GNU General Public License
along with this program. If not, see <http://www.gnu.org/licenses/>
On Debian systems, the complete text of the GNU General Public
License version 2 can be found in
""/usr/share/common-licenses/GPL-2"".






07/10/2020
 









Source file:


check-support-status.1.en.gz (from debian-security-support 2020.06.21~deb10u1)




Source last updated:


2020-07-10T17:29:25Z




Converted to HTML:


2020-09-12T15:17:52Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# check-support-status

> Identify installed Debian packages for which support has had to be limited or prematurely ended.
> More information: <https://manpages.debian.org/buster/debian-security-support/check-support-status.1.en.html>.

- Display packages whose support is limited, has already ended or will end earlier than the distribution's end of life:

`check-support-status`

- Display only packages whose support has ended:

`check-support-status --type {{ended}}`

- Skip printing a headline:

`check-support-status --no-heading`
"
extundelete,http://extundelete.sourceforge.net,"




extundelete: An ext3 and ext4 file undeletion utility



About extundelete

extundelete is a utility that can recover deleted files from an ext3 or ext4 partition.
The ext3 and ext4 file systems are the most common default file systems in Linux distributions like Mint, Mageia, or Ubuntu.
extundelete uses information stored in the partition's journal to attempt to recover a file that has been deleted from the partition.
There is no guarantee that any particular file will be able to be undeleted, so always try to have a good backup system in place, or at least put one in place after recovering your files!

Download the latest version

The latest version of extundelete is 0.2.4, which was released in January 2013.
Download extundelete from its sourceforge project site.
For brief descriptions of the various options the program understands, see the extundelete command-line options summary.
Binary packages are available for some distibutions, but may not have the latest version, which could contain improvements to make it more likely to recover a deleted file.
To take advantage of the latest features and bug fixes, read the notes on compiling and using the program below.
extundelete has been recovering deleted files since April 2009, when the first version was released.

Why use extundelete?

extundelete is a complex program that makes data recovery from an ext3 or ext4 partition simple.
Most people are able to recover their files by running one command from the terminal, as explained in the next section.
extundelete was the first program able to restore both the contents and the file name of a deleted file on an ext4 partition.
ext3grep was the first program to use the filesystem's journal to recover data, and much of its code is shared by extundelete, but ext3grep only worked for ext3 partitions and could take hours to start recovering files if the files were on a large partition.
extundelete, by contrast, starts recovering files immediately after parsing the filesystem's journal, usually within a minute or two after starting the program.
ext4magic is a program to recover files that was based on extundelete, and has a slightly different set of features and limitations.
extundelete makes heavy use of the ext2fs library, which allows it to automatically support many features of ext3 and ext4 file systems.

Documentation
How to compile and install extundelete

To compile and install this program, you must first install the binary and development packages for e2fsprogs (called libext2fs-devel on Mageia, or e2fslibs-dev on Ubuntu, or e2fsprogs-devel on Fedora).
extundelete requires libext2fs version 1.39 or newer to run, but for ext4 support, ensure you have e2fsprogs version 1.41 or newer (which may be found by running the command 'dumpe2fs' and noting the version it outputs).
You must have g++ and GNU make to compile the program.
You can install those with the package called build-essential on Ubuntu, or gcc-c++ and make on Fedora, or gcc-c++ and make on Mageia.


To compile the program, simply enter the command
“./configure” from the directory the tar.bz2 file was extracted to.
The configure step ensures all the necessary programs to install and run extundelete have been installed.
Then, run “make” from the same directory to compile the program.
The command will generate an executable file called “extundelete” in the “src” directory.
You can the run “make install” to install the program in the /usr/bin directory, or it could be run from the “src” directory without this step.

How to use extundelete

extundelete is designed to undelete files from an unmounted partition to a separate (mounted) partition.
extundelete will restore any files it finds to a subdirectory of the current directory named “RECOVERED_FILES”.
To run the program, type “extundelete --help” to see various options available to you.


Typical usage to restore all deleted files from a partition looks like this:
$ extundelete /dev/sda4 --restore-all


For an example of running the program, see the file “README” included with the program.
It is normal for extundelete to appear to pause (while taking up a lot of cpu cycles) for a minute or longer; during this time, the program is reading the directory structure and looking for a recoverable file within it.  To restore important files quickly, you may use the --restore-file, --restore-files, or --restore-directory options.


If you have questions or comments about using extundelete or how to recover your lost files, or to report a success/failure of your recovery efforts with this utility, send a note to the extundelete mailing list.

What to do if you've deleted a file (or multiple files)

Do not save any more data to the partition with the deleted file for any reason!  Doing so may overwrite your deleted data and sabotage any recovery effort.  Many background processes will periodically write to disk, so work quickly until the partition is unmounted.


If you think the file may be still open by some program (for example, if it is a movie file currently being played by a movie player), and you know the filename, then first follow this procedure:

$ lsof|grep ""/path/to/file""
progname    5559     user    22r    REG    8,5  1282410   1294349  /path/to/file

Notice the number in the second column is 5559 and the number in the fourth column is 22.  The command to restore that file is:

$ cp /proc/5559/fd/22  restored.file



If lsof doesn't find your file, then immediately remount the partition read-only:

$ mount -o remount,ro /dev/partition
or unmount the partition:
 $ umount /dev/partition
Typically, you would replace ""partition"" in the above examples by a device name like ""sda4"" or ""hdb7"".
When either of those commands successfully completes, you can now take the next steps leisurely - you will no longer make anything worse by waiting.  If you would like to make a backup of your partition, you may do so by a command such as:
$ dd bs=4M if=/dev/partition of=partition.backup


Now is the time to run extundelete, which you may safely run on either the backup you may have made above or the raw device, as long as it is not mounted (or mounted read-only).
See the section above for details on how to use this program.
If extundelete was unable to recover your files, then you may try to recover your files with debugfs, a tool included with the e2fsprogs package.
If you unmounted the partition before the file system got a chance to fully delete the files you are interested in, running debugfs may allow you to recover the files before the file system deletes them (which it may do the next time the partition is mounted).
The 'dump' and 'rdump' commands in debugfs may be useful to you for these purposes.
If you were unable to recover your files using extundelete or debugfs, then you may try to recover your files with ext3grep or ext4magic.
The generation of ext3grep's stage2 cache file depends on the size and speed of your hard drive's partition, with typical speeds close to one minute for every 2 GB (30 s per GB, or 8 hours per TB).


If the above options didn't recover your files, then you may try a program that searches for identifying patterns throughout the entire partition, like foremost, scalpel, or Photorec.
ext3grep's --search options may also be used for this purpose.

ext3/4 filesystem details

This section lists resources about the extended filesystem families (ext2/3/4), which will be useful for those wanting to understand more about how the filesystem functions and how extundelete is able to undelete a file.
Also note that the ext3grep link provides an example of advanced usage of ext3grep, which can help explain how to use extundelete to comprehensively search for an important deleted file, as both programs have many features in common.



Information about the ext2 filesystem


e2fsprogs: the standard utilities for ext2/3/4 filesystems


Carlo Wood's explanation of the ext3 filesystem and ext3grep


Why recovering a deleted ext3 file is difficult


How extundelete works

extundelete uses some concepts and code first shown to be successful by the ext3grep program.
extundelete is able to recover the contents of an inode by searching the file system's journal for an old copy of that inode.
It then uses that information to determine the file's location within the file system.
Then, extundelete reads the corresponding data and copies it to a file in the recovery directory.


extundelete is able to match the inode number of a file to a file name by searching the deleted entries in a directory, which are often left behind after deleting the file.
If the deleted entry does not exist in the directory in the file system, extundelete will look for a match in older copies which are still in the journal.

Current abilities of extundelete


extundelete is able to undelete a file from an ext3 filesystem or an ext4 file system, as long as the ext4 filesystem has a journal.


extundelete will not restore hardlinks or softlinks, but will restore the file a link points to.


extundelete will not restore extended attributes.


If you run in to a problem that results in the program not working properly, please send a note to the mailing list, and it will likely be fixed in the next version.
For a complete example of how to use extundelete, see the README file.


Other extundelete links


extundelete SourceForge project page


extundelete mailing list - Send a message here to report your experience with extundelete, or for any other questions or comments about extundelete.


extundelete command-line options summary




",,"# extundelete

> Recover deleted files from ext3 or ext4 partitions by parsing the journal.
> See also `date` for Unix time information and `umount` for unmounting partitions.
> More information: <http://extundelete.sourceforge.net>.

- Restore all deleted files inside partition N on device X:

`sudo extundelete {{/dev/sdXN}} --restore-all`

- Restore a file from a path relative to root (Do not start the path with `/`):

`extundelete {{/dev/sdXN}} --restore-file {{path/to/file}}`

- Restore a directory from a path relative to root (Do not start the path with `/`):

`extundelete {{/dev/sdXN}} --restore-directory {{path/to/directory}}`

- Restore all files deleted after January 1st, 2020 (in Unix time):

`extundelete {{/dev/sdXN}} --restore-all --after {{1577840400}}`
"
ethtool,http://man7.org/linux/man-pages/man8/ethtool.8.html,"




ethtool(8) - Linux manual page









man7.org > Linux > man-pages



Linux/UNIX system programming training






ethtool(8) — Linux manual page




NAME | SYNOPSIS | DESCRIPTION | OPTIONS | BUGS | AUTHOR | AVAILABILITY | COLOPHON













 



ETHTOOL(8)                 System Manager's Manual                ETHTOOL(8)

NAME          top
       ethtool - query or control network driver and hardware settings

SYNOPSIS          top
       ethtool devname

       ethtool -h|--help

       ethtool --version

       ethtool [--debug N] args

       ethtool [--json] args

       ethtool --monitor [ command ] [ devname ]

       ethtool -a|--show-pause devname

       ethtool -A|--pause devname [autoneg on|off] [rx on|off] [tx on|off]

       ethtool -c|--show-coalesce devname

       ethtool -C|--coalesce devname [adaptive-rx on|off]
              [adaptive-tx on|off] [rx-usecs N] [rx-frames N]
              [rx-usecs-irq N] [rx-frames-irq N] [tx-usecs N] [tx-frames N]
              [tx-usecs-irq N] [tx-frames-irq N] [stats-block-usecs N]
              [pkt-rate-low N] [rx-usecs-low N] [rx-frames-low N]
              [tx-usecs-low N] [tx-frames-low N] [pkt-rate-high N]
              [rx-usecs-high N] [rx-frames-high N] [tx-usecs-high N]
              [tx-frames-high N] [sample-interval N]

       ethtool -g|--show-ring devname

       ethtool -G|--set-ring devname [rx N] [rx-mini N] [rx-jumbo N] [tx N]

       ethtool -i|--driver devname

       ethtool -d|--register-dump devname [raw on|off] [hex on|off] [file
              name]

       ethtool -e|--eeprom-dump devname [raw on|off] [offset N] [length N]

       ethtool -E|--change-eeprom devname [magic N] [offset N] [length N]
              [value N]

       ethtool -k|--show-features|--show-offload devname

       ethtool -K|--features|--offload devname feature on|off ...

       ethtool -p|--identify devname [N]

       ethtool -P|--show-permaddr devname

       ethtool -r|--negotiate devname

       ethtool -S|--statistics devname

       ethtool --phy-statistics devname

       ethtool -t|--test devname [offline|online|external_lb]

       ethtool -s devname [speed N] [duplex half|full] [port tp|aui|bnc|mii]
              [mdix auto|on|off] [autoneg on|off] [advertise N[/M] |
              advertise mode on|off ...]  [phyad N] [xcvr internal|external]
              [wol N[/M] | wol p|u|m|b|a|g|s|f|d...]
              [sopass xx:yy:zz:aa:bb:cc] [master-slave preferred-
              master|preferred-slave|forced-master|forced-slave] [msglvl
              N[/M] | msglvl type on|off ...]

       ethtool -n|-u|--show-nfc|--show-ntuple devname
              [ rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6 |
              rule N ]

       ethtool -N|-U|--config-nfc|--config-ntuple devname
              rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6
              m|v|t|s|d|f|n|r... |
              flow-type
              ether|ip4|tcp4|udp4|sctp4|ah4|esp4|ip6|tcp6|udp6|ah6|esp6|sctp6
              [src xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]]
              [dst xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]] [proto N [m N]]
              [src-ip ip-address [m ip-address]] [dst-ip ip-address [m ip-
              address]] [tos N [m N]] [tclass N [m N]] [l4proto N [m N]]
              [src-port N [m N]] [dst-port N [m N]] [spi N [m N]]
              [l4data N [m N]] [vlan-etype N [m N]] [vlan N [m N]]
              [user-def N [m N]] [dst-
              mac xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]] [action N]
              [context N] [loc N] |
              delete N

       ethtool -w|--get-dump devname [data filename]

       ethtool -W|--set-dump devname N

       ethtool -T|--show-time-stamping devname

       ethtool -x|--show-rxfh-indir|--show-rxfh devname

       ethtool -X|--set-rxfh-indir|--rxfh devname
              [hkey xx:yy:zz:aa:bb:cc:...]  [start N] [ equal N | weight W0
              W1 ... | default ] [hfunc FUNC] [context CTX | new] [delete]

       ethtool -f|--flash devname file [N]

       ethtool -l|--show-channels devname

       ethtool -L|--set-channels devname [rx N] [tx N] [other N]
              [combined N]

       ethtool -m|--dump-module-eeprom|--module-info devname [raw on|off]
              [hex on|off] [offset N] [length N]

       ethtool --show-priv-flags devname

       ethtool --set-priv-flags devname flag on|off ...

       ethtool --show-eee devname

       ethtool --set-eee devname [eee on|off] [tx-lpi on|off] [tx-timer N]
              [advertise N]

       ethtool --set-phy-tunable devname [ downshift on|off [count N] ] [
              fast-link-down on|off [msecs N] ] [ energy-detect-power-down
              on|off [msecs N] ]

       ethtool --get-phy-tunable devname [downshift] [fast-link-down]
              [energy-detect-power-down]

       ethtool --get-tunable devname [rx-copybreak] [tx-copybreak] [pfc-
              prevention-tout]

       ethtool --set-tunable devname [rx-copybreak N] [tx-copybreak N]
              [pfc-prevention-tout N]

       ethtool --reset devname [flags N] [mgmt] [mgmt-shared] [irq] [irq-
              shared] [dma] [dma-shared] [filter] [filter-shared] [offload]
              [offload-shared] [mac] [mac-shared] [phy] [phy-shared] [ram]
              [ram-shared] [ap] [ap-shared] [dedicated] [all]

       ethtool --show-fec devname

       ethtool --set-fec devname encoding auto|off|rs|baser|llrs [...]

       ethtool -Q|--per-queue devname [queue_mask %x] sub_command ...
               .

       ethtool --cable-test devname

       ethtool --cable-test-tdr devname [first N] [last N] [step N] [pair N]

DESCRIPTION          top
       ethtool is used to query and control network device driver and
       hardware settings, particularly for wired Ethernet devices.

       devname is the name of the network device on which ethtool should
       operate.

OPTIONS          top
       ethtool with a single argument specifying the device name prints
       current settings of the specified device.

       -h --help
              Shows a short help message.

       --version
              Shows the ethtool version number.

       --debug N
              Turns on debugging messages. Argument is interpreted as a
              mask:

              0x01  Parser information

       --json Output results in JavaScript Object Notation (JSON). Only a
              subset of options support this. Those which do not will
              continue to output plain text in the presence of this option.

       -a --show-pause
              Queries the specified Ethernet device for pause parameter
              information.

       -A --pause
              Changes the pause parameters of the specified Ethernet device.

           autoneg on|off
                  Specifies whether pause autonegotiation should be enabled.

           rx on|off
                  Specifies whether RX pause should be enabled.

           tx on|off
                  Specifies whether TX pause should be enabled.

       -c --show-coalesce
              Queries the specified network device for coalescing
              information.

       -C --coalesce
              Changes the coalescing settings of the specified network
              device.

       -g --show-ring
              Queries the specified network device for rx/tx ring parameter
              information.

       -G --set-ring
              Changes the rx/tx ring parameters of the specified network
              device.

           rx N   Changes the number of ring entries for the Rx ring.

           rx-mini N
                  Changes the number of ring entries for the Rx Mini ring.

           rx-jumbo N
                  Changes the number of ring entries for the Rx Jumbo ring.

           tx N   Changes the number of ring entries for the Tx ring.

       -i --driver
              Queries the specified network device for associated driver
              information.

       -d --register-dump
              Retrieves and prints a register dump for the specified network
              device.  The register format for some devices is known and
              decoded others are printed in hex.  When raw is enabled, then
              ethtool dumps the raw register data to stdout.  If file is
              specified, then use contents of previous raw register dump,
              rather than reading from the device.

       -e --eeprom-dump
              Retrieves and prints an EEPROM dump for the specified network
              device.  When raw is enabled, then it dumps the raw EEPROM
              data to stdout. The length and offset parameters allow dumping
              certain portions of the EEPROM.  Default is to dump the entire
              EEPROM.

           raw on|off

           offset N

           length N

       -E --change-eeprom
              If value is specified, changes EEPROM byte for the specified
              network device.  offset and value specify which byte and it's
              new value. If value is not specified, stdin is read and
              written to the EEPROM. The length and offset parameters allow
              writing to certain portions of the EEPROM.  Because of the
              persistent nature of writing to the EEPROM, a device-specific
              magic key must be specified to prevent the accidental writing
              to the EEPROM.

       -k --show-features --show-offload
              Queries the specified network device for the state of protocol
              offload and other features.

       -K --features --offload
              Changes the offload parameters and other features of the
              specified network device.  The following feature names are
              built-in and others may be defined by the kernel.

           rx on|off
                  Specifies whether RX checksumming should be enabled.

           tx on|off
                  Specifies whether TX checksumming should be enabled.

           sg on|off
                  Specifies whether scatter-gather should be enabled.

           tso on|off
                  Specifies whether TCP segmentation offload should be
                  enabled.

           ufo on|off
                  Specifies whether UDP fragmentation offload should be
                  enabled

           gso on|off
                  Specifies whether generic segmentation offload should be
                  enabled

           gro on|off
                  Specifies whether generic receive offload should be
                  enabled

           lro on|off
                  Specifies whether large receive offload should be enabled

           rxvlan on|off
                  Specifies whether RX VLAN acceleration should be enabled

           txvlan on|off
                  Specifies whether TX VLAN acceleration should be enabled

           ntuple on|off
                  Specifies whether Rx ntuple filters and actions should be
                  enabled

           rxhash on|off
                  Specifies whether receive hashing offload should be
                  enabled

       -p --identify
              Initiates adapter-specific action intended to enable an
              operator to easily identify the adapter by sight.  Typically
              this involves blinking one or more LEDs on the specific
              network port.

           [ N]   Length of time to perform phys-id, in seconds.

       -P --show-permaddr
              Queries the specified network device for permanent hardware
              address.

       -r --negotiate
              Restarts auto-negotiation on the specified Ethernet device, if
              auto-negotiation is enabled.

       -S --statistics
              Queries the specified network device for NIC- and driver-
              specific statistics.

       --phy-statistics
              Queries the specified network device for PHY specific
              statistics.

       -t --test
              Executes adapter selftest on the specified network device.
              Possible test modes are:

           offline
                  Perform full set of tests, possibly interrupting normal
                  operation during the tests,

           online Perform limited set of tests, not interrupting normal
                  operation,

           external_lb
                  Perform full set of tests, as for offline, and
                  additionally an external-loopback test.

       -s --change
              Allows changing some or all settings of the specified network
              device.  All following options only apply if -s was specified.

           speed N
                  Set speed in Mb/s.  ethtool with just the device name as
                  an argument will show you the supported device speeds.

           duplex half|full
                  Sets full or half duplex mode.

           port tp|aui|bnc|mii
                  Selects device port.

           master-slave preferred-master|preferred-slave|forced-
           master|forced-slave
                  Configure MASTER/SLAVE role of the PHY. When the PHY is
                  configured as MASTER, the PMA Transmit function shall
                  source TX_TCLK from a local clock source. When configured
                  as SLAVE, the PMA Transmit function shall source TX_TCLK
                  from the clock recovered from data stream provided by
                  MASTER. Not all devices support this.

                  preferred-master   Prefer MASTER role on autonegotiation
                  preferred-slave    Prefer SLAVE role on autonegotiation
                  forced-master      Force the PHY in MASTER role. Can be used without autonegotiation
                  forced-slave       Force the PHY in SLAVE role. Can be used without autonegotiation

           mdix auto|on|off
                  Selects MDI-X mode for port. May be used to override the
                  automatic detection feature of most adapters. An argument
                  of auto means automatic detection of MDI status, on forces
                  MDI-X (crossover) mode, while off means MDI (straight
                  through) mode.  The driver should guarantee that this
                  command takes effect immediately, and if necessary may
                  reset the link to cause the change to take effect.

           autoneg on|off
                  Specifies whether autonegotiation should be enabled.
                  Autonegotiation is enabled by default, but in some network
                  devices may have trouble with it, so you can disable it if
                  really necessary.

           advertise N
                  Sets the speed and duplex advertised by autonegotiation.
                  The argument is a hexadecimal value using one or a
                  combination of the following values:

                  0x001                  10baseT Half
                  0x002                  10baseT Full
                  0x004                  100baseT Half
                  0x008                  100baseT Full
                  0x80000000000000000    100baseT1 Full
                  0x010                  1000baseT Half               (not supported by IEEE standards)
                  0x020                  1000baseT Full
                  0x100000000000000000   1000baseT1 Full
                  0x20000                1000baseKX Full
                  0x20000000000          1000baseX Full
                  0x800000000000         2500baseT Full
                  0x8000                 2500baseX Full               (not supported by IEEE standards)
                  0x1000000000000        5000baseT Full
                  0x1000                 10000baseT Full
                  0x40000                10000baseKX4 Full
                  0x80000                10000baseKR Full
                  0x100000               10000baseR_FEC
                  0x40000000000          10000baseCR  Full
                  0x80000000000          10000baseSR  Full
                  0x100000000000         10000baseLR  Full
                  0x200000000000         10000baseLRM Full
                  0x400000000000         10000baseER  Full
                  0x200000               20000baseMLD2 Full           (not supported by IEEE standards)
                  0x400000               20000baseKR2 Full            (not supported by IEEE standards)
                  0x80000000             25000baseCR Full
                  0x100000000            25000baseKR Full
                  0x200000000            25000baseSR Full
                  0x800000               40000baseKR4 Full
                  0x1000000              40000baseCR4 Full
                  0x2000000              40000baseSR4 Full
                  0x4000000              40000baseLR4 Full
                  0x400000000            50000baseCR2 Full
                  0x800000000            50000baseKR2 Full
                  0x10000000000          50000baseSR2 Full
                  0x10000000000000       50000baseKR Full
                  0x20000000000000       50000baseSR Full
                  0x40000000000000       50000baseCR Full
                  0x80000000000000       50000baseLR_ER_FR Full
                  0x100000000000000      50000baseDR Full
                  0x8000000              56000baseKR4 Full
                  0x10000000             56000baseCR4 Full
                  0x20000000             56000baseSR4 Full
                  0x40000000             56000baseLR4 Full
                  0x1000000000           100000baseKR4 Full
                  0x2000000000           100000baseSR4 Full
                  0x4000000000           100000baseCR4 Full
                  0x8000000000           100000baseLR4_ER4 Full
                  0x200000000000000      100000baseKR2 Full
                  0x400000000000000      100000baseSR2 Full
                  0x800000000000000      100000baseCR2 Full
                  0x1000000000000000     100000baseLR2_ER2_FR2 Full
                  0x2000000000000000     100000baseDR2 Full
                  0x4000000000000000     200000baseKR4 Full
                  0x8000000000000000     200000baseSR4 Full
                  0x10000000000000000    200000baseLR4_ER4_FR4 Full
                  0x20000000000000000    200000baseDR4 Full
                  0x40000000000000000    200000baseCR4 Full

           phyad N
                  PHY address.

           xcvr internal|external
                  Selects transceiver type. Currently only internal and
                  external can be specified, in the future further types
                  might be added.

           wol p|u|m|b|a|g|s|f|d...
                  Sets Wake-on-LAN options.  Not all devices support this.
                  The argument to this option is a string of characters
                  specifying which options to enable.

                  p   Wake on PHY activity
                  u   Wake on unicast messages
                  m   Wake on multicast messages
                  b   Wake on broadcast messages
                  a   Wake on ARP
                  g   Wake on MagicPacketâ¢
                  s   Enable SecureOnâ¢ password for MagicPacketâ¢
                  f   Wake on filter(s)
                  d   Disable (wake on nothing).  This option
                      clears all previous options.

           sopass xx:yy:zz:aa:bb:cc
                  Sets the SecureOnâ¢ password.  The argument to this option
                  must be 6 bytes in Ethernet MAC hex format
                  (xx:yy:zz:aa:bb:cc).

           msglvl N
           msglvl type on|off ...
                  Sets the driver message type flags by name or number. type
                  names the type of message to enable or disable; N
                  specifies the new flags numerically. The defined type
                  names and numbers are:

                  drv         0x0001  General driver status
                  probe       0x0002  Hardware probing
                  link        0x0004  Link state
                  timer       0x0008  Periodic status check
                  ifdown      0x0010  Interface being brought down
                  ifup        0x0020  Interface being brought up
                  rx_err      0x0040  Receive error
                  tx_err      0x0080  Transmit error
                  tx_queued   0x0100  Transmit queueing
                  intr        0x0200  Interrupt handling
                  tx_done     0x0400  Transmit completion
                  rx_status   0x0800  Receive completion
                  pktdata     0x1000  Packet contents
                  hw          0x2000  Hardware status
                  wol         0x4000  Wake-on-LAN status

                  The precise meanings of these type flags differ between
                  drivers.

       -n -u --show-nfc --show-ntuple
              Retrieves receive network flow classification options or
              rules.

           rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6
                  Retrieves the hash options for the specified flow type.

                  tcp4    TCP over IPv4
                  udp4    UDP over IPv4
                  ah4     IPSEC AH over IPv4
                  esp4    IPSEC ESP over IPv4
                  sctp4   SCTP over IPv4
                  tcp6    TCP over IPv6
                  udp6    UDP over IPv6
                  ah6     IPSEC AH over IPv6
                  esp6    IPSEC ESP over IPv6
                  sctp6   SCTP over IPv6

           rule N Retrieves the RX classification rule with the given ID.

       -N -U --config-nfc --config-ntuple
              Configures receive network flow classification options or
              rules.

           rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6
           m|v|t|s|d|f|n|r...
                  Configures the hash options for the specified flow type.

                  m   Hash on the Layer 2 destination address of the rx packet.
                  v   Hash on the VLAN tag of the rx packet.
                  t   Hash on the Layer 3 protocol field of the rx packet.
                  s   Hash on the IP source address of the rx packet.
                  d   Hash on the IP destination address of the rx packet.
                  f   Hash on bytes 0 and 1 of the Layer 4 header of the rx packet.
                  n   Hash on bytes 2 and 3 of the Layer 4 header of the rx packet.
                  r   Discard all packets of this flow type. When this option is
                      set, all other options are ignored.

           flow-type
           ether|ip4|tcp4|udp4|sctp4|ah4|esp4|ip6|tcp6|udp6|ah6|esp6|sctp6
                  Inserts or updates a classification rule for the specified
                  flow type.

                  ether   Ethernet
                  ip4     Raw IPv4
                  tcp4    TCP over IPv4
                  udp4    UDP over IPv4
                  sctp4   SCTP over IPv4
                  ah4     IPSEC AH over IPv4
                  esp4    IPSEC ESP over IPv4
                  ip6     Raw IPv6
                  tcp6    TCP over IPv6
                  udp6    UDP over IPv6
                  sctp6   SCTP over IPv6
                  ah6     IPSEC AH over IPv6
                  esp6    IPSEC ESP over IPv6

           For all fields that allow both a value and a mask to be
           specified, the mask may be specified immediately after the value
           using the m keyword, or separately using the field name keyword
           with -mask appended, e.g. src-mask.

           src xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]
                  Includes the source MAC address, specified as 6 bytes in
                  hexadecimal separated by colons, along with an optional
                  mask.  Valid only for flow-type ether.

           dst xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]
                  Includes the destination MAC address, specified as 6 bytes
                  in hexadecimal separated by colons, along with an optional
                  mask.  Valid only for flow-type ether.

           proto N [m N]
                  Includes the Ethernet protocol number (ethertype) and an
                  optional mask.  Valid only for flow-type ether.

           src-ip ip-address [m ip-address]
                  Specify the source IP address of the incoming packet to
                  match along with an optional mask.  Valid for all IP based
                  flow-types.

           dst-ip ip-address [m ip-address]
                  Specify the destination IP address of the incoming packet
                  to match along with an optional mask.  Valid for all IP
                  based flow-types.

           tos N [m N]
                  Specify the value of the Type of Service field in the
                  incoming packet to match along with an optional mask.
                  Applies to all IPv4 based flow-types.

           tclass N [m N]
                  Specify the value of the Traffic Class field in the
                  incoming packet to match along with an optional mask.
                  Applies to all IPv6 based flow-types.

           l4proto N [m N]
                  Includes the layer 4 protocol number and optional mask.
                  Valid only for flow-types ip4 and ip6.

           src-port N [m N]
                  Specify the value of the source port field (applicable to
                  TCP/UDP packets) in the incoming packet to match along
                  with an optional mask.  Valid for flow-types ip4, tcp4,
                  udp4, and sctp4 and their IPv6 equivalents.

           dst-port N [m N]
                  Specify the value of the destination port field
                  (applicable to TCP/UDP packets)in the incoming packet to
                  match along with an optional mask.  Valid for flow-types
                  ip4, tcp4, udp4, and sctp4 and their IPv6 equivalents.

           spi N [m N]
                  Specify the value of the security parameter index field
                  (applicable to AH/ESP packets)in the incoming packet to
                  match along with an optional mask.  Valid for flow-types
                  ip4, ah4, and esp4 and their IPv6 equivalents.

           l4data N [m N]
                  Specify the value of the first 4 Bytes of Layer 4 in the
                  incoming packet to match along with an optional mask.
                  Valid for ip4 and ip6 flow-types.

           vlan-etype N [m N]
                  Includes the VLAN tag Ethertype and an optional mask.

           vlan N [m N]
                  Includes the VLAN tag and an optional mask.

           user-def N [m N]
                  Includes 64-bits of user-specific data and an optional
                  mask.

           dst-mac xx:yy:zz:aa:bb:cc [m xx:yy:zz:aa:bb:cc]
                  Includes the destination MAC address, specified as 6 bytes
                  in hexadecimal separated by colons, along with an optional
                  mask.  Valid for all IP based flow-types.

           action N
                  Specifies the Rx queue to send packets to, or some other
                  action.

                  -1            Drop the matched flow
                  -2            Use the matched flow as a Wake-on-LAN filter
                  0 or higher   Rx queue to route the flow

           context N
                  Specifies the RSS context to spread packets over multiple
                  queues; either 0 for the default RSS context, or a value
                  returned by ethtool -X ... context new.

           vf N   Specifies the Virtual Function the filter applies to. Not
                  compatible with action.

           queue N
                  Specifies the Rx queue to send packets to. Not compatible
                  with action.

           loc N  Specify the location/ID to insert the rule. This will
                  overwrite any rule present in that location and will not
                  go through any of the rule ordering process.

           delete N
                  Deletes the RX classification rule with the given ID.

       -w --get-dump
              Retrieves and prints firmware dump for the specified network
              device.  By default, it prints out the dump flag, version and
              length of the dump data.  When data is indicated, then ethtool
              fetches the dump data and directs it to a file.

       -W --set-dump
              Sets the dump flag for the device.

       -T --show-time-stamping
              Show the device's time stamping capabilities and associated
              PTP hardware clock.

       -x --show-rxfh-indir --show-rxfh
              Retrieves the receive flow hash indirection table and/or RSS
              hash key.

       -X --set-rxfh-indir --rxfh
              Configures the receive flow hash indirection table and/or RSS
              hash key.

           hkey   Sets RSS hash key of the specified network device. RSS
                  hash key should be of device supported length.  Hash key
                  format must be in xx:yy:zz:aa:bb:cc format meaning both
                  the nibbles of a byte should be mentioned even if a nibble
                  is zero.

           hfunc  Sets RSS hash function of the specified network device.
                  List of RSS hash functions which kernel supports is shown
                  as a part of the --show-rxfh command output.

           start N
                  For the equal and weight options, sets the starting
                  receive queue for spreading flows to N.

           equal N
                  Sets the receive flow hash indirection table to spread
                  flows evenly between the first N receive queues.

           weight W0 W1 ...
                  Sets the receive flow hash indirection table to spread
                  flows between receive queues according to the given
                  weights.  The sum of the weights must be non-zero and must
                  not exceed the size of the indirection table.

           default
                  Sets the receive flow hash indirection table to its
                  default value.

           context CTX | new
                  Specifies an RSS context to act on; either new to allocate
                  a new RSS context, or CTX, a value returned by a previous
                  ... context new.

           delete Delete the specified RSS context.  May only be used in
                  conjunction with context and a non-zero CTX value.

       -f --flash
              Write a firmware image to flash or other non-volatile memory
              on the device.

           file   Specifies the filename of the firmware image.  The
                  firmware must first be installed in one of the directories
                  where the kernel firmware loader or firmware agent will
                  look, such as /lib/firmware.

           N      If the device stores multiple firmware images in separate
                  regions of non-volatile memory, this parameter may be used
                  to specify which region is to be written.  The default is
                  0, requesting that all regions are written.  All other
                  values are driver-dependent.

       -l --show-channels
              Queries the specified network device for the numbers of
              channels it has.  A channel is an IRQ and the set of queues
              that can trigger that IRQ.

       -L --set-channels
              Changes the numbers of channels of the specified network
              device.

           rx N   Changes the number of channels with only receive queues.

           tx N   Changes the number of channels with only transmit queues.

           other N
                  Changes the number of channels used only for other
                  purposes e.g. link interrupts or SR-IOV co-ordination.

           combined N
                  Changes the number of multi-purpose channels.

       -m --dump-module-eeprom --module-info
              Retrieves and if possible decodes the EEPROM from plugin
              modules, e.g SFP+, QSFP.  If the driver and module support it,
              the optical diagnostic information is also read and decoded.

       --show-priv-flags
              Queries the specified network device for its private flags.
              The names and meanings of private flags (if any) are defined
              by each network device driver.

       --set-priv-flags
              Sets the device's private flags as specified.

           flag on|off Sets the state of the named private flag.

       --show-eee
              Queries the specified network device for its support of
              Energy-Efficient Ethernet (according to the IEEE 802.3az
              specifications)

       --set-eee
              Sets the device EEE behaviour.

           eee on|off
                  Enables/disables the device support of EEE.

           tx-lpi on|off
                  Determines whether the device should assert its Tx LPI.

           advertise N
                  Sets the speeds for which the device should advertise EEE
                  capabilities.  Values are as for --change advertise

           tx-timer N
                  Sets the amount of time the device should stay in idle
                  mode prior to asserting its Tx LPI (in microseconds). This
                  has meaning only when Tx LPI is enabled.

       --set-phy-tunable
              Sets the PHY tunable parameters.

           downshift on|off
                  Specifies whether downshift should be enabled.

                  count N
                      Sets the PHY downshift re-tries count.

           fast-link-down on|off
                  Specifies whether Fast Link Down should be enabled and
                  time until link down (if supported).

                  msecs N
                      Sets the period after which the link is reported as down. Note that the PHY may choose
                      the closest supported value. Only on reading back the tunable do you get the actual value.

           energy-detect-power-down on|off
                  Specifies whether Energy Detect Power Down (EDPD) should
                  be enabled (if supported).  This will put the RX and TX
                  circuit blocks into a low power mode, and the PHY will
                  wake up periodically to send link pulses to avoid any
                  lock-up situation with a peer PHY that may also have EDPD
                  enabled. By default, this setting will also enable the
                  periodic transmission of TX pulses.

                  msecs N
                      Some PHYs support configuration of the wake-up interval to send TX pulses.
                      This setting allows the control of this interval, and 0 disables TX pulses
                      if the PHY supports this. Disabling TX pulses can create a lock-up situation
                      where neither of the PHYs wakes the other one. If unspecified the default
                      value (in milliseconds) will be used by the PHY.

       --get-phy-tunable
              Gets the PHY tunable parameters.

           downshift
                  For operation in cabling environments that are
                  incompatible with 1000BASE-T, PHY device provides an
                  automatic link speed downshift operation.  Link speed
                  downshift after N failed 1000BASE-T auto-negotiation
                  attempts.  Downshift is useful where cable does not have
                  the 4 pairs instance.

                  Gets the PHY downshift count/status.

           fast-link-down
                  Depending on the mode it may take 0.5s - 1s until a broken
                  link is reported as down.  In certain use cases a link-
                  down event needs to be reported as soon as possible.  Some
                  PHYs support a Fast Link Down Feature and may allow
                  configuration of the delay before a broken link is
                  reported as being down.

                  Gets the PHY Fast Link Down status / period.

           energy-detect-power-down
                  Gets the current configured setting for Energy Detect
                  Power Down (if supported).

       --get-tunable
              Get the tunable parameters.

           rx-copybreak
                  Get the current rx copybreak value in bytes.

           tx-copybreak
                  Get the current tx copybreak value in bytes.

           pfc-prevention-tout
                  Get the current pfc prevention timeout value in msecs.

       --set-tunable
              Set driver's tunable parameters.

           rx-copybreak N
                  Set the rx copybreak value in bytes.

           tx-copybreak N
                  Set the tx copybreak value in bytes.

           pfc-prevention-tout N
                  Set pfc prevention timeout in msecs. Value of 0 means
                  disable and 65535 means auto.

       --reset
              Reset hardware components specified by flags and components
              listed below

           flags N
                  Resets the components based on direct flags mask

           mgmt   Management processor

           irq    Interrupt requester

           dma    DMA engine

           filter Filtering/flow direction

           offload
                  Protocol offload

           mac    Media access controller

           phy    Transceiver/PHY

           ram    RAM shared between multiple components ap Application
                  Processor

           dedicated
                  All components dedicated to this interface

           all    All components used by this interface, even if shared

       --show-fec
              Queries the specified network device for its support of
              Forward Error Correction.

       --set-fec
              Configures Forward Error Correction for the specified network
              device.

              Forward Error Correction modes selected by a user are expected
              to be persisted after any hotplug events. If a module is
              swapped that does not support the current FEC mode, the driver
              or firmware must take the link down administratively and
              report the problem in the system logs for users to correct.

           encoding auto|off|rs|baser|llrs [...]

                  Sets the FEC encoding for the device.  Combinations of
                  options are specified as e.g.  encoding auto rs ; the
                  semantics of such combinations vary between drivers.

                  auto    Use the driver's default encoding
                  off     Turn off FEC
                  RS      Force RS-FEC encoding
                  BaseR   Force BaseR encoding
                  LLRS    Force LLRS-FEC encoding

       -Q|--per-queue
              Applies provided sub command to specific queues.

           queue_mask %x
                  Sets the specific queues which the sub command is applied
                  to.  If queue_mask is not set, the sub command will be
                  applied to all queues.

           sub_command
                  Sub command to apply. The supported sub commands include
                  --show-coalesce and --coalesce.

       q.B --cable-test
              Perform a cable test and report the results. What results are
              returned depends on the capabilities of the network interface.
              Typically open pairs and shorted pairs can be reported, along
              with pairs being O.K. When a fault is detected the approximate
              distance to the fault may be reported.

       --cable-test-tdr
              Perform a cable test and report the raw Time Domain
              Reflectometer data.  A pulse is sent down a cable pair and the
              amplitude of the reflection, for a given distance, is
              reported. A break in the cable returns a big reflection. Minor
              damage to the cable returns a small reflection. If the cable
              is shorted, the amplitude of the reflection can be negative.
              By default, data is returned for lengths between 0 and 150m at
              1m steps, for all pairs. However parameters can be passed to
              restrict the collection of data. It should be noted, that the
              interface will round the distances to whatever granularity is
              actually implemented. This is often 0.8 of a meter. The
              results should include the actual rounded first and last
              distance and step size.

           first  N
                  Distance along the cable, in meters, where the first
                  measurement should be made.

           last  N
                  Distance along the cable, in meters, where the last
                  measurement should be made.

           step  N
                  Distance, in meters, between each measurement.

           pair  N
                  Which pair should be measured. Typically a cable has 4
                  pairs. 0 = Pair A, 1 = Pair B, ...

       --monitor
              Listens to netlink notification and displays them.

           command
                  If argument matching a command is used, ethtool only shows
                  notifications of this type. Without such argument or with
                  --all, all notification types are shown.

           devname
                  If a device name is used as argument, only notification
                  for this device are shown. Default is to show
                  notifications for all devices.

BUGS          top
       Not supported (in part or whole) on all network drivers.

AUTHOR          top
       ethtool was written by David Miller.

       Modifications by Jeff Garzik, Tim Hockin, Jakub Jelinek, Andre
       Majorel, Eli Kupermann, Scott Feldman, Andi Kleen, Alexander Duyck,
       Sucheta Chakraborty, Jesse Brandeburg, Ben Hutchings, Scott Branden.

AVAILABILITY          top
       ethtool is available from 
       â¨http://www.kernel.org/pub/software/network/ethtool/â©

COLOPHON          top
       This page is part of the ethtool (utility for controlling network
       drivers and hardware) project.  Information about the project can be
       found at â¨https://www.kernel.org/pub/software/network/ethtool/â©.  If
       you have a bug report for this manual page, send it to
       bwh@kernel.org, netdev@vger.kernel.org.  This page was obtained from
       the project's upstream Git repository
       â¨git://git.kernel.org/pub/scm/network/ethtool/ethtool.gitâ© on
       2020-08-13.  (At that time, the date of the most recent commit that
       was found in the repository was 2020-08-04.)  If you discover any
       rendering problems in this HTML version of the page, or you believe
       there is a better or more up-to-date source for the page, or you have
       corrections or improvements to the information in this COLOPHON
       (which is not part of the original manual page), send a mail to
       man-pages@man7.org

Ethtool version 5.8               Aug 2020                        ETHTOOL(8)


Pages that refer to this page: 
    veth(4),  
    ip-link(8),  
    ovs-l3ping(8)








            HTML rendering created 2020-08-13
            by Michael Kerrisk, 
            author of 
            The Linux Programming Interface, 
            maintainer of the 
            Linux man-pages project.
        

            For details of in-depth
            Linux/UNIX system programming training courses
            that I teach, look here.
        

            Hosting by jambit GmbH.
        



























",,"# ethtool

> Display and modify Network Interface Controller (NIC) parameters.
> More information: <http://man7.org/linux/man-pages/man8/ethtool.8.html>.

- Set the link speed, duplex mode, and parameter autonegotiation for a given interface:

`ethtool -s {{eth0}} speed {{10|100|1000}} duplex {{half|full}} autoneg {{on|off}}`
"
guake,,,,"# guake

> A drop-down terminal for GNOME.

- Toggle Guake visiblity:

`F12`

- Toggle fullscreen mode:

`F11`

- Open a new tab:

`Ctrl+Shift+T`

- Close the terminal:

`Super+X`

- Go to the previous tab:

`Ctrl+PageUp`

- Search the selected text in the browser:

`Shift+Ctrl+L`
"
tcpflow,,,,"# tcpflow

> Capture TCP traffic for debugging and analysis.

- Show all data on the given interface and port:

`tcpflow -c -i {{eth0}} port {{80}}`
"
apt-file,,,,"# apt-file

> Search for files in apt packages, including ones not yet installed.

- Update the metadata database:

`sudo apt update`

- Search for packages that contain the specified file or path:

`apt-file search {{part/of/filename}}`

- List the contents of a specific package:

`apt-file list {{package_name}}`
"
apt-add-repository,,,,"# apt-add-repository

> Manages apt repository definitions.

- Add a new apt repository:

`apt-add-repository {{repository_spec}}`

- Remove an apt repository:

`apt-add-repository --remove {{repository_spec}}`

- Update the package cache after adding a repository:

`apt-add-repository --update {{repository_spec}}`

- Enable source packages:

`apt-add-repository --enable-source {{repository_spec}}`
"
squeue,,,,"# squeue

> View the jobs queued in the SLURM scheduler.

- View the queue:

`squeue`

- View jobs queued by a specific user:

`squeue -u {{username}}`

- View the queue and refresh every 5 seconds:

`squeue -i {{5}}`

- View the queue with expected start times:

`squeue --start`
"
mcookie,,,,"# mcookie

> Generates random 128 bit hexadecimal numbers.

- Generate a random number:

`mcookie`

- Generate a random number, using the contents of a file as a seed for the randomness:

`mcookie --file {{path/to/file}}`

- Generate a random number, using a specific number of bytes from a file as a seed for the randomness:

`mcookie --file {{path/to/file}} --max-size {{number_of_bytes}}`

- Print the details of the randomness used, such as the origin and seed for each source:

`mcookie --verbose`
"
xfce4-terminal,,,,"# xfce4-terminal

> The XFCE4 terminal emulator.

- Open a new terminal window:

`xfce4-terminal`

- Set the initial title:

`xfce4-terminal --initial-title ""{{initial_title}}""`

- Open a new tab in the current terminal window:

`xfce4-terminal --tab`

- Execute a command in a new terminal window:

`xfce4-terminal --command ""{{command_with_args}}""`

- Keep the terminal around after the executed command finishes executing:

`xfce4-terminal --command ""{{command_with_args}}"" --hold`

- Open multiple new tabs, executing a command in each:

`xfce4-terminal --tab --command ""{{command_a}}"" --tab --command ""{{command_b}}""`
"
enum4linux,,,,"# enum4linux

> Tool for enumerating Windows and Samba information from remote systems.
> It attempts to offer similar functionality to enum.exe formerly available from www.bindview.com.

- Try to enumerate using all methods:

`enum4linux -a {{remote_host}}`

- Enumerate using given login credentials:

`enum4liux -u {{user_name}} -p {{password}} {{remote_host}}`

- List usernames from a given host:

`enum4liux -U {{remote_host}}`

- List shares:

`enum4liux -S {{remote_host}}`

- Get OS information:

`enum4liux -o {{remote_host}}`
"
a2enmod,https://manpages.debian.org/buster/apache2/a2enmod.8.en.html,"



a2enmod(8) — apache2 — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / apache2
     
     
     
     / a2enmod(8)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


EXIT STATUS


EXAMPLES


FILES


SEE ALSO


AUTHOR







other versions




buster 2.4.38-3+deb10u3


buster-backports 2.4.46-1~bpo10+1


testing 2.4.46-1


unstable 2.4.46-1






Scroll to navigation



A2ENMOD(8)
System Manager's Manual
A2ENMOD(8)




NAME¶
a2enmod, a2dismod - enable or disable an apache2 module


SYNOPSIS¶
a2enmod [ [-q|--quiet] module]
a2dismod [ [-q|--quiet] module]


DESCRIPTION¶
This manual page documents briefly the a2enmod and a2dismod
  commands.
a2enmod is a script that enables the specified module
    within the apache2 configuration. It does this by creating symlinks
    within /etc/apache2/mods-enabled. Likewise, a2dismod disables
    a module by removing those symlinks. It is not an error to enable a module
    which is already enabled, or to disable one which is already disabled.
Note that many modules have, in addition to a .load file, an
    associated .conf file. Enabling the module puts the configuration directives
    in the .conf file as directives into the main server context of
    apache2.


OPTIONS¶

-q, --quiet
Don't show informative messages.
-m, --maintmode
Enables the maintainer mode, that is the program invocation is effectuated
      automatically by a maintainer script. This switch should not be used by
      end users.
-p, --purge
When disabling a module, purge all traces of the module in the internal
      state data base.



EXIT STATUS¶
a2enmod and a2dismod exit with status 0 if all modules are
  processed successfully, 1 if errors occur, 2 if an invalid option was used.


EXAMPLES¶
a2enmod imagemap

a2dismod mime_magic
Enables the mod_imagemap module, and disables the
    mod_mime_magic module.


FILES¶

/etc/apache2/mods-available
Directory with files giving information on available modules.
/etc/apache2/mods-enabled
Directory with links to the files in mods-available for enabled
      modules.



SEE ALSO¶
apache2ctl(8), a2enconf(8), a2disconf(8).


AUTHOR¶
This manual page was written by Daniel Stone <daniel@sfarc.net> for the
  Debian GNU/Linux distribution, as it is a Debian-specific script with the
  package.




12 October 2006










Source file:


a2enmod.8.en.gz (from apache2 2.4.38-3+deb10u3)




Source last updated:


2019-10-15T19:53:42Z




Converted to HTML:


2020-09-01T03:18:56Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# a2enmod

> Enable an Apache module on Debian-based OSes.
> More information: <https://manpages.debian.org/buster/apache2/a2enmod.8.en.html>.

- Enable a module:

`sudo a2enmod {{module}}`

- Don't show informative messages:

`sudo a2enmod --quiet {{module}}`
"
cpuid,,,,"# cpuid

> Display detailed information about all CPUs.

- Display information for all CPUs:

`cpuid`

- Display information only for the current CPU:

`cpuid -1`

- Display raw hex information with no decoding:

`cpuid -r`
"
notify-send,,,,"# notify-send

> Uses the current desktop environment's notification system to create a notification.

- Show a notification with the title ""Test"" and the content ""This is a test"":

`notify-send {{""Test""}} {{""This is a test""}}`

- Show a notification with a custom icon:

`notify-send -i {{icon.png}} {{""Test""}} {{""This is a test""}}`

- Show a notification for 5 seconds:

`notify-send -t 5000 {{""Test""}} {{""This is a test""}}`

- Show a notification with an app's icon:

`notify-send {{""Test""}} --icon={{google-chrome}}`
"
ufw,,,,"# ufw

> Uncomplicated Firewall.
> Frontend for iptables aiming to make configuration of a firewall easier.

- Enable ufw:

`ufw enable`

- Disable ufw:

`ufw disable`

- Show ufw rules, along with their numbers:

`ufw status numbered`

- Allow incoming traffic on port 5432 on this host with a comment identifying the service:

`ufw allow {{5432}} comment {{""Service""}}`

- Allow only TCP traffic from 192.168.0.4 to any address on this host, on port 22:

`ufw allow proto {{tcp}} from {{192.168.0.4}} to {{any}} port {{22}}`

- Deny traffic on port 80 on this host:

`ufw deny {{80}}`

- Deny all UDP traffic to port 22:

`ufw deny proto {{udp}} from {{any}} to {{any}} port {{22}}`

- Delete a particular rule. The rule number can be retrieved from the `ufw status numbered` command:

`ufw delete {{rule_number}}`
"
mandb,,,,"# mandb

> Manage the pre-formatted manual page database.

- Purge and process manual pages:

`mandb`

- Update a single entry:

`mandb --filename {{path/to/file}}`

- Create entries from scratch instead of updating:

`mandb --create`

- Only process user databases:

`mandb --user-db`

- Do not purge obsolete entries:

`mandb --no-purge`

- Check the validity of manual pages:

`mandb --test`
"
radeontop,https://github.com/clbr/radeontop,"













GitHub - clbr/radeontop








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















clbr

/

radeontop







    Watch
 
      17
    




      Star


      331
    




          Fork


        44
      







            GPL-3.0 License
        




331
        stars
 

44
        forks
 




      Star





    Watch









Code

 



Issues
17
 



Pull requests
4
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



15
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit






 




clbr

Update pot file



…



ef27e8b

Apr 15, 2020





Update pot file


ef27e8b



Git stats





269
commits







Files
Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






include



Transparency support



Apr 15, 2020







translations



Update pot file



Apr 15, 2020







.gitignore



Add optional unprivileged mode in Xorg



Jul 4, 2016







COPYING



GPLv3 this



Jul 7, 2012







Makefile



Round the size of the percentage bar to the nearest integer



Nov 4, 2019







README.md



Add Screenshot



Oct 18, 2019







amdgpu.c



Rework of DRM initialization code



Sep 30, 2019







auth.c



Add a warning when failing to drop DRM master



Sep 30, 2019







auth_xcb.c



Rework of DRM initialization code



Sep 30, 2019







detect.c



Add support to open DRM device nodes by pathname



Sep 30, 2019







dump.c



Display shader clock on APUs



Aug 14, 2019







family_str.c



Update pci ids: arcturus, renoir, navi12, navi14



Dec 18, 2019







familycheck.sh



Add a script to check enum consistency



Oct 1, 2014







getamdgpuids.sh



Add support for Topaz, Tonga, and Carrizo



Aug 6, 2015







getver.sh



getver.sh: Only use git if its a git repo.



Dec 9, 2018







radeon.c



Rework of DRM initialization code



Sep 30, 2019







radeontop.1



Refresh man page



Sep 30, 2019







radeontop.asc



Add support to open DRM device nodes by pathname



Sep 30, 2019







radeontop.c



Transparency support



Apr 15, 2020







radeontop.metainfo.xml



Add appstream info file, from luyatshimbalanga



Aug 7, 2017







ticks.c



Use directly the backend functions to get GPU usage



Aug 14, 2019







ui.c



Transparency style fixes



Apr 15, 2020





        View code
      






        README.md
      


RadeonTop
View your GPU utilization, both for the total activity percent and individual blocks.
Requires access to /dev/dri/cardN files or /dev/mem (root privileges).

Supported cards
R600 and up, even Southern Islands should work fine.
Works with both the open drivers and AMD Catalyst.
For the Catalyst driver, only the mem path is currently supported - this
means it won't run on the default Ubuntu kernels that block /dev/mem.
The total GPU utilization is also valid for OpenCL loads; the other blocks
are only useful in GL loads.
Translations
If you'd like to translate RadeonTop to your own language, please go here:
https://translations.launchpad.net/radeontop
Running
Prerequisites

libdrm
libncurses
libpciaccess
libxcb

Simply start radeontop and it auto-selects the first supported GPU:
./radeontop

Running radeontop on a bus 0f:
./radeontop -b 0f

Writing values to stdout instead of showing a GUI:
./radeontop -d -

Getting all options:
./radeontop --help

Building
Prerequisites

all run time prerequisites with dev files
gcc / clang
pkgconf

Building
If all prerequisites are fullfilled, it can be build by simply running:
make

Build options
Build options can be specified to having the following variables being set to ""1""
nls     enable translations, default on
debug   enable debug symbols, default off
nostrip disable stripping, default off
plain   apply neither gcc's -g nor -s.
xcb     enable libxcb to run unprivileged in Xorg, default on
amdgpu  enable amdgpu usage reporting, default auto (requires libdrm >= 2.4.63)

Example:
make amdgpu=1 xcb=1

This will build radeontop with amdgpu reporting and xcb support.








About

      No description, website, or topics provided.
    
Resources



      Readme
 
License



        GPL-3.0 License
    







    Releases



15
tags







    Packages 0


        No packages published 













    Contributors 15





 



 



 



 



 



 



 



 



 



 



 



      + 4 contributors





Languages












C
65.0%





C++
24.6%





Makefile
4.7%





Roff
4.2%





Shell
1.5%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# radeontop

> Show utilisation of AMD GPUs.
> More information: <https://github.com/clbr/radeontop>.

- Show the utilisation of the default AMD GPU:

`sudo radeontop`

- Enable colourised output:

`sudo radeontop --colour`

- Select a specific GPU (the bus number is the first number in the output of `lspci`):

`sudo radeontop --bus {{bus_number}}`

- Specify the display refresh rate (higher means more GPU overhead):

`sudo radeontop --ticks {{samples_per_second}}`
"
dash,,,,"# dash

> Debian Almquist Shell.
> Modern POSIX-compliant implementation of `sh` (isn't Bash compatible).

- Start interactive shell:

`dash`

- Execute a command:

`dash -c ""{{command}}""`

- Run commands from a file:

`dash {{file.sh}}`

- Run commands from a file, logging all commands executed to the terminal:

`dash -x {{file.sh}}`
"
at,,,"
AT(1)			  BSD General Commands Manual			 AT(1)

NAME
     at, batch, atq, atrm -- queue, examine, or delete jobs for later execu-
     tion

SYNOPSIS
     at [-q queue] [-f file] [-mldbv] time
     at [-q queue] [-f file] [-mldbv] -t [[CC]YY]MMDDhhmm[.SS]
     at -c job [job ...]
     at -l [job ...]
     at -l -q queue
     at -r job [job ...]

     atq [-q queue] [-v]

     atrm job [job ...]

     batch [-q queue] [-f file] [-mv] [time]

DESCRIPTION
     The at and batch utilities read commands from standard input or a speci-
     fied file.  The commands are executed at a later time, using sh(1).

     at      executes commands at a specified time;

     atq     lists the user's pending jobs, unless the user is the superuser;
	     in that case, everybody's jobs are listed;

     atrm    deletes jobs;

     batch   executes commands when system load levels permit; in other words,
	     when the load average drops below _LOADAVG_MX (1.5), or the value
	     specified in the invocation of atrun.

     The at utility allows some moderately complex time specifications.  It
     accepts times of the form HHMM or HH:MM to run a job at a specific time
     of day.  (If that time is already past, the next day is assumed.)	As an
     alternative, the following keywords may be specified: midnight, noon, or
     teatime (4pm) and time-of-day may be suffixed with AM or PM for running
     in the morning or the evening.  The day on which the job is to be run may
     also be specified by giving a date in the form month-name day with an
     optional year, or giving a date of the forms DD.MM.YYYY, DD.MM.YY,
     MM/DD/YYYY, MM/DD/YY, MMDDYYYY, or MMDDYY.  The specification of a date
     must follow the specification of the time of day.	Time can also be spec-
     ified as: [now] + count time-units, where the time-units can be minutes,
     hours, days, weeks, months or years and at may be told to run the job
     today by suffixing the time with today and to run the job tomorrow by
     suffixing the time with tomorrow.	The shortcut next can be used instead
     of + 1.

     For example, to run a job at 4pm three days from now, use at 4pm + 3
     days, to run a job at 10:00am on July 31, use at 10am Jul 31 and to run a
     job at 1am tomorrow, use at 1am tomorrow.

     The at utility also supports the POSIX time format (see -t option).

     For both at and batch, commands are read from standard input or the file
     specified with the -f option.  The working directory, the environment
     (except for the variables TERM, TERMCAP, DISPLAY and _), and the umask
     are retained from the time of invocation.	An at or batch command invoked
     from a su(1) shell will retain the current userid.  The user will be
     mailed standard error and standard output from his commands, if any.
     Mail will be sent using the command sendmail(8).  If at is executed from
     a su(1) shell, the owner of the login shell will receive the mail.

     The superuser may use these commands in any case.	For other users, per-
     mission to use at is determined by the files _PERM_PATH/at.allow and
     _PERM_PATH/at.deny.

     If the file _PERM_PATH/at.allow exists, only usernames mentioned in it
     are allowed to use at.  In these two files, a user is considered to be
     listed only if the user name has no blank or other characters before it
     on its line and a newline character immediately after the name, even at
     the end of the file.  Other lines are ignored and may be used for com-
     ments.

     If _PERM_PATH/at.allow does not exist, _PERM_PATH/at.deny is checked,
     every username not mentioned in it is then allowed to use at.

     If neither exists, only the superuser is allowed use of at.

IMPLEMENTATION NOTES
     Note that at is implemented through the launchd(8) daemon periodically
     invoking atrun(8), which is disabled by default.  See atrun(8) for infor-
     mation about enabling atrun.

OPTIONS
     -b      Is an alias for batch.

     -c      Cat the jobs listed on the command line to standard output.

     -d      Is an alias for atrm (this option is deprecated; use -r instead).

     -f file
	     Read the job from file rather than standard input.

     -l      With no arguments, list all jobs for the invoking user.  If one
	     or more job numbers are given, list only those jobs.

     -m      Send mail to the user when the job has completed even if there
	     was no output.

     -q queue
	     Use the specified queue.  A queue designation consists of a sin-
	     gle letter; valid queue designations range from a to z and A to
	     Z.  The _DEFAULT_AT_QUEUE queue (a) is the default for at and the
	     _DEFAULT_BATCH_QUEUE queue (b) is the default for batch.  Queues
	     with higher letters run with increased niceness.  If a job is
	     submitted to a queue designated with an uppercase letter, it is
	     treated as if it had been submitted to batch at that time.  If
	     atq is given a specific queue, it will only show jobs pending in
	     that queue.

     -r      Remove the specified jobs.

     -t      Specify the job time using the POSIX time format.	The argument
	     should be in the form [[CC]YY]MMDDhhmm[.SS] where each pair of
	     letters represents the following:

		   CC	   The first two digits of the year (the century).
		   YY	   The second two digits of the year.
		   MM	   The month of the year, from 1 to 12.
		   DD	   the day of the month, from 1 to 31.
		   hh	   The hour of the day, from 0 to 23.
		   mm	   The minute of the hour, from 0 to 59.
		   SS	   The second of the minute, from 0 to 61.

	     If the CC and YY letter pairs are not specified, the values
	     default to the current year.  If the SS letter pair is not speci-
	     fied, the value defaults to 0.

     -v      For atq, shows completed but not yet deleted jobs in the queue;
	     otherwise shows the time the job will be executed.

FILES
     _ATJOB_DIR 	   directory containing job files
			   (/usr/lib/cron/jobs/)
     _ATJOB_DIR/_LOCKFILE  job-creation lock file (/usr/lib/cron/jobs/...)
     _ATSPOOL_DIR	   directory containing output spool files
			   (/usr/lib/cron/spool/)
     _PERM_PATH/at.allow   allow permission control (/usr/lib/cron/at.allow)
     _PERM_PATH/at.deny    deny permission control (/usr/lib/cron/at.deny)
     /var/run/utmpx	   login records

SEE ALSO
     nice(1), sh(1), umask(2), compat(5), atrun(8), cron(8), sendmail(8)

BUGS
     If the file /var/run/utmpx is not available or corrupted, or if the user
     is not logged on at the time at is invoked, the mail is sent to the
     userid found in the environment variable LOGNAME.	If that is undefined
     or empty, the current userid is assumed.

     The at and batch utilities as presently implemented are not suitable when
     users are competing for resources.  If this is the case, another batch
     system such as nqs may be more suitable.

     Specifying a date past 2038 may not work on some systems.

AUTHORS
     At was mostly written by Thomas Koenig <ig25@rz.uni-karlsruhe.de>.  The
     time parsing routines are by
     David Parsons <orc@pell.chi.il.us>, with minor enhancements by
     Joe Halpin <joe.halpin@attbi.com>.

BSD			       January 13, 2002 			   BSD
","# at

> Executes commands at a specified time.

- Open an `at` prompt to create a new set of scheduled commands, press `Ctrl + D` to save and exit:

`at {{hh:mm}}`

- Execute the commands and email the result using a local mailing program such as sendmail:

`at {{hh:mm}} -m`

- Execute a script at the given time:

`at {{hh:mm}} -f {{path/to/file}}`

- Display a system notification at 11pm on February 18th:

`echo ""notify-send '{{Wake up!}}'"" | at {{11pm}} {{Feb 18}}`
"
postfix,http://postfix.org,,"POSTFIX(1)							    POSTFIX(1)



NAME
       postfix - Postfix control program

SYNOPSIS
       postfix [-Dv] [-c config_dir] command

DESCRIPTION
       This  command  is  reserved  for the superuser. To submit mail, use the
       Postfix sendmail(1) command.

       The postfix(1) command controls the operation of the Postfix mail  sys-
       tem:  start  or stop the master(8) daemon, do a health check, and other
       maintenance.

       By default, the postfix(1) command sets up a  standardized  environment
       and runs the postfix-script shell script to do the actual work.

       However,  when  support	for  multiple Postfix instances is configured,
       postfix(1) executes the command specified with the multi_instance_wrap-
       per configuration parameter.  This command will execute the command for
       each applicable Postfix instance.

       The following commands are implemented:

       check  Warn about bad directory/file ownership or permissions, and cre-
	      ate missing directories.

       start  Start  the Postfix mail system. This also runs the configuration
	      check described above.

       stop   Stop the Postfix mail system in an orderly fashion. If possible,
	      running  processes  are  allowed	to terminate at their earliest
	      convenience.

	      Note: in order to refresh the Postfix mail system after  a  con-
	      figuration  change,  do  not  use the start and stop commands in
	      succession. Use the reload command instead.

       abort  Stop the Postfix mail system  abruptly.  Running	processes  are
	      signaled to stop immediately.

       flush  Force delivery: attempt to deliver every message in the deferred
	      mail queue. Normally, attempts to deliver delayed mail happen at
	      regular  intervals,  the	interval  doubling  after  each failed
	      attempt.

	      Warning: flushing undeliverable mail frequently will  result  in
	      poor delivery performance of all other mail.

       reload Re-read  configuration  files.  Running  processes  terminate at
	      their earliest convenience.

       status Indicate if the Postfix mail system is currently running.

       set-permissions [name=value ...]
	      Set the ownership and permissions of Postfix related  files  and
	      directories, as specified in the postfix-files file.

	      Specify  name=value to override and update specific main.cf con-
	      figuration parameters. Use this,	for  example,  to  change  the
	      mail_owner  or  setgid_group  setting  for  an already installed
	      Postfix system.

	      This feature is available in Postfix 2.1 and later.  With  Post-
	      fix   2.0   and	earlier,  use  ""$config_directory/post-install
	      set-permissions"".

       tls subcommand
	      Enable opportunistic TLS in the Postfix SMTP client  or  server,
	      and  manage  Postfix  SMTP  server TLS private keys and certifi-
	      cates.  See postfix-tls(1) for documentation.

	      This feature is available in Postfix 3.1 and later.

       upgrade-configuration [name=value ...]
	      Update the main.cf and master.cf	files  with  information  that
	      Postfix  needs  in order to run: add or update services, and add
	      or update configuration parameter settings.

	      Specify name=value to override and update specific main.cf  con-
	      figuration parameters.

	      This  feature is available in Postfix 2.1 and later.  With Post-
	      fix  2.0	and   earlier,	 use   ""$config_directory/post-install
	      upgrade-configuration"".

       The following options are implemented:

       -c config_dir
	      Read  the main.cf and master.cf configuration files in the named
	      directory instead of the default configuration  directory.   Use
	      this  to	distinguish  between multiple Postfix instances on the
	      same host.

	      With Postfix 2.6 and later, this option  forces  the  postfix(1)
	      command to operate on the specified Postfix instance only.  This
	      behavior is inherited by	postfix(1)  commands  that  run  as  a
	      descendant of the current process.

       -D (with postfix start only)
	      Run each Postfix daemon under control of a debugger as specified
	      via the debugger_command configuration parameter.

       -v     Enable verbose  logging  for  debugging  purposes.  Multiple  -v
	      options make the software increasingly verbose.

ENVIRONMENT
       The  postfix(1)	command  exports  the  following environment variables
       before executing the postfix-script file:

       MAIL_CONFIG
	      This is set when the -c command-line option is present.

	      With Postfix 2.6 and later, this environment variable forces the
	      postfix(1)  command to operate on the specified Postfix instance
	      only.  This behavior is inherited by  postfix(1)	commands  that
	      run as a descendant of the current process.

       MAIL_VERBOSE
	      This is set when the -v command-line option is present.

       MAIL_DEBUG
	      This is set when the -D command-line option is present.

CONFIGURATION PARAMETERS
       The following main.cf configuration parameters are exported as environ-
       ment variables with the same names:

       config_directory (see 'postconf -d' output)
	      The default location of the Postfix main.cf and  master.cf  con-
	      figuration files.

       command_directory (see 'postconf -d' output)
	      The location of all postfix administrative commands.

       daemon_directory (see 'postconf -d' output)
	      The directory with Postfix support programs and daemon programs.

       html_directory (see 'postconf -d' output)
	      The location of Postfix HTML files that describe how  to	build,
	      configure or operate a specific Postfix subsystem or feature.

       mail_owner (postfix)
	      The  UNIX  system  account  that owns the Postfix queue and most
	      Postfix daemon processes.

       mailq_path (see 'postconf -d' output)
	      Sendmail compatibility feature that specifies where the  Postfix
	      mailq(1) command is installed.

       manpage_directory (see 'postconf -d' output)
	      Where the Postfix manual pages are installed.

       newaliases_path (see 'postconf -d' output)
	      Sendmail	compatibility  feature	that specifies the location of
	      the newaliases(1) command.

       queue_directory (see 'postconf -d' output)
	      The location of the Postfix top-level queue directory.

       readme_directory (see 'postconf -d' output)
	      The location of Postfix README files that describe how to build,
	      configure or operate a specific Postfix subsystem or feature.

       sendmail_path (see 'postconf -d' output)
	      A  Sendmail compatibility feature that specifies the location of
	      the Postfix sendmail(1) command.

       setgid_group (postdrop)
	      The  group  ownership  of  set-gid  Postfix  commands   and   of
	      group-writable Postfix directories.

       Available in Postfix version 2.5 and later:

       data_directory (see 'postconf -d' output)
	      The  directory  with  Postfix-writable  data files (for example:
	      caches, pseudo-random numbers).

       Available in Postfix version 3.0 and later:

       meta_directory (see 'postconf -d' output)
	      The location of non-executable files that are shared among  mul-
	      tiple  Postfix instances, such as postfix-files, dynamicmaps.cf,
	      and the multi-instance template  files  main.cf.proto  and  mas-
	      ter.cf.proto.

       shlib_directory (see 'postconf -d' output)
	      The  location  of Postfix dynamically-linked libraries (libpost-
	      fix-*.so), and the default location of Postfix database  plugins
	      (postfix-*.so)  that  have  a  relative  pathname  in the dynam-
	      icmaps.cf file.

       Available in Postfix version 3.1 and later:

       openssl_path (openssl)
	      The location of the OpenSSL command line program openssl(1).

       Other configuration parameters:

       import_environment (see 'postconf -d' output)
	      The list of environment parameters that a Postfix  process  will
	      import from a non-Postfix parent process.

       syslog_facility (mail)
	      The syslog facility of Postfix logging.

       syslog_name (see 'postconf -d' output)
	      A  prefix  that  is  prepended  to  the  process	name in syslog
	      records, so that, for example, ""smtpd"" becomes ""prefix/smtpd"".

       Available in Postfix version 2.6 and later:

       multi_instance_directories (empty)
	      An optional list of non-default Postfix  configuration  directo-
	      ries;  these  directories belong to additional Postfix instances
	      that share the Postfix executable files and  documentation  with
	      the  default  Postfix  instance,	and that are started, stopped,
	      etc., together with the default Postfix instance.

       multi_instance_wrapper (empty)
	      The pathname of a multi-instance manager command that the  post-
	      fix(1)   command	invokes  when  the  multi_instance_directories
	      parameter value is non-empty.

       multi_instance_group (empty)
	      The optional instance group name of this Postfix instance.

       multi_instance_name (empty)
	      The optional instance name of this Postfix instance.

       multi_instance_enable (no)
	      Allow this Postfix instance to be started, stopped, etc.,  by  a
	      multi-instance manager.

FILES
       Prior  to Postfix version 2.6, all of the following files were in $con-
       fig_directory. Some files are now in $daemon_directory so that they can
       be shared among multiple instances that run the same Postfix version.

       Use  the command ""postconf config_directory"" or ""postconf daemon_direc-
       tory"" to expand the names into their actual values.

       $config_directory/main.cf, Postfix configuration parameters
       $config_directory/master.cf, Postfix daemon processes
       $daemon_directory/postfix-files, file/directory permissions
       $daemon_directory/postfix-script, administrative commands
       $daemon_directory/post-install, post-installation configuration
       $daemon_directory/dynamicmaps.cf, plug-in database clients

SEE ALSO
       Commands:
       postalias(1), create/update/query alias database
       postcat(1), examine Postfix queue file
       postconf(1), Postfix configuration utility
       postfix(1), Postfix control program
       postfix-tls(1), Postfix TLS management
       postkick(1), trigger Postfix daemon
       postlock(1), Postfix-compatible locking
       postlog(1), Postfix-compatible logging
       postmap(1), Postfix lookup table manager
       postmulti(1), Postfix multi-instance manager
       postqueue(1), Postfix mail queue control
       postsuper(1), Postfix housekeeping
       mailq(1), Sendmail compatibility interface
       newaliases(1), Sendmail compatibility interface
       sendmail(1), Sendmail compatibility interface

       Postfix configuration:
       bounce(5), Postfix bounce message templates
       master(5), Postfix master.cf file syntax
       postconf(5), Postfix main.cf file syntax
       postfix-wrapper(5), Postfix multi-instance API

       Table-driven mechanisms:
       access(5), Postfix SMTP access control table
       aliases(5), Postfix alias database
       canonical(5), Postfix input address rewriting
       generic(5), Postfix output address rewriting
       header_checks(5), body_checks(5), Postfix content inspection
       relocated(5), Users that have moved
       transport(5), Postfix routing table
       virtual(5), Postfix virtual aliasing

       Table lookup mechanisms:
       cidr_table(5), Associate CIDR pattern with value
       ldap_table(5), Postfix LDAP client
       lmdb_table(5), Postfix LMDB database driver
       memcache_table(5), Postfix memcache client
       mysql_table(5), Postfix MYSQL client
       nisplus_table(5), Postfix NIS+ client
       pcre_table(5), Associate PCRE pattern with value
       pgsql_table(5), Postfix PostgreSQL client
       regexp_table(5), Associate POSIX regexp pattern with value
       socketmap_table(5), Postfix socketmap client
       sqlite_table(5), Postfix SQLite database driver
       tcp_table(5), Postfix client-server table lookup

       Daemon processes:
       anvil(8), Postfix connection/rate limiting
       bounce(8), defer(8), trace(8), Delivery status reports
       cleanup(8), canonicalize and enqueue message
       discard(8), Postfix discard delivery agent
       dnsblog(8), DNS black/whitelist logger
       error(8), Postfix error delivery agent
       flush(8), Postfix fast ETRN service
       local(8), Postfix local delivery agent
       master(8), Postfix master daemon
       oqmgr(8), old Postfix queue manager
       pickup(8), Postfix local mail pickup
       pipe(8), deliver mail to non-Postfix command
       postscreen(8), Postfix zombie blocker
       proxymap(8), Postfix lookup table proxy server
       qmgr(8), Postfix queue manager
       qmqpd(8), Postfix QMQP server
       scache(8), Postfix connection cache manager
       showq(8), list Postfix mail queue
       smtp(8), lmtp(8), Postfix SMTP+LMTP client
       smtpd(8), Postfix SMTP server
       spawn(8), run non-Postfix server
       tlsmgr(8), Postfix TLS cache and randomness manager
       tlsproxy(8), Postfix TLS proxy server
       trivial-rewrite(8), Postfix address rewriting
       verify(8), Postfix address verification
       virtual(8), Postfix virtual delivery agent

       Other:
       syslogd(8), system logging

README FILES
       Use ""postconf readme_directory"" or ""postconf html_directory"" to	locate
       this information.
       OVERVIEW, overview of Postfix commands and processes
       BASIC_CONFIGURATION_README, Postfix basic configuration
       ADDRESS_REWRITING_README, Postfix address rewriting
       SMTPD_ACCESS_README, SMTP relay/access control
       CONTENT_INSPECTION_README, Postfix content inspection
       QSHAPE_README, Postfix queue analysis

LICENSE
       The Secure Mailer license must be distributed with this software.

AUTHOR(S)
       Wietse Venema
       IBM T.J. Watson Research
       P.O. Box 704
       Yorktown Heights, NY 10598, USA

       Wietse Venema
       Google, Inc.
       111 8th Avenue
       New York, NY 10011, USA

       TLS support by:
       Lutz Jaenicke
       Brandenburg University of Technology
       Cottbus, Germany

       Victor Duchovni
       Morgan Stanley

       SASL support originally by:
       Till Franke
       SuSE Rhein/Main AG
       65760 Eschborn, Germany

       LMTP support originally by:
       Philip A. Prindeville
       Mirapoint, Inc.
       USA.

       Amos Gouaux
       University of Texas at Dallas
       P.O. Box 830688, MC34
       Richardson, TX 75083, USA

       IPv6 support originally by:
       Mark Huizer, Eindhoven University, The Netherlands
       Jun-ichiro 'itojun' Hagino, KAME project, Japan
       The Linux PLD project
       Dean Strik, Eindhoven University, The Netherlands



								    POSTFIX(1)
","# postfix

> Postfix mail transfer agent (MTA) control program.
> See also `dovecot`, a mail delivery agent (MDA) that integrates with Postfix.
> More information: <http://postfix.org>.

- Check the configuration:

`sudo postfix check`

- Check the status of the Postfix daemon:

`sudo postfix status`

- Start Postfix:

`sudo postfix start`

- Gracefully stop Postfix:

`sudo postfix stop`

- Flush the mail queue:

`sudo postfix flush`

- Reload the configuration files:

`sudo postfix reload`
"
wodim,,,,"# wodim

> Command (aliased as `cdrecord` on some systems) for recording data to CDs or DVDs.
> Some invocations of wodim can cause destructive actions, such as erasing all the data on a disc.

- Display optical drives available to `wodim`:

`wodim --devices`

- Record (""burn"") an audio-only disc:

`wodim dev=/dev/{{optical_drive}} -audio {{track*.cdaudio}}`

- Burn a file to a disc, ejecting the disc once done (some recorders require this):

`wodim -eject dev=/dev/{{optical_drive}} -data {{file.iso}}`

- Burn a file to the disc in an optical drive, potentially writing to multiple discs in succession:

`wodim -tao dev=/dev/{{optical_drive}} -data {{file.iso}}`
"
logger,,,"
LOGGER(1)		  BSD General Commands Manual		     LOGGER(1)

NAME
     logger -- make entries in the system log

SYNOPSIS
     logger [-is] [-f file] [-p pri] [-t tag] [message ...]

DESCRIPTION
     Logger provides a shell command interface to the syslog(3) system log
     module.

     Options:

     -i       Log the process id of the logger process with each line.

     -s       Log the message to standard error, as well as the system log.

     -f file  Log the specified file.

     -p pri   Enter the message with the specified priority.  The priority may
	      be specified numerically or as a ``facility.level'' pair.  For
	      example, ``-p local3.info'' logs the message(s) as informational
	      level in the local3 facility.  The default is ``user.notice.''

     -t tag   Mark every line in the log with the specified tag.

     message  Write the message to log; if not specified, and the -f flag is
	      not provided, standard input is logged.

     The logger utility exits 0 on success, and >0 if an error occurs.

EXAMPLES
	   logger System rebooted

	   logger -p local0.notice -t HOSTIDM -f /dev/idmc

SEE ALSO
     syslog(3), syslogd(8)

STANDARDS
     The logger utility conforms to IEEE Std 1003.2-1992 (``POSIX.2'').

4.3 Berkeley Distribution	 June 6, 1993	     4.3 Berkeley Distribution
","# logger

> Add messages to syslog (/var/log/syslog).

- Log a message to syslog:

`logger {{message}}`

- Take input from `stdin` and log to syslog:

`echo {{log_entry}} | logger`

- Send the output to a remote syslog server running at a given port. Default port is 514:

`echo {{log_entry}} | logger --server {{hostname}} --port {{port}}`

- Use a specific tag for every line logged. Default is the name of logged in user:

`echo {{log_entry}} | logger --tag {{tag}}`

- Log messages with a given priority. Default is `user.notice`. See `man logger` for all priority options:

`echo {{log_entry}} | logger --priority {{user.warning}}`
"
mkfs.exfat,,,,"# mkfs.exfat

> Creates an exfat filesystem inside a partition.

- Create an exfat filesystem inside partition 1 on device b (`sdb1`):

`mkfs.exfat {{/dev/sdb1}}`

- Create filesystem with a volume-name:

`mkfs.exfat -n {{volume_name}} {{/dev/sdb1}}`

- Create filesystem with a volume-id:

`mkfs.exfat -i {{volume_id}} {{/dev/sdb1}}`
"
top,,,"
TOP(1)			  BSD General Commands Manual			TOP(1)

NAME
     top -- display and update sorted information about processes

SYNOPSIS
     top [-a | -d | -e | -c mode]
	 [-F | -f]
	 [-h]
	 [-i interval]
	 [-l samples]
	 [-ncols columns]
	 [-o key | -O skey]
	 [-R | -r]
	 [-S]
	 [-s delay-secs]
	 [-n nprocs]
	 [-stats keys]
	 [-pid processid]
	 [-user username]
	 [-U username]
	 [-u]

DESCRIPTION
     The top program periodically displays a sorted list of system processes.
     The default sorting key is pid, but other keys can be used instead.  Var-
     ious output options are available.

OPTIONS
     Command line option specifications are processed from left to right.
     Options can be specified more than once.  If conflicting options are
     specified, later specifications override earlier ones.  This makes it
     viable to create a shell alias for top with preferred defaults specified,
     then override those preferred defaults as desired on the command line.

     -a      Equivalent to Fl c Ar a .

     -c mode
	     Set event counting mode to mode.  The supported modes are

	     a	     Accumulative mode.  Count events cumulatively, starting
		     at the launch of top.  Calculate CPU usage and CPU time
		     since the launch of top.

	     d	     Delta mode.  Count events relative to the previous sam-
		     ple.  Calculate CPU usage since the previous sample.
		     This mode by default disables the memory object map
		     reporting.  The memory object map reporting may be re-
		     enabled with the -r option or the interactive r command.

	     e	     Absolute mode.  Count events using absolute counters.

	     n	     Non-event mode (default).	Calculate CPU usage since the
		     previous sample.

     -d      Equivalent to -c d.

     -e      Equivalent to -c e.

     -F      Do not calculate statistics on shared libraries, also known as
	     frameworks.

     -f      Calculate statistics on shared libraries, also known as frame-
	     works (default).

     -h      Print command line usage information and exit.

     -i interval
	     Update framework (-f) info every interval samples; see the
	     PERFORMANCE/ACCURACY TRADEOFF section for more details.

     -l samples
	     Use logging mode and display samples samples, even if standard
	     output is a terminal.  0 is treated as infinity.  Rather than
	     redisplaying, output is periodically printed in raw form.	Note
	     that the first sample displayed will have an invalid %CPU dis-
	     played for each process, as it is calculated using the delta
	     between samples.

     -ncols columns
	     Display columns when using logging mode.  The default is infi-
	     nite.  The number must be >0 or an error will occur.

     -n nprocs
	     Only display up to nprocs processes.

     -O skey
	     Use skey as a secondary key when ordering the process display.
	     See -o for key names (pid is the default).

     -o key  Order the process display by sorting on key in descending order.
	     A + or - can be prefixed to the key name to specify ascending or
	     descending order, respectively.  The supported keys are:

	     pid     Process ID (default).

	     command
		     Command name.

	     cpu     CPU usage.

	     cpu_me  CPU time charged to me by other processes.

	     cpu_others
		     CPU time charged to other processes by me.

	     csw     The number of context switches.

	     time    Execution time.

	     threads
		     alias: th
		     Number of threads (total/running).

	     ports   alias: prt
		     Number of Mach ports.

	     mregion
		     alias: mreg, reg
		     Number of memory regions.

	     mem     Physical memory footprint of the process.

	     rprvt   Resident private address space size.

	     purg    Purgeable memory size.

	     vsize   Total memory size.

	     vprvt   Private address space size.

	     kprvt   Private kernel memory size.

	     kshrd   Shared kernel memory size.

	     pgrp    Process group ID.

	     ppid    Parent process ID.

	     state   alias: pstate
		     Process state.

	     uid     User ID.

	     wq      alias: #wq, workqueue
		     The workqueue total/running.

	     faults  alias: fault
		     The number of page faults.

	     cow     alias: cow_faults
		     The copy-on-write faults.

	     user    alias: username
		     Username.

	     msgsent
		     Total number of Mach messages sent.

	     msgrecv
		     Total number of Mach messages received.

	     sysbsd  Total BSD syscalls.

	     sysmach
		     Total Mach syscalls.

	     pageins
		     Total pageins.

	     boosts  The number of boosts help by the process.	This is fol-
		     lowed by the number of times the process has transitioned
		     from unboosted to boosted in brackets.  An asterisk
		     before the value indicates that the process was able to
		     send boosts at some point since the previous update.  For
		     more information about boosts, see xpc_transac-
		     tion_begin(3).

	     instrs  The number of instructions retired by the process in both
		     user space and the kernel.

	     cycles  The number of cycles spent executing instructions in the
		     process in both user space and the kernel.

     -R      Do not traverse and report the memory object map for each process
	     (default).

     -r      Traverse and report the memory object map for each process.

     -S      Display the global statistics for swap and purgeable memory.

     -s delay-secs
	     Set the delay between updates to delay-secs seconds.  The default
	     delay between updates is 1 second.

     -stats keys
	     Only display the comma separated statistics.  See the -o flag for
	     the valid keys.

     -pid processid
	     Only display processid in top.  This option may be specified mul-
	     tiple times.

     -user user
	     Only display processes owned by user

     -U user
	     This is an alias for -user.

     -u      This is an alas equivalent to: -o cpu -O time

DISPLAY
     The first several lines of the top display show various global state.
     All of the information is labeled.  Following is an alphabetical list of
     global state fields and their descriptions.

     CPU	 Percentage of processor usage, broken into user, system, and
		 idle components.  The time period for which these percentages
		 are calculated depends on the event counting mode.

     Disks	 Number and total size of disk reads and writes.

     LoadAvg	 Load average over 1, 5, and 15 minutes.  The load average is
		 the average number of jobs in the run queue.

     MemRegions  Number and total size of memory regions, and total size of
		 memory regions broken into private (broken into non-library
		 and library) and shared components.

     Networks	 Number and total size of input and output network packets.

     PhysMem	 Physical memory usage, broken into wired, active, inactive,
		 used, and free components.

     Procs	 Total number of processes and number of processes in each
		 process state.

     SharedLibs  Resident sizes of code and data segments, and link editor
		 memory usage.

     Threads	 Number of threads.

     Time	 Time, in H:MM:SS format.  When running in logging mode, Time
		 is in YYYY/MM/DD HH:MM:SS format by default, but may be over-
		 ridden with accumulative mode.  When running in accumulative
		 event counting mode, the Time is in HH:MM:SS since the begin-
		 ning of the top process.

     VirtMem	 Total virtual memory, virtual memory consumed by shared
		 libraries, and number of pageins and pageouts.

     Swap	 Swap usage: total size of swap areas, amount of swap space in
		 use and amount of swap space available.

     Purgeable	 Number of pages purged and number of pages currently purge-
		 able.

     Below the global state fields, a list of processes is displayed.  The
     fields that are displayed depend on the options that are set.  The pid
     field displays the following for the architecture:

     + for 64-bit native architecture, or - for 32-bit native architecture, or
     * for a non-native architecture.

INTERACTION
     When top is run in interactive (non-logging) mode, it is possible to con-
     trol the output of top, as well as interactively send signals to pro-
     cesses.  The interactive command syntax is terse.	Each command is one
     character, followed by 0 to 2 arguments.  Commands that take arguments
     prompt interactively for the arguments, and where applicable, the default
     value is shown in square brackets.  The default value can be selected by
     leaving the input field blank and pressing enter.	^G escapes the inter-
     active argument prompt, and has the same effect as leaving the input
     field blank and pressing enter.

     The following commands are supported:

     ?	     Display the help screen.  Any character exits help screen mode.
	     This command always works, even in the middle of a command.

     ^L      Redraw the screen.

     cmode   Set output mode to mode.  See the -c option for descriptions of
	     the allowed modes.

     Oskey   Use skey as a secondary key when ordering the process display.
	     See the -o option for key names.

     okey    Order the process display by sorting on key in descending order.
	     A + or - can be prefixed to the key name to specify ascending or
	     descending order, respectively.  The supported keys and alises
	     are listed with the -o option above.

     q	     Quit.

     r	     Toggle traversal and reporting of the memory object map for each
	     process.

     Ssignalpid
	     Send signal signal to pid.  signal can be specified either as a
	     number or as a name (for example, HUP).  The default signal
	     starts out as TERM.  Each time a signal is successfully sent, the
	     default signal is updated to be that signal.  pid is a process
	     id.

     s delay-secs
	     Set the delay between updates to delay-secs seconds.

     U user  Only display processes owned by user. Either the username or uid
	     number can be specified.  To display all processes, press enter
	     without entering a username or uid number.

PERFORMANCE/ACCURACY TRADEOFF
     Calculating detailed memory statistics is fundamentally resource-inten-
     sive.  To reduce the CPU usage in top, the -i option has been introduced
     to allow the user to tune this tradeoff.  With the default value of 10,
     framework stats will be updated once every 10 samples.  Specifying -i 1
     will result in the most accurate display, at the expense of system
     resources.

NOT AVAILABLE
     When N/A occurs in a stat, it's caused by the memory object map reporting
     being disabled.  Memory object map reporting is disabled by default in
     delta mode, but may be optionally enabled via -r or the interactive r
     command.  To enable the -r option, use it after any -c mode options.

EXAMPLES
     top -o cpu -O +rsize -s 5 -n 20
	     Sort the processes according to CPU usage (descending) and resi-
	     dent memory size (ascending), sample and update the display at 5
	     second intervals, and limit the display to 20 processes.

     top -c d
	     Run top in delta mode.

     top -stats pid,command,cpu,th,pstate,time
	     Display only the specified statistics, regardless of any growth
	     of the terminal.  If the terminal is too small, only the statis-
	     tics that fit will be displayed.

SEE ALSO
     kill(2), vm_stat(1), signal(3), vmmap(1)

Darwin				 13 March 2017				Darwin
","# top

> Display dynamic real-time information about running processes.

- Start top:

`top`

- Do not show any idle or zombie processes:

`top -i`

- Show only processes owned by given user:

`top -u {{username}}`

- Sort processes by a field:

`top -o {{field_name}}`

- Show the individual threads of a given process:

`top -Hp {{process_id}}`

- Show only the processes with the given PID(s), passed as a comma-separated list. (Normally you wouldn't know PIDs off hand. This example picks the PIDs from the process name):

`top -p $(pgrep -d ',' {{process_name}})`

- Get help about interactive commands:

`?`
"
xsel,,,,"# xsel

> X11 selection and clipboard manipulation tool.

- Use a command's output as input of the clip[b]oard (equivalent to `Ctrl + C`):

`echo 123 | xsel -ib`

- Use the contents of a file as input of the clipboard:

`cat {{file}} | xsel -ib`

- Output the clipboard's contents into the terminal (equivalent to `Ctrl + V`):

`xsel -ob`

- Output the clipboard's contents into a file:

`xsel -ob > {{file}}`

- Clear the clipboard:

`xsel -cb`

- Output the X11 primary selection's contents into the terminal (equivalent to a mouse middle-click):

`xsel -op`
"
export,,,"
BUILTIN(1)		  BSD General Commands Manual		    BUILTIN(1)

NAME
     builtin, !, %, ., :, @, {, }, alias, alloc, bg, bind, bindkey, break,
     breaksw, builtins, case, cd, chdir, command, complete, continue, default,
     dirs, do, done, echo, echotc, elif, else, end, endif, endsw, esac, eval,
     exec, exit, export, false, fc, fg, filetest, fi, for, foreach, getopts,
     glob, goto, hash, hashstat, history, hup, if, jobid, jobs, kill, limit,
     local, log, login, logout, ls-F, nice, nohup, notify, onintr, popd,
     printenv, pushd, pwd, read, readonly, rehash, repeat, return, sched, set,
     setenv, settc, setty, setvar, shift, source, stop, suspend, switch,
     telltc, test, then, time, times, trap, true, type, ulimit, umask,
     unalias, uncomplete, unhash, unlimit, unset, unsetenv, until, wait,
     where, which, while -- shell built-in commands

SYNOPSIS
     builtin [-options] [args ...]

DESCRIPTION
     Shell builtin commands are commands that can be executed within the run-
     ning shell's process.  Note that, in the case of csh(1) builtin commands,
     the command is executed in a subshell if it occurs as any component of a
     pipeline except the last.

     If a command specified to the shell contains a slash ``/'', the shell
     will not execute a builtin command, even if the last component of the
     specified command matches the name of a builtin command.  Thus, while
     specifying ``echo'' causes a builtin command to be executed under shells
     that support the echo builtin command, specifying ``/bin/echo'' or
     ``./echo'' does not.

     While some builtin commands may exist in more than one shell, their oper-
     ation may be different under each shell which supports them.  Below is a
     table which lists shell builtin commands, the standard shells that sup-
     port them and whether they exist as standalone utilities.

     Only builtin commands for the csh(1) and sh(1) shells are listed here.
     Consult a shell's manual page for details on the operation of its builtin
     commands.	Beware that the sh(1) manual page, at least, calls some of
     these commands ``built-in commands'' and some of them ``reserved words''.
     Users of other shells may need to consult an info(1) page or other
     sources of documentation.

     Commands marked ``No**'' under External do exist externally, but are
     implemented as scripts using a builtin command of the same name.

	   Command	 External    csh(1)    sh(1)
	   !		 No	     No        Yes
	   %		 No	     Yes       No
	   .		 No	     No        Yes
	   :		 No	     Yes       Yes
	   @		 No	     Yes       Yes
	   {		 No	     No        Yes
	   }		 No	     No        Yes
	   alias	 No**	     Yes       Yes
	   alloc	 No	     Yes       No
	   bg		 No**	     Yes       Yes
	   bind 	 No	     No        Yes
	   bindkey	 No	     Yes       No
	   break	 No	     Yes       Yes
	   breaksw	 No	     Yes       No
	   builtin	 No	     No        Yes
	   builtins	 No	     Yes       No
	   case 	 No	     Yes       Yes
	   cd		 No**	     Yes       Yes
	   chdir	 No	     Yes       Yes
	   command	 No**	     No        Yes
	   complete	 No	     Yes       No
	   continue	 No	     Yes       Yes
	   default	 No	     Yes       No
	   dirs 	 No	     Yes       No
	   do		 No	     No        Yes
	   done 	 No	     No        Yes
	   echo 	 Yes	     Yes       Yes
	   echotc	 No	     Yes       No
	   elif 	 No	     No        Yes
	   else 	 No	     Yes       Yes
	   end		 No	     Yes       No
	   endif	 No	     Yes       No
	   endsw	 No	     Yes       No
	   esac 	 No	     No        Yes
	   eval 	 No	     Yes       Yes
	   exec 	 No	     Yes       Yes
	   exit 	 No	     Yes       Yes
	   export	 No	     No        Yes
	   false	 Yes	     No        Yes
	   fc		 No**	     No        Yes
	   fg		 No**	     Yes       Yes
	   filetest	 No	     Yes       No
	   fi		 No	     No        Yes
	   for		 No	     No        Yes
	   foreach	 No	     Yes       No
	   getopts	 No**	     No        Yes
	   glob 	 No	     Yes       No
	   goto 	 No	     Yes       No
	   hash 	 No	     No        Yes
	   hashstat	 No	     Yes       No
	   history	 No	     Yes       No
	   hup		 No	     Yes       No
	   if		 No	     Yes       Yes
	   jobid	 No	     No        Yes
	   jobs 	 No**	     Yes       Yes
	   kill 	 Yes	     Yes       No
	   limit	 No	     Yes       No
	   local	 No	     No        Yes
	   log		 No	     Yes       No
	   login	 Yes	     Yes       No
	   logout	 No	     Yes       No
	   ls-F 	 No	     Yes       No
	   nice 	 Yes	     Yes       No
	   nohup	 Yes	     Yes       No
	   notify	 No	     Yes       No
	   onintr	 No	     Yes       No
	   popd 	 No	     Yes       No
	   printenv	 Yes	     Yes       No
	   pushd	 No	     Yes       No
	   pwd		 Yes	     No        Yes
	   read 	 No**	     No        Yes
	   readonly	 No	     No        Yes
	   rehash	 No	     Yes       No
	   repeat	 No	     Yes       No
	   return	 No	     No        Yes
	   sched	 No	     Yes       No
	   set		 No	     Yes       Yes
	   setenv	 No	     Yes       No
	   settc	 No	     Yes       No
	   setty	 No	     Yes       No
	   setvar	 No	     No        Yes
	   shift	 No	     Yes       Yes
	   source	 No	     Yes       No
	   stop 	 No	     Yes       No
	   suspend	 No	     Yes       No
	   switch	 No	     Yes       No
	   telltc	 No	     Yes       No
	   test 	 Yes	     No        Yes
	   then 	 No	     No        Yes
	   time 	 Yes	     Yes       No
	   times	 No	     No        Yes
	   trap 	 No	     No        Yes
	   true 	 Yes	     No        Yes
	   type 	 No	     No        Yes
	   ulimit	 No	     No        Yes
	   umask	 No**	     Yes       Yes
	   unalias	 No**	     Yes       Yes
	   uncomplete	 No	     Yes       No
	   unhash	 No	     Yes       No
	   unlimit	 No	     Yes       No
	   unset	 No	     Yes       Yes
	   unsetenv	 No	     Yes       No
	   until	 No	     No        Yes
	   wait 	 No**	     Yes       Yes
	   where	 No	     Yes       No
	   which	 Yes	     Yes       No
	   while	 No	     Yes       Yes

SEE ALSO
     csh(1), echo(1), false(1), info(1), kill(1), login(1), nice(1), nohup(1),
     printenv(1), pwd(1), sh(1), test(1), time(1), true(1), which(1)

HISTORY
     The builtin manual page first appeared in FreeBSD 3.4.

AUTHORS
     This manual page was written by Sheldon Hearn <sheldonh@FreeBSD.org>.

BSD			       February 23, 2005			   BSD
","# export

> Command to mark shell variables in the current environment to be exported with any newly forked child processes.

- Set a new environment variable:

`export {{VARIABLE}}={{value}}`

- Remove an environment variable:

`export -n {{VARIABLE}}`

- Mark a shell function for export:

`export -f {{FUNCTION_NAME}}`

- Append something to the PATH variable:

`export PATH=$PATH:{{path/to/append}}`
"
pvcreate,,,,"# pvcreate

> Initialize a physical volume (disk or partition) for use by the Logical Volume Manager (LVM).

- Initialize the `/dev/sda1` volume for use by LVM:

`pvcreate {{/dev/sda1}}`

- Force the creation without any confirmation prompts:

`pvcreate --force {{/dev/sda1}}`
"
modinfo,,,,"# modinfo

> Extract information about a Linux kernel module.

- List all attributes of a kernel module:

`modinfo {{kernel_module}}`

- List the specified attribute only:

`modinfo -F {{author|description|license|parm|filename}} {{kernel_module}}`
"
hostnamectl,,,,"# hostnamectl

> Get or set the hostname of the computer.

- Get the hostname of the computer:

`hostnamectl`

- Set the hostname of the computer:

`sudo hostnamectl set-hostname ""{{some_hostname}}""`
"
sm,https://github.com/nomeata/screen-message,"













GitHub - nomeata/screen-message: Very simple tool to display some text as large as possible








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















nomeata

/

screen-message







    Watch
 
      3
    




      Star


      30
    




          Fork


        4
      





        Very simple tool to display some text as large as possible
      



30
        stars
 

4
        forks
 




      Star





    Watch









Code

 



Issues
3
 



Pull requests
1
 



Actions

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



0
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit



 
 
Git stats





397
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






debian


 


 







.travis.yml


 


 







Makefile.am


 


 







README.Win32.in


 


 







README.md


 


 







configure.ac


 


 







gtkzoom.c


 


 







gtkzoom.h


 


 







push-sm.nomeata.de.sh


 


 







setup.iss.in


 


 







sm-128.png


 


 







sm-fsmi-ka.jpg


 


 







sm.6


 


 







sm.c


 


 







sm.desktop.in


 


 







sm.html


 


 







sm.ico


 


 







sm.png


 


 







sm.py


 


 







sm.rc


 


 







sm.svg


 


 







sm.webapp


 


 







webapp.html


 


 





        View code
      







        README.md
      








screen-message
If you just want to display a word or a short, possibly multi-line, text as
large and as quickly as possible on your screen, then screen-message is the
right too for you. It has been used already twice at a Debian conference for
the Mugshots.
screen-message runs on Linux and Windows and there is an online version on http://sm.nomeata.de/.
Installation Linux
Get it from your distribution with
apt install sm

or install it from this source repository, if you know how to do these things.
Installation Windows
Get the latest windows installer
from my webpage. The windows installer lags behind a few versions; let me know if you need a new version.
Usage
Screen Message  will display a given multi-line message as large as possible, fullscreen
and black on white. You can specify the text either when launching sm, or edit it  while
the program is running.
After  a short timeout, the text entry and the quit button will disappear, leaving
nothing on the screen but the entered text. To continue entering text, just start typing
or (left-)click anywhere on the screen.
To clear the displayed text, press Escape.
To invert the colors of the text and the background, press Ctrl-I.
To quit the program, press Ctrl-Q, or Escape twice, or click the “Quit”-button.
Options


[ text | - ]
Text  to  display at start up. Defaults to "":-)"". If ""-"" is passed to sm, it will
read the text to display from the standard input, see REMOTE CONTROLLING SM.


-f, --foreground=colordesc
Define a different color to use for the foreground of the text  to  display  than
black.  The text string can be in any of the forms accepted by XParseColor; these
include name for a color from rgb.txt, such as DarkSlateGray, or a hex
specification such as #3050b2 or #35b.


-b, --background=colordesc
Define  a  different  color to use for the background of the text to display than
white. For possible values, see above.


-i, --invert
Switch the roles for foreground and  background  colors.  Useful  if  you  prefer
white-on-black.


-n, --font=fontspec
Define  a  different font to use than the default sans-serif font of your system.
The fontspec be the complete name for a truetype  font  (like  ""DejaVu  Sans""  or
""Bitstream  Vera  Serif"")  or  just  a  short font family specification (""serif"",
""sans-serif"").


-r, --rotate=rotation
Rotates the display by rotation * 90 degrees counter-clock-wise. So  -r 1  rotates
the display to the left, and -r 2 puts it upside down.


-a, --align=alignment
Aligns the text centered (-a 0), left (-a 1) or right (-a 2).


-- (Double  dash)
End option parsing. This is used to be able to actually hand over
text that starts of with an dash.


-h, --help
This option will give you  a  short  usage  message  summarizing  the  recognized
options and quits.


-V --version
This prints the project name together with its version number quits.


Remote controlling sm
If  sm  is  called  with - as a command line argument, it will read the text to be shown
from the standard input. It will read the input until it reaches the end of the file, or
the  line  form character \f, and show the input read so far at once. Newline characters
at the beginning or the end are ignored. The input is assumed to be UTF-8  encoded.
This  can  be  used to create automatic displays of changing data or similar tricks. For
example, the following command will create a simple digital watch:
(while sleep 1; do date +%T; printf '\f'; done) | sm -

Contact
Use the GitHub issue tracker or write to Joachim Breitner <mail@joachim-breitner.de>.








About

      Very simple tool to display some text as large as possible
    
Resources



      Readme
 






    Releases

No releases published






    Packages 0


        No packages published 













    Contributors 9




































Languages














C
45.0%





HTML
25.0%





Roff
10.4%





Python
10.3%





M4
5.0%





Makefile
3.9%





Shell
0.4%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# sm

> Displays a short message fullscreen.
> More information: <https://github.com/nomeata/screen-message>.

- Display a message in full-screen:

`sm ""{{Hello World!}}""`

- Display a message with inverted colors:

`sm -i ""{{Hello World!}}""`

- Display a message with a custom foreground color:

`sm -f {{blue}} ""{{Hello World!}}""`

- Display a message with a custom background color:

`sm -b {{#008888}} ""{{Hello World!}}""`

- Display a message rotated 3 times (in steps of 90 degrees, counterclockwise):

`sm -r {{3}} ""{{Hello World!}}""`

- Display a message using the output from another command:

`{{echo ""Hello World!""}} | sm -`
"
ddrescue,https://www.gnu.org/software/ddrescue/,"


Ddrescue - GNU Project - Free Software Foundation (FSF)





Ddrescue - Data recovery tool



[ English
| Español
| Français
| Italiano ]

Introduction

GNU ddrescue is a data recovery tool. It copies data from one file or
block device (hard disc, cdrom, etc) to another, trying to rescue the
good parts first in case of read errors.

Ddrescuelog is a tool that manipulates ddrescue mapfiles, shows mapfile
contents, converts mapfiles to/from other formats, compares mapfiles,
tests rescue status, and can delete a mapfile if the rescue is done.
Ddrescuelog operations can be restricted to one or several parts of the
mapfile if the domain setting options are used.

The basic operation of ddrescue is fully automatic. That is, you don't
have to wait for an error, stop the program, restart it from a new
position, etc.

If you use the mapfile feature of ddrescue, the data are rescued very
efficiently, (only the needed blocks are read). Also you can interrupt
the rescue at any time and resume it later at the same point. The
mapfile is an essential part of ddrescue's effectiveness. Use it unless
you know what you are doing.

Ddrescue does not write zeros to the output when it finds bad sectors in
the input, and does not truncate the output file if not asked to. So,
every time you run it on the same output file, it tries to fill in the
gaps without wiping out the data already rescued.

Automatic merging of backups: If you have two or more damaged copies of
a file, cdrom, etc, and run ddrescue on all of them, one at a time, with
the same output file, you will probably obtain a complete and error-free
file. This is so because the probability of having the same area damaged
in all copies is low (if the errors are randomly located). Using the
mapfile, only the needed blocks are read from the second and successive
copies.

Ddrescue recommends lzip
for compression of backups because the lzip format is designed for long-term
archiving and provides data recovery capabilities which nicely complement
those of ddrescue. (Ddrescue fills unreadable sectors with data from other
copies, while lziprecover corrects corrupt sectors with data from other
copies). If the cause of file corruption is damaged media, the combination
ddrescue + lziprecover
is the best option for recovering data from multiple damaged copies.

Recordable CD and DVD media keep their data only for a finite time
(typically for some years). After that time, data loss develops slowly
with read errors growing from the outer media region towards the inside.
Just make two (or more) copies of every important CD-ROM/DVD you burn so
that you can later recover them with ddrescue.

The mapfile is periodically saved to disc. So in case of a crash you can
resume the rescue with little recopying.

Also, the same mapfile can be used for multiple commands that copy
different areas of the file, and for multiple recovery attempts over
different subsets.

Ddrescue also features a ""fill mode"" able to selectively overwrite parts
of the output file, which has a number of interesting uses like wiping
data, marking bad areas or even, in some cases, ""repair"" damaged
sectors.

One of the great strengths of ddrescue is that it is interface-agnostic,
and so can be used for any kind of device supported by your kernel (ATA,
SATA, SCSI, old MFM drives, floppy discs, or even flash media cards like
SD).

Documentation

The manual is available in the info system of the GNU
Operating System. Use info to access the top level info
page. Use info ddrescue to access the ddrescue section directly.

An online manual for ddrescue can be found
here.

Download

The latest released version of GNU ddrescue can be found at

http://ftpmirror.gnu.org/ddrescue/
or in the subdirectory /gnu/ddrescue/ on your favorite
GNU mirror.
For other ways to obtain ddrescue, please read
How
to get GNU Software. The latest released version will be the most
recent version available at 
http://ftp.gnu.org/gnu/ddrescue/.

To decompress ddrescue tarballs you may need lzip from

http://www.nongnu.org/lzip/lzip.html.
Then use ""tar -xf ddrescue[version].tar.lz"" or
""lzip -cd ddrescue[version].tar.lz | tar -xf -""
to extract the files.

Old versions and testing versions can be found at

http://download.savannah.gnu.org/releases/ddrescue/.

How to Get Help

For general discussion of bugs in ddrescue the mailing list
bug-ddrescue@gnu.org
is the most appropriate forum. Please send messages as plain text.
Please do not send messages encoded as HTML nor encoded as base64 MIME
nor included as multiple formats. Please include a descriptive subject
line. If all of the subject are ""bug in ddrescue"" it is impossible to
differentiate them.

An archive of the bug report mailing list is available at

http://lists.gnu.org/mailman/listinfo/bug-ddrescue.

How to Help

To contact the author, either to report a bug or to contribute fixes or
improvements, send mail to
bug-ddrescue@gnu.org.
Please send messages as plain text. If posting patches they should be in
unified diff format against the latest version. They should include a
text description.

You may also help ddrescue by

donating money via PayPal or debit/credit card.

See also the
ddrescue
project page at Savannah.

Links

DDRescue-GUI -
A simple GUI (Graphical User Interface) for ddrescue.
Ddrescueview -
A graphical viewer for GNU ddrescue mapfiles.
Ddrutility -
A set of tools designed to work with ddrescue to aid with data recovery.

Licensing

Ddrescue is free software: you can redistribute it and/or modify it
under the terms of the GNU General Public License as published by the
Free Software Foundation, either version 2 of the License, or (at your
option) any later version.


Valid HTML 4.01 Strict



Return to GNU's home page.

Please send FSF & GNU inquiries & questions to
gnu@gnu.org. There are also
other ways to contact
the FSF.

Please send comments on this particular web page to
bug-ddrescue@gnu.org,
send comments about www.gnu.org web pages in general to
webmasters@www.gnu.org,
send other questions to gnu@gnu.org.

Copyright © 2020 Free Software Foundation, Inc., 51 Franklin St, Fifth
Floor, Boston, MA 02110-1301 USA

Verbatim copying and distribution of this entire article is
permitted in any medium, provided this notice is preserved.

Updated: $Date: 2020/03/03 12:23:04 $ $Author: antonio $



",,"# ddrescue

> Data recovery tool that reads data from damaged block devices.
> More information: <https://www.gnu.org/software/ddrescue/>.

- Take an image of a device, creating a log file:

`sudo ddrescue {{/dev/sdb}} {{path/to/image.dd}} {{path/to/log.txt}}`

- Clone Disk A to Disk B, creating a log file:

`sudo ddrescue --force --no-scrape {{/dev/sda}} {{/dev/sdb}} {{path/to/log.txt}}`
"
phpdismod,,,,"# phpdismod

> Disable PHP extensions on Debian-based OSes.

- Disable the json extension for every SAPI of every PHP version:

`sudo phpdismod {{json}}`

- Disable the json extension for PHP 7.3 with the cli SAPI:

`sudo phpdismod -v {{7.3}} -s {{cli}} {{json}}`
"
lastcomm,https://manpages.debian.org/stable/acct/lastcomm.1.en.html,"



lastcomm(1) — acct — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / acct
     
     
     
     / lastcomm(1)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


FILES


AUTHOR


SEE ALSO







other versions




buster 6.6.4-2


testing 6.6.4-3


unstable 6.6.4-3






Scroll to navigation



LASTCOMM(1)
General Commands Manual
LASTCOMM(1)




NAME¶
lastcomm - print out information about previously executed commands.


SYNOPSIS¶

lastcomm
[ command-name ... ]
    
    [ user-name ... ]
    
    [ terminal-name ... ]
    
    [ OPTION ... ]



DESCRIPTION¶
lastcomm prints out information about previously executed commands. If no
  arguments are specified, lastcomm will print info about all of the
  commands in acct (the record file). If called with one or more of
  command-name, user-name, or terminal-name, only records
  containing those items will be displayed. For example, to find out which users
  used command `a.out' and which users were logged into `tty0', type:

lastcomm a.out tty0


This will print any entry for which `a.out' or `tty0' matches in
    any of the record's fields (command, name, or terminal). If you want to find
    only items that match *all* of the arguments on the command line, you must
    use the '-strict-match' option. For example, to list all of the executions
    of command a.out by user root on terminal tty0, type:
  
  lastcomm --strict-match --command a.out --user root --tty tty0
  


The order of the arguments is not important.
For each entry the following information is printed:
   + command name of the process
   + flags, as recorded by the system accounting routines:
   S -- command executed by super-user
   F -- command executed after a fork but without a following exec
   C -- command run in PDP-11 compatibility mode (VAX only)
   D -- command terminated with the generation of a core file
   X -- command was terminated with the signal SIGTERM
   + the name of the user who ran the process
   + time the process started


OPTIONS¶

--strict-match
Print only entries that match *all* of the arguments on the command
    line.
--print-controls
Print control characters.
--user name
List records for user with name. This is useful if you're trying to
      match a username that happens to be the same as a command (e.g., ed
      ).
--command name
List records for command name.
--tty name
List records for tty name.
--forwards
Read file forwards instead of backwards. This avoids trying to seek on the
      file and can be used to read from a pipe. This must be specified prior to
      any -f arguments.
-f filename, --file filename
Read from the file filename instead of acct. A filename of
      ""-"" will result in reading from stdin. This must either be the
      first -f option, or --forwards must precede all -f
      options.
--ahz hz
Use this flag to tell the program what AHZ should be (in hertz).
      This option is useful if you are trying to view an acct file
      created on another machine which has the same byte order and file format
      as your current machine, but has a different value for AHZ.
-p, --show-paging
Print paging statistics.
--pid
Show PID and PPID of the process if acct version 3 format is supported by
      kernel.
--pid
Add pid of the process and pid of the process parent to the output (pid is
      the last but one and parent pid the last column). These values are shown
      only when they are generated by acct function (depends on the version of
      kernel)
--debug
Print verbose internal information.
-V, --version
Print the version number of lastcomm.
-h, --help
Prints the usage string and default locations of system files to standard
      output and exits.
    




FILES¶
acct
The system wide process accounting file. See
  acct(5) (or pacct(5)) for further details.
  /var/log/account
This directory contains pacct files which contain the
  binary process accounting data as written by the kernel.



AUTHOR¶
The GNU accounting utilities were written by Noel Cragg
  <noel@gnu.ai.mit.edu>. The man page was adapted from the accounting
  texinfo page by Susan Kleinmann <sgk@sgk.tiac.net>.


SEE ALSO¶
last(1), acct(5)





1995 October 31










Source file:


lastcomm.1.en.gz (from acct 6.6.4-2)




Source last updated:


2018-08-23T16:01:38Z




Converted to HTML:


2020-08-08T10:10:34Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




","
LASTCOMM(1)		  BSD General Commands Manual		   LASTCOMM(1)

NAME
     lastcomm -- show last commands executed in reverse order

SYNOPSIS
     lastcomm [-f file] [command ...] [user ...] [terminal ...]

DESCRIPTION
     lastcomm gives information on previously executed commands.  With no
     arguments, lastcomm prints information about all the commands recorded
     during the current accounting file's lifetime.

     Option:

     -f file	 Read from file rather than the default accounting file.

     If called with arguments, only accounting entries with a matching command
     name, user name, or terminal name are printed.  So, for example:

	   lastcomm a.out root ttyd0

     would produce a listing of all the executions of commands named a.out by
     user root on the terminal ttyd0.

     For each process entry, the following are printed.

	   o   The name of the user who ran the process.
	   o   Flags, as accumulated by the accounting facilities in the sys-
	       tem.
	   o   The command name under which the process was called.
	   o   The amount of cpu time used by the process (in seconds).
	   o   The time the process started.
	   o   The elapsed time of the process.

     The flags are encoded as follows: ``S'' indicates the command was exe-
     cuted by the super-user, ``F'' indicates the command ran after a fork,
     but without a following exec(3), ``C'' indicates the command was run in
     PDP-11 compatibility mode (VAX only), ``D'' indicates the command termi-
     nated with the generation of a core file, and ``X'' indicates the command
     was terminated with a signal.

FILES
     /var/account/acct	Default accounting file.

SEE ALSO
     last(1), sigaction(2), acct(5), core(5)

HISTORY
     The lastcomm command appeared in 3.0BSD.

BSD			       December 22, 2006			   BSD
","# lastcomm

> Show last commands executed.
> More information: <https://manpages.debian.org/stable/acct/lastcomm.1.en.html>.

- Print informations about all of the commands in the acct (record file):

`lastcomm`

- Display commands executed by a given user:

`lastcomm --user {{user}}`

- Display information about a given command executed on the system:

`lastcomm --command {{command}}`

- Display information about commands executed on a given terminal:

`lastcomm --tty {{terminal_name}}`
"
cp,,,"
CP(1)			  BSD General Commands Manual			 CP(1)

NAME
     cp -- copy files

SYNOPSIS
     cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file target_file
     cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file ...
	target_directory

DESCRIPTION
     In the first synopsis form, the cp utility copies the contents of the
     source_file to the target_file.  In the second synopsis form, the con-
     tents of each named source_file is copied to the destination
     target_directory.	The names of the files themselves are not changed.  If
     cp detects an attempt to copy a file to itself, the copy will fail.

     The following options are available:

     -a    Same as -pPR options. Preserves structure and attributes of files
	   but not directory structure.

     -f    If the destination file cannot be opened, remove it and create a
	   new file, without prompting for confirmation regardless of its per-
	   missions.  (The -f option overrides any previous -n option.)

	   The target file is not unlinked before the copy.  Thus, any exist-
	   ing access rights will be retained.

     -H    If the -R option is specified, symbolic links on the command line
	   are followed.  (Symbolic links encountered in the tree traversal
	   are not followed.)

     -i    Cause cp to write a prompt to the standard error output before
	   copying a file that would overwrite an existing file.  If the
	   response from the standard input begins with the character `y' or
	   `Y', the file copy is attempted.  (The -i option overrides any pre-
	   vious -n option.)

     -L    If the -R option is specified, all symbolic links are followed.

     -n    Do not overwrite an existing file.  (The -n option overrides any
	   previous -f or -i options.)

     -P    If the -R option is specified, no symbolic links are followed.
	   This is the default.

     -p    Cause cp to preserve the following attributes of each source file
	   in the copy: modification time, access time, file flags, file mode,
	   user ID, and group ID, as allowed by permissions.  Access Control
	   Lists (ACLs) and Extended Attributes (EAs), including resource
	   forks, will also be preserved.

	   If the user ID and group ID cannot be preserved, no error message
	   is displayed and the exit value is not altered.

	   If the source file has its set-user-ID bit on and the user ID can-
	   not be preserved, the set-user-ID bit is not preserved in the
	   copy's permissions.	If the source file has its set-group-ID bit on
	   and the group ID cannot be preserved, the set-group-ID bit is not
	   preserved in the copy's permissions.  If the source file has both
	   its set-user-ID and set-group-ID bits on, and either the user ID or
	   group ID cannot be preserved, neither the set-user-ID nor set-
	   group-ID bits are preserved in the copy's permissions.

     -R    If source_file designates a directory, cp copies the directory and
	   the entire subtree connected at that point.	If the source_file
	   ends in a /, the contents of the directory are copied rather than
	   the directory itself.  This option also causes symbolic links to be
	   copied, rather than indirected through, and for cp to create spe-
	   cial files rather than copying them as normal files.  Created
	   directories have the same mode as the corresponding source direc-
	   tory, unmodified by the process' umask.

	   In -R mode, cp will continue copying even if errors are detected.

	   Note that cp copies hard-linked files as separate files.  If you
	   need to preserve hard links, consider using tar(1), cpio(1), or
	   pax(1) instead.

     -v    Cause cp to be verbose, showing files as they are copied.

     -X    Do not copy Extended Attributes (EAs) or resource forks.

     -c    copy files using clonefile(2)

     For each destination file that already exists, its contents are overwrit-
     ten if permissions allow.	Its mode, user ID, and group ID are unchanged
     unless the -p option was specified.

     In the second synopsis form, target_directory must exist unless there is
     only one named source_file which is a directory and the -R flag is speci-
     fied.

     If the destination file does not exist, the mode of the source file is
     used as modified by the file mode creation mask (umask, see csh(1)).  If
     the source file has its set-user-ID bit on, that bit is removed unless
     both the source file and the destination file are owned by the same user.
     If the source file has its set-group-ID bit on, that bit is removed
     unless both the source file and the destination file are in the same
     group and the user is a member of that group.  If both the set-user-ID
     and set-group-ID bits are set, all of the above conditions must be ful-
     filled or both bits are removed.

     Appropriate permissions are required for file creation or overwriting.

     Symbolic links are always followed unless the -R flag is set, in which
     case symbolic links are not followed, by default.	The -H or -L flags (in
     conjunction with the -R flag) cause symbolic links to be followed as
     described above.  The -H, -L and -P options are ignored unless the -R
     option is specified.  In addition, these options override each other and
     the command's actions are determined by the last one specified.

     If cp receives a SIGINFO (see the status argument for stty(1)) signal,
     the current input and output file and the percentage complete will be
     written to the standard output.

EXIT STATUS
     The cp utility exits 0 on success, and >0 if an error occurs.

COMPATIBILITY
     Historic versions of the cp utility had a -r option.  This implementation
     supports that option; however, its use is strongly discouraged, as it
     does not correctly copy special files, symbolic links, or fifo's.

     The -v and -n options are non-standard and their use in scripts is not
     recommended.

LEGACY DESCRIPTION
     In legacy mode, -f will override -i.  Also, under the -f option, the tar-
     get file is always unlinked before the copy.  Thus, new access rights
     will always be set.

     In -R mode, copying will terminate if an error is encountered.

     For more information about legacy mode, see compat(5).

SEE ALSO
     mv(1), rcp(1), umask(2), fts(3), compat(5), symlink(7)

STANDARDS
     The cp command is expected to be IEEE Std 1003.2 (``POSIX.2'') compati-
     ble.

HISTORY
     A cp command appeared in Version 1 AT&T UNIX.

BSD			       February 23, 2005			   BSD
","# cp

> Copy files and directories.

- Copy a file to another location:

`cp {{path/to/source_file.ext}} {{path/to/target_file.ext}}`

- Copy a file into another directory, keeping the filename:

`cp {{path/to/source_file.ext}} {{path/to/target_parent_directory}}`

- Recursively copy a directory's contents to another location (if the destination exists, the directory is copied inside it):

`cp -r {{path/to/source_directory}} {{path/to/target_directory}}`

- Copy a directory recursively, in verbose mode (shows files as they are copied):

`cp -vr {{path/to/source_directory}} {{path/to/target_directory}}`

- Copy text files to another location, in interactive mode (prompts user before overwriting):

`cp -i {{*.txt}} {{path/to/target_directory}}`

- Dereference symbolic links before copying:

`cp -L {{link}} {{path/to/target_directory}}`

- Use the full path of source files, creating any missing intermediate directories when copying:

`cp --parents {{source/path/to/file}} {{path/to/target_file}}`
"
reportbug,https://manpages.debian.org/buster/reportbug/reportbug.1.en.html,"



reportbug(1) — reportbug — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / reportbug
     
     
     
     / reportbug(1)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


EXAMPLES


CONFIGURATION FILES


ENVIRONMENT


NOTES


SEE ALSO


AUTHOR







other versions




buster 7.5.3~deb10u1


testing 7.7.0


unstable 7.7.0






Scroll to navigation



reportbug(1)
General Commands Manual
reportbug(1)




NAME¶
reportbug - reports a bug to a debbugs server


SYNOPSIS¶
reportbug [options] <package | pseudo-package |
  absolute-pathname>


DESCRIPTION¶
reportbug is primarily designed to report bugs in the Debian
  distribution; by default, it creates an email to the Debian bug tracking
  system at submit@bugs.debian.org with information about the bug you've
  found, and makes a carbon copy of the report for you as well.
Using the --bts option, you can also report bugs to other
    servers that use the Debian bug tracking system, debbugs.
You may specify either a package name or a filename; if you use a
    filename, it must either be an absolute filename (so beginning with a
    /) or if you want reportbug to search the system for a
    filename, see the --filename and --path options below. If
    installed, also dlocate is used to identify the filename location and
    thus the package containing it.
You can also specify a pseudo-package; these are used in
    the Debian bug tracking system to track issues that are not related to one
    specific package. Run reportbug without any arguments, then enter
    other at the package prompt, to see a list of the most commonly-used
    pseudo-packages.


OPTIONS¶
The program follows the usual GNU command line syntax, with long options
  starting with two dashes (`--'). A summary of options are included
  below.

-h, --help
Show summary of options.
--version
Show the version of reportbug and exit.
-A FILENAME, --attach=FILENAME
Attach a file to the bug report; both text and binary files are
      acceptable; this option can be specified multiple times to attach several
      files. This routine will create a MIME attachment with the file included;
      in some cases (usually text files), it is probably better to use
      -i/--include option. (Please note that Debian's bug tracking system
      has limited support for MIME attachments.)
    This option supports also globbing (i.e. names with wildcards,
        like file.*) but remember to include them between single quotes (the
        previous example becomes: 'file.*') else the shell would expand it
        before calling reportbug leading to an error.
Be aware that when using an external MUA to send the message
        (such as mutt), the attachment feature is not available and no file will
        be attached at all: the MUA feature to attach files must be used instead
        (so from within the MUA).

-b, --no-query-bts
Don't check the Debian bug tracking system to see if this problem has
      already been reported; useful for offline use or if you're really
      sure it's a bug.
--query-bts
Check the Debian bug tracking system to see if this problem has already
      been reported (default).
-B SYSTEM, --bts=SYSTEM
Instead of the Debian bug server (or the bug server specified in
      /etc/reportbug.conf, use the server specified by
    SYSTEM.
--body=BODY
Use the specified BODY as the body of the message. The body text
      will be wrapped at 70 columns, and the normal reportbug headers and
      footers will be added as appropriate. The editor prompt and any
      ""special"" prompting will be bypassed.
--body-file=BODYFILE, --bodyfile=BODYFILE
The contents of the (assumed to be) text file BODYFILE will be used
      as the message body. This file is assumed to be properly formatted (i.e.
      reasonable line lengths, etc.). The usual headers and footers will be
      added, and the editor step and ""special"" prompts will be
      skipped. (BODYFILE may also be a named pipe; using a device special
      file may lead to unusual results.)
-c, --no-config-files
Omit configuration files from the bug report without asking. By default,
      you are asked if you want to include them; in some cases, doing so may
      cause sensitive information to be sent via email.
-C CLASS, --class=CLASS
Specify report class for GNATS BTSes.
--configure
Rerun the reportbug first time configuration routine, and write a
      new $HOME/.reportbugrc file. This will erase any pre-existing
      settings in the file; however, a backup will be written as
      $HOME/.reportbugrc~.
--check-available
Check for newer releases of the package at packages.debian.org
      (default). In advanced and expert mode, check
      incoming.debian.org and
      http://ftp-master.debian.org/new.html too.
--no-check-available
Do not check for newer releases of the package at
      packages.debian.org.
--debconf
Include debconf settings in your report.
--no-debconf
Do not include debconf settings from your report.
-d, --debug
Don't send a real bug report to Debian; send it to yourself instead. This
      is primarily used for testing by the maintainer.
--test
Operate in test mode (maintainer use only).
--draftpath=DRAFTPATH
Save the draft (for example, when exiting and saving the report without
      reporting it) into DRAFTPATH directory(default /tmp).
-e EDITOR, --editor=EDITOR
Specify the editor to use, overriding any EDITOR or VISUAL
      environment variable setting.
--email=ADDRESS
Set the email address your report should appear to be sent from (i.e. the
      address that appears in the From header). This should be the actual
      Internet email address on its own (i.e. without a real name or comment
      part, like foo@example.com). This setting will override the
      EMAIL and DEBEMAIL environment variables, but not
      REPORTBUGEMAIL.
--envelope-from
Specify the Envelope From mail header (also known as Return-path); by
      default it's the From address but it can be selected a different one in
      case the MTA doesn't canonicalize local users to public addresses.
    

--mbox-reader-cmd=MBOX_READER_CMD
Specify a command to open the bug reports mbox file. You can use %s
      to substitute the mbox file to be used, and %% to insert a literal
      percent sign. If no %s is specified, the mbox file name is supplied
      at the end of the argument list.
--exit-prompt
Display a prompt before exiting; this is useful if reportbug is run
      in a transient terminal (i.e. from its Debian menu entry).
-f FILENAME, --filename=FILENAME
Report a bug in the package containing FILENAME so you don't have
      to figure out what package the file belongs to. The path will be searched
      for an exact path for FILENAME before attempting to broaden the
      search to all files. If dlocate is installed, FILENAME is
      actually a regular expression.
--from-buildd=BUILDD_FORMAT
This options is a shortcut for buildd admins to report bugs from buildd
      log; the option expects a value in the format of $source_$version
      where $source is the source package the bug will be reported
      against and $version is its version.
--path
If the -f/--filename option is also specified, only search the path
      for the specified FILENAME. Specifying an absolute path with the
      -f/--filename option (i.e. one beginning with a /) overrides
      this behavior.
-g, --gnupg, --gpg
Attach a digital signature to the bug report using GnuPG (the GNU
      Privacy Guard). (This argument will be ignored if you are using an MUA to
      edit and send your report.)
-G, --gnus
Use the Gnus mail and news reader to send your report, rather than using
      the editor.
-H HEADER, --header=HEADER
Add a custom RFC2822 header to your email; for example, to send a carbon
      copy of the report to debian-68k@lists.linux-m68k.org you could use
      -H 'X-Debbugs-CC: debian-68k@lists.linux-m68k.org'
-i FILE, --include=FILE
Include the specified FILE as part of the body of the message to be
      edited. Can be used multiple times to add multiple files; text-only
      please! From a suggestion by Michael Alan Dorman in the bug mailing
      list. (See also the -A/--attach option.)
-I, --no-check-installed
Do not check whether the package is installed before filing a report. This
      is generally only useful when filing a report on a package you know is not
      installed on your system.
--check-installed
Check if the specified package is installed when filing reports. (This is
      the default behavior of reportbug.)
-j JUSTIFICATION, --justification=JUSTIFICATION
Bugs in Debian that have serious, grave, or critical
      severities must meet certain criteria to be classified as such. This
      option allows you to specify the justification for a release-critical bug,
      instead of being prompted for it.
-k, --kudos
Send appreciative email to the recorded maintainer address, rather than
      filing a bug report. (You can also send kudos to
      packagename@packages.debian.org, for packages in the Debian
      archive; however, this option uses the Maintainer address from the control
      file, so it works with other package sources too.)
-K KEYID, --keyid=KEYID
Private key to use for PGP/GnuPG signatures. If not specified, the first
      key in the secret keyring that matches your email address will be
    used.
--latest-first
Display the bug reports list sorted and with the latest reports at the
      top.
--license
Show reportbug's copyright and license information on standard
      output.
--list-cc=ADDRESS
Send a carbon copy of the report to the specified list after a report
      number is assigned; this is the equivalent to the option -H
      'X-Debbugs-CC: ADDRESS'. This option will only work as intended with
      debbugs systems.
--list-cc-me
Send a carbon copy of the report to your automatically detected email
      address after a report number is assigned. This sets an
      X-Debbugs-CC header specifying that address. This option will only
      work as intended with debbugs systems. See the documentation for
      the --email option and the ENVIRONMENT section for
      information on how reportbug detects your email address.
-m, --maintonly
Only send the bug to the package maintainer; the bug tracking system will
      not send a copy to the bug report distribution lists.
--max-attachment-size=MAX_ATTACHMENT_SIZE
Specify the maximum size any attachment file can have (this also include
      the file for --body-file option). If an attachment file is too big, there
      could be problems in delivering the email (and also to compose it), so we
      set a limit to attachment size. By default this is 10 megabytes.
--mirror=MIRRORS
Add a BTS mirror.
--mode=MODE
Set the operating mode for reportbug. reportbug currently
      has four operating modes: novice (the default), standard,
      advanced, and expert.
    novice mode is designed to minimize prompting about
        things that ""ordinary users"" would be unlikely to know or care
        about, shifting the triage burden onto the maintainer. Checking for new
        versions is only done for the stable distribution in this mode. It is
        currently the default mode.
standard mode includes a relatively large number of
        prompts and tries to encourage users to not file frivolous or duplicate
        bug reports.
advanced mode is like standard mode, but may
        include shortcuts suitable for more advanced users of Debian, without
        being as close to the metal (and potential flamage) as expert
        mode. (Currently, the only differences from standard mode are
        that it assumes familiarity with the ""incoming"" queue; it
        allows the reporting of bugs on ""dependency"" packages; and it
        does not prompt where to insert the report text in the editor.)
expert mode is designed to minimize prompts that are
        designed to discourage frivolous or unnecessary bug reports,
        ""severity inflation,"" and the like. In expert mode,
        reportbug assumes the user is thoroughly familiar with Debian
        policies. In practice, this means that reporters are no longer required
        to justify setting a high severity on a bug report, and certain
        automated cleanups of the message are bypassed. Individuals who do not
        regularly contribute to the Debian project are highly discouraged
        from using expert mode, as it can lead to flamage from maintainers when
        used improperly.

-M, --mutt
Instead of spawning an editor to revise the bug report, use the
      mutt mail reader to edit and send it.
--mta=MTA
Specify an alternate MTA, instead of /usr/sbin/sendmail (the
      default). Any smtphost setting will override this one.
--mua=MUA
Instead of spawning an editor to revise the bug report, use the specified
      MUA (mail user agent) to edit and send it. --mutt and
      --nmh options are processed.
-n, --mh, --nmh
Instead of spawning an editor to revise the bug report, use the
      comp command (part of the nmh and mh mail systems) to
      edit and send it.
-N BUGNUMBER, --bugnumber BUGNUMBER
Run reportbug against the specified bug report, useful when
      following-up a bug and its number is already known.
--no-bug-script
Do not execute the bug script (if present); this option can be useful
      together with --template to suppress every interactive actions, since some
      bug scripts can ask questions.
--no-cc-menu
Don't display the menu to enter additional addresses (CC).
--no-tags-menu
Don't display the menu to enter additional tags.
-o FILE, --output=FILE
Instead of sending an email, redirect it to the specified filename.
    The output file is a full dump of the email message, so it
        contains both headers and mail body. If you want to use it as a template
        to create a new bug report, then you have to remove all the headers
        (mind the Subject one, though) and start the report at the
        Package pseudo-header.

-O, --offline
Disable all external queries. Currently has the same effect as
      --no-check-available --no-query-bts.
-p, --print
Instead of sending an email, print the bug report to standard output, so
      you can redirect it to a file or pipe it to another program.
    This option only outputs a template for a bug report (but,
        differently from --template it's more interactive); you will need
        to fill in the long description.

--paranoid
Show the contents of the message before it is sent, including all headers.
      Automatically disabled if in template mode.
--no-paranoid
Don't show the full contents of the message before it is sent
    (default).
--pgp
Attach a digital signature to the bug report using PGP (Pretty Good
      Privacy). Please note, however, that the Debian project is phasing out the
      use of PGP in favor of GnuPG. (This argument will be ignored
      if using an MUA to edit and send your report.)
--proxy=PROXY, --http_proxy=PROXY
Specify the WWW proxy server to use to handle the query of the bug
      tracking system. You should only need this parameter if you are behind a
      firewall. The PROXY argument should be formatted as a valid HTTP
      URL, including (if necessary) a port number; for example,
      http://192.168.1.1:3128/.
-P PSEUDO-HEADER, --pseudo-header=PSEUDO-HEADER
Add a custom pseudo-header to your report; for example, to add the
      mytag usertag for the user humberto@example.com to the bug,
      you could use -P 'User: humberto@example.com' -P 'Usertags:
mytag'.
-q, --quiet
Suppress diagnostic messages to standard error.
-Q, --query-only
Do not submit a bug report; just query the BTS. Option ignored if you
      specify --no-bts-query.
--query-source
Query on all binary packages built by the same source, not just the binary
      package specified.
--no-query-source
Only query on the binary package specified on the command line.
--realname=NAME
Set the real name (human-readable name) to use for your report.
--report-quiet
Register the bug in the bug tracking system, but don't send a report to
      the package maintainer or anyone else. Don't do this unless you're the
      maintainer of the package in question, or you really know what you are
      doing.
--reply-to=ADDRESS, --replyto=ADDRESS
Set the Reply-To address header in your report.
-s SUBJECT, --subject=SUBJECT
Set the subject of the bug report (i.e. a brief explanation of the
      problem, less than 60 characters). If you do not specify this switch, you
      will be prompted for a subject.
--security-team
If the 'security' tag is set, this option will explicitly specify to send
      the report only to the Debian Security Team, as this is an undisclosed
      vulnerability.
--no-security-team
If the 'security' tag is set, this option will explicitly specify to not
      send the report only to the Debian Security Team, as this is not an
      undisclosed vulnerability.
-S SEVERITY, --severity=SEVERITY
Specify a severity level, from critical, grave,
      serious, important, normal, minor, and
      wishlist.
--smtphost=HOST[:PORT]
Use the mail transport agent (MTA) at HOST to send your report,
      instead of your local /usr/sbin/sendmail program. This should
      generally be your ISP's outgoing mail server; you can also use 'localhost'
      if you have a working mail server running on your machine. If the
      PORT is omitted, the standard port for SMTP, port 25, is used.
--timeout=SECONDS
Specify the network timeout, the number of seconds to wait for a resource
      to respond. If nothing is specified, a default timeout of 1 minute is
      selected.
    In case of a network error, there are chances it's due to a
        too low timeout: try passing the --timeout option with a higher value
        than default.

--tls
If using SMTP, use Transport Layer Security (TLS) encryption to secure the
      connection to the mail server. Some SMTP servers may require this
    option.
--smtpuser=USERNAME
If using SMTP, use the specified USERNAME for authentication.
--smtppasswd=PASSWORD
If using SMTP, use the specified PASSWORD for authentication. If
      the password isn't specified on the command line or in the configuration
      file, a prompt will be displayed asking for it.
    Use of this option is insecure on multiuser systems. Instead,
        you should set this option in $HOME/.reportbugrc and ensure it is
        only readable by your user (e.g. with chmod 600
$HOME/.reportbugrc).

--src, --source
Specify to report the bug against the source package, and not the binary
      package (default behaviour). In order for this option to work, you have to
      populate the relevant 'deb-src' lines in /etc/apt/sources.list so that apt
      cache will know about source packages too.
-t TYPE, --type=TYPE
Specify the type of report to be submitted; currently accepts either
      gnats or debbugs.
-T TAG, --tag=TAG
Specify a tag to be filed on this report, for example --tag=patch.
      Multiple tags can be specified using multiple -T/--tag arguments.
    Alternatively, you can specify the 'tag' none to bypass
        the tags prompt without specifying any tags; this will also ignore any
        tags specified on the command line.

--template
Output a template report to standard output. Differently from
      -p/--print, it tries to be not interactive, and presents a template
      without user's input.
-u INTERFACE, --interface=INTERFACE, --ui=INTERFACE
Specify the user interface to use. Valid options are text,
      urwid, and gtk; default is taken from the reportbug
      configuration files.
-v, --verify
Verify the integrity of the package (if installed) using debsums
      before reporting.
--no-verify
Do not verify the integrity of the package with debsums.
-V VERSION, --package-version=VERSION
Specify the version of the package the problem was found in. This is
      probably most useful if you are reporting a bug in a package that is not
      installable or installed on a different system.
-x, --no-cc
Don't send a blind carbon copy (BCC) of the bug report to the submitter
      (i.e. yourself).
-z, --no-compress
Don't compress configuration files by removing comments and blank
    lines.



EXAMPLES¶

reportbug lynx-ssl
Report a bug in the lynx-ssl package.
reportbug --path --filename=ls
Report a bug in the installed package that includes a program in your path
      called ls.



CONFIGURATION FILES¶
From version 0.22 on, reportbug has supported a simple run control file
  syntax. Commands are read from /etc/reportbug.conf and
  $HOME/.reportbugrc with commands in the latter overriding those in the
  former.
Commands are not case sensitive, and currently take 0 or 1
    argument; arguments containing whitespace must be enclosed in quotes.
Any line starting with # is taken to be a comment and will
    be ignored.
Generally, options corresponding to the long options for
    reportbug are supported, without leading -- sequences. See
    reportbug.conf(5) for all acceptable options and detailed
    information.


ENVIRONMENT¶

VISUAL
Editor to use for editing your bug report.
EDITOR
Editor to use for editing the bug report (overridden by
    VISUAL).
REPORTBUGEMAIL, DEBEMAIL, EMAIL
Email address to use as your from address (in this order). If no
      environment variable exists, the default is taken from your user name and
      /etc/mailname.
DEBFULLNAME, DEBNAME, NAME
Real name to use; default is taken from /etc/passwd.
REPLYTO
Address for Reply-To header in outgoing mail.
MAILCC
Use the specified CC address on your email. Note you can also use the
      -H option for this (and for Bcc's too).
MAILBCC
Use the specified BCC address, instead of your email address. (CC and BCC
      based on suggestions from Herbert Thielen in the bug
    wishlist).
http_proxy
Provides the address of a proxy server to handle the BTS query. This
      should be a valid http URL for a proxy server, including any
      required port number (simply specifying a hostname, or omitting a port
      other than 80, WILL NOT WORK).



NOTES¶
reportbug should probably be compatible with other bug tracking systems,
  like bugzilla (used by the GNOME and Mozilla projects) and
  jitterbug (used by Samba, AbiSource and FreeCiv) but it isn't.


SEE ALSO¶
reportbug.conf(5), http://www.debian.org/Bugs/Developer#tags for
  available tags, querybts(1)


AUTHOR¶
Chris Lawrence <lawrencc@debian.org>, Sandro Tosi
  <morph@debian.org>.
























Source file:


reportbug.1.en.gz (from reportbug 7.5.3~deb10u1)




Source last updated:


2019-08-30T11:52:06Z




Converted to HTML:


2020-08-08T10:05:46Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# reportbug

> Bug report tool of Debian distribution.
> More information: <https://manpages.debian.org/buster/reportbug/reportbug.1.en.html>.

- Generate a bug report about a specific package, then send it by e-mail:

`reportbug {{package}}`

- Report a bug that is not about a specific package (general problem, infrastructure, etc.):

`reportbug other`

- Write the bug report to a file instead of sending it by e-mail:

`reportbug -o {{filename}} {{package}}`
"
calcurse,https://calcurse.org,"

calcurse: a text-based calendar and scheduling application











About
Downloads
Support
Development
❤ Donate






Download now
calcurse 4.6.0 (source)


MD5 checksum
Signature
Binary packages
Release notes


What is calcurse?

	calcurse is a calendar and scheduling application for the command line.
	It helps keep track of events, appointments and everyday tasks. A
	configurable notification system reminds user of upcoming deadlines,
	the curses based interface can be customized to suit user needs and a
	very powerful set of command line options can be used to filter and
	format appointments, making it suitable for use in scripts.


Never miss a release again.

	If you want to receive release announcements, you can add your
	email address to the announcement mailing list
	here.


Love calcurse?

	Contribute by writing code or
	make a donation to support the
	project.




Important features

hooks – run scripts when loading/saving data, e.g. to put your calendar data under version control
experimental CalDAV support – synchronize calcurse with your mobile devices!
support for various types of appointments and TODO items, including all-day events and recurring appointments
fast and customizable curses-based interface
powerful non-interactive command line interface that can be used by scripts
user-definable key bindings
fully user-configurable notification system (ability to send mails or anything else that could remind you of your upcoming appointments)
import capabilities with support for iCalendar format
export capabilities with support for iCalendar and pcal formats
ability to attach notes to each calendar element, and to edit them with your favorite text editor
support for internationalization with texts translated to English, French, German, Dutch, Spanish and Italian
UTF-8 support



			Copyright © 2012–2020
			calcurse Development Team.
			Licensed under the terms of the BSD License.
		

",,"# calcurse

> A text-based calendar and scheduling application for the command line.
> More information: <https://calcurse.org>.

- Start calcurse on interactive mode:

`calcurse`

- Print the appointments and events for the current day and exit:

`calcurse --appointment`

- Remove all local calcurse items and import remote objects:

`calcurse-caldav --init=keep-remote`

- Remove all remote objects and push local calcurse items:

`calcurse-caldav --init=keep-local`

- Copy local objects to the CalDAV server and vice versa:

`calcurse-caldav --init=two-way`
"
see,,,,"# see

> Alias to `run-mailcap`'s view.
> An alias to a `run-mailcap`'s action print.

- See action can be used to view any file (usually image) on default mailcap explorer:

`see {{filename}}`

- Using with `run-mailcap`:

`run-mailcap --action=view {{filename}}`
"
isoinfo,,,,"# isoinfo

> Utility programs for dumping and verifying ISO disk images.

- List all the files included in an ISO image:

`isoinfo -f -i {{path/to/image.iso}}`

- E[x]tract a specific file from an ISO image and send it out `stdout`:

`isoinfo -i {{path/to/image.iso}} -x {{/PATH/TO/FILE/INSIDE/ISO.EXT}}`

- Show header information for an ISO disk image:

`isoinfo -d -i {{path/to/image.iso}}`
"
sensible-browser,,,,"# sensible-browser

> Open the default browser.

- Open a new window of the default browser:

`sensible-browser`

- Open a url in the default browser:

`sensible-browser {{url}}`
"
thunar,,,,"# thunar

> Graphical file manager for XFCE desktop environments.

- Open a new window showing the current directory:

`thunar`

- Open the bulk rename utility:

`thunar --bulk-rename`

- Close all open thunar windows:

`thunar --quit`
"
debuild,https://manpages.debian.org/debuild,"



debuild(1) — devscripts — Debian buster — Debian Manpages
















MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / devscripts
     
     
     
     / debuild(1)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


Directory name checking


ENVIRONMENT VARIABLES


SUPERUSER REQUIREMENTS


HOOKS


OPTIONS


CONFIGURATION VARIABLES


EXAMPLES


SEE ALSO


AUTHOR







other versions




buster 2.19.5+deb10u1


buster-backports 2.20.4~bpo10+1


testing 2.20.4


unstable 2.20.4






other languages




Deutsch


English


français






Scroll to navigation



DEBUILD(1)
General Commands Manual
DEBUILD(1)




NAME¶
debuild - build a Debian package


SYNOPSIS¶
debuild [debuild options] [dpkg-buildpackage options]
  [--lintian-opts lintian options]

debuild [debuild options] --
  binary|binary-arch|binary-indep|clean ...


DESCRIPTION¶
debuild creates all the files necessary for uploading a Debian package.
  It first runs dpkg-buildpackage, then runs lintian on the
  .changes file created (assuming that lintian is installed), and
  finally signs the appropriate files (using debsign(1) to do this
  instead of dpkg-buildpackage(1) itself; all relevant key-signing
  options are passed on). Signing will be skipped if the distribution is
  UNRELEASED, unless dpkg-buildpackage's --force-sign
  option is used. Parameters can be passed to dpkg-buildpackage and
  lintian, where the parameters to the latter are indicated with the
  --lintian-opts option. The allowable options in this case are
  --lintian and --no-lintian to force or skip the lintian
  step, respectively. The default is to run lintian. There are also
  various options available for setting and preserving environment variables, as
  described below in the Environment Variables section. In this method of
  running debuild, we also save a build log to the file
  ../<package>_<version>_<arch>.build.
An alternative way of using debuild is to use one or more
    of the parameters binary, binary-arch, binary-indep and
    clean, in which case debuild will attempt to gain root
    privileges and then run debian/rules with the given parameters. A
    --rootcmd=gain-root-command or
    -rgain-root-command option may be used to specify a method of
    gaining root privileges. The gain-root-command is likely to be one of
    fakeroot, sudo or super. See below for further
    discussion of this point. Again, the environment preservation options may be
    used. In this case, debuild will also attempt to run
    dpkg-checkbuilddeps first; this can be explicitly requested or
    switched off using the options -D and -d respectively. Note
    also that if either of these or a -r option is specified in the
    configuration file option DEBUILD_DPKG_BUILDPACKAGE_OPTS, then it
    will be recognised even in this method of invocation of debuild.
debuild also reads the devscripts configuration
    files as described below. This allows default options to be given.


Directory name checking¶
In common with several other scripts in the devscripts package,
  debuild will climb the directory tree until it finds a
  debian/changelog file before attempting to build the package. As a
  safeguard against stray files causing potential problems, it will examine the
  name of the parent directory once it finds the debian/changelog file,
  and check that the directory name corresponds to the package name. Precisely
  how it does this is controlled by two configuration file variables
  DEVSCRIPTS_CHECK_DIRNAME_LEVEL and
  DEVSCRIPTS_CHECK_DIRNAME_REGEX, and their corresponding command-line
  options --check-dirname-level and --check-dirname-regex.
DEVSCRIPTS_CHECK_DIRNAME_LEVEL can take the following
    values:

0
Never check the directory name.
1
Only check the directory name if we have had to change directory in our
      search for debian/changelog. This is the default behaviour.
2
Always check the directory name.

The directory name is checked by testing whether the current
    directory name (as determined by pwd(1)) matches the regex given by
    the configuration file option DEVSCRIPTS_CHECK_DIRNAME_REGEX or by
    the command line option --check-dirname-regex regex. Here
    regex is a Perl regex (see perlre(3perl)), which will be
    anchored at the beginning and the end. If regex contains a '/', then
    it must match the full directory path. If not, then it must match the full
    directory name. If regex contains the string ´PACKAGE', this
    will be replaced by the source package name, as determined from the
    changelog. The default value for the regex is:
    ´PACKAGE(-.+)?', thus matching directory names such as PACKAGE and
    PACKAGE-version.


ENVIRONMENT VARIABLES¶
As environment variables can affect the building of a package, often
  unintentionally, debuild sanitises the environment by removing all
  environment variables except for TERM, HOME, LOGNAME,
  GNUPGHOME, PGPPATH, GPG_AGENT_INFO, GPG_TTY,
  DBUS_SESSION_BUS_ADDRESS, FAKEROOTKEY, DEBEMAIL,
  DEB_ *, the (C, CPP, CXX, LD and
  F)FLAGS variables and their _APPEND counterparts and the
  locale variables LANG and LC_*. TERM is set to
  `dumb' if it is unset, and PATH is set to
  ""/usr/sbin:/usr/bin:/sbin:/bin:/usr/bin/X11"".
If a particular environment variable is required to be passed
    through untouched to the build process, this may be specified by using a
    --preserve-envvar envvar (which can also be written as
    -e envvar option). The environment may be left untouched by
    using the --preserve-env option. However, even in this case, the
    PATH will be set to the sane value described above. The only
    way to prevent PATH from being reset is to specify a
    --preserve-envvar PATH option. But you are warned that using programs
    from non-standard locations can easily result in the package being broken,
    as it will not be able to be built on standard systems.
Note that one may add directories to the beginning of the
    sanitised PATH, using the --prepend-path option. This is
    useful when one wishes to use tools such as ccache or distcc
    for building.
It is also possible to avoid having to type something like
    FOO =bar debuild -e FOO by writing
    debuild -e FOO=bar or the long form
    debuild --set-envvar FOO=bar.


SUPERUSER REQUIREMENTS¶
debuild needs to be run as superuser to function properly. There are
  three fundamentally different ways to do this. The first, and preferable,
  method is to use some root-gaining command. The best one to use is probably
  fakeroot(1), since it does not involve granting any genuine privileges.
  super(1) and sudo(1) are also possibilities. If no -r (or
  --rootcmd) option is given (and recall that dpkg-buildpackage
  also accepts a -r option) and neither of the following methods is used,
  then -rfakeroot will silently be assumed.
The second method is to use some command such as su(1) to
    become root, and then to do everything as root. Note, though, that
    lintian will abort if it is run as root or setuid root; this can be
    overcome using the --allow-root option of lintian if you know
    what you are doing.
The third possible method is to have debuild installed as
    setuid root. This is not the default method, and will have to be installed
    as such by the system administrator. It must also be realised that anyone
    who can run debuild as root or setuid root has full access
    to the whole machine. This method is therefore not recommended, but will
    work. debuild could be installed with mode 4754, so that only members
    of the owning group could run it. A disadvantage of this method would be
    that other users would then not be able to use the program. There are many
    other variants of this option involving multiple copies of debuild,
    or the use of programs such as sudo or super to grant root
    privileges to users selectively. If the sysadmin wishes to do this, she
    should use the dpkg-statoverride program to change the permissions of
    /usr/bin/debuild. This will ensure that these permissions are
    preserved across upgrades.


HOOKS¶
debuild supports a number of hooks when running dpkg-buildpackage.
  Note that the hooks dpkg-buildpackage to lintian (inclusive) are
  passed through to dpkg-buildpackage using its corresponding
  --hook-name option. The available hooks are as follows:

dpkg-buildpackage-hook
Run before dpkg-buildpackage begins by calling
      dpkg-checkbuilddeps.



Hook is run inside the unpacked source.

Corresponds to dpkg's init hook.


clean-hook
Run before dpkg-buildpackage runs debian/rules clean to
      clean the source tree. (Run even if the tree is not being cleaned because
      -nc is used.)



Hook is run inside the unpacked source.

Corresponds to dpkg's preclean hook.


dpkg-source-hook
Run after cleaning the tree and before running dpkg-source. (Run
      even if dpkg-source is not being called because -b,
      -B, or -A is used.)



Hook is run inside the unpacked source.

Corresponds to dpkg's source hook.


dpkg-build-hook
Run after dpkg-source and before calling debian/rules build.
      (Run even if this is a source-only build, so debian/rules build is
      not being called.)



Hook is run inside the unpacked source.

Corresponds to dpkg's build hook.


dpkg-binary-hook
Run between debian/rules build and debian/rules
      binary(-arch). Run only if a binary package is being
      built.



Hook is run inside the unpacked source.

Corresponds to dpkg's binary hook.


dpkg-genchanges-hook
Run after the binary package is built and before calling
      dpkg-genchanges.



Hook is run inside the unpacked source.

Corresponds to dpkg's changes hook.


final-clean-hook
Run after dpkg-genchanges and before the final debian/rules
      clean. (Run even if we are not cleaning the tree post-build, which is
      the default.)



Hook is run inside the unpacked source.

Corresponds to dpkg's postclean hook.


lintian-hook
Run (once) before calling lintian. (Run even if we are not calling
      lintian.)



Hook is run from parent directory of unpacked source.

Corresponds to dpkg's check hook.


signing-hook
Run after calling lintian before any signing takes place. (Run even
      if we are not signing anything.)



Hook is run from parent directory of unpacked source.

Corresponds to dpkg's sign hook, but is run by
      debuild.


post-dpkg-buildpackage-hook
Run after everything has finished.



Hook is run from parent directory of unpacked source.

Corresponds to dpkg's done hook, but is run by
      debuild.

A hook command can be specified either in the configuration file
    as, for example, DEBUILD_SIGNING_HOOK='foo' (note the hyphens change into
    underscores!) or as a command line option --signing-hook-foo. The
    command will have certain percent substitutions made on it: %% will
    be replaced by a single % sign, %p will be replaced by the
    package name, %v by the package version number, %s by the
    source version number, %u by the upstream version number. Neither
    %s nor %u will contain an epoch. %a will be 1 if
    the immediately following action is to be performed and 0 if not (for
    example, in the dpkg-source hook, %a will become 1 if
    dpkg-source is to be run and 0 if not). Then it will be handed
    to the shell to deal with, so it can include redirections and stuff. For
    example, to only run the dpkg-source hook if dpkg-source is to
    be run, the hook could be something like: ""if [ %a -eq 1 ]; then ...;
    fi"".
Please take care with hooks, as misuse of them can lead to
    packages which FTBFS (fail to build from source). They can be useful for
    taking snapshots of things or the like.


OPTIONS¶
For details, see above.

--no-conf, --noconf
Do not read any configuration files. This can only be used as the first
      option given on the command-line.
--rootcmd=gain-root-command,
    -rgain-root-command
Command to gain root (or fake root) privileges.
--preserve-env
Do not clean the environment, except for PATH.
--preserve-envvar=var, -evar
Do not clean the var variable from the environment.



If var ends in an asterisk (""*"") then all variables with
      names that match the portion of var before the asterisk will be
      preserved.


--set-envvar=var=value,
    -evar=value
Set the environment variable var to value and do not remove
      it from the environment.
--prepend-path=value 
Once the normalized PATH has been set, prepend value to it.
--lintian
Run lintian after dpkg-buildpackage. This is the default
      behaviour, and it overrides any configuration file directive to the
      contrary.
--no-lintian
Do not run lintian after dpkg-buildpackage.
--no-tgz-check
Even if we're running dpkg-buildpackage and the version number has
      a Debian revision, do not check that the .orig.tar.gz file or
      .orig directory exists before starting the build.
--tgz-check
If we're running dpkg-buildpackage and the version number has a
      Debian revision, check that the .orig.tar.gz file or .orig
      directory exists before starting the build. This is the default
    behaviour.
--username username
When signing, use debrsign instead of debsign.
      username specifies the credentials to be used.
--foo-hook=hook
Set a hook as described above. If hook is blank, this unsets the
      hook.
--clear-hooks
Clears all hooks. They may be reinstated by later command line
    options.
--check-dirname-level N
See the above section Directory name checking for an explanation of
      this option.
--check-dirname-regex regex
See the above section Directory name checking for an explanation of
      this option.
-d
Do not run dpkg-checkbuilddeps to check build dependencies.
-D
Run dpkg-checkbuilddeps to check build dependencies.



CONFIGURATION VARIABLES¶
The two configuration files /etc/devscripts.conf and ~/.devscripts
  are sourced by a shell in that order to set configuration variables. Command
  line options can be used to override some of these configuration file
  settings, otherwise the --no-conf option can be used to prevent reading
  these files. Environment variable settings are ignored when these
  configuration files are read. The currently recognised variables are:

DEBUILD_PRESERVE_ENV
If this is set to yes, then it is the same as the
      --preserve-env command line parameter being used.
DEBUILD_PRESERVE_ENVVARS
Which environment variables to preserve. This should be a comma-separated
      list of variables. This corresponds to using possibly multiple
      --preserve-envvar or -e options.
DEBUILD_SET_ENVVAR_var=value
This corresponds to
    --set-envvar=var=value.
DEBUILD_PREPEND_PATH
This corresponds to --prepend-path.
DEBUILD_ROOTCMD
Setting this variable to prog is the equivalent of
      -rprog.
DEBUILD_TGZ_CHECK
Setting this variable to no is the same as the
      --no-tgz-check command line option.
DEBUILD_SIGNING_USERNAME
Setting this variable is the same as using the --username command
      line option.
DEBUILD_DPKG_BUILDPACKAGE_OPTS
These are options which should be passed to the invocation of
      dpkg-buildpackage. They are given before any command-line options.
      Due to issues of shell quoting, if a word containing spaces is required as
      a single option, extra quotes will be required. For example, to ensure
      that your own GPG key is always used, even for sponsored uploads, the
      configuration file might contain the line:




DEBUILD_DPKG_BUILDPACKAGE_OPTS=""-k'Julian Gilbey <jdg@debian.org>' -sa""
    


which gives precisely two options. Without the extra single quotes,
      dpkg-buildpackage would reasonably complain that Gilbey is
      an unrecognised option (it doesn't start with a - sign).

Also, if this option contains any -r, -d or -D
      options, these will always be taken account of by debuild. Note
      that a -r option in this variable will override the setting in
      DEBUILD_ROOTCMD.


DEBUILD_FOO_HOOK
The hook variable for the foo hook. See the section on hooks above
      for more details. By default, this is empty.
DEBUILD_LINTIAN
Should we run lintian? If this is set to no, then
      lintian will not be run.
DEBUILD_LINTIAN_OPTS
These are options which should be passed to the invocation of
      lintian. They are given before any command-line options, and the
      usage of this variable is as described for the
      DEBUILD_DPKG_BUILDPACKAGE_OPTS variable.
DEVSCRIPTS_CHECK_DIRNAME_LEVEL,
    DEVSCRIPTS_CHECK_DIRNAME_REGEX
See the above section Directory name checking for an explanation of
      these variables. Note that these are package-wide configuration variables,
      and will therefore affect all devscripts scripts which check their
      value, as described in their respective manpages and in
      devscripts.conf(5).



EXAMPLES¶
To build your own package, simply run debuild from inside the source
  tree. dpkg-buildpackage(1) options may be given on the command line.
The typical command line options to build only the binary
    package(s) without signing the .changes file (or the non-existent .dsc
    file):



debuild -i -us -uc -b
    


Change the -b to -S to build only a source
  package.
An example using lintian to check the resulting packages
    and passing options to it:



debuild --lintian-opts -i
    


Note the order of options here: the debuild options come
    first, then the dpkg-buildpackage ones, then finally the checker
    options. (And lintian is called by default.) If you find yourself
    using the same dpkg-buildpackage options repeatedly, consider using
    the DEBUILD_DPKG_BUILDPACKAGE_OPTS configuration file option as
    described above.
To build a package for a sponsored upload, given
    foobar_1.0-1.dsc and the respective source files, run something like
    the following commands:



dpkg-source -x foobar_1.0-1.dsc
cd foobar-1.0
debuild -k0x12345678
    


where 0x12345678 is replaced by your GPG key ID or other key
    identifier such as your email address. Again, you could also use the
    DEBUILD_DPKG_BUILDPACKAGE_OPTS configuration file option as described
    above to avoid having to type the -k option each time you do a
    sponsored upload.


SEE ALSO¶
chmod(1), debsign(1), dpkg-buildpackage(1),
  dpkg-checkbuilddeps(1), fakeroot(1), lintian(1),
  su(1), sudo(1), super(1), devscripts.conf(5),
  dpkg-statoverride(8)


AUTHOR¶
The original debuild program was written by Christoph Lameter
  <clameter@debian.org>. The current version has been written by Julian
  Gilbey <jdg@debian.org>.




Debian Utilities
DEBIAN









Source file:


debuild.1.en.gz (from devscripts 2.19.5+deb10u1)




Source last updated:


2019-08-04T21:15:44Z




Converted to HTML:


2020-08-08T10:08:51Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# debuild

> Tool to build a Debian package from source.
> More information: <https://manpages.debian.org/debuild>.

- Build the package in the current directory:

`debuild`

- Build a binary package only:

`debuild -b`

- Do not run lintian after building the package:

`debuild --no-lintian`
"
pamac,,,,"# pamac

> A command line utility for the GUI package manager pamac.

- Install a new package:

`pamac install {{package_name}}`

- Remove a package and its no longer required dependencies (orphans):

`pamac remove -o {{package_name}}`

- Search the package database for a package:

`pamac search {{package_name}}`

- List installed packages:

`pamac list -i`

- Check for package updates:

`pamac checkupdates`
"
foreman,,,,"# foreman

> Manage Procfile-based applications.

- Start an application with the Procfile in the current directory:

`foreman start`

- Start an application with a specified Procfile:

`foreman start -f {{Procfile}}`

- Start a specific application:

`foreman start {{process}}`

- Validate Procfile format:

`foreman check`

- Run one-off commands with the process's environment:

`foreman run {{command}}`

- Start all processes except the one named ""worker"":

`foreman start -m all=1,{{worker}}=0`
"
lastb,,,,"# lastb

> Show a listing of last logged in users.

- Show a list of all last logged in users:

`sudo lastb`

- Show a list of all last logged in users since a given time:

`sudo lastb --since {{YYYY-MM-DD}}`

- Show a list of all last logged in users until a given time:

`sudo lastb --until {{YYYY-MM-DD}}`

- Show a list of all logged in users at a specific time:

`sudo lastb --present {{hh:mm}}`

- Show a list of all last logged in users and translate the IP into a hostname:

`sudo lastb --dns`
"
prename,,,,"# rename

> Rename multiple files.
> NOTE: this page refers to the command from the `prename` Fedora package.

- Rename files using a Perl Common Regular Expression (substitute 'foo' with 'bar' wherever found):

`rename {{'s/foo/bar/'}} {{*}}`

- Dry-run - display which renames would occur without performing them:

`rename -n {{'s/foo/bar/'}} {{*}}`

- Force renaming even if the operation would remove existing destination files:

`rename -f {{'s/foo/bar/'}} {{*}}`

- Convert filenames to lower case (use `-f` in case-insensitive filesystems to prevent ""already exists"" errors):

`rename 'y/A-Z/a-z/' {{*}}`

- Replace whitespace with underscores:

`rename 's/\s+/_/g' {{*}}`
"
poweroff,,,,"# poweroff

> Shutdown the system.

- Poweroff the system:

`sudo poweroff`
"
e2label,,,,"# e2label

> Change the label on an ext2/ext3/ext4 filesystem.

- Change the volume label on a specific ext partition:

`e2label {{/dev/sda1}} {{""label_name""}}`
"
lsattr,,,,"# lsattr

> List file attributes on a Linux file system.

- Display the attributes of the files in the current directory:

`lsattr`

- List the attributes of files in a particular path:

`lsattr {{path}}`

- List file attributes recursively in the current and subsequent directories:

`lsattr -R`

- Show attributes of all the files in the current directory, including hidden ones:

`lsattr -a`

- Display attributes of directories in the current directory:

`lsattr -d`
"
getent,,,,"# getent

> Get entries from Name Service Switch libraries.

- Get list of all groups:

`getent group`

- See the members of a group:

`getent group {{group_name}}`

- Get list of all services:

`getent services`

- Find a username by UID:

`getent passwd 1000`

- Perform a reverse DNS lookup:

`getent hosts {{host}}`
"
ascii,http://www.catb.org/~esr/ascii/,"






Resource page for ascii 3.18






Resource page for ascii 3.18

20 Mar 2019





Home Page
What's New
Site Map
Software



Summary
List ASCII idiomatic names and octal/decimal code-point forms.
Provides easy conversion between various byte representations and the
American Standard Code for Information Interchange (ASCII) character
table.  It knows about a wide variety of hex, binary, octal, Teletype
mnemonic, ISO/ECMA code point, slang names, XML entity names, and
other representations.  Given any one on the command line, it will try
to display all others.  Called with no arguments it displays a handy
small ASCII chart.

Resources


READMEroadmap file
ascii-3.18.tar.gzgzipped source tarball
COPYINGproject license
NEWSproject news
ascii.htmlHTML rendering of ascii.1


The project repository is at https://gitlab.com/esr/ascii.
If you appreciate this code (and especially if you make money by using it) please support me on Patreon.
Recent Changes

  Fix a packaging error, include NEWS in the tarball.


Supporters
This work is funded by...
My Bronze supporters on Patreon: Martin Hohenberg, Jae
Yang, Daniel Garber, Kyle Burkholder, Mike Nichols,
Mark Ping, Tom Taylor, Arnold F. Williams,
George Brower, Michael Nygard, Brendan Long, Sven
Dowideit, Dave Witten, Jonathan Cast, James Cronin, David L. Jessup,
Christopher Chang, Killer Delicious, Jacob Lyles, Neil Anuskiewicz,
Mordant, Clemens Ladisch, Wojciech Woytniak, Masa Bando, John Carmack,
Xingyu Wang, Jane Tang, Steven Evans, Jan Roudaut, Hsueh Sung.

My Institutional supporters on Patreon: Jason Azze and the DEVOPS team
at his $DAYJOB.



","
ASCII(7)	     BSD Miscellaneous Information Manual	      ASCII(7)

NAME
     ascii -- octal, hexadecimal and decimal ASCII character sets

DESCRIPTION
     The octal set:

     000 nul  001 soh  002 stx	003 etx  004 eot  005 enq  006 ack  007 bel
     010 bs   011 ht   012 nl	013 vt	 014 np   015 cr   016 so   017 si
     020 dle  021 dc1  022 dc2	023 dc3  024 dc4  025 nak  026 syn  027 etb
     030 can  031 em   032 sub	033 esc  034 fs   035 gs   036 rs   037 us
     040 sp   041  !   042  ""	043  #	 044  $   045  %   046	&   047  '
     050  (   051  )   052  *	053  +	 054  ,   055  -   056	.   057  /
     060  0   061  1   062  2	063  3	 064  4   065  5   066	6   067  7
     070  8   071  9   072  :	073  ;	 074  <   075  =   076	>   077  ?
     100  @   101  A   102  B	103  C	 104  D   105  E   106	F   107  G
     110  H   111  I   112  J	113  K	 114  L   115  M   116	N   117  O
     120  P   121  Q   122  R	123  S	 124  T   125  U   126	V   127  W
     130  X   131  Y   132  Z	133  [	 134  \   135  ]   136	^   137  _
     140  `   141  a   142  b	143  c	 144  d   145  e   146	f   147  g
     150  h   151  i   152  j	153  k	 154  l   155  m   156	n   157  o
     160  p   161  q   162  r	163  s	 164  t   165  u   166	v   167  w
     170  x   171  y   172  z	173  {	 174  |   175  }   176	~   177 del

     The hexadecimal set:

     00 nul   01 soh   02 stx	03 etx	 04 eot   05 enq   06 ack   07 bel
     08 bs    09 ht    0a nl	0b vt	 0c np	  0d cr    0e so    0f si
     10 dle   11 dc1   12 dc2	13 dc3	 14 dc4   15 nak   16 syn   17 etb
     18 can   19 em    1a sub	1b esc	 1c fs	  1d gs    1e rs    1f us
     20 sp    21  !    22  ""	23  #	 24  $	  25  %    26  &    27	'
     28  (    29  )    2a  *	2b  +	 2c  ,	  2d  -    2e  .    2f	/
     30  0    31  1    32  2	33  3	 34  4	  35  5    36  6    37	7
     38  8    39  9    3a  :	3b  ;	 3c  <	  3d  =    3e  >    3f	?
     40  @    41  A    42  B	43  C	 44  D	  45  E    46  F    47	G
     48  H    49  I    4a  J	4b  K	 4c  L	  4d  M    4e  N    4f	O
     50  P    51  Q    52  R	53  S	 54  T	  55  U    56  V    57	W
     58  X    59  Y    5a  Z	5b  [	 5c  \	  5d  ]    5e  ^    5f	_
     60  `    61  a    62  b	63  c	 64  d	  65  e    66  f    67	g
     68  h    69  i    6a  j	6b  k	 6c  l	  6d  m    6e  n    6f	o
     70  p    71  q    72  r	73  s	 74  t	  75  u    76  v    77	w
     78  x    79  y    7a  z	7b  {	 7c  |	  7d  }    7e  ~    7f del

     The decimal set:

       0 nul	1 soh	 2 stx	  3 etx    4 eot    5 enq    6 ack    7 bel
       8 bs	9 ht	10 nl	 11 vt	  12 np    13 cr    14 so    15 si
      16 dle   17 dc1	18 dc2	 19 dc3   20 dc4   21 nak   22 syn   23 etb
      24 can   25 em	26 sub	 27 esc   28 fs    29 gs    30 rs    31 us
      32 sp    33  !	34  ""	 35  #	  36  $    37  %    38	&    39  '
      40  (    41  )	42  *	 43  +	  44  ,    45  -    46	.    47  /
      48  0    49  1	50  2	 51  3	  52  4    53  5    54	6    55  7
      56  8    57  9	58  :	 59  ;	  60  <    61  =    62	>    63  ?
      64  @    65  A	66  B	 67  C	  68  D    69  E    70	F    71  G
      72  H    73  I	74  J	 75  K	  76  L    77  M    78	N    79  O
      80  P    81  Q	82  R	 83  S	  84  T    85  U    86	V    87  W
      88  X    89  Y	90  Z	 91  [	  92  \    93  ]    94	^    95  _
      96  `    97  a	98  b	 99  c	 100  d   101  e   102	f   103  g
     104  h   105  i   106  j	107  k	 108  l   109  m   110	n   111  o
     112  p   113  q   114  r	115  s	 116  t   117  u   118	v   119  w
     120  x   121  y   122  z	123  {	 124  |   125  }   126	~   127 del

FILES
     /usr/share/misc/ascii

HISTORY
     An ascii manual page appeared in Version 7 AT&T UNIX.

BSD				 June 5, 1993				   BSD
","# ascii

> Show ASCII character aliases.
> More information: <http://www.catb.org/~esr/ascii/>.

- Show ASCII aliases of a character:

`ascii {{a}}`

- Show ASCII aliases in short, script-friendly mode:

`ascii -t {{a}}`

- Show ASCII aliases of multiple characters:

`ascii -s {{tldr}}`

- Show ASCII table in decimal:

`ascii -d`

- Show ASCII table in hexadecimal:

`ascii -x`

- Show ASCII table in octal:

`ascii -o`

- Show ASCII table in binary:

`ascii -b`

- Show options summary and complete ASCII table:

`ascii`
"
bluetoothctl,,,,"# bluetoothctl

> Handling bluetooth devices from the shell.

- Enter the bluetoothctl shell:

`bluetoothctl`

- List devices:

`bluetoothctl -- devices`

- Pair a device:

`bluetoothctl -- pair {{mac_address}}`

- Remove a device:

`bluetoothctl -- remove {{mac_address}}`

- Connect a paired device:

`bluetoothctl -- connect {{mac_address}}`

- Disconnect a paired device:

`bluetoothctl -- disconnect {{mac_address}}`
"
mkfs.vfat,,,,"# mkfs.vfat

> Creates an MS-DOS filesystem inside a partition.

- Create a.vfat filesystem inside partition 1 on device b (`sdb1`):

`mkfs.vfat {{/dev/sdb1}}`

- Create filesystem with a volume-name:

`mkfs.vfat -n {{volume_name}} {{/dev/sdb1}}`

- Create filesystem with a volume-id:

`mkfs.vfat -i {{volume_id}} {{/dev/sdb1}}`

- Use 5 instead of 2 file allocation tables:

`mkfs.vfat -f 5 {{/dev/sdb1}}`
"
nft,,,,"# nft

> Allows configuration of tables, chains and rules provided by the Linux kernel firewall.
> Nftables replaces iptables.

- View current configuration:

`sudo nft list ruleset`

- Add a new table with family ""inet"" and table ""filter"":

`sudo nft add table {{inet}} {{filter}}`

- Add a new chain to accept all inbound traffic:

`sudo nft add chain {{inet}} {{filter}} {{input}} \{ type {{filter}} hook {{input}} priority {{0}} \; policy {{accept}} \}`

- Add a new rule to accept several TCP ports:

`sudo nft add rule {{inet}} {{filter}} {{input}} {{tcp}} {{dport \{ telnet, ssh, http, https \} accept}}`

- Show rule handles:

`sudo nft --handle --numeric list chain {{family}} {{table}} {{chain}}`

- Delete a rule:

`sudo nft delete rule {{inet}} {{filter}} {{input}} handle {{3}}`

- Save current configuration:

`sudo nft list ruleset > {{/etc/nftables.conf}}`
"
ark,https://docs.kde.org/stable5/en/kdeutils/ark/,"The Ark Handbook The Ark Handbookhttp://docs.kde.org/ NextThe Ark HandbookMatt Johnston (mattj  flashmail.com)Henrique Pinto (henrique.pinto  kdemail.net)Ragnar Thomsen (rthomsen6  gmail.com)Revision Applications 16.12 (2016-09-10)Copyright © 2000 Matt JohnstonCopyright © 2004 Henrique PintoCopyright © 2015, 2016 Ragnar ThomsenLegal NoticeArk is an archive manager by KDE.Table of Contents1. Introduction2. Using ArkOpening ArchivesArchive OperationsArchive CommentsWorking with FilesEditing FilesExtracting FilesThe Extract dialogCreating Archives and Adding FilesCompressionPassword ProtectionMulti-volume Archive3. Using Ark in the Filemanager4. Advanced Batch Mode5. Credits and License Next   Introductionhttp://docs.kde.org/",,"# ark

> KDE archiving tool.
> More information: <https://docs.kde.org/stable5/en/kdeutils/ark/>.

- Extract an archive into the current directory:

`ark --batch {{archive}}`

- Change extraction directory:

`ark --batch --destination {{path/to/directory}} {{archive}}`

- Create an archive if it does not exist and add files to it:

`ark --add-to {{archive}} {{file1}} {{file2}}`
"
medusa,,,,"# Medusa

> A modular and parallel login brute-forcer for a variety of protocols.

- Execute brute force against an FTP server using a file containing usernames and a file containing passwords:

`medusa -M ftp -h host -U {{path/to/username_file}} -P {{path/to/password_file}}`

- Execute a login attempt against a HTTP server using the username, password and user-agent specified:

`medusa -M HTTP -h host -u {{username}} -p {{password}} -m USER-AGENT:""{{Agent}}""`

- Execute a brute force against a MySQL server using a file cointaining usernames and a hash:

`medusa -M mysql -h host -U {{path/to/username_file}} -p {{hash}} -m PASS:HASH`

- Execute a brute force against a list of SMB servers using a username and a pwdump file:

`medusa -M smbnt -H {{path/to/hosts_file}} -C {{path/to/pwdump_file}} -u {{username}} -m PASS:HASH`
"
blkdiscard,,,,"# blkdiscard

> Discards device sectors on storage devices. Useful for SSDs.

- Discard all sectors on a device, removing all data:

`blkdiscard /dev/{{device}}`

- Securely discard all blocks on a device, removing all data:

`blkdiscard --secure /dev/{{device}}`

- Discard the first 100MB of a device:

`blkdiscard --length {{100MB}} /dev/{{device}}`
"
cal,,,"
CAL(1)			  BSD General Commands Manual			CAL(1)

NAME
     cal, ncal -- displays a calendar and the date of Easter

SYNOPSIS
     cal [-3hjy] [-A number] [-B number] [[month] year]
     cal [-3hj] [-A number] [-B number] -m month [year]
     ncal [-3hjJpwy] [-A number] [-B number] [-s country_code] [[month] year]
     ncal [-3hJeo] [-A number] [-B number] [year]
     ncal [-CN] [-H yyyy-mm-dd] [-d yyyy-mm]

DESCRIPTION
     The cal utility displays a simple calendar in traditional format and ncal
     offers an alternative layout, more options and the date of Easter.  The
     new format is a little cramped but it makes a year fit on a 25x80 termi-
     nal.  If arguments are not specified, the current month is displayed.

     The options are as follows:

     -h      Turns off highlighting of today.

     -J      Display Julian Calendar, if combined with the -e option, display
	     date of Easter according to the Julian Calendar.

     -e      Display date of Easter (for western churches).

     -j      Display Julian days (days one-based, numbered from January 1).

     -m month
	     Display the specified month.  If month is specified as a decimal
	     number, it may be followed by the letter `f' or `p' to indicate
	     the following or preceding month of that number, respectively.

     -o      Display date of Orthodox Easter (Greek and Russian Orthodox
	     Churches).

     -p      Print the country codes and switching days from Julian to Grego-
	     rian Calendar as they are assumed by ncal.  The country code as
	     determined from the local environment is marked with an asterisk.

     -s country_code
	     Assume the switch from Julian to Gregorian Calendar at the date
	     associated with the country_code.	If not specified, ncal tries
	     to guess the switch date from the local environment or falls back
	     to September 2, 1752.  This was when Great Britain and her
	     colonies switched to the Gregorian Calendar.

     -w      Print the number of the week below each week column.

     -y      Display a calendar for the specified year.

     -3      Display the previous, current and next month surrounding today.

     -A number
	     Display the number of months after the current month.

     -B number
	     Display the number of months before the current month.

     -C      Switch to cal mode.

     -N      Switch to ncal mode.

     -d yyyy-mm
	     Use yyyy-mm as the current date (for debugging of date selec-
	     tion).

     -H yyyy-mm-dd
	     Use yyyy-mm-dd as the current date (for debugging of highlight-
	     ing).

     A single parameter specifies the year (1-9999) to be displayed; note the
     year must be fully specified: ``cal 89'' will not display a calendar for
     1989.  Two parameters denote the month and year; the month is either a
     number between 1 and 12, or a full or abbreviated name as specified by
     the current locale.  Month and year default to those of the current sys-
     tem clock and time zone (so ``cal -m 8'' will display a calendar for the
     month of August in the current year).

     Not all options can be used together. For example ``-3 -A 2 -B 3 -y -m
     7'' would mean: show me the three months around the seventh month, three
     before that, two after that and the whole year.  ncal will warn about
     these combinations.

     A year starts on January 1.

     Highlighting of dates is disabled if stdout is not a tty.

SEE ALSO
     calendar(3), strftime(3)

HISTORY
     A cal command appeared in Version 5 AT&T UNIX.  The ncal command appeared
     in FreeBSD 2.2.6.

AUTHORS
     The ncal command and manual were written by Wolfgang Helbig
     <helbig@FreeBSD.org>.

BUGS
     The assignment of Julian-Gregorian switching dates to country codes is
     historically naive for many countries.

     Not all options are compatible and using them in different orders will
     give varying results.

BSD				March 14, 2009				   BSD
","# cal

> Prints calendar information, with the current day highlighted.

- Display a calendar for the current month:

`cal`

- Display previous, current and next month:

`cal -3`

- Use monday as the first day of the week:

`cal --monday`

- Display a calendar for a specific year (4 digits):

`cal {{year}}`

- Display a calendar for a specific month and year:

`cal {{month}} {{year}}`
"
dos2unix,,,,"# dos2unix

> Change DOS-style line endings to Unix-style.
> Replaces CRLF with CR.

- Change the line endings of a file:

`dos2unix {{filename}}`

- Create a copy with Unix-style line endings:

`dos2unix -n {{filename}} {{new_filename}}`
"
homeshick,https://github.com/andsens/homeshick/wiki,"













Home · andsens/homeshick Wiki · GitHub







































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















andsens

/

homeshick







    Watch
 
      61
    




      Star


      1.6k
    




          Fork


        125
      








Code

 



Issues
14
 



Pull requests
0
 



Actions

 



Projects
0
 



Wiki

 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Wiki
 


                    Security
 


                    Insights
 


 






Home

Jump to bottom



      Joseph Frazier edited this page Mar 5, 2017
      ·
      
        31 revisions
      







Table of contents

How does it work?

Installation

Homebrew

Completion (bash zsh fish)



Commands (link clone pull check list track generate refresh cd)


Switches (quiet skip force batch)



Tutorials

Bootstrapping
Adding other machines
Refreshing
Updating your castle


Automatic deployment

Packages

Available packages
Packaging homeshick



Symlinking

Linking table
Combining directories
Repos with no home directory
Shallow symlinking
Files outside your home directory



Testing

Dependencies
Fixtures
Interactive testing
GNU coreutils on OSX


FAQ
Using myrepos to manage multiple castles across machines
Simplistic bootstrapping script alternative
Forks
homeshick and homesick


How does it work?
Symlinking.
On the simplest level, all homeshick really does is look for files and folders
in your cloned repositories and symlink them to your home directory (the linking table explains the symlinking process in more detail).
The symlinked files must however reside in a folder named home.
This way you can prevent homeshick from cluttering your home folder with
files that are only included from elsewhere.
A repository managed by homeshick is referred to as a castle.











      Pages 13








Home


Automatic deployment


Commands


FAQ


Forks


homeshick and homesick


Installation


Myrepos


Packages


Simplistic bootstraping script


Symlinking


Testing


Tutorials





Clone this wiki locally









 







© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  



















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# Homeshick

> Synchronize Git dotfiles.
> More information <https://github.com/andsens/homeshick/wiki>.

- Create a new castle:

`homeshick generate {{castle_name}}`

- Add a file to your castle:

`homeshick track {{castle_name}} {{path/to/file}}`

- Go to a castle:

`homeshick cd {{castle_name}}`

- Clone a castle:

`homeshick clone {{github_username}}/{{repository_name}}`

- Symlink all files from a castle:

`homeshick link {{castle_name}}`
"
rc-service,,,,"# rc-service

> Locate and run OpenRC services with arguments.
> See also `openrc`.

- Show a service's status:

`rc-service {{service_name}} status`

- Start a service:

`sudo rc-service {{service_name}} start`

- Stop a service:

`sudo rc-servie {{service_name}} stop`

- Restart a service:

`sudo rc-service {{service_name}} restart`

- Simulate running a service's custom command:

`sudo rc-service --dry-run {{service_name}} {{command_name}}`

- Actually run a service's custom command:

`sudo rc-service {{service_name}} {{command_name}}`

- Resolve the location of a service definition on disk:

`sudo rc-service --resolve {{service_name}}`
"
tune2fs,,,,"# tune2fs

> Adjust parameters of an ext2, ext3 or ext4 filesystem.
> May be used on mounted filesystems.

- Set the max number of counts before a filesystem is checked to 2:

`tune2fs -c {{2}} {{/dev/sdXN}}`

- Set the filesystem label to MY_LABEL:

`tune2fs -L {{'MY_LABEL'}} {{/dev/sdXN}}`

- Enable discard and user-specified extended attributes for a filesystem:

`tune2fs -o {{discard,user_xattr}} {{/dev/sdXN}}`

- Enable journaling for a filesystem:

`tune2fs -o^{{nobarrier}} {{/dev/sdXN}}`
"
sinfo,https://slurm.schedmd.com/sinfo.html,"



Slurm Workload Manager - sinfo















Slurm Workload Manager




SchedMD





Navigation

Slurm Workload Manager
Version 20.02



About

Overview
Release Notes
Slurm Team
Meetings
Testimonials
Legal Notices



Using

Tutorials
Documentation
FAQ
Publications



Installing

Download
Installation Guide



Getting Help

Support
Mailing Lists
Training
Troubleshooting














sinfo
Section: Slurm Commands (1)Updated: Slurm CommandsIndex

 

NAME

sinfo - View information about Slurm nodes and partitions.

 

SYNOPSIS
sinfo [OPTIONS...]
 

DESCRIPTION
sinfo is used to view partition and node information for a
system running Slurm.

 

OPTIONS



-a, --all
Display information about all partitions. This causes information to be
displayed about partitions that are configured as hidden and partitions that
are unavailable to the user's group.


-d, --dead
If set, only report state information for non-responding (dead) nodes.


-e, --exact
If set, do not group node information on multiple nodes unless
their configurations to be reported are identical. Otherwise
cpu count, memory size, and disk space for nodes will be listed
with the minimum value followed by a ""+"" for nodes with the
same partition and state (e.g. ""250+"").


--federation
Show all partitions from the federation if a member of one.


-h, --noheader
Do not print a header on the output.


--help
Print a message describing all sinfo options.


--hide
Do not display information about hidden partitions. Partitions
that are configured as hidden or are not available to the user's group
will not be displayed. This is the default behavior.


-i <seconds>, --iterate=<seconds>
Print the state on a periodic basis.
Sleep for the indicated number of seconds between reports.
By default prints a time stamp with the header.


--local
Show only jobs local to this cluster. Ignore other clusters in this federation
(if any). Overrides --federation.


-l, --long
Print more detailed information.
This is ignored if the --format option is specified.


-M, --clusters=<string>
Clusters to issue commands to.  Multiple cluster names may be comma separated.
A value of of 'all' will query all clusters. Note that the
SlurmDBD must be up for this option to work properly.
This option implicitly sets the --local option.


-n <nodes>, --nodes=<nodes>
Print information about the specified node(s).
Multiple nodes may be comma separated or expressed using a
node range expression (e.g. ""linux[00-17]"")
Limiting the query to just the relevant nodes can measurably improve the
performance of the command for large clusters.


--noconvert
Don't convert units from their original type (e.g. 2048M won't be converted to
2G).


-N, --Node
Print information in a node-oriented format with one line per node
and partition. That is, if a node belongs to more than one partition, then one
line for each node-partition pair will be shown.
If --partition is also specified, then only one line per node in this
partition is shown.
The default is to print information in a partition-oriented format.
This is ignored if the --format option is specified.


-o <output_format>, --format=<output_format>
Specify the information to be displayed using an sinfo
format string.
If the command is executed in a federated cluster environment and information
about more than one cluster is to be displayed and the -h, --noheader
option is used, then the cluster name will be displayed before the default
output formats shown below.
Format strings transparently used by sinfo when running with various
options are:


default

""%#P %.5a %.10l %.6D %.6t %N""
--summarize

""%#P %.5a %.10l %.16F  %N""
--long

""%#P %.5a %.10l %.10s %.4r %.8h %.10g %.6D %.11T %N""
--Node

""%#N %.6D %#P %6t""
--long --Node

""%#N %.6D %#P %.11T %.4c %.8z %.6m %.8d %.6w %.8f %20E""
--list-reasons

""%20E %9u %19H %N""
--long --list-reasons

""%20E %12U %19H %6t %N""




In the above format strings, the use of ""#"" represents the
maximum length of any partition name or node list to be printed.
A pass is made over the records to be printed to establish the size in order
to align the sinfo output, then a second pass is made over the records to
print them.
Note that the literal character ""#"" itself is not a valid field length
specification, but is only used to document this behaviour.

The field specifications available include:



%all
Print all fields available for this data type with a vertical bar separating
each field.

%a
State/availability of a partition.

%A
Number of nodes by state in the format ""allocated/idle"".
Do not use this with a node state option (""%t"" or ""%T"") or
the different node states will be placed on separate lines.

%b
Features currently active on the nodes, also see %f.

%B
The max number of CPUs per node available to jobs in the partition.

%c
Number of CPUs per node.

%C
Number of CPUs by state in the format
""allocated/idle/other/total"". Do not use this with a node
state option (""%t"" or ""%T"") or the different node states will
be placed on separate lines.

%d
Size of temporary disk space per node in megabytes.

%D
Number of nodes.

%e
Free memory of a node.

%E
The reason a node is unavailable (down, drained, or draining states).

%f
Features available the nodes, also see %b.

%F
Number of nodes by state in the format
""allocated/idle/other/total"".  Note the use of this format option with a node
state format option (""%t"" or ""%T"") will result in the different node states
being be reported on separate lines.

%g
Groups which may use the nodes.

%G
Generic resources (gres) associated with the nodes.

%h
Print the OverSubscribe setting for the partition.

%H
Print the timestamp of the reason a node is unavailable.

%I
Partition job priority weighting factor.

%l
Maximum time for any job in the format ""days-hours:minutes:seconds""

%L
Default time for any job in the format ""days-hours:minutes:seconds""

%m
Size of memory per node in megabytes.

%M
PreemptionMode.

%n
List of node hostnames.

%N
List of node names.

%o
List of node communication addresses.

%O
CPU load of a node.

%p
Partition scheduling tier priority.

%P
Partition name followed by ""*"" for the default partition, also see %R.

%r
Only user root may initiate jobs, ""yes"" or ""no"".

%R
Partition name, also see %P.

%s
Maximum job size in nodes.

%S
Allowed allocating nodes.

%t
State of nodes, compact form.

%T
State of nodes, extended form.

%u
Print the user name of who set the reason a node is unavailable.

%U
Print the user name and uid of who set the reason a node is unavailable.

%v
Print the version of the running slurmd daemon.

%V
Print the cluster name if running in a federation.

%w
Scheduling weight of the nodes.

%X
Number of sockets per node.

%Y
Number of cores per socket.

%Z
Number of threads per core.

%z
Extended processor information: number of sockets, cores, threads (S:C:T) per node.

%.<*>
Right justification of the field.

%<Number><*>
Size of the field.




-O <output_format>, --Format=<output_format>
Specify the information to be displayed.
Also see the -o <output_format>, --format=<output_format>
option (which supports greater flexibility in formatting, but
does not support access to all fields because we ran out of letters).
Requests a comma separated list of job information to be displayed.


The format of each field is ""type[:[.]size]""


size
The minimum field size.
If no size is specified, 20 characters will be allocated to print the information.
 .
Indicates the output should be right justified and size must be specified.
By default, output is left justified.




Valid type specifications include:



All

Print all fields available in the -o format for this data type with a
vertical bar separating each field.


AllocMem
Prints the amount of allocated memory on a node.

AllocNodes
Allowed allocating nodes.

Available
State/availability of a partition.

Cluster
Print the cluster name if running in a federation.

Cores

Number of cores per socket.


CPUs

Number of CPUs per node.


CPUsLoad
CPU load of a node.

CPUsState
Number of CPUs by state in the format
""allocated/idle/other/total"". Do not use this with a node
state option (""%t"" or ""%T"") or the different node states will
be placed on separate lines.

DefaultTime
Default time for any job in the format ""days-hours:minutes:seconds"".

Disk

Size of temporary disk space per node in megabytes.


Features
Features available on the nodes. Also see features_act.

features_act
Features currently active on the nodes. Also see features.

FreeMem
Free memory of a node.

Gres

Generic resources (gres) associated with the nodes.


GresUsed
Generic resources (gres) currently in use on the nodes.

Groups

Groups which may use the nodes.


MaxCPUsPerNode
The max number of CPUs per node available to jobs in the partition.

Memory

Size of memory per node in megabytes.


NodeAddr
List of node communication addresses.

NodeAI

Number of nodes by state in the format ""allocated/idle"".
Do not use this with a node state option (""%t"" or ""%T"") or
the different node states will be placed on separate lines.


NodeAIOT
Number of nodes by state in the format
""allocated/idle/other/total"".  Do not use this with a node
state option (""%t"" or ""%T"") or the different node states will
be placed on separate lines.

NodeHost
List of node hostnames.

NodeList
List of node names.

Nodes

Number of nodes.


OverSubscribe
Whether jobs may oversubscribe compute resources (e.g. CPUs).

Partition
Partition name followed by ""*"" for the default partition, also see %R.

PartitionName
Partition name, also see %P.

Port

Node TCP port.


PreemptMode
Preemption mode.

PriorityJobFactor
Partition factor used by priority/multifactor plugin in calculating job priority.

PriorityTier or Priority
Partition scheduling tier priority.

Reason

The reason a node is unavailable (down, drained, or draining states).


Root

Only user root may initiate jobs, ""yes"" or ""no"".


Size

Maximum job size in nodes.


SocketCoreThread
Extended processor information: number of sockets, cores, threads (S:C:T) per node.

Sockets
Number of sockets per node.

StateCompact
State of nodes, compact form.

StateLong
State of nodes, extended form.

Threads
Number of threads per core.

Time

Maximum time for any job in the format ""days-hours:minutes:seconds"".


TimeStamp
Print the timestamp of the reason a node is unavailable.

User

Print the user name of who set the reason a node is unavailable.


UserLong
Print the user name and uid of who set the reason a node is unavailable.

Version
Print the version of the running slurmd daemon.

Weight

Scheduling weight of the nodes.





-p <partition>, --partition=<partition>
Print information only about the specified partition(s). Multiple partitions
are separated by commas.


-r, --responding
If set only report state information for responding nodes.


-R, --list-reasons
List reasons nodes are in the down, drained, fail or failing state.
When nodes are in these states Slurm supports the inclusion
of a ""reason"" string by an administrator.
This option will display the first 20 characters of the reason
field and list of nodes with that reason for all nodes that are,
by default, down, drained, draining or failing.
This option may be used with other node filtering options
(e.g. -r, -d, -t, -n),
however, combinations of these options that result in a
list of nodes that are not down or drained or failing will
not produce any output.
When used with -l the output additionally includes
the current node state.


-s, --summarize
List only a partition state summary with no node state details.
This is ignored if the --format option is specified.


-S <sort_list>, --sort=<sort_list>
Specification of the order in which records should be reported.
This uses the same field specification as the <output_format>.
Multiple sorts may be performed by listing multiple sort fields
separated by commas.  The field specifications may be preceded
by ""+"" or ""-"" for ascending (default) and descending order
respectively.  The partition field specification, ""P"", may be
preceded by a ""#"" to report partitions in the same order that
they appear in Slurm's  configuration file, slurm.conf.
For example, a sort value of ""+P,-m"" requests that records
be printed in order of increasing partition name and within a
partition by decreasing memory size.  The default value of sort
is ""#P,-t"" (partitions ordered as configured then decreasing
node state).  If the --Node option is selected, the
default sort value is ""N"" (increasing node name).


-t <states> , --states=<states>
List nodes only having the given state(s).  Multiple states
may be comma separated and the comparison is case insensitive.
Possible values include (case insensitive): ALLOC, ALLOCATED,
COMP, COMPLETING, DOWN, DRAIN (for node in DRAINING or DRAINED
states), DRAINED, DRAINING, FAIL, FUTURE, FUTR,
IDLE, MAINT, MIX, MIXED, NO_RESPOND, NPC, PERFCTRS,
POWER_DOWN, POWERING_DOWN, POWER_UP, RESV, RESERVED, UNK, and UNKNOWN.
By default nodes in the specified state are reported whether
they are responding or not.
The --dead and --responding options may be
used to filter nodes by the corresponding flag.


-T, --reservation
Only display information about Slurm reservations.

NOTE: This option causes sinfo to ignore most other options,
which are focused on partition and node information.


--usage
Print a brief message listing the sinfo options.


-v, --verbose
Provide detailed event logging through program execution.


-V, --version
Print version information and exit.


 

OUTPUT FIELD DESCRIPTIONS


AVAIL
Partition state. Can be either up, down, drain, or inact
(for INACTIVE). See the partition definition's State parameter in the
slurm.conf(5) man page for more information.

CPUS
Count of CPUs (processors) on these nodes.

S:C:T
Count of sockets (S), cores (C), and threads (T) on these nodes.

SOCKETS
Count of sockets on these nodes.

CORES
Count of cores on these nodes.

THREADS
Count of threads on these nodes.

GROUPS
Resource allocations in this partition are restricted to the
named groups.  all indicates that all groups may use
this partition.

JOB_SIZE
Minimum and maximum node count that can be allocated to any
user job.  A single number indicates the minimum and maximum
node count are the same.  infinite is used to identify
partitions without a maximum node count.

TIMELIMIT
Maximum time limit for any user job in
days-hours:minutes:seconds.  infinite is used to identify
partitions without a job time limit.

MEMORY
Size of real memory in megabytes on these nodes.

NODELIST
Names of nodes associated with this particular configuration.

NODES
Count of nodes with this particular configuration.

NODES(A/I)
Count of nodes with this particular configuration by node
state in the form ""available/idle"".

NODES(A/I/O/T)
Count of nodes with this particular configuration by node
state in the form ""available/idle/other/total"".

PARTITION
Name of a partition.  Note that the suffix ""*"" identifies the
default partition.

PORT
Local TCP port used by slurmd on the node.

ROOT
Is the ability to allocate resources in this partition
restricted to user root, yes or no.

OVERSUBSCRIBE
Whether jobs allocated resources in this partition can/will oversubscribe
those compute resources (e.g. CPUs).
NO indicates resources are never oversubscribed.
EXCLUSIVE indicates whole nodes are dedicated to jobs
(equivalent to srun --exclusive option, may be used even
with select/cons_res managing individual processors).
FORCE indicates resources are always available to be oversubscribed.
YES indicates resource may be oversubscribed, if requested by the job's
resource allocation.

NOTE: If OverSubscribe is set to FORCE or YES,
the OversubScribe value will be appended to the output.

STATE
State of the nodes.
Possible states include: allocated, completing, down,
drained, draining, fail, failing, future, idle, maint, mixed,
perfctrs, power_down, power_up, reserved, and unknown.
Their abbreviated forms are: alloc, comp, down, drain, drng,
fail, failg, futr, idle, maint, mix, npc, pow_dn, pow_up, resv,
and unk respectively.

NOTE: The suffix ""*"" identifies nodes that are presently
not responding.

TMP_DISK
Size of temporary disk space in megabytes on these nodes.


 

NODE STATE CODES


Node state codes are shortened as required for the field size.
These node states may be followed by a special character to identify
state flags associated with the node.
The following node suffixes and states are used:


*
The node is presently not responding and will not be allocated
any new work.  If the node remains non-responsive, it will
be placed in the DOWN state (except in the case of
COMPLETING, DRAINED, DRAINING,
FAIL, FAILING nodes).

~
The node is presently in a power saving mode (typically
running at reduced frequency).

#
The node is presently being powered up or configured.

%
The node is presently being powered down.

$
The node is currently in a reservation with a flag value of ""maintenance"".

@
The node is pending reboot.

ALLOCATED
The node has been allocated to one or more jobs.

ALLOCATED+
The node is allocated to one or more active jobs plus
one or more jobs are in the process of COMPLETING.

COMPLETING
All jobs associated with this node are in the process of
COMPLETING.  This node state will be removed when
all of the job's processes have terminated and the Slurm
epilog program (if any) has terminated. See the Epilog
parameter description in the slurm.conf(5) man page for
more information.

DOWN
The node is unavailable for use. Slurm can automatically
place nodes in this state if some failure occurs. System
administrators may also explicitly place nodes in this state. If
a node resumes normal operation, Slurm can automatically
return it to service. See the ReturnToService
and SlurmdTimeout parameter descriptions in the
slurm.conf(5) man page for more information.

DRAINED
The node is unavailable for use per system administrator
request.  See the update node command in the
scontrol(1) man page or the slurm.conf(5) man page
for more information.

DRAINING
The node is currently executing a job, but will not be allocated
additional jobs. The node state will be changed to state
DRAINED when the last job on it completes. Nodes enter
this state per system administrator request. See the update
node command in the scontrol(1) man page or the
slurm.conf(5) man page for more information.

FAIL
The node is expected to fail soon and is unavailable for
use per system administrator request.
See the update node command in the scontrol(1)
man page or the slurm.conf(5) man page for more information.

FAILING
The node is currently executing a job, but is expected to fail
soon and is unavailable for use per system administrator request.
See the update node command in the scontrol(1)
man page or the slurm.conf(5) man page for more information.

FUTURE
The node is currently not fully configured, but expected to be available at
some point in the indefinite future for use.

IDLE
The node is not allocated to any jobs and is available for use.

MAINT
The node is currently in a reservation with a flag value of ""maintenance"".

REBOOT
The node is currently scheduled to be rebooted.

MIXED
The node has some of its CPUs ALLOCATED while others are IDLE.

PERFCTRS (NPC)
Network Performance Counters associated with this node are in use, rendering
this node as not usable for any other jobs

POWER_DOWN
The node is currently powered down and not capable of running any jobs.

POWERING_DOWN
The node is in the process of powering down and not capable of running any jobs.

POWER_UP
The node is in the process of being powered up.

RESERVED
The node is in an advanced reservation and not generally available.

UNKNOWN
The Slurm controller has just started and the node's state
has not yet been determined.


 

PERFORMANCE


Executing sinfo sends a remote procedure call to slurmctld. If
enough calls from sinfo or other Slurm client commands that send remote
procedure calls to the slurmctld daemon come in at once, it can result in
a degradation of performance of the slurmctld daemon, possibly resulting
in a denial of service.


Do not run sinfo or other Slurm client commands that send remote procedure
calls to slurmctld from loops in shell scripts or other programs. Ensure
that programs limit calls to sinfo to the minimum necessary for the
information you are trying to gather.

 

ENVIRONMENT VARIABLES


Some sinfo options may
be set via environment variables. These environment variables,
along with their corresponding options, are listed below.
NOTE: Command line options will always override these settings.


SINFO_ALL
Same as -a, --all

SINFO_FEDERATION
Same as --federation

SINFO_FORMAT
Same as -o <output_format>, --format=<output_format>

SINFO_LOCAL
Same as --local

SINFO_PARTITION
Same as -p <partition>, --partition=<partition>

SINFO_SORT
Same as -S <sort>, --sort=<sort>

SLURM_CLUSTERS
Same as --clusters

SLURM_CONF
The location of the Slurm configuration file.

SLURM_TIME_FORMAT
Specify the format used to report time stamps. A value of standard, the
default value, generates output in the form ""year-month-dateThour:minute:second"".
A value of relative returns only ""hour:minute:second"" if the current day.
For other dates in the current year it prints the ""hour:minute"" preceded by
""Tomorr"" (tomorrow), ""Ystday"" (yesterday), the name of the day for the coming
week (e.g. ""Mon"", ""Tue"", etc.), otherwise the date (e.g. ""25 Apr"").
For other years it returns a date month and year without a time (e.g.
""6 Jun 2012""). All of the time stamps use a 24 hour format.

A valid strftime() format can also be specified. For example, a value of
""%a %T"" will report the day of the week and a time stamp (e.g. ""Mon 12:34:56"").


 

EXAMPLES


Report basic node and partition configurations:



> sinfo
PARTITION AVAIL TIMELIMIT NODES STATE  NODELIST
batch     up     infinite     2 alloc  adev[8-9]
batch     up     infinite     6 idle   adev[10-15]
debug*    up        30:00     8 idle   adev[0-7]



Report partition summary information:


> sinfo -s
PARTITION AVAIL TIMELIMIT NODES(A/I/O/T) NODELIST
batch     up     infinite 2/6/0/8        adev[8-15]
debug*    up        30:00 0/8/0/8        adev[0-7]



Report more complete information about the partition debug:


> sinfo --long --partition=debug
PARTITION AVAIL TIMELIMIT JOB_SIZE ROOT OVERSUBS GROUPS NODES STATE NODELIST
debug*    up        30:00        8 no   no       all        8 idle  dev[0-7]


Report only those nodes that are in state DRAINED:


> sinfo --states=drained
PARTITION AVAIL NODES TIMELIMIT STATE  NODELIST
debug*    up        2     30:00 drain  adev[6-7]



Report node-oriented information with details and exact matches:


> sinfo -Nel
NODELIST    NODES PARTITION STATE  CPUS MEMORY TMP_DISK WEIGHT FEATURES REASON
adev[0-1]       2 debug*    idle      2   3448    38536     16 (null)   (null)
adev[2,4-7]     5 debug*    idle      2   3384    38536     16 (null)   (null)
adev3           1 debug*    idle      2   3394    38536     16 (null)   (null)
adev[8-9]       2 batch     allocated 2    246    82306     16 (null)   (null)
adev[10-15]     6 batch     idle      2    246    82306     16 (null)   (null)



Report only down, drained and draining nodes and their reason field:


> sinfo -R
REASON                              NODELIST
Memory errors                       dev[0,5]
Not Responding                      dev8



 

COPYING

Copyright (C) 2002-2007 The Regents of the University of California.
Produced at Lawrence Livermore National Laboratory (cf, DISCLAIMER).


Copyright (C) 2008-2009 Lawrence Livermore National Security.


Copyright (C) 2010-2017 SchedMD LLC.


This file is part of Slurm, a resource management program.
For details, see <https://slurm.schedmd.com/>.


Slurm is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 2 of the License, or (at your option)
any later version.


Slurm is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more
details.

 

SEE ALSO
scontrol(1), squeue(1),
slurm_load_ctl_conf (3), slurm_load_jobs (3),
slurm_load_node (3),
slurm_load_partitions (3),
slurm_reconfigure (3), slurm_shutdown (3),
slurm_update_job (3), slurm_update_node (3),
slurm_update_partition (3),
slurm.conf(5)


 Index

NAME
SYNOPSIS
DESCRIPTION
OPTIONS
OUTPUT FIELD DESCRIPTIONS
NODE STATE CODES
PERFORMANCE
ENVIRONMENT VARIABLES
EXAMPLES
COPYING
SEE ALSO


This document was created by
man2html using the manual pages.
Time: 19:40:53 GMT, August 28, 2020
			 
 
 
 



Legal Notices





",,"# sinfo

> View information about Slurm nodes and partitions.
> See also `squeue` and `sbatch`, which are also part of the Slurm workload manager.
> More information: <https://slurm.schedmd.com/sinfo.html>.

- Show a quick summary overview of the cluster:

`sinfo --summarize`

- View the detailed status of all partitions across the entire cluster:

`sinfo`

- View the detailed status of a specific partition:

`sinfo --partition {{partition_name}}`

- View information about idle nodes:

`sinfo --states {{idle}}`

- Summarise dead nodes:

`sinfo --dead`

- List dead nodes and the reasons why:

`sinfo --list-reasons`
"
fallocate,,,,"# fallocate

> Reserve or deallocate disk space to files.
> The utility allocates space without zeroing.

- Reserve a file taking up 700MB of disk space:

`fallocate --length {{700M}} {{path/to/file}}`

- Shrink an already allocated file by 200MB:

`fallocate --collapse-range --length {{200M}} {{path/to/file}}`

- Shrink 20MB of space after 100MB in a file:

`fallocate --collapse-range --offset {{100M}} --length {{20M}} {{path/to/file}}`
"
brctl,,,"
BRCTL(1)		  BSD General Commands Manual		      BRCTL(1)

NAME
     brctl -- Manage the CloudDocs daemon

SYNOPSIS
     brctl <command> [command-options and arguments]

DESCRIPTION
     brctl understands the following commands:

     diagnose [options] [<diagnosis-output-path>]
	 diagnose and collect logs

	 -M,--collect-mobile-documents[=<container>]  (default: all contain-
     ers)
	 -s,--sysdiagnose     Do not collect what's already part of sysdiag-
     nose
	 -n,--name=<name>     Change the device name
	 [<diagnosis-output-path>]
			      Specifies the output path of the diagnosis; -n
     becomes useless.

     download <path>
	 download a local copy of the document at this path

     evict <path>
	 evict the local copy of the document at this path

     log [options] [<command>]

	 -c,--color[={yes,no}]
			      turn on or off color use
	 -d,--path=<logs-dir> use <logs-dir> instead of default
	 -H,--home=<home-dir> use this as the ~ prefix, to look for ~/L/
	 -f,--filter=<predicate>
			      only show lines matching predicate
	 -m,--multiline[={yes,no}]
			      turn on or off multiple line logging
	 -n=<number>	      number of initial lines to display
	 -p,--page	      use paging
	 -w,--wait	      wait for new logs continuously (syslog -w)
	 -t,--shorten	      Shorten UUIDs, paths, etc
	 -s,--digest	      Only print digest logs

     dump [options] [<container>]
	 dump the CloudDocs database

	 -o,--output=<file-path>
			      redirect output to <file-path>
	 -d,--database-path=<db-path>
			      Use the database at <db-path>
	 [<container>]	      the container to be dumped

     monitor [options] <container>
	 use NSMetadataQuery to monitor the container

	 -S,--scope=<scope>
			      restrict the NSMDQ scope to DOCS, DATA, or BOTH

     versions [options] <path> [ALL|etags...]
	 list the non-local versions of the document at this path.

	 -a,--all	      List all non-local versions including those that
			      are locally cached

SEE ALSO
     bird(8)

Mac OS			      September 25, 2020			Mac OS
","# brctl

> Ethernet bridge administration.

- Show a list with information about currently existing ethernet bridges:

`sudo brctl show`

- Create a new ethernet bridge interface:

`sudo brctl add {{bridge_name}}`

- Delete an existing ethernet bridge interface:

`sudo brctl del {{bridge_name}}`

- Add an interface to an existing bridge:

`sudo brctl addif {{bridge_name}} {{interface_name}}`

- Remove an interface from an existing bridge:

`sudo brctl delif {{bridge_name}} {{interface_name}}`
"
ncdu,,,,"# ncdu

> Disk usage analyzer with an ncurses interface.

- Analyze the current working directory:

`ncdu`

- Analyze a given directory:

`ncdu {{path/to/directory}}`

- Save results to a file:

`ncdu -o {{path/to/file}}`

- Exclude files that match a pattern, argument can be given multiple times to add more patterns:

`ncdu --exclude '{{*.txt}}'`
"
ncat,,,,"# ncat

> Use the normal `cat` functionality over networks.

- Listen for input on the specified port and write it to the specified file:

`ncat -l {{port}} > {{path/to/file}}`

- Accept multiple connections and keep ncat open after they have been closed:

`ncat -lk {{port}}`

- Write output of specified file to the specified host on the specified port:

`ncat {{address}} {{port}} < {{path/to/file}}`
"
extrace,https://github.com/chneukirchen/extrace,"













GitHub - leahneukirchen/extrace: trace exec() calls system-wide








































Skip to content













                Sign up
              
















                    Why GitHub?
                    




Features →

Code review
Project management
Integrations
Actions
Packages
Security
Team management
Hosting
Mobile


Customer stories →
Security →





Team


Enterprise




                    Explore
                    





Explore GitHub →

Learn & contribute

Topics
Collections
Trending
Learning Lab
Open source guides

Connect with others

Events
Community forum
GitHub Education
GitHub Stars program





Marketplace




                    Pricing
                    




Plans →

Compare plans
Contact Sales


Nonprofit →
Education →






























        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






No suggested jump to results















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵















        In this repository
      

        All GitHub
      
↵


      Jump to
      ↵






 



          Sign in
        

              Sign up
            



















leahneukirchen

/

extrace







    Watch
 
      8
    




      Star


      63
    




          Fork


        4
      





        trace exec() calls system-wide
      



            View license
        




63
        stars
 

4
        forks
 




      Star





    Watch









Code

 



Issues
2
 



Pull requests
0
 



Actions

 



Projects
0
 



Security

 



Insights

 
 




More

 




                    Code
 


                    Issues
 


                    Pull requests
 


                    Actions
 


                    Projects
 


                    Security
 


                    Insights
 


 










          Dismiss
        
Join GitHub today
GitHub is home to over 50 million developers working together to host and review code, manage projects, and build software together.
Sign up










master














1
branch



8
tags




    Go to file






      Code
      
 








  Clone






            HTTPS
 
            GitHub CLI
 









      Use Git or checkout with SVN using the web URL.
    









      Work fast with our official CLI.
      Learn more.
    







                Open with GitHub Desktop
 



                Download ZIP
 



Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching GitHub Desktop
If nothing happens, download GitHub Desktop and try again.
Go back


Launching Xcode
If nothing happens, download Xcode and try again.
Go back


Launching Visual Studio
If nothing happens, download the GitHub extension for Visual Studio and try again.
Go back









Latest commit



 
 
Git stats





70
commits







Files

Permalink


  
    Failed to load latest commit information.

 


Type
Name
Latest commit message
Commit time






LICENSE


 


 







Makefile


 


 







NEWS.md


 


 







README


 


 







extrace-bpf


 


 







extrace.1


 


 







extrace.c


 


 







pwait.1


 


 







pwait.c


 


 





        View code
      







        README
      


EXTRACE(1)                  General Commands Manual                 EXTRACE(1)

NAME
     extrace – trace exec() calls system-wide

SYNOPSIS
     extrace [-deflqtu] [-o file] [-p pid | cmd ...]

DESCRIPTION
     extrace traces all program executions occurring on a system.

     The options are as follows:

     -d      Print the current working directory of the new process.

     -e      Print environment of process, or ‘-’ if unreadable.

     -f      Generate flat output without indentation.  By default, the line
             indentation reflects the process hierarchy.

     -l      Resolve full path of the executable.  By default, argv[0] is
             shown.

     -q      Suppress printing of exec(3) arguments.

     -t      Also display process exit status and duration.

     -u      Also display the user running the process.

     -o file
             Redirect trace output to file.

     -p pid  Only trace exec(3) calls descendant of pid.

     cmd ...
             Run cmd ... and only trace descendants of this command.

             By default, all exec(3) calls are traced globally.

EXIT STATUS
     The extrace utility exits 0 on success, and >0 if an error occurs.

ERRORS
     Check these prerequisites if you see this error:

           binding sk_nl error: Operation not permitted

     extrace requires special permissions to run, either root or the Linux
     CAP_NET_ADMIN capability.

     extrace only works on Linux kernels with the kernel options

           CONFIG_CONNECTOR=y
           CONFIG_PROC_EVENTS=y

SEE ALSO
     fatrace(1), ps(1), pwait(1), strace(1)

AUTHORS
     Leah Neukirchen <leah@vuxu.org>

     May contain traces of code from Guillaume Thouvenin, Matt Helsley, and
     Sebastian Krahmer.

BUGS
     While process tracing is exact, looking up all information is inherently
     sensitive to race conditions.  In doubt, you can only trust the PID was
     written correctly.

LICENSE
     extrace is licensed under the terms of the GPLv2.

Void Linux                       June 19, 2018                      Void Linux

------------------------------------------------------------------------------

PWAIT(1)                    General Commands Manual                   PWAIT(1)

NAME
     pwait – wait for processes to terminate

SYNOPSIS
     pwait [-v] [-c] pid ...

DESCRIPTION
     pwait waits until each of the given processes has terminated.

     The options are as follows:

     -v      Print the exit status when each process terminates.

     -c      Return 111 if any process exited non-successfully.

EXIT STATUS
     The pwait utility exits 0 on success, and >0 if an error occurs.

     Invalid pids elicit a warning message but are otherwise ignored.

ERRORS
     Check these prerequisites if you see this error:

           binding sk_nl error: Operation not permitted

     pwait requires special permissions to run, either root or the Linux
     CAP_NET_ADMIN capability.

     pwait only works on Linux kernels with the kernel options

           CONFIG_CONNECTOR=y
           CONFIG_PROC_EVENTS=y

SEE ALSO
     extrace(1), kill(1), pkill(1), ps(1), wait(1)

AUTHORS
     Leah Neukirchen <leah@vuxu.org>

     Built upon code from FreeBSD pwait written by Jilles Tjoelker.

LICENSE
     pwait is licensed under the terms of the GPLv2.

Void Linux                    September 17, 2018                    Void Linux








About

      trace exec() calls system-wide
    
Resources



      Readme
 
License



        View license
    







    Releases



8
tags







    Packages 0


        No packages published 













    Contributors 3





 



 



 







Languages











C
77.2%





Ruby
10.6%





Roff
10.4%





Makefile
1.8%















© 2020 GitHub, Inc.
Terms
Privacy
Security
Status
Help





Contact GitHub
Pricing
API
Training
Blog
About











    You can’t perform that action at this time.
  


















You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.







",,"# extrace

> Trace exec() calls.
> More information: <https://github.com/chneukirchen/extrace>.

- Trace all program executions occurring on the system:

`sudo extrace`

- Run a command and only trace descendants of this command:

`sudo extrace {{command}}`

- Print the current working directory of each process:

`sudo extrace -d`

- Resolve the full path of each executable:

`sudo extrace -l`

- Display the user running each process:

`sudo extrace -u`
"
ipcalc,,,,"# ipcalc

> Perform simple operations and calculations on IP addresses and networks.

- Show information about an address or network with a given subnet mask:

`ipcalc {{1.2.3.4}} {{255.255.255.0}}`

- Show information about an address or network in CIDR notation:

`ipcalc {{1.2.3.4}}/{{24}}`

- Show the broadcast address of an address or network:

`ipcalc -b {{1.2.3.4}}/{{30}}`

- Show the network address of provided IP address and netmask:

`ipcalc -n {{1.2.3.4}}/{{24}}`

- Display geographic information about a given IP address:

`ipcalc -g {{1.2.3.4}}`
"
terminator,,,,"# terminator

> Arrange multiple GNOME terminals in one window.

- Start terminator window:

`terminator`

- Start with a fullscreen window:

`terminator -f`

- Split terminals horizontally:

`Ctrl + Shift + O`

- Split terminals vertically:

`Ctrl + Shift + E`

- Open new tab:

`Ctrl + Shift + T`
"
i7z,,,,"# i7z

> An Intel CPU (only i3, i5 and i7) realtime reporting tool.

- Start i7z (needs to be run in super user mode):

`sudo i7z`
"
etckeeper,http://etckeeper.branchable.com/,"


etckeeper
















etckeeper











Edit
RecentChanges
History
Preferences
Branchable




README
Install
News
Todo
Forum



etckeeper is a collection of tools to let /etc be stored in a git,
mercurial, bazaar or darcs repository. This lets you use git to review or
revert changes that were made to /etc. Or even push the repository
elsewhere for backups or cherry-picking configuration changes.
It hooks into package managers like apt to automatically commit changes
made to /etc during package upgrades. It tracks file metadata that git does
not normally support, but that is important for /etc, such as the
permissions of /etc/shadow.
It's quite modular and configurable, while also being simple to use if you
understand the basics of working with version control.








Last edited Sat Mar 10 16:32:52 2018










",,"# etckeeper

> Track system configuration files in git.
> More information: <http://etckeeper.branchable.com/>.

- Set up a git repo and perform various setup tasks (run from /etc):

`sudo etckeeper init`

- Commit all changes in /etc:

`sudo etckeeper commit {{message}}`

- Run arbitrary git commands:

`sudo etckeeper vcs {{status}}`

- Check if there are uncommitted changes (only returns an exit code):

`sudo etckeeper unclean`

- Destroy existing repo and stop tracking changes:

`sudo etckeeper uninit`
"
macchanger,,,,"# macchanger

> Command-line utility for manipulating network interface MAC addresses.

- View the current and permanent MAC addresses of a interface:

`macchanger --show {{interface}}`

- Set interface to a random MAC:

`macchanger --random {{interface}}`

- Set interface to a specific MAC:

`macchanger --mac {{XX:XX:XX:XX:XX:XX}} {{interface}}`

- Reset interface to its permanent hardware MAC:

`macchanger --permanent {{interface}}`
"
namei,,,,"# namei

> Follows a pathname (which can be a symbolic link) until a terminal point is found (a file/directory/char device etc).
> This program is useful for finding ""too many levels of symbolic links"" problems.

- Resolve the pathnames specified as the argument parameters:

`namei {{path/to/a}} {{path/to/b}} {{path/to/c}}`

- Display the results in a long-listing format:

`namei --long {{path/to/a}} {{path/to/b}} {{path/to/c}}`

- Show the mode bits of each file type in the style of `ls`:

`namei --modes {{path/to/a}} {{path/to/b}} {{path/to/c}}`

- Show owner and group name of each file:

`namei --owners {{path/to/a}} {{path/to/b}} {{path/to/c}}`

- Don't follow symlinks while resolving:

`namei --nosymlinks {{path/to/a}} {{path/to/b}} {{path/to/c}}`
"
reflector,,,,"# reflector

> Arch script to fetch and sort mirrorlists.

- Get all mirrors, sort for download speed and save them:

`sudo reflector --sort {{rate}} --save {{/etc/pacman.d/mirrorlist}}`

- Only get German HTTPS mirrors:

`reflector --country {{Germany}} --protocol {{https}}`

- Only get the 10 recently sync'd mirrors:

`reflector --latest {{10}}`
"
ports,,,,"# ports

> Update/list the ports tree on a CRUX system.

- Update the ports tree:

`ports -u`

- List the ports in the current tree:

`ports -l`

- Check the differences between installed packages and the ports tree:

`ports -d`
"
lvs,https://www.man7.org/linux/man-pages/man8/lvs.8.html,"




lvs(8) - Linux manual page









man7.org > Linux > man-pages



Linux/UNIX system programming training






lvs(8) — Linux manual page




NAME | SYNOPSIS | DESCRIPTION | USAGE | OPTIONS | VARIABLES | ENVIRONMENT VARIABLES | NOTES | SEE ALSO | COLOPHON













 



LVS(8)                     System Manager's Manual                    LVS(8)

NAME          top
       lvs - Display information about logical volumes

SYNOPSIS          top
       lvs
           [ option_args ]
           [ position_args ]

DESCRIPTION          top
       lvs produces formatted output about LVs.

USAGE          top
       lvs
           [ -H|--history ]
           [ -a|--all ]
           [ -o|--options String ]
           [ -S|--select String ]
           [ -O|--sort String ]
           [    --segments ]
           [    --aligned ]
           [    --binary ]
           [    --configreport log|vg|lv|pv|pvseg|seg ]
           [    --foreign ]
           [    --ignorelockingfailure ]
           [    --logonly ]
           [    --nameprefixes ]
           [    --noheadings ]
           [    --nosuffix ]
           [    --readonly ]
           [    --reportformat basic|json ]
           [    --rows ]
           [    --separator String ]
           [    --shared ]
           [    --unbuffered ]
           [    --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E ]
           [    --unquoted ]
           [ COMMON_OPTIONS ]
           [ VG|LV|Tag ... ]

       Common options for lvm:
           [ -d|--debug ]
           [ -h|--help ]
           [ -q|--quiet ]
           [ -t|--test ]
           [ -v|--verbose ]
           [ -y|--yes ]
           [    --commandprofile String ]
           [    --config String ]
           [    --driverloaded y|n ]
           [    --lockopt String ]
           [    --longhelp ]
           [    --nolocking ]
           [    --profile String ]
           [    --version ]

OPTIONS          top
       --aligned
              Use with --separator to align the output columns

       -a|--all
              Show information about internal LVs.  These are components of
              normal LVs, such as mirrors, which are not independently
              accessible, e.g. not mountable.

       --binary
              Use binary values ""0"" or ""1"" instead of descriptive literal
              values for columns that have exactly two valid values to
              report (not counting the ""unknown"" value which denotes that
              the value could not be determined).

       --commandprofile String
              The command profile to use for command configuration.  See
              lvm.conf(5) for more information about profiles.

       --config String
              Config settings for the command. These override lvm.conf
              settings.  The String arg uses the same format as lvm.conf, or
              may use section/field syntax.  See lvm.conf(5) for more
              information about config.

       --configreport log|vg|lv|pv|pvseg|seg
              See lvmreport(7).

       -d|--debug ...
              Set debug level. Repeat from 1 to 6 times to increase the
              detail of messages sent to the log file and/or syslog (if
              configured).

       --driverloaded y|n
              If set to no, the command will not attempt to use device-
              mapper.  For testing and debugging.

       --foreign
              Report/display foreign VGs that would otherwise be skipped.
              See lvmsystemid(7) for more information about foreign VGs.

       -h|--help
              Display help text.

       -H|--history
              Include historical LVs in the output.  (This has no effect
              unless LVs were removed while lvm.conf
              metadata/record_lvs_history was enabled.

       --ignorelockingfailure
              Allows a command to continue with read-only metadata
              operations after locking failures.

       --lockopt String
              Used to pass options for special cases to lvmlockd.  See
              lvmlockd(8) for more information.

       --logonly
              Suppress command report and display only log report.

       --longhelp
              Display long help text.

       --nameprefixes
              Add an ""LVM2_"" prefix plus the field name to the output.
              Useful with --noheadings to produce a list of field=value
              pairs that can be used to set environment variables (for
              example, in udev rules).

       --noheadings
              Suppress the headings line that is normally the first line of
              output.  Useful if grepping the output.

       --nolocking
              Disable locking.

       --nosuffix
              Suppress the suffix on output sizes. Use with --units (except
              h and H) if processing the output.

       -o|--options String
              Comma-separated, ordered list of fields to display in columns.
              String arg syntax is: [+|-|#]Field1[,Field2 ...]  The prefix +
              will append the specified fields to the default fields, - will
              remove the specified fields from the default fields, and #
              will compact specified fields (removing them when empty for
              all rows.)  Use -o help to view the list of all available
              fields.  Use separate lists of fields to add, remove or
              compact by repeating the -o option: -o+field1,field2 -o-
              field3,field4 -o#field5.  These lists are evaluated from left
              to right.  Use field name lv_all to view all LV fields, vg_all
              all VG fields, pv_all all PV fields, pvseg_all all PV segment
              fields, seg_all all LV segment fields, and pvseg_all all PV
              segment columns.  See the lvm.conf report section for more
              config options.  See lvmreport(7) for more information about
              reporting.

       --profile String
              An alias for --commandprofile or --metadataprofile, depending
              on the command.

       -q|--quiet ...
              Suppress output and log messages. Overrides --debug and
              --verbose.  Repeat once to also suppress any prompts with
              answer 'no'.

       --readonly
              Run the command in a special read-only mode which will read
              on-disk metadata without needing to take any locks. This can
              be used to peek inside metadata used by a virtual machine
              image while the virtual machine is running. No attempt will be
              made to communicate with the device-mapper kernel driver, so
              this option is unable to report whether or not LVs are
              actually in use.

       --reportformat basic|json
              Overrides current output format for reports which is defined
              globally by the report/output_format setting in lvm.conf.
              basic is the original format with columns and rows.  If there
              is more than one report per command, each report is prefixed
              with the report name for identification. json produces report
              output in JSON format. See lvmreport(7) for more information.

       --rows
              Output columns as rows.

       --segments
              Use default columns that emphasize segment information.

       -S|--select String
              Select objects for processing and reporting based on specified
              criteria.  The criteria syntax is described by --select help
              and lvmreport(7).  For reporting commands, one row is
              displayed for each object matching the criteria.  See
              --options help for selectable object fields.  Rows can be
              displayed with an additional ""selected"" field (-o selected)
              showing 1 if the row matches the selection and 0 otherwise.
              For non-reporting commands which process LVM entities, the
              selection is used to choose items to process.

       --separator String
              String to use to separate each column. Useful if grepping the
              output.

       --shared
              Report/display shared VGs that would otherwise be skipped when
              lvmlockd is not being used on the host.  See lvmlockd(8) for
              more information about shared VGs.

       -O|--sort String
              Comma-separated ordered list of columns to sort by. Replaces
              the default selection. Precede any column with - for a reverse
              sort on that column.

       -t|--test
              Run in test mode. Commands will not update metadata.  This is
              implemented by disabling all metadata writing but nevertheless
              returning success to the calling function. This may lead to
              unusual error messages in multi-stage operations if a tool
              relies on reading back metadata it believes has changed but
              hasn't.

       --unbuffered
              Produce output immediately without sorting or aligning the
              columns properly.

       --units r|R|h|H|b|B|s|S|k|K|m|M|g|G|t|T|p|P|e|E
              All sizes are output in these units: human-(r)eadable with '<'
              rounding indicator, (h)uman-readable, (b)ytes, (s)ectors,
              (k)ilobytes, (m)egabytes, (g)igabytes, (t)erabytes,
              (p)etabytes, (e)xabytes.  Capitalise to use multiples of 1000
              (S.I.) instead of 1024.  Custom units can be specified, e.g.
              --units 3M.

       --unquoted
              When used with --nameprefixes, output values in the
              field=value pairs are not quoted.

       -v|--verbose ...
              Set verbose level. Repeat from 1 to 4 times to increase the
              detail of messages sent to stdout and stderr.

       --version
              Display version information.

       -y|--yes
              Do not prompt for confirmation interactively but always assume
              the answer yes. Use with extreme caution.  (For automatic no,
              see -qq.)

VARIABLES          top
       VG
              Volume Group name.  See lvm(8) for valid names.

       LV
              Logical Volume name.  See lvm(8) for valid names.  An LV
              positional arg generally includes the VG name and LV name,
              e.g. VG/LV.

       Tag
              Tag name.  See lvm(8) for information about tag names and
              using tags in place of a VG, LV or PV.

       String
              See the option description for information about the string
              content.

       Size[UNIT]
              Size is an input number that accepts an optional unit.  Input
              units are always treated as base two values, regardless of
              capitalization, e.g. 'k' and 'K' both refer to 1024.  The
              default input unit is specified by letter, followed by |UNIT.
              UNIT represents other possible input units: bBsSkKmMgGtTpPeE.
              b|B is bytes, s|S is sectors of 512 bytes, k|K is kilobytes,
              m|M is megabytes, g|G is gigabytes, t|T is terabytes, p|P is
              petabytes, e|E is exabytes.  (This should not be confused with
              the output control --units, where capital letters mean
              multiple of 1000.)

ENVIRONMENT VARIABLES          top
       See lvm(8) for information about environment variables used by lvm.
       For example, LVM_VG_NAME can generally be substituted for a required
       VG parameter.

NOTES          top
       The lv_attr bits are:

       1  Volume type: (C)ache, (m)irrored, (M)irrored without initial sync,
          (o)rigin, (O)rigin with merging snapshot, (r)aid, (R)aid without
          initial sync, (s)napshot, merging (S)napshot, (p)vmove, (v)irtual,
          mirror or raid (i)mage, mirror or raid (I)mage out-of-sync, mirror
          (l)og device, under (c)onversion, thin (V)olume, (t)hin pool,
          (T)hin pool data, v(d)o pool, v(D)o pool data, raid or pool
          m(e)tadata or pool metadata spare.

       2  Permissions: (w)riteable, (r)ead-only, (R)ead-only activation of
          non-read-only volume

       3  Allocation policy:  (a)nywhere, (c)ontiguous, (i)nherited,
          c(l)ing, (n)ormal This is capitalised if the volume is currently
          locked against allocation changes, for example during pvmove(8).

       4  fixed (m)inor

       5  State: (a)ctive, (h)istorical, (s)uspended, (I)nvalid snapshot,
          invalid (S)uspended snapshot, snapshot (m)erge failed, suspended
          snapshot (M)erge failed, mapped (d)evice present without tables,
          mapped device present with (i)nactive table, thin-pool (c)heck
          needed, suspended thin-pool (C)heck needed, (X) unknown

       6  device (o)pen, (X) unknown

       7  Target type: (C)ache, (m)irror, (r)aid, (s)napshot, (t)hin,
          (u)nknown, (v)irtual.  This groups logical volumes related to the
          same kernel target together.  So, for example, mirror images,
          mirror logs as well as mirrors themselves appear as (m) if they
          use the original device-mapper mirror kernel driver; whereas the
          raid equivalents using the md raid kernel driver all appear as
          (r).  Snapshots using the original device-mapper driver appear as
          (s); whereas snapshots of thin volumes using the new thin
          provisioning driver appear as (t).

       8  Newly-allocated data blocks are overwritten with blocks of
          (z)eroes before use.

       9  Volume Health, where there are currently three groups of
          attributes identified:

          Common ones for all Logical Volumes: (p)artial, (X) unknown.
          (p)artial signifies that one or more of the Physical Volumes this
          Logical Volume uses is missing from the system. (X) unknown
          signifies the status is unknown.

          Related to RAID Logical Volumes: (r)efresh needed, (m)ismatches
          exist, (w)ritemostly.
          (r)efresh signifies that one or more of the Physical Volumes this
          RAID Logical Volume uses had suffered a write error. The write
          error could be due to a temporary failure of that Physical Volume
          or an indication that it is failing.  The device should be
          refreshed or replaced. (m)ismatches signifies that the RAID
          logical volume has portions of the array that are not coherent.
          Inconsistencies are detected by initiating a ""check"" on a RAID
          logical volume.  (The scrubbing operations, ""check"" and ""repair"",
          can be performed on a RAID logical volume via the 'lvchange'
          command.)  (w)ritemostly signifies the devices in a RAID 1 logical
          volume that have been marked write-mostly.  Re(s)haping signifies
          a RAID Logical Volume is either undergoing a stripe
          addition/removal, a stripe size or RAID algorithm change.
          (R)emove after reshape signifies freed striped raid images to be
          removed.

          Related to Thin pool Logical Volumes: (F)ailed, out of (D)ata
          space, (M)etadata read only.
          (F)ailed is set if thin pool encounters serious failures and hence
          no further I/O is permitted at all. The out of (D)ata space is set
          if thin pool has run out of data space. (M)etadata read only
          signifies that thin pool encounters certain types of failures but
          it's still possible to do reads at least, but no metadata changes
          are allowed.

          Related to Thin Logical Volumes: (F)ailed.
          (F)ailed is set when related thin pool enters Failed state and no
          further I/O is permitted at all.

          Related to writecache logical volumes: (E)rror.
          (E)rror is set dm-writecache reports an error.

       10 s(k)ip activation: this volume is flagged to be skipped during
          activation.

SEE ALSO          top
       lvm(8) lvm.conf(5) lvmconfig(8)

       pvchange(8) pvck(8) pvcreate(8) pvdisplay(8) pvmove(8) pvremove(8)
       pvresize(8) pvs(8) pvscan(8)

       vgcfgbackup(8) vgcfgrestore(8) vgchange(8) vgck(8) vgcreate(8)
       vgconvert(8) vgdisplay(8) vgexport(8) vgextend(8) vgimport(8)
       vgimportclone(8) vgmerge(8) vgmknodes(8) vgreduce(8) vgremove(8)
       vgrename(8) vgs(8) vgscan(8) vgsplit(8)

       lvcreate(8) lvchange(8) lvconvert(8) lvdisplay(8) lvextend(8)
       lvreduce(8) lvremove(8) lvrename(8) lvresize(8) lvs(8) lvscan(8)

       lvm-fullreport(8) lvm-lvpoll(8) lvm2-activation-generator(8)
       blkdeactivate(8) lvmdump(8)

       dmeventd(8) lvmpolld(8) lvmlockd(8) lvmlockctl(8) cmirrord(8)
       lvmdbusd(8)

       lvmsystemid(7) lvmreport(7) lvmraid(7) lvmthin(7) lvmcache(7)

COLOPHON          top
       This page is part of the lvm2 (Logical Volume Manager 2) project.
       Information about the project can be found at 
       â¨http://www.sourceware.org/lvm2/â©.  If you have a bug report for this
       manual page, see â¨https://github.com/lvmteam/lvm2/issuesâ©.  This page
       was obtained from the tarball
       https://github.com/lvmteam/lvm2/archive/v2_03_10.tar.gz fetched from
       â¨https://github.com/lvmteam/lvm2/releasesâ© on 2020-08-13.  If you
       discover any rendering problems in this HTML version of the page, or
       you believe there is a better or more up-to-date source for the page,
       or you have corrections or improvements to the information in this
       COLOPHON (which is not part of the original manual page), send a mail
       to man-pages@man7.org

Red Hat, Inc.         LVM TOOLS 2.03.10(2) (2020-08-09)               LVS(8)


Pages that refer to this page: 
    lvmcache(7),  
    lvmreport(7),  
    lvmthin(7),  
    lvmvdo(7),  
    fullreport(8),  
    lvchange(8),  
    lvconvert(8),  
    lvcreate(8),  
    lvdisplay(8),  
    lvextend(8),  
    lvm(8),  
    lvm-config(8),  
    lvmconfig(8),  
    lvmdiskscan(8),  
    lvm-dumpconfig(8),  
    lvm-fullreport(8),  
    lvm-lvpoll(8),  
    lvpoll(8),  
    lvreduce(8),  
    lvremove(8),  
    lvrename(8),  
    lvresize(8),  
    lvs(8),  
    lvscan(8),  
    pvchange(8),  
    pvck(8),  
    pvcreate(8),  
    pvdisplay(8),  
    pvmove(8),  
    pvremove(8),  
    pvresize(8),  
    pvs(8),  
    pvscan(8),  
    vgcfgbackup(8),  
    vgcfgrestore(8),  
    vgchange(8),  
    vgck(8),  
    vgconvert(8),  
    vgcreate(8),  
    vgdisplay(8),  
    vgexport(8),  
    vgextend(8),  
    vgimport(8),  
    vgimportclone(8),  
    vgmerge(8),  
    vgmknodes(8),  
    vgreduce(8),  
    vgremove(8),  
    vgrename(8),  
    vgs(8),  
    vgscan(8),  
    vgsplit(8)








            HTML rendering created 2020-08-13
            by Michael Kerrisk, 
            author of 
            The Linux Programming Interface, 
            maintainer of the 
            Linux man-pages project.
        

            For details of in-depth
            Linux/UNIX system programming training courses
            that I teach, look here.
        

            Hosting by jambit GmbH.
        



























",,"# lvs

> Display information about LVM logical volumes.
> More information: <https://www.man7.org/linux/man-pages/man8/lvs.8.html>.

- Display information about logical volumes:

`lvs`

- Display all logical volumes:

`lvs -a`

- Change default display to show more details:

`lvs -v`

- Display only specific fields:

`lvs -o {{field_name_1}},{{field_name_2}}`

- Append field to default display:

`lvs -o +{{field_name}}`

- Suppress heading line:

`lvs --noheadings`

- Use a separator to separate fields:

`lvs --separator {{=}}`
"
reset,,,"tput(1) 							       tput(1)



NAME
       tput, reset - initialize a terminal or query terminfo database

SYNOPSIS
       tput [-Ttype] capname [parms ... ]
       tput [-Ttype] init
       tput [-Ttype] reset
       tput [-Ttype] longname
       tput -S	<<
       tput -V

DESCRIPTION
       The  tput utility uses the terminfo database to make the values of ter-
       minal-dependent capabilities and information  available	to  the  shell
       (see  sh(1)),  to  initialize or reset the terminal, or return the long
       name of the requested terminal type.  The result depends upon the capa-
       bility's type:

	      string
		   tput writes the string to the standard output.  No trailing
		   newline is supplied.

	      integer
		   tput writes the decimal value to the standard output,  with
		   a trailing newline.

	      boolean
		   tput  simply sets the exit code (0 for TRUE if the terminal
		   has the capability, 1 for FALSE if it does not), and writes
		   nothing to the standard output.

       Before  using  a value returned on the standard output, the application
       should test the exit code (e.g., $?, see sh(1)) to be  sure  it	is  0.
       (See  the EXIT CODES and DIAGNOSTICS sections.)	For a complete list of
       capabilities and the capname associated with each, see terminfo(5).

       -Ttype indicates the type of terminal.  Normally this option is	unnec-
	      essary,  because the default is taken from the environment vari-
	      able TERM.  If -T is specified, then the shell  variables  LINES
	      and COLUMNS will be ignored,and the operating system will not be
	      queried for the actual screen size.

       capname
	      indicates the capability from the terminfo database.  When term-
	      cap  support is compiled in, the termcap name for the capability
	      is also accepted.

       parms  If the capability is a string that takes parameters,  the  argu-
	      ments parms will be instantiated into the string.

	      Most  parameters	are numbers.  Only a few terminfo capabilities
	      require string parameters; tput uses a table to decide which  to
	      pass  as	strings.  Normally tput uses tparm (3X) to perform the
	      substitution.  If no parameters are given  for  the  capability,
	      tput writes the string without performing the substitution.

       -S     allows  more  than  one  capability per invocation of tput.  The
	      capabilities must be passed to  tput  from  the  standard  input
	      instead  of  from the command line (see example).  Only one cap-
	      name is allowed per line.  The -S option changes the meaning  of
	      the  0  and  1 boolean and string exit codes (see the EXIT CODES
	      section).

	      Again, tput uses a table and the presence of parameters  in  its
	      input  to decide whether to use tparm (3X), and how to interpret
	      the parameters.

       -V     reports the version of ncurses which was used in	this  program,
	      and exits.

       init   If  the terminfo database is present and an entry for the user's
	      terminal exists (see -Ttype, above), the following will occur:

	      (1)    if present, the terminal's initialization strings will be
		     output as detailed in the terminfo(5) section on Tabs and
		     Initialization,

	      (2)    any delays (e.g., newline) specified in the entry will be
		     set in the tty driver,

	      (3)    tabs  expansion will be turned on or off according to the
		     specification in the entry, and

	      (4)    if tabs are not  expanded,  standard  tabs  will  be  set
		     (every 8 spaces).

	      If  an  entry does not contain the information needed for any of
	      the four	above  activities,  that  activity  will  silently  be
	      skipped.

       reset  Instead  of  putting  out initialization strings, the terminal's
	      reset strings will be output if present (rs1, rs2, rs3, rf).  If
	      the  reset  strings  are not present, but initialization strings
	      are, the initialization  strings	will  be  output.   Otherwise,
	      reset acts identically to init.

       longname
	      If  the terminfo database is present and an entry for the user's
	      terminal exists (see -Ttype above), then the long  name  of  the
	      terminal will be put out.  The long name is the last name in the
	      first line of the terminal's description in the  terminfo  data-
	      base [see term(5)].

       If  tput  is invoked by a link named reset, this has the same effect as
       tput reset.  See tset for comparison, which has similar behavior.

EXAMPLES
       tput init
	    Initialize the terminal according to the type of terminal  in  the
	    environmental  variable  TERM.  This command should be included in
	    everyone's .profile after the environmental variable TERM has been
	    exported, as illustrated on the profile(5) manual page.

       tput -T5620 reset
	    Reset  an  AT&T  5620 terminal, overriding the type of terminal in
	    the environmental variable TERM.

       tput cup 0 0
	    Send the sequence to move the cursor to row 0, column 0 (the upper
	    left  corner  of  the  screen,  usually known as the ""home"" cursor
	    position).

       tput clear
	    Echo the clear-screen sequence for the current terminal.

       tput cols
	    Print the number of columns for the current terminal.

       tput -T450 cols
	    Print the number of columns for the 450 terminal.

       bold=`tput smso` offbold=`@TPUT@ rmso`
	    Set the shell variables bold, to begin  stand-out  mode  sequence,
	    and offbold, to end standout mode sequence, for the current termi-
	    nal.  This might be followed by a prompt: echo ""${bold}Please type
	    in your name: ${offbold}\c""

       tput hc
	    Set  exit  code to indicate if the current terminal is a hard copy
	    terminal.

       tput cup 23 4
	    Send the sequence to move the cursor to row 23, column 4.

       tput cup
	    Send the terminfo string for cursor-movement, with	no  parameters
	    substituted.

       tput longname
	    Print  the	long  name  from the terminfo database for the type of
	    terminal specified in the environmental variable TERM.

	    tput -S <<!
	    > clear
	    > cup 10 10
	    > bold
	    > !

	    This example shows tput processing	several  capabilities  in  one
	    invocation.   It  clears  the screen, moves the cursor to position
	    10, 10 and turns on bold (extra bright) mode.  The list is	termi-
	    nated by an exclamation mark (!) on a line by itself.

FILES
       /usr/share/terminfo
	      compiled terminal description database

       /usr/share/tabset/*
	      tab  settings  for some terminals, in a format appropriate to be
	      output to the terminal (escape sequences that  set  margins  and
	      tabs);  for  more information, see the ""Tabs and Initialization""
	      section of terminfo(5)

EXIT CODES
       If the -S option is used, tput checks for errors from each line, and if
       any  errors  are  found, will set the exit code to 4 plus the number of
       lines with errors.  If no errors are found, the exit  code  is  0.   No
       indication  of which line failed can be given so exit code 1 will never
       appear.	Exit codes 2, 3, and 4 retain their usual interpretation.   If
       the  -S	option	is not used, the exit code depends on the type of cap-
       name:

	    boolean
		   a value of 0 is set for TRUE and 1 for FALSE.

	    string a value of 0 is set if the capname is defined for this ter-
		   minal  type	(the  value of capname is returned on standard
		   output); a value of 1 is set if capname is not defined  for
		   this terminal type (nothing is written to standard output).

	    integer
		   a value of 0 is always  set,  whether  or  not  capname  is
		   defined for this terminal type.  To determine if capname is
		   defined for this terminal type,  the  user  must  test  the
		   value written to standard output.  A value of -1 means that
		   capname is not defined for this terminal type.

	    other  reset or init may fail to find their respective files.   In
		   that case, the exit code is set to 4 + errno.

       Any other exit code indicates an error; see the DIAGNOSTICS section.

DIAGNOSTICS
       tput  prints  the  following  error messages and sets the corresponding
       exit codes.


       exit code   error message
       ---------------------------------------------------------------------
       0	   (capname is a numeric variable that is not specified  in
		   the	terminfo(5)  database  for this terminal type, e.g.
		   tput -T450 lines and @TPUT@ -T2621 xmc)
       1	   no error message is printed, see the EXIT CODES section.
       2	   usage error
       3	   unknown terminal type or no terminfo database
       4	   unknown terminfo capability capname
       >4	   error occurred in -S
       ---------------------------------------------------------------------

PORTABILITY
       The longname and -S options, and  the  parameter-substitution  features
       used in the cup example, are not supported in BSD curses or in AT&T/USL
       curses before SVr4.

       X/Open documents only the operands for clear, init and reset.  In  this
       implementation,	clear is part of the capname support.  Other implemen-
       tations of tput on SVr4-based systems such as Solaris, IRIX64 and  HPUX
       as well as others such as AIX and Tru64 provide support for capname op-
       erands.	A few platforms such as FreeBSD and NetBSD  recognize  termcap
       names  rather  than  terminfo capability names in their respective tput
       commands.

SEE ALSO
       clear(1), stty(1), tabs(1), terminfo(5).

       This describes ncurses version 5.7 (patch 20081102).



								       tput(1)
","# reset

> Reinitialises the current terminal. Clears the entire terminal screen.

- Reinitialise the current terminal:

`reset`

- Display the terminal type instead:

`reset -q`
"
lspci,,,,"# lspci

> List all PCI devices.

- Show a brief list of devices:

`lspci`

- Display additional info:

`lspci -v`

- Display drivers and modules handling each device:

`lspci -k`

- Show a specific device:

`lspci -s {{00:18.3}}`

- Dump info in a readable form:

`lspci -vm`
"
readelf,http://man7.org/linux/man-pages/man1/readelf.1.html,"




readelf(1) - Linux manual page









man7.org > Linux > man-pages



Linux/UNIX system programming training






readelf(1) — Linux manual page




NAME | SYNOPSIS | DESCRIPTION | OPTIONS | SEE ALSO | COPYRIGHT | COLOPHON













 



READELF(1)                  GNU Development Tools                 READELF(1)

NAME          top
       readelf - display information about ELF files

SYNOPSIS          top
       readelf [-a|--all]
               [-h|--file-header]
               [-l|--program-headers|--segments]
               [-S|--section-headers|--sections]
               [-g|--section-groups]
               [-t|--section-details]
               [-e|--headers]
               [-s|--syms|--symbols]
               [--dyn-syms]
               [-n|--notes]
               [-r|--relocs]
               [-u|--unwind]
               [-d|--dynamic]
               [-V|--version-info]
               [-A|--arch-specific]
               [-D|--use-dynamic]
               [-L|--lint|--enable-checks]
               [-x <number or name>|--hex-dump=<number or name>]
               [-p <number or name>|--string-dump=<number or name>]
               [-R <number or name>|--relocated-dump=<number or name>]
               [-z|--decompress]
               [-c|--archive-index]
               [-w[lLiaprmfFsoORtUuTgAckK]|
                --debug-dump[=rawline,=decodedline,=info,=abbrev,=pubnames,=aranges,=macro,=frames,=frames-interp,=str,=str-offsets,=loc,=Ranges,=pubtypes,=trace_info,=trace_abbrev,=trace_aranges,=gdb_index,=addr,=cu_index,=links,=follow-links]]
               [--dwarf-depth=n]
               [--dwarf-start=n]
               [--ctf=section]
               [--ctf-parent=section]
               [--ctf-symbols=section]
               [--ctf-strings=section]
               [-I|--histogram]
               [-v|--version]
               [-W|--wide]
               [-T|--silent-truncation]
               [-H|--help]
               elffile...

DESCRIPTION          top
       readelf displays information about one or more ELF format object
       files.  The options control what particular information to display.

       elffile... are the object files to be examined.  32-bit and 64-bit
       ELF files are supported, as are archives containing ELF files.

       This program performs a similar function to objdump but it goes into
       more detail and it exists independently of the BFD library, so if
       there is a bug in BFD then readelf will not be affected.

OPTIONS          top
       The long and short forms of options, shown here as alternatives, are
       equivalent.  At least one option besides -v or -H must be given.

       -a
       --all
           Equivalent to specifying --file-header, --program-headers,
           --sections, --symbols, --relocs, --dynamic, --notes,
           --version-info, --arch-specific, --unwind, --section-groups and
           --histogram.

           Note - this option does not enable --use-dynamic itself, so if
           that option is not present on the command line then dynamic
           symbols and dynamic relocs will not be displayed.

       -h
       --file-header
           Displays the information contained in the ELF header at the start
           of the file.

       -l
       --program-headers
       --segments
           Displays the information contained in the file's segment headers,
           if it has any.

       -S
       --sections
       --section-headers
           Displays the information contained in the file's section headers,
           if it has any.

       -g
       --section-groups
           Displays the information contained in the file's section groups,
           if it has any.

       -t
       --section-details
           Displays the detailed section information. Implies -S.

       -s
       --symbols
       --syms
           Displays the entries in symbol table section of the file, if it
           has one.  If a symbol has version information associated with it
           then this is displayed as well.  The version string is displayed
           as a suffix to the symbol name, preceeded by an @ character.  For
           example foo@VER_1.  If the version is the default version to be
           used when resolving unversioned references to the symbol then it
           is displayed as a suffix preceeded by two @ characters.  For
           example foo@@VER_2.

       --dyn-syms
           Displays the entries in dynamic symbol table section of the file,
           if it has one.  The output format is the same as the format used
           by the --syms option.

       -e
       --headers
           Display all the headers in the file.  Equivalent to -h -l -S.

       -n
       --notes
           Displays the contents of the NOTE segments and/or sections, if
           any.

       -r
       --relocs
           Displays the contents of the file's relocation section, if it has
           one.

       -u
       --unwind
           Displays the contents of the file's unwind section, if it has
           one.  Only the unwind sections for IA64 ELF files, as well as ARM
           unwind tables ("".ARM.exidx"" / "".ARM.extab"") are currently
           supported.  If support is not yet implemented for your
           architecture you could try dumping the contents of the .eh_frames
           section using the --debug-dump=frames or
           --debug-dump=frames-interp options.

       -d
       --dynamic
           Displays the contents of the file's dynamic section, if it has
           one.

       -V
       --version-info
           Displays the contents of the version sections in the file, it
           they exist.

       -A
       --arch-specific
           Displays architecture-specific information in the file, if there
           is any.

       -D
       --use-dynamic
           When displaying symbols, this option makes readelf use the symbol
           hash tables in the file's dynamic section, rather than the symbol
           table sections.

           When displaying relocations, this option makes readelf display
           the dynamic relocations rather than the static relocations.

       -L
       --lint
       --enable-checks
           Displays warning messages about possible problems with the
           file(s) being examined.  If used on its own then all of the
           contents of the file(s) will be examined.  If used with one of
           the dumping options then the warning messages will only be
           produced for the things being displayed.

       -x <number or name>
       --hex-dump=<number or name>
           Displays the contents of the indicated section as a hexadecimal
           bytes.  A number identifies a particular section by index in the
           section table; any other string identifies all sections with that
           name in the object file.

       -R <number or name>
       --relocated-dump=<number or name>
           Displays the contents of the indicated section as a hexadecimal
           bytes.  A number identifies a particular section by index in the
           section table; any other string identifies all sections with that
           name in the object file.  The contents of the section will be
           relocated before they are displayed.

       -p <number or name>
       --string-dump=<number or name>
           Displays the contents of the indicated section as printable
           strings.  A number identifies a particular section by index in
           the section table; any other string identifies all sections with
           that name in the object file.

       -z
       --decompress
           Requests that the section(s) being dumped by x, R or p options
           are decompressed before being displayed.  If the section(s) are
           not compressed then they are displayed as is.

       -c
       --archive-index
           Displays the file symbol index information contained in the
           header part of binary archives.  Performs the same function as
           the t command to ar, but without using the BFD library.

       -w[lLiaprmfFsOoRtUuTgAckK]
       --debug-dump[=rawline,=decodedline,=info,=abbrev,=pubnames,=aranges,=macro,=frames,=frames-interp,=str,=str-offsets,=loc,=Ranges,=pubtypes,=trace_info,=trace_abbrev,=trace_aranges,=gdb_index,=addr,=cu_index,=links,=follow-links]
           Displays the contents of the DWARF debug sections in the file, if
           any are present.  Compressed debug sections are automatically
           decompressed (temporarily) before they are displayed.  If one or
           more of the optional letters or words follows the switch then
           only those type(s) of data will be dumped.  The letters and words
           refer to the following information:

           ""a""
           ""=abbrev""
               Displays the contents of the .debug_abbrev section.

           ""A""
           ""=addr""
               Displays the contents of the .debug_addr section.

           ""c""
           ""=cu_index""
               Displays the contents of the .debug_cu_index and/or
               .debug_tu_index sections.

           ""f""
           ""=frames""
               Display the raw contents of a .debug_frame section.

           ""F""
           ""=frame-interp""
               Display the interpreted contents of a .debug_frame section.

           ""g""
           ""=gdb_index""
               Displays the contents of the .gdb_index and/or .debug_names
               sections.

           ""i""
           ""=info""
               Displays the contents of the .debug_info section.  Note: the
               output from this option can also be restricted by the use of
               the --dwarf-depth and --dwarf-start options.

           ""k""
           ""=links""
               Displays the contents of the .gnu_debuglink and/or
               .gnu_debugaltlink sections.  Also displays any links to
               separate dwarf object files (dwo), if they are specified by
               the DW_AT_GNU_dwo_name or DW_AT_dwo_name attributes in the
               .debug_info section.

           ""K""
           ""=follow-links""
               Display the contents of any selected debug sections that are
               found in linked, separate debug info file(s).  This can
               result in multiple versions of the same debug section being
               displayed if it exists in more than one file.

               In addition, when displaying DWARF attributes, if a form is
               found that references the separate debug info file, then the
               referenced contents will also be displayed.

           ""l""
           ""=rawline""
               Displays the contents of the .debug_line section in a raw
               format.

           ""L""
           ""=decodedline""
               Displays the interpreted contents of the .debug_line section.

           ""m""
           ""=macro""
               Displays the contents of the .debug_macro and/or
               .debug_macinfo sections.

           ""o""
           ""=loc""
               Displays the contents of the .debug_loc and/or
               .debug_loclists sections.

           ""O""
           ""=str-offsets""
               Displays the contents of the .debug_str_offsets section.

           ""p""
           ""=pubnames""
               Displays the contents of the .debug_pubnames and/or
               .debug_gnu_pubnames sections.

           ""r""
           ""=aranges""
               Displays the contents of the .debug_aranges section.

           ""R""
           ""=Ranges""
               Displays the contents of the .debug_ranges and/or
               .debug_rnglists sections.

           ""s""
           ""=str""
               Displays the contents of the .debug_str, .debug_line_str
               and/or .debug_str_offsets sections.

           ""t""
           ""=pubtype""
               Displays the contents of the .debug_pubtypes and/or
               .debug_gnu_pubtypes sections.

           ""T""
           ""=trace_aranges""
               Displays the contents of the .trace_aranges section.

           ""u""
           ""=trace_abbrev""
               Displays the contents of the .trace_abbrev section.

           ""U""
           ""=trace_info""
               Displays the contents of the .trace_info section.

           Note: displaying the contents of .debug_static_funcs,
           .debug_static_vars and debug_weaknames sections is not currently
           supported.

       --dwarf-depth=n
           Limit the dump of the "".debug_info"" section to n children.  This
           is only useful with --debug-dump=info.  The default is to print
           all DIEs; the special value 0 for n will also have this effect.

           With a non-zero value for n, DIEs at or deeper than n levels will
           not be printed.  The range for n is zero-based.

       --dwarf-start=n
           Print only DIEs beginning with the DIE numbered n.  This is only
           useful with --debug-dump=info.

           If specified, this option will suppress printing of any header
           information and all DIEs before the DIE numbered n.  Only
           siblings and children of the specified DIE will be printed.

           This can be used in conjunction with --dwarf-depth.

       --ctf=section
           Display the contents of the specified CTF section.  CTF sections
           themselves contain many subsections, all of which are displayed
           in order.

       --ctf-parent=section
           Specify the name of another section from which the CTF dictionary
           can inherit types.  (If none is specified, we assume the CTF
           dictionary inherits types from the default-named member of the
           archive contained within this section.)

       --ctf-symbols=section
       --ctf-strings=section
           Specify the name of another section from which the CTF file can
           inherit strings and symbols.  By default, the "".symtab"" and its
           linked string table are used.

           If either of --ctf-symbols or --ctf-strings is specified, the
           other must be specified as well.

       -I
       --histogram
           Display a histogram of bucket list lengths when displaying the
           contents of the symbol tables.

       -v
       --version
           Display the version number of readelf.

       -W
       --wide
           Don't break output lines to fit into 80 columns. By default
           readelf breaks section header and segment listing lines for
           64-bit ELF files, so that they fit into 80 columns. This option
           causes readelf to print each section header resp. each segment
           one a single line, which is far more readable on terminals wider
           than 80 columns.

       -T
       --silent-truncation
           Normally when readelf is displaying a symbol name, and it has to
           truncate the name to fit into an 80 column display, it will add a
           suffix of ""[...]"" to the name.  This command line option disables
           this behaviour, allowing 5 more characters of the name to be
           displayed and restoring the old behaviour of readelf (prior to
           release 2.35).

       -H
       --help
           Display the command-line options understood by readelf.

       @file
           Read command-line options from file.  The options read are
           inserted in place of the original @file option.  If file does not
           exist, or cannot be read, then the option will be treated
           literally, and not removed.

           Options in file are separated by whitespace.  A whitespace
           character may be included in an option by surrounding the entire
           option in either single or double quotes.  Any character
           (including a backslash) may be included by prefixing the
           character to be included with a backslash.  The file may itself
           contain additional @file options; any such options will be
           processed recursively.

SEE ALSO          top
       objdump(1), and the Info entries for binutils.

COPYRIGHT          top
       Copyright (c) 1991-2020 Free Software Foundation, Inc.

       Permission is granted to copy, distribute and/or modify this document
       under the terms of the GNU Free Documentation License, Version 1.3 or
       any later version published by the Free Software Foundation; with no
       Invariant Sections, with no Front-Cover Texts, and with no Back-Cover
       Texts.  A copy of the license is included in the section entitled
       ""GNU Free Documentation License"".

COLOPHON          top
       This page is part of the binutils (a collection of tools for working
       with executable binaries) project.  Information about the project can
       be found at â¨http://www.gnu.org/software/binutils/â©.  If you have a
       bug report for this manual page, see
       â¨http://sourceware.org/bugzilla/enter_bug.cgi?product=binutilsâ©.
       This page was obtained from the tarball binutils-2.35.tar.gz fetched
       from â¨https://ftp.gnu.org/gnu/binutils/â© on 2020-08-13.  If you disâ
       cover any rendering problems in this HTML version of the page, or you
       believe there is a better or more up-to-date source for the page, or
       you have corrections or improvements to the information in this
       COLOPHON (which is not part of the original manual page), send a mail
       to man-pages@man7.org

binutils-2.35                    2020-07-24                       READELF(1)


Pages that refer to this page: 
    elfedit(1),  
    ld(1),  
    objdump(1),  
    size(1),  
    strings(1),  
    dl_iterate_phdr(3),  
    edata(3),  
    end(3),  
    etext(3),  
    elf(5)








            HTML rendering created 2020-08-13
            by Michael Kerrisk, 
            author of 
            The Linux Programming Interface, 
            maintainer of the 
            Linux man-pages project.
        

            For details of in-depth
            Linux/UNIX system programming training courses
            that I teach, look here.
        

            Hosting by jambit GmbH.
        



























",,"# readelf

> Displays information about ELF files.
> More information: <http://man7.org/linux/man-pages/man1/readelf.1.html>.

- Display all information about the ELF file:

`readelf -all {{path/to/binary}}`

- Display all the headers present in the ELF file:

`readelf --headers {{path/to/binary}}`

- Display the entries in symbol table section of the ELF file, if it has one:

`readelf --symbols {{path/to/binary}}`

- Display the information contained in the ELF header at the start of the file:

`readelf --file-header {{path/to/binary}}`
"
htop,,,"HTOP(1) 			     Utils			       HTOP(1)



NAME
       htop - interactive process viewer

SYNOPSIS
       htop [-dChustv]

DESCRIPTION
       Htop is a free (GPL) ncurses-based process viewer for Linux.

       It  is similar to top, but allows you to scroll vertically and horizon-
       tally, so you can see all the processes running on  the	system,  along
       with  their  full  command  lines, as well as viewing them as a process
       tree, selecting multiple processes and acting on them all at once.

       Tasks related to processes (killing,  renicing)	can  be  done  without
       entering their PIDs.

COMMAND-LINE OPTIONS
       Mandatory  arguments  to  long  options are mandatory for short options
       too.


       -d --delay=DELAY
	      Delay between updates, in tenths of seconds

       -C --no-color --no-colour
	      Start htop in monochrome mode

       -h --help
	      Display a help message and exit

       -p --pid=PID,PID...
	      Show only the given PIDs

       -s --sort-key COLUMN
	      Sort by this column (use --sort-key help for a column list)

       -u --user=USERNAME
	      Show only the processes of a given user

       -v --version
	      Output version information and exit

       -t --tree
	      Show processes in tree view


INTERACTIVE COMMANDS
       The following commands are supported while in htop:


       Up, Alt-k
	    Select (highlight) the  previous  process  in  the	process  list.
	    Scroll the list if necessary.

       Down, Alt-j
	    Select  (highlight)  the  next process in the process list. Scroll
	    the list if necessary.

       Left, Alt-h
	    Scroll the process list left.

       Right, Alt-l
	    Scroll the process list right.

       PgUp, PgDn
	    Scroll the process list up or down one window.

       Home Scroll to the top  of  the	process  list  and  select  the  first
	    process.

       End  Scroll  to	the  bottom  of  the  process list and select the last
	    process.

       Ctrl-A, ^
	    Scroll left to the beginning of the process entry (i.e.  beginning
	    of line).

       Ctrl-E, $
	    Scroll right to the end of the process entry (i.e. end of line).

       Space
	    Tag or untag a process. Commands that can operate on multiple pro-
	    cesses, like ""kill"", will then apply over the list of tagged  pro-
	    cesses, instead of the currently highlighted one.

       U    Untag all processes (remove all tags added with the Space key).

       s    Trace  process  system  calls: if strace(1) is installed, pressing
	    this key will attach it to the currently  selected	process,  pre-
	    senting a live update of system calls issued by the process.

       l    Display  open files for a process: if lsof(1) is installed, press-
	    ing this key will display the list of file descriptors  opened  by
	    the process.

       F1, h, ?
	    Go to the help screen

       F2, S
	    Go	to  the  setup screen, where you can configure the meters dis-
	    played at the top of the  screen,  set  various  display  options,
	    choose  among  color  schemes,  and  select which columns are dis-
	    played, in which order.

       F3, /
	    Incrementally search the command lines of all the  displayed  pro-
	    cesses.  The  currently selected (highlighted) command will update
	    as you type. While in search mode, pressing F3 will cycle  through
	    matching occurrences.

       F4, \
	    Incremental  process  filtering: type in part of a process command
	    line and only processes whose names match will be shown. To cancel
	    filtering, enter the Filter option again and press Esc.

       F5, t
	    Tree  view: organize processes by parenthood, and layout the rela-
	    tions between them as a tree. Toggling the key will switch between
	    tree and your previously selected sort view. Selecting a sort view
	    will exit tree view.

       F6   On sorted view,  select  a	field  for  sorting,  also  accessible
	    through  <	and >.	The current sort field is indicated by a high-
	    light in the header.  On tree view, expand or collapse the current
	    subtree.  A  ""+""  indicator  in the tree node indicates that it is
	    collapsed.

       F7, ]
	    Increase the selected process's  priority  (subtract  from	'nice'
	    value).  This can only be done by the superuser.

       F8, [
	    Decrease the selected process's priority (add to 'nice' value)

       F9, k
	    ""Kill"" process: sends a signal which is selected in a menu, to one
	    or a group of processes. If processes were tagged, sends the  sig-
	    nal to all tagged processes.  If none is tagged, sends to the cur-
	    rently selected process.

       F10, q
	    Quit

       I    Invert the sort order: if sort  order  is  increasing,  switch  to
	    decreasing, and vice-versa.

       +, - When in tree view mode, expand or collapse subtree. When a subtree
	    is collapsed a ""+"" sign shows to the left of the process name.

       a (on multiprocessor machines)
	    Set CPU affinity: mark which CPUs a process is allowed to use.

       u    Show only processes owned by a specified user.

       M    Sort by memory usage (top compatibility key).

       P    Sort by processor usage (top compatibility key).

       T    Sort by time (top compatibility key).

       F    ""Follow"" process: if the sort order causes the currently  selected
	    process  to  move  in  the list, make the selection bar follow it.
	    This is useful for monitoring a process: this way, you can keep  a
	    process  always  visible  on  screen. When a movement key is used,
	    ""follow"" loses effect.

       K    Hide kernel threads: prevent the threads belonging the  kernel  to
	    be displayed in the process list. (This is a toggle key.)

       H    Hide user threads: on systems that represent them differently than
	    ordinary processes (such as recent NPTL-based systems),  this  can
	    hide  threads  from userspace processes in the process list. (This
	    is a toggle key.)

       p    Show full paths to running programs, where applicable. (This is  a
	    toggle key.)

       Ctrl-L
	    Refresh: redraw screen and recalculate values.

       Numbers
	    PID search: type in process ID and the selection highlight will be
	    moved to it.


COLUMNS
       The following columns can display data about each process. A  value  of
       '-' in all the rows indicates that a column is unsupported on your sys-
       tem, or currently unimplemented in htop. The names below are  the  ones
       used  in the ""Available Columns"" section of the setup screen. If a dif-
       ferent name is shown in htop's main screen, it is shown below in paren-
       thesis.


       Command
	    The  full command line of the process (i.e. program name and argu-
	    ments).

       PID  The process ID.

       STATE (S)
	    The state of the process:
	       S for sleeping (idle)
	       R for running
	       D for disk sleep (uninterruptible)
	       Z for zombie (waiting for parent to read its exit status)
	       T for traced or suspended (e.g by SIGTSTP)
	       W for paging

       PPID The parent process ID.

       PGRP The process's group ID.

       SESSION (SID)
	    The process's session ID.

       TTY_NR (TTY)
	    The controlling terminal of the process.

       TPGID
	    The process ID of the foreground process group of the  controlling
	    terminal.

       MINFLT
	    The number of page faults happening in the main memory.

       CMINFLT
	    The  number  of minor faults for the process's waited-for children
	    (see MINFLT above).

       MAJFLT
	    The number of page faults happening out of the main memory.

       CMAJFLT
	    The number of major faults for the process's  waited-for  children
	    (see MAJFLT above).

       UTIME (UTIME+)
	    The  user  CPU  time,  which is the amount of time the process has
	    spent executing on the CPU in user mode (i.e. everything but  sys-
	    tem calls), measured in clock ticks.

       STIME (STIME+)
	    The  system  CPU  time, which is the amount of time the kernel has
	    spent executing system calls on behalf of the process, measured in
	    clock ticks.

       CUTIME (CUTIME+)
	    The  children's  user  CPU	time,  which is the amount of time the
	    process's waited-for children have spent executing	in  user  mode
	    (see UTIME above).

       CSTIME (CSTIME+)
	    The  children's  system  CPU time, which is the amount of time the
	    kernel has spent executing system  calls  on  behalf  of  all  the
	    process's waited-for children (see STIME above).

       PRIORITY (PRI)
	    The  kernel's  internal priority for the process, usually just its
	    nice value plus twenty. Different for real-time processes.

       NICE (NI)
	    The nice value of a process, from 19 (low priority) to  -20  (high
	    priority).	A  high value means the process is being nice, letting
	    others have a higher relative priority. The  usual	OS  permission
	    restrictions for adjusting priority apply.

       STARTTIME (START)
	    The time the process was started.

       PROCESSOR (CPU)
	    The ID of the CPU the process last executed on.

       M_SIZE (VIRT)
	    The size of the virtual memory of the process.

       M_RESIDENT (RES)
	    The  resident  set size (text + data + stack) of the process (i.e.
	    the size of the process's used physical memory).

       M_SHARE (SHR)
	    The size of the process's shared pages.

       M_TRS (CODE)
	    The text resident set size of the process (i.e. the  size  of  the
	    process's executable instructions).

       M_DRS (DATA)
	    The data resident set size (data + stack) of the process (i.e. the
	    size of anything except the process's executable instructions).

       M_LRS (LIB)
	    The library size of the process.

       M_DT (DIRTY)
	    The size of the dirty pages of the process.

       ST_UID (UID)
	    The user ID of the process owner.

       PERCENT_CPU (CPU%)
	    The percentage of the CPU  time  that  the	process  is  currently
	    using.

       PERCENT_MEM (MEM%)
	    The  percentage of memory the process is currently using (based on
	    the process's resident memory size, see M_RESIDENT above).

       USER The username of the process owner, or the  user  ID  if  the  name
	    can't be determined.

       TIME (TIME+)
	    The  time,	measured  in clock ticks that the process has spent in
	    user and system time (see UTIME, STIME above).

       NLWP The number of threads in the process.

       TGID The thread group ID.

       CTID OpenVZ container ID, a.k.a virtual environment ID.

       VPID OpenVZ process ID.

       VXID VServer process ID.

       RCHAR (RD_CHAR)
	    The number of bytes the process has read.

       WCHAR (WR_CHAR)
	    The number of bytes the process has written.

       SYSCR (RD_SYSC)
	    The number of read(2) syscalls for the process.

       SYSCW (WR_SYSC)
	    The number of write(2) syscalls for the process.

       RBYTES (IO_RBYTES)
	    Bytes of read(2) I/O for the process.

       WBYTES (IO_WBYTES)
	    Bytes of write(2) I/O for the process.

       CNCLWB (IO_CANCEL)
	    Bytes of cancelled write(2) I/O.

       IO_READ_RATE (DISK READ)
	    The I/O rate of read(2) in bytes per second, for the process.

       IO_WRITE_RATE (DISK WRITE)
	    The I/O rate of write(2) in bytes per second, for the process.

       IO_RATE (DISK R/W)
	    The I/O rate, IO_READ_RATE + IO_WRITE_RATE (see above).

       CGROUP
	    Which cgroup the process is in.

       OOM  OOM killer score.

       IO_PRIORITY (IO)
	    The I/O scheduling class followed by the  priority	if  the  class
	    supports it:
	       R for Realtime
	       B for Best-effort
	       id for Idle

       PERCENT_CPU_DELAY (CPUD%)
	    The  percentage  of time spent waiting for a CPU (while runnable).
	    Requires CAP_NET_ADMIN.

       PERCENT_IO_DELAY (IOD%)
	    The percentage of time spent waiting for the  completion  of  syn-
	    chronous block I/O. Requires CAP_NET_ADMIN.

       PERCENT_SWAP_DELAY (SWAPD%)
	    The   percentage   of  time  spent	swapping  in  pages.  Requires
	    CAP_NET_ADMIN.

       All other flags
	    Currently unsupported (always displays '-').


CONFIG FILE
       By default htop reads its configuration	from  the  XDG-compliant  path
       ~/.config/htop/htoprc  --  the  configuration  file  is	overwritten by
       htop's in-program Setup configuration, so it should not be hand-edited.
       If no user configuration exists htop tries to read the system-wide con-
       figuration from ${prefix}/etc/htoprc and as a last resort,  falls  back
       to its hard coded defaults.

       You may override the location of the configuration file using the $HTO-
       PRC environment variable (so you can have multiple  configurations  for
       different machines that share the same home directory, for example).


MEMORY SIZES
       Memory  sizes  in  htop are displayed as they are in tools from the GNU
       Coreutils (when ran with the --human-readable option). This means  that
       sizes are printed in powers of 1024. (e.g., 1023M = 1072693248 Bytes)

       The  decision  to  use  this  convention  was made in order to conserve
       screen space and make memory size representations consistent throughout
       htop.


SEE ALSO
       proc(5), top(1), free(1), ps(1), uptime(1), limits.conf(5)


AUTHORS
       htop is developed by Hisham Muhammad <hisham@gobolinux.org>.

       This  man  page	was  written  by  Bartosz Fenski <fenio@o2.pl> for the
       Debian GNU/Linux distribution (but it may be used by  others).  It  was
       updated	by Hisham Muhammad, and later by Vincent Launchbury, who wrote
       the 'Columns' section.



htop 2.2.0			     2015			       HTOP(1)
","# htop

> Display dynamic real-time information about running processes. An enhanced version of `top`.

- Start htop:

`htop`

- Start htop displaying only processes owned by given user:

`htop -u {{username}}`

- Sort processes by a column (use `--sort-key help` for a column list):

`htop -s {{column_name}}`

- Get help about interactive commands:

`?`
"
apk,,,,"# apk

> Alpine Linux package management tool.

- Update repository indexes from all remote repositories:

`apk update`

- Install a new package:

`apk add {{package}}`

- Remove a package:

`apk del {{package}}`

- Repair package or upgrade it without modifying main dependencies:

`apk fix {{package}}`

- Search package via keyword:

`apk search {{keyword}}`

- Get info about a specific package:

`apk info {{package}}`
"
snap,,,,"# snap

> Tool for managing the ""snap"" self-contained software packages.
> Similar to what `apt` is for "".deb"".

- Search for a package:

`snap find {{package_name}}`

- Install a package:

`snap install {{package_name}}`

- Update a package:

`snap refresh {{package_name}}`

- Update all packages:

`snap refresh`

- Display basic information about installed snap software:

`snap list`

- Uninstall a package:

`snap remove {{package_name}}`

- Check for recent snap changes in the system:

`snap changes`
"
xar,,,"XAR(1)				 User Commands				XAR(1)



NAME
       xar - eXtensible ARchiver

SYNOPSIS
       xar -[ctx][v] ...

DESCRIPTION
       The  XAR  project  aims to provide an easily extensible archive format.
       Important design decisions include an easily extensible	XML  table  of
       contents  (TOC) for random access to archived files, storing the TOC at
       the beginning of  the  archive  to  allow  for  efficient  handling  of
       streamed  archives,  the  ability  to handle files of arbitrarily large
       sizes, the ability to choose independent encodings for individual files
       in  the archive, the ability to store checksums for individual files in
       both compressed and uncompressed form, and the ability to query the ta-
       ble of content's rich meta-data.

FUNCTIONS
       One of the following options must be used:

       -c     Creates an archive

       -t     Lists the contents of an archive

       -x     Extracts an archive

       NOTE:  all  of the above require the use of the -f option (filename) as
       this release of xar doesn't correctly handle pipes or sockets.

       -f     The  filename  to use for creation, listing or extraction.  With
	      extraction, this can be a POSIX regular expression.

OPTIONS
       --compression
	      Specifies the compression type  to  use.	 Valid	values:  none,
	      gzip, bzip2, lzma (on some systems).  Default value: gzip

       -C <path>
	      On extract, xar will chdir to the specified path before extract-
	      ing the archive.

       -a     Synonym for --compression=lzma

       -j     Synonym for --compression=bzip2

       -z     Synonym for --compression=gzip

       --compression-args=<arguments>
	      Specifies arguments to the compression engine  selected.	 gzip,
	      bzip2, and lzma all take a single integer argument between 0 and
	      9 specifying the compression level to use.

       --dump-toc=<filename>
	      Has xar dump the xml header into the specified file.  ""-"" can be
	      specified to mean stdout.

       --dump-toc-cksum
	      Dumps the ToC checksum to stdout along with the algorithm of the
	      ToC.

       --dump-header
	      Has xar print out the xar binary header information to stdout.

       --extract-subdoc=<name>
	      Extracts the specified subdocument to a document	in  cwd  named
	      <name>.xml

       --list-subdocs
	      List the subdocuments in the xml header

       --toc-cksum
	      Specifies  the hashing algorithm to use for xml header verifica-
	      tion.  Valid values: md5 (on some systems),  sha1,  sha256,  and
	      sha512.  Default value: sha1

       --file-cksum
	      Specifies  the hashing algorithm to use for file content verifi-
	      cation.  Valid values: md5 (on some systems), sha1, sha256,  and
	      sha512.  Default value: sha1

       -l     On archival, stay on the local device.

       -P     On  extract, set ownership based on uid/gid.  If the uid/gid can
	      be set on the extracted file, setuid/setgid bits	will  also  be
	      preserved.

       -p     On  extract, set ownership based on symbolic names, if possible.
	      If the uid/gid can be set on the extracted  file,  setuid/setgid
	      bits will also be preserved.

       -s <filename>
	      On  extract,  specifies the file to extract subdocuments to.  On
	      archival, specifies an xml file to add as a subdocument.

       -v     Verbose output

       --exclude
	      Specifies a POSIX regular expression of files  to  exclude  from
	      adding  to  the  archive during creation or from being extracted
	      during extraction.  This option can be specified multiple times.

       --rsize
	      Specifies  a size (in bytes) for the internal libxar read buffer
	      while performing I/O.

       --coalesce-heap
	      When multiple files in the archive are identical, only store one
	      copy  of	the  data in the heap.	This creates smaller archives,
	      but the archives created are not streamable.

       --link-same
	      When the data section of multiple files are identical,  hardlink
	      them within the archive.

       --no-compress
	      Specifies  a  POSIX  regular expression of files to archive, but
	      not compress.  The archived files will be copied	raw  into  the
	      archive.	This can be used to exclude already gzipped files from
	      being gzipped during the archival process.

       --prop-include
	      Specifies a file property to be included in the  archive.   When
	      this  option  is	specified,  only the specified options will be
	      included.  Anything not specifically included with  this	option
	      will be omitted.	This option can be used multiple times.

       --prop-exclude
	      Specifies a file property to be excluded from the archive.  When
	      this option is specified, all file properties will  be  included
	      except the specified properties.	This option can be used multi-
	      ple times.

       --distribution
	      Creates an archive to only contain file properties safe for file
	      distribution.   Currently,  only	name, type, mode, and data are
	      preserved with this option.

       --keep-existing
	      Does not overwrite existing files during extraction.  Keeps  any
	      previously existing files while extracting.

       -k     Synonym for --keep-existing.

       --keep-setuid
	      When extracting without -p or -P options, xar will extract files
	      as the uid/gid of the extracting process.   In  this  situation,
	      xar  will  strip setuid/setgid bits from the extracted files for
	      security reasons.  --keep-setuid will preserve the setuid/setgid
	      bits  even  though  the uid/gid of the extracted file is not the
	      same as the archived file.

EXAMPLES
       xar -cf sample.xar /home/uid
	      Create a xar archive of all files in /home/uid

       xar -tf sample.xar
	      List the contents of the xar archive sample.xar

       xar -xf sample.xar
	      Extract the contents of sample.xar to the current working direc-
	      tory

BUGS
       Doesn't	currently  work  with  pipes  or streams.  Might be fixed in a
       future release.

       Probably  one  or  two  more somewhere in there. If you find one please
       report it to http://code.google.com/p/xar/

AUTHORS
       Rob Braun <bbraun AT synack DOT net>
       Landon Fuller <landonf AT bikemonkey DOT org>
       David Leimbach
       Kevin Van Vechten




version 1.8			 June 4, 2015				XAR(1)
","# xar

> Manage .xar archives.

- Create a xar archive of all files in a given directory:

`xar -cf {{archive.xar}} {{path/to/directory}}`

- List the contents of a given xar archive:

`xar -tf {{archive.xar}}`

- Extract the contents of a given xar archive to the current directory:

`xar -xf {{archive.xar}}`
"
xclock,,,,"# xclock

> Display the time in analog or digital form.

- Display an analog clock:

`xclock`

- Display a 24-hour digital clock with the hour and minute fields only:

`xclock -digital -brief`

- Display a digital clock using an strftime format string (see strftime(3)):

`xclock -digital -strftime {{format}}`

- Display a 24-hour digital clock with the hour, minute and second fields that updates every second:

`xclock -digital -strftime '%H:%M:%S' -update 1`

- Display a 12-hour digital clock with the hour and minute fields only:

`xclock -digital -twelve -brief`
"
mkfs,,,,"# mkfs

> Build a Linux filesystem on a hard disk partition.
> This command is deprecated in favor of filesystem specific mkfs.<type> utils.

- Build a Linux ext2 filesystem on a partition:

`mkfs {{path/to/partition}}`

- Build a filesystem of a specified type:

`mkfs -t {{ext4}} {{path/to/partition}}`

- Build a filesystem of a specified type and check for bad blocks:

`mkfs -c -t {{ntfs}} {{path/to/partition}}`
"
mimetype,,,,"# mimetype

> Automatically determine the MIME type of a file.

- Print the MIME type of a given file:

`mimetype {{path/to/file}}`

- Display only the MIME type, and not the filename:

`mimetype --brief {{path/to/file}}`

- Display a description of the MIME type:

`mimetype --describe {{path/to/file}}`

- Determine the MIME type of stdin (does not check a filename):

`{{some_command}} | mimetype --stdin`

- Display debug information about how the MIME type was determined:

`mimetype --debug {{path/to/file}}`

- Display all the possible MIME types of a given file in confidence order:

`mimetype --all {{path/to/file}}`

- Explicitly specify the 2-letter language code of the output:

`mimetype --language {{path/to/file}}`
"
iw,,,,"# iw

> Show and manipulate wireless devices.

- Scan for available wireless networks:

`iw dev {{wlp}} scan`

- Join an open wireless network:

`iw dev {{wlp}} connect {{SSID}}`

- Close the current connection:

`iw dev {{wlp}} disconnect`

- Show information about the current connection:

`iw dev {{wlp}} link`
"
halt,,,"
REBOOT(8)		  BSD System Manager's Manual		     REBOOT(8)

NAME
     halt, reboot -- stopping and restarting the system

SYNOPSIS
     halt [-lnqu]
     reboot [-lnq]

DESCRIPTION
     The halt and reboot utilities flush the file system cache to disk, send
     all running processes a SIGTERM (and subsequently a SIGKILL) and, respec-
     tively, halt or restart the system.  The action is logged, including
     entering a shutdown record into the wtmp(5) file.

     When the system is halted with the halt command, the system is powered
     off.

     The options are as follows:

     -l      The halt or reboot is not recorded in the system log.  This
	     option is intended for applications such as shutdown(8), that
	     call reboot or halt and log this themselves.

     -n      The file system cache is not flushed.  This option should proba-
	     bly not be used.

     -q      The system is halted or restarted quickly and ungracefully, and
	     only the flushing of the file system cache is performed (if the
	     -n option is not specified).  This option should probably not be
	     used.

     -u      The system is halted up until the point of removing system power,
	     but waits before removing power for 5 minutes so that an external
	     UPS (uninterruptible power supply) can forcibly remove power.
	     This simulates a dirty shutdown to permit a later automatic power
	     on. OS X uses this mode automatically with supported UPSs in
	     emergency shutdowns.

     Normally, the shutdown(8) utility is used when the system needs to be
     halted or restarted, giving users advance warning of their impending doom
     and cleanly terminating specific programs.

SIGTERM TO SIGKILL INTERVAL
     The SIGKILL will follow the SIGTERM by an intentionally indeterminate
     period of time.  Programs are expected to take only enough time to flush
     all dirty data and exit.  Developers are encouraged to file a bug with
     the OS vendor, should they encounter an issue with this functionality.

SEE ALSO
     wtmp(5), shutdown(8), sync(8)

HISTORY
     A reboot utility appeared in Version 6 AT&T UNIX.

BSD				 June 9, 1993				   BSD
","# halt

> Power off or reboot the machine.

- Power the machine off:

`halt`

- Reboot the machine:

`halt --reboot`
"
chattr,,,,"# chattr

> Change attributes of files or directories.

- Make a file or directory immutable to changes and deletion, even by superuser:

`chattr +i {{path/to/file_or_directory}}`

- Make a file or directory mutable:

`chattr -i {{path/to/file_or_directory}}`

- Recursively make an entire directory and contents immutable:

`chattr -R +i {{path/to/directory}}`
"
a2disconf,https://manpages.debian.org/buster/apache2/a2disconf.8.en.html,"



a2disconf(8) — apache2 — Debian buster — Debian Manpages













MANPAGES












Skip Quicknav

Index
About Manpages
FAQ
Service Information


 
     
     / buster
     
     
     
     / apache2
     
     
     
     / a2disconf(8)
     
     





links




language-indep link


package tracker


raw man page







table of contents




NAME


SYNOPSIS


DESCRIPTION


OPTIONS


EXIT STATUS


EXAMPLES


FILES


SEE ALSO


AUTHOR







other versions




buster 2.4.38-3+deb10u3


buster-backports 2.4.43-1~bpo10+1


testing 2.4.43-1


unstable 2.4.43-1






Scroll to navigation



A2ENCONF(8)
System Manager's Manual
A2ENCONF(8)




NAME¶
a2enconf, a2disconf - enable or disable an apache2 configuration file


SYNOPSIS¶
a2enconf [ [-q|--quiet] configuration]
a2disconf [ [-q|--quiet] configuration]


DESCRIPTION¶
This manual page documents briefly the a2enconf and a2disconf
  commands.
a2enconf is a script that enables the specified
    configuration file within the apache2 configuration. It does this by
    creating symlinks within /etc/apache2/conf-enabled. Likewise,
    a2disconf disables a specific configuration part by removing those
    symlinks. It is not an error to enable a configuration which is already
    enabled, or to disable one which is already disabled.
Note that many configuration file may have a dependency to
    specific modules. Unlike module dependencies, these are not resolved
    automatically. Configuration fragments stored in the conf-available
    directory are considered non-essential or being installed and manged by
    reverse dependencies (e.g. web scripts).


OPTIONS¶

-q, --quiet
Don't show informative messages.
-m, --maintmode
Enables the maintainer mode, that is the program invocation is effectuated
      automatically by a maintainer script. This switch should not be used by
      end users.
-p, --purge
When disabling a module, purge all traces of the module in the internal
      state data base.



EXIT STATUS¶
a2enconf and a2disconf exit with status 0 if all
  configurations are processed successfully, 1 if errors occur, 2 if an
  invalid option was used.


EXAMPLES¶
a2enconf security

a2disconf charset
Enables Apache security directives stored in the security
    configuration files, and disables the charset configuration.


FILES¶

/etc/apache2/conf-available
Directory with files giving information on available configuration
    files.
/etc/apache2/conf-enabled
Directory with links to the files in conf-available for enabled
      configuration files.



SEE ALSO¶
apache2ctl(8), a2enmod(8), a2dismod(8).


AUTHOR¶
This manual page was written by Arno Toell <debian@toell.net> for the
  Debian GNU/Linux distribution, as it is a Debian-specific script with the
  package.




14 February 2012










Source file:


a2disconf.8.en.gz (from apache2 2.4.38-3+deb10u3)




Source last updated:


2019-04-07T18:15:40Z




Converted to HTML:


2020-08-08T10:05:54Z





debiman 503568d, see github.com/Debian/debiman.
Found a problem? See the FAQ.




",,"# a2disconf

> Disable an Apache configuration file on Debian-based OSes.
> More information: <https://manpages.debian.org/buster/apache2/a2disconf.8.en.html>.

- Disable a configuration file:

`sudo a2disconf {{configuration_file}}`

- Don't show informative messages:

`sudo a2disconf --quiet {{configuration_file}}`
"
locate,,,"
LOCATE(1)		  BSD General Commands Manual		     LOCATE(1)

NAME
     locate -- find filenames quickly

SYNOPSIS
     locate [-0Scims] [-l limit] [-d database] pattern ...

DESCRIPTION
     The locate program searches a database for all pathnames which match the
     specified pattern.  The database is recomputed periodically (usually
     weekly or daily), and contains the pathnames of all files which are pub-
     licly accessible.

     Shell globbing and quoting characters (``*'', ``?'', ``\'', ``['' and
     ``]'') may be used in pattern, although they will have to be escaped from
     the shell.  Preceding any character with a backslash (``\'') eliminates
     any special meaning which it may have.  The matching differs in that no
     characters must be matched explicitly, including slashes (``/'').

     As a special case, a pattern containing no globbing characters (``foo'')
     is matched as though it were ``*foo*''.

     Historically, locate only stored characters between 32 and 127.  The cur-
     rent implementation store any character except newline (`\n') and NUL
     (`\0').  The 8-bit character support does not waste extra space for plain
     ASCII file names.	Characters less than 32 or greater than 127 are stored
     in 2 bytes.

     The following options are available:

     -0 	 Print pathnames separated by an ASCII NUL character (charac-
		 ter code 0) instead of default NL (newline, character code
		 10).

     -S 	 Print some statistics about the database and exit.

     -c 	 Suppress normal output; instead print a count of matching
		 file names.

     -d database
		 Search in database instead of the default file name database.
		 Multiple -d options are allowed.  Each additional -d option
		 adds the specified database to the list of databases to be
		 searched.

		 The option database may be a colon-separated list of data-
		 bases.  A single colon is a reference to the default data-
		 base.

		 $ locate -d $HOME/lib/mydb: foo

		 will first search string ``foo'' in $HOME/lib/mydb and then
		 in /var/db/locate.database.

		 $ locate -d $HOME/lib/mydb::/cdrom/locate.database foo

		 will first search string ``foo'' in $HOME/lib/mydb and then
		 in /var/db/locate.database and then in
		 /cdrom/locate.database.

		       $ locate -d db1 -d db2 -d db3 pattern

		 is the same as

		       $ locate -d db1:db2:db3 pattern

		 or

		       $ locate -d db1:db2 -d db3 pattern

		 If - is given as the database name, standard input will be
		 read instead.	For example, you can compress your database
		 and use:

		 $ zcat database.gz | locate -d - pattern

		 This might be useful on machines with a fast CPU and little
		 RAM and slow I/O.  Note: you can only use one pattern for
		 stdin.

     -i 	 Ignore case distinctions in both the pattern and the data-
		 base.

     -l number	 Limit output to number of file names and exit.

     -m 	 Use mmap(2) instead of the stdio(3) library.  This is the
		 default behavior and is faster in most cases.

     -s 	 Use the stdio(3) library instead of mmap(2).

ENVIRONMENT
     LOCATE_PATH  path to the locate database if set and not empty, ignored if
		  the -d option was specified.

FILES
     /var/db/locate.database				   locate database
     /usr/libexec/locate.updatedb			   Script to update
							   the locate database
     /System/Library/LaunchDaemons/com.apple.locate.plist  Job that starts the
							   database rebuild

SEE ALSO
     find(1), whereis(1), which(1), fnmatch(3), locate.updatedb(8)

     Woods, James A., ""Finding Files Fast"", ;login, 8:1, pp. 8-10, 1983.

HISTORY
     The locate command first appeared in 4.4BSD.  Many new features were
     added in FreeBSD 2.2.

BUGS
     The locate program may fail to list some files that are present, or may
     list files that have been removed from the system.  This is because
     locate only reports files that are present in the database, which is typ-
     ically only regenerated once a week by the
     /System/Library/LaunchDaemons/com.apple.locate.plist job.	Use find(1) to
     locate files that are of a more transitory nature.

     The locate database is typically built by user ``nobody'' and the
     locate.updatedb(8) utility skips directories which are not readable for
     user ``nobody'', group ``nobody'', or world.  For example, if your HOME
     directory is not world-readable, none of your files are in the database.

     The locate database is not byte order independent.  It is not possible to
     share the databases between machines with different byte order.  The cur-
     rent locate implementation understands databases in host byte order or
     network byte order if both architectures use the same integer size.  So
     on a FreeBSD/i386 machine (little endian), you can read a locate database
     which was built on SunOS/sparc machine (big endian, net).

     The locate utility does not recognize multibyte characters.

BSD				August 17, 2006 			   BSD
","# locate

> Find filenames quickly.

- Look for pattern in the database. Note: the database is recomputed periodically (usually weekly or daily):

`locate {{pattern}}`

- Look for a file by its exact filename (a pattern containing no globbing characters is interpreted as `*pattern*`):

`locate */{{filename}}`

- Recompute the database. You need to do it if you want to find recently added files:

`sudo updatedb`
"
vboxmanage,https://www.virtualbox.org/manual/ch08.html#vboxmanage-intro,"Chapter 8. VBoxManageChapter 8. VBoxManageTable of Contents8.1. Introduction8.2. Commands Overview8.3. General Options8.4. VBoxManage list8.5. VBoxManage showvminfo8.6. VBoxManage registervm/unregistervm8.7. VBoxManage createvm8.8. VBoxManage modifyvm8.8.1. General Settings8.8.2. Networking Settings8.8.3. Miscellaneous Settings8.8.4. Recording Settings8.8.5. Remote Machine Settings8.8.6. Teleporting Settings8.8.7. Debugging Settings8.8.8. USB Card Reader Settings8.8.9. Autostarting VMs During Host System Boot8.9. VBoxManage movevm8.10. VBoxManage import8.10.1. Import from OVF8.10.2. Import from Oracle Cloud Infrastructure8.11. VBoxManage export8.11.1. Export to OVF8.11.2. Export to Oracle Cloud Infrastructure8.12. VBoxManage startvm8.13. VBoxManage controlvm8.14. VBoxManage discardstate8.15. VBoxManage adoptstate8.16. VBoxManage closemedium8.17. VBoxManage storageattach8.18. VBoxManage storagectl8.19. VBoxManage bandwidthctl8.20. VBoxManage showmediuminfo8.21. VBoxManage createmedium8.22. VBoxManage modifymedium8.23. VBoxManage clonemedium8.24. VBoxManage mediumproperty8.25. VBoxManage encryptmedium8.26. VBoxManage checkmediumpwd8.27. VBoxManage convertfromraw8.28. VBoxManage getextradata/setextradata8.29. VBoxManage setproperty8.30. VBoxManage usbfilter add/modify/remove8.31. VBoxManage guestproperty8.32. VBoxManage guestcontrol8.33. VBoxManage metrics8.34. VBoxManage natnetwork8.35. VBoxManage hostonlyif8.36. VBoxManage usbdevsource8.37. VBoxManage unattended8.38. VBoxManage snapshot8.39. VBoxManage clonevm8.40. VBoxManage sharedfolder8.41. VBoxManage extpack8.42. VBoxManage dhcpserver8.43. VBoxManage debugvm8.44. VBoxManage cloudprofile8.45. VBoxManage cloud8.46. vboximg-mount8.1. Introduction
      As briefly mentioned in Section 1.16, “Alternative Front-Ends”,
      VBoxManage is the command-line interface to
      Oracle VM VirtualBox. With it, you can completely control Oracle VM VirtualBox
      from the command line of your host operating system.
      VBoxManage supports all the features that the
      graphical user interface gives you access to, but it supports a
      lot more than that. It exposes all the features of the
      virtualization engine, even those that cannot be accessed from the
      GUI.
    
      You will need to use the command line if you want to do the
      following:
    
          Use a different user interface than the main GUI such as the
          VBoxHeadless server.
        
          Control some of the more advanced and experimental
          configuration settings for a VM.
        
      There are two main things to keep in mind when using
      VBoxManage. First,
      VBoxManage must always be used with a specific
      subcommand, such as list or
      createvm or startvm. All the
      subcommands that VBoxManage supports are
      described in detail in Chapter 8, VBoxManage.
    
      Second, most of these subcommands require that you specify a
      particular virtual machine after the subcommand. There are two
      ways you can do this:
    
          You can specify the VM name, as it is shown in the
          Oracle VM VirtualBox GUI. Note that if that name contains spaces,
          then you must enclose the entire name in double quotes. This
          is always required with command line arguments that contain
          spaces. For example:
        VBoxManage startvm ""Windows XP""
          You can specify the UUID, which is the internal unique
          identifier that Oracle VM VirtualBox uses to refer to the virtual
          machine. Assuming that the VM called ""Windows XP"" has the UUID
          shown below, the following command has the same effect as the
          previous example:
        VBoxManage startvm 670e746d-abea-4ba6-ad02-2a3b043810a5
      You can enter VBoxManage list vms to have all
      currently registered VMs listed with all their settings, including
      their respective names and UUIDs.
    
      Some typical examples of how to control Oracle VM VirtualBox from the
      command line are listed below:
    
          To create a new virtual machine from the command line and
          immediately register it with Oracle VM VirtualBox, use
          VBoxManage createvm with the
          --register option, as follows:
        $ VBoxManage createvm --name ""SUSE 10.2"" --register
VirtualBox Command Line Management Interface Version version-number
(C) 2005-2018 Oracle Corporation
All rights reserved.

Virtual machine 'SUSE 10.2' is created.
UUID: c89fc351-8ec6-4f02-a048-57f4d25288e5
Settings file: '/home/username/.config/VirtualBox/Machines/SUSE 10.2/SUSE 10.2.xml'
          As can be seen from the above output, a new virtual machine
          has been created with a new UUID and a new XML settings file.
        
          For more details, see
          Section 8.7, “VBoxManage createvm”.
        
          To show the configuration of a particular VM, use
          VBoxManage showvminfo. See
          Section 8.5, “VBoxManage showvminfo” for details
          and an example.
        
          To change settings while a VM is powered off, use
          VBoxManage modifyvm. For example:
        VBoxManage modifyvm ""Windows XP"" --memory 512
          See also Section 8.8, “VBoxManage modifyvm”.
        
          To change the storage configuration, such as to add a storage
          controller and then a virtual disk, use VBoxManage
          storagectl and VBoxManage
          storageattach. See
          Section 8.18, “VBoxManage storagectl” and
          Section 8.17, “VBoxManage storageattach”.
        
          To control VM operation, use one of the following:
        
              To start a VM that is currently powered off, use
              VBoxManage startvm. See
              Section 8.12, “VBoxManage startvm”.
            
              To pause or save a VM that is currently running or change
              some of its settings, use VBoxManage
              controlvm. See
              Section 8.13, “VBoxManage controlvm”.
            8.2. Commands Overview
      When running VBoxManage without parameters or
      when supplying an invalid command line, the following command
      syntax list is shown. Note that the output will be slightly
      different depending on the host platform. If in doubt, check the
      output of VBoxManage for the commands available
      on your particular host.
    Usage:

  VBoxManage [<general option>] <command>
 
 
General Options:
 
  [-v|--version]            print version number and exit
  [-q|--nologo]             suppress the logo
  [--settingspw <pw>]       provide the settings password
  [--settingspwfile <file>] provide a file containing the settings password
  [@<response-file>]        load arguments from the given response file (bourne style)
 
 
Commands:
 
  list [--long|-l] [--sorted|-s]          vms|runningvms|ostypes|hostdvds|hostfloppies|
                            intnets|bridgedifs|hostonlyifs|natnets|dhcpservers|
                            hostinfo|hostcpuids|hddbackends|hdds|dvds|floppies|
                            usbhost|usbfilters|systemproperties|extpacks|
                            groups|webcams|screenshotformats|cloudproviders|
                            cloudprofiles|cloudnets

  showvminfo                <uuid|vmname> [--details]
                            [--machinereadable]
  showvminfo                <uuid|vmname> --log <idx>

  registervm                <filename>

  unregistervm              <uuid|vmname> [--delete]

  createvm                  --name <name>
                            [--groups <group>, ...]
                            [--ostype <ostype>]
                            [--register]
                            [--basefolder <path>]
                            [--uuid <uuid>]
                            [--default]

  modifyvm                  <uuid|vmname>
                            [--name <name>]
                            [--groups <group>, ...]
                            [--description <desc>]
                            [--ostype <ostype>]
                            [--iconfile <filename>]
                            [--memory <memorysize in MB>]
                            [--pagefusion on|off]
                            [--vram <vramsize in MB>]
                            [--acpi on|off]
                            [--ioapic on|off]
                            [--hpet on|off]
                            [--triplefaultreset on|off]
                            [--apic on|off]
                            [--x2apic on|off]
                            [--paravirtprovider none|default|legacy|minimal|
                                                hyperv|kvm]
                            [--paravirtdebug <key=value> [,<key=value> ...]]
                            [--hwvirtex on|off]
                            [--nestedpaging on|off]
                            [--largepages on|off]
                            [--vtxvpid on|off]
                            [--vtxux on|off]
                            [--pae on|off]
                            [--longmode on|off]
                            [--ibpb-on-vm-exit on|off]
                            [--ibpb-on-vm-entry on|off]
                            [--spec-ctrl on|off]
                            [--l1d-flush-on-sched on|off]
                            [--l1d-flush-on-vm-entry on|off]
                            [--mds-clear-on-sched on|off]
                            [--mds-clear-on-vm-entry on|off]
                            [--nested-hw-virt on|off]
                            [--cpu-profile ""host|Intel 80[86|286|386]""]
                            [--cpuid-portability-level <0..3>]
                            [--cpuid-set <leaf[:subleaf]> <eax> <ebx> <ecx> <edx>]
                            [--cpuid-remove <leaf[:subleaf]>]
                            [--cpuidremoveall]
                            [--hardwareuuid <uuid>]
                            [--cpus <number>]
                            [--cpuhotplug on|off]
                            [--plugcpu <id>]
                            [--unplugcpu <id>]
                            [--cpuexecutioncap <1-100>]
                            [--rtcuseutc on|off]
                            [--graphicscontroller none|vboxvga|vmsvga|vboxsvga]
                            [--monitorcount <number>]
                            [--accelerate3d on|off]
                            [--accelerate2dvideo on|off]
                            [--firmware bios|efi|efi32|efi64]
                            [--chipset ich9|piix3]
                            [--bioslogofadein on|off]
                            [--bioslogofadeout on|off]
                            [--bioslogodisplaytime <msec>]
                            [--bioslogoimagepath <imagepath>]
                            [--biosbootmenu disabled|menuonly|messageandmenu]
                            [--biosapic disabled|apic|x2apic]
                            [--biossystemtimeoffset <msec>]
                            [--biospxedebug on|off]
                            [--system-uuid-le on|off]
                            [--boot<1-4> none|floppy|dvd|disk|net>]
                            [--nic<1-N> none|null|nat|bridged|intnet|hostonly|
                                        generic|natnetwork]
                            [--nictype<1-N> Am79C970A|Am79C973|Am79C960|
                                            82540EM|82543GC|82545EM|
                                            virtio]
                            [--cableconnected<1-N> on|off]
                            [--nictrace<1-N> on|off]
                            [--nictracefile<1-N> <filename>]
                            [--nicproperty<1-N> name=[value]]
                            [--nicspeed<1-N> <kbps>]
                            [--nicbootprio<1-N> <priority>]
                            [--nicpromisc<1-N> deny|allow-vms|allow-all]
                            [--nicbandwidthgroup<1-N> none|<name>]
                            [--bridgeadapter<1-N> none|<devicename>]
                            [--hostonlyadapter<1-N> none|<devicename>]
                            [--intnet<1-N> <network name>]
                            [--nat-network<1-N> <network name>]
                            [--nicgenericdrv<1-N> <driver>]
                            [--natnet<1-N> <network>|default]
                            [--natsettings<1-N> [<mtu>],[<socksnd>],
                                                [<sockrcv>],[<tcpsnd>],
                                                [<tcprcv>]]
                            [--natpf<1-N> [<rulename>],tcp|udp,[<hostip>],
                                          <hostport>,[<guestip>],<guestport>]
                            [--natpf<1-N> delete <rulename>]
                            [--nattftpprefix<1-N> <prefix>]
                            [--nattftpfile<1-N> <file>]
                            [--nattftpserver<1-N> <ip>]
                            [--natbindip<1-N> <ip>]
                            [--natdnspassdomain<1-N> on|off]
                            [--natdnsproxy<1-N> on|off]
                            [--natdnshostresolver<1-N> on|off]
                            [--nataliasmode<1-N> default|[log],[proxyonly],
                                                         [sameports]]
                            [--macaddress<1-N> auto|<mac>]
                            [--mouse ps2|usb|usbtablet|usbmultitouch]
                            [--keyboard ps2|usb]
                            [--uart<1-N> off|<I/O base> <IRQ>]
                            [--uartmode<1-N> disconnected|
                                             server <pipe>|
                                             client <pipe>|
                                             tcpserver <port>|
                                             tcpclient <hostname:port>|
                                             file <file>|
                                             <devicename>]
                            [--uarttype<1-N> 16450|16550A|16750]
                            [--lpt<1-N> off|<I/O base> <IRQ>]
                            [--lptmode<1-N> <devicename>]
                            [--guestmemoryballoon <balloonsize in MB>]
                            [--vm-process-priority default|flat|low|normal|high]
                            [--audio none|null|dsound|oss|alsa|pulse|
                                     oss|pulse|coreaudio]
                            [--audioin on|off]
                            [--audioout on|off]
                            [--audiocontroller ac97|hda|sb16]
                            [--audiocodec stac9700|ad1980|stac9221|sb16]
                            [--clipboard-mode disabled|hosttoguest|guesttohost|
                                              bidirectional]
                            [--draganddrop disabled|hosttoguest|guesttohost|
                                           bidirectional]
                            [--vrde on|off]
                            [--vrdeextpack default|<name>]
                            [--vrdeproperty <name=[value]>]
                            [--vrdeport <hostport>]
                            [--vrdeaddress <hostip>]
                            [--vrdeauthtype null|external|guest]
                            [--vrdeauthlibrary default|<name>]
                            [--vrdemulticon on|off]
                            [--vrdereusecon on|off]
                            [--vrdevideochannel on|off]
                            [--vrdevideochannelquality <percent>]
                            [--usbohci on|off]
                            [--usbehci on|off]
                            [--usbxhci on|off]
                            [--usbrename <oldname> <newname>]
                            [--snapshotfolder default|<path>]
                            [--teleporter on|off]
                            [--teleporterport <port>]
                            [--teleporteraddress <address|empty>]
                            [--teleporterpassword <password>]
                            [--teleporterpasswordfile <file>|stdin]
                            [--tracing-enabled on|off]
                            [--tracing-config <config-string>]
                            [--tracing-allow-vm-access on|off]
                            [--usbcardreader on|off]
                            [--autostart-enabled on|off]
                            [--autostart-delay <seconds>]
                            [--recording on|off]
                            [--recordingscreens all|<screen ID> [<screen ID> ...]]
                            [--recordingfile <filename>]
                            [--recordingvideores <width> <height>]
                            [--recordingvideorate <rate>]
                            [--recordingvideofps <fps>]
                            [--recordingmaxtime <s>]
                            [--recordingmaxsize <MB>]
                            [--recordingopts <key=value> [,<key=value> ...]]
                            [--defaultfrontend default|<name>]

  movevm                    <uuid|vmname>
                            --type basic
                            [--folder <path>]

  import                    <ovfname/ovaname>
                            [--dry-run|-n]
                            [--options keepallmacs|keepnatmacs|importtovdi]
                            [--vmname <name>]
                            [--cloud]
                            [--cloudprofile <cloud profile name>]
                            [--cloudinstanceid <instance id>]
                            [--cloudbucket <bucket name>]
                            [more options]
                            (run with -n to have options displayed
                             for a particular OVF. It doesn't work for the Cloud import.)

  export                    <machines> --output|-o <name>.<ovf/ova/tar.gz>
                            [--legacy09|--ovf09|--ovf10|--ovf20|--opc10]
                            [--manifest]
                            [--iso]
                            [--options manifest|iso|nomacs|nomacsbutnat]
                            [--vsys <number of virtual system>]
                                    [--vmname <name>]
                                    [--product <product name>]
                                    [--producturl <product url>]
                                    [--vendor <vendor name>]
                                    [--vendorurl <vendor url>]
                                    [--version <version info>]
                                    [--description <description info>]
                                    [--eula <license text>]
                                    [--eulafile <filename>]
                            [--cloud <number of virtual system>]
                                    [--vmname <name>]
                                    [--cloudprofile <cloud profile name>]
                                    [--cloudbucket <bucket name>]
                                    [--cloudkeepobject <true/false>]
                                    [--cloudlaunchmode EMULATED|PARAVIRTUALIZED]
                                    [--cloudlaunchinstance <true/false>]
                                    [--clouddomain <domain>]
                                    [--cloudshape <shape>]
                                    [--clouddisksize <disk size in GB>]
                                    [--cloudocivcn <OCI vcn id>]
                                    [--cloudocisubnet <OCI subnet id>]
                                    [--cloudpublicip <true/false>]
                                    [--cloudprivateip <ip>]

  startvm                   <uuid|vmname>...
                            [--type gui|sdl|headless|separate]
                            [-E|--putenv <NAME>[=<VALUE>]]

  controlvm                 <uuid|vmname>
                            pause|resume|reset|poweroff|savestate|
                            acpipowerbutton|acpisleepbutton|
                            keyboardputscancode <hex> [<hex> ...]|
                            keyboardputstring <string1> [<string2> ...]|
                            keyboardputfile <filename>|
                            setlinkstate<1-N> on|off |
                            nic<1-N> null|nat|bridged|intnet|hostonly|generic|
                                     natnetwork [<devicename>] |
                            nictrace<1-N> on|off |
                            nictracefile<1-N> <filename> |
                            nicproperty<1-N> name=[value] |
                            nicpromisc<1-N> deny|allow-vms|allow-all |
                            natpf<1-N> [<rulename>],tcp|udp,[<hostip>],
                                        <hostport>,[<guestip>],<guestport> |
                            natpf<1-N> delete <rulename> |
                            guestmemoryballoon <balloonsize in MB> |
                            usbattach <uuid>|<address>
                                      [--capturefile <filename>] |
                            usbdetach <uuid>|<address> |
                            audioin on|off |
                            audioout on|off |
                            clipboard mode disabled|hosttoguest|guesttohost|
                                           bidirectional |
                            draganddrop disabled|hosttoguest|guesttohost|
                                        bidirectional |
                            vrde on|off |
                            vrdeport <port> |
                            vrdeproperty <name=[value]> |
                            vrdevideochannelquality <percent> |
                            setvideomodehint <xres> <yres> <bpp>
                                            [[<display>] [<enabled:yes|no> |
                                              [<xorigin> <yorigin>]]] |
                            setscreenlayout <display> on|primary <xorigin> <yorigin> <xres> <yres> <bpp> | off
                            screenshotpng <file> [display] |
                            recording on|off |
                            recording screens all|none|<screen>,[<screen>...] |
                            recording filename <file> |
                            recording videores <width>x<height> |
                            recording videorate <rate> |
                            recording videofps <fps> |
                            recording maxtime <s> |
                            recording maxfilesize <MB> |
                            setcredentials <username>
                                           --passwordfile <file> | <password>
                                           <domain>
                                           [--allowlocallogon <yes|no>] |
                            teleport --host <name> --port <port>
                                     [--maxdowntime <msec>]
                                     [--passwordfile <file> |
                                      --password <password>] |
                            plugcpu <id> |
                            unplugcpu <id> |
                            cpuexecutioncap <1-100>
                            webcam <attach [path [settings]]> | <detach [path]> | <list>
                            addencpassword <id>
                                           <password file>|-
                                           [--removeonsuspend <yes|no>]
                            removeencpassword <id>
                            removeallencpasswords
                            changeuartmode<1-N> disconnected|
                                                server <pipe>|
                                                client <pipe>|
                                                tcpserver <port>|
                                                tcpclient <hostname:port>|
                                                file <file>|
                                                <devicename>
                            vm-process-priority default|flat|low|normal|high

  discardstate              <uuid|vmname>

  adoptstate                <uuid|vmname> <state_file>

  closemedium               [disk|dvd|floppy] <uuid|filename>
                            [--delete]

  storageattach             <uuid|vmname>
                            --storagectl <name>
                            [--port <number>]
                            [--device <number>]
                            [--type dvddrive|hdd|fdd]
                            [--medium none|emptydrive|additions|
                                      <uuid|filename>|host:<drive>|iscsi]
                            [--mtype normal|writethrough|immutable|shareable|
                                     readonly|multiattach]
                            [--comment <text>]
                            [--setuuid <uuid>]
                            [--setparentuuid <uuid>]
                            [--passthrough on|off]
                            [--tempeject on|off]
                            [--nonrotational on|off]
                            [--discard on|off]
                            [--hotpluggable on|off]
                            [--bandwidthgroup <name>]
                            [--forceunmount]
                            [--server <name>|<ip>]
                            [--target <target>]
                            [--tport <port>]
                            [--lun <lun>]
                            [--encodedlun <lun>]
                            [--username <username>]
                            [--password <password>]
                            [--passwordfile <file>]
                            [--initiator <initiator>]
                            [--intnet]

  storagectl                <uuid|vmname>
                            --name <name>
                            [--add ide|sata|scsi|floppy|sas|usb|pcie|virtio]
                            [--controller LSILogic|LSILogicSAS|BusLogic|
                                          IntelAHCI|PIIX3|PIIX4|ICH6|I82078|
                            [             USB|NVMe|VirtIO]
                            [--portcount <1-n>]
                            [--hostiocache on|off]
                            [--bootable on|off]
                            [--rename <name>]
                            [--remove]

  bandwidthctl              <uuid|vmname>
                            add <name> --type disk|network
                                --limit <megabytes per second>[k|m|g|K|M|G] |
                            set <name>
                                --limit <megabytes per second>[k|m|g|K|M|G] |
                            remove <name> |
                            list [--machinereadable]
                            (limit units: k=kilobit, m=megabit, g=gigabit,
                                          K=kilobyte, M=megabyte, G=gigabyte)

  showmediuminfo            [disk|dvd|floppy] <uuid|filename>

  createmedium              [disk|dvd|floppy] --filename <filename>
                            [--size <megabytes>|--sizebyte <bytes>]
                            [--diffparent <uuid>|<filename>]
                            [--format VDI|VMDK|VHD] (default: VDI)]
                            [--variant Standard,Fixed,Split2G,Stream,ESX,
                                       Formatted]
                            [[--property <name>=<value>] --property <name>=<value]...

  modifymedium              [disk|dvd|floppy] <uuid|filename>
                            [--type normal|writethrough|immutable|shareable|
                                    readonly|multiattach]
                            [--autoreset on|off]
                            [--property <name=[value]>]
                            [--compact]
                            [--resize <megabytes>|--resizebyte <bytes>]
                            [--move <path>]
                            [--setlocation <path>]
                            [--description <description string>]
  clonemedium               [disk|dvd|floppy] <uuid|inputfile> <uuid|outputfile>
                            [--format VDI|VMDK|VHD|RAW|<other>]
                            [--variant Standard,Fixed,Split2G,Stream,ESX]
                            [--existing]

  mediumproperty            [disk|dvd|floppy] set <uuid|filename>
                            <property> <value>

                            [disk|dvd|floppy] get <uuid|filename>
                            <property>

                            [disk|dvd|floppy] delete <uuid|filename>
                            <property>

  encryptmedium             <uuid|filename>
                            [--newpassword <file>|-]
                            [--oldpassword <file>|-]
                            [--cipher <cipher identifier>]
                            [--newpasswordid <password identifier>]

  checkmediumpwd            <uuid|filename>
                            <pwd file>|-

  convertfromraw            <filename> <outputfile>
                            [--format VDI|VMDK|VHD]
                            [--variant Standard,Fixed,Split2G,Stream,ESX]
                            [--uuid <uuid>]
  convertfromraw            stdin <outputfile> <bytes>
                            [--format VDI|VMDK|VHD]
                            [--variant Standard,Fixed,Split2G,Stream,ESX]
                            [--uuid <uuid>]

  getextradata              global|<uuid|vmname>
                            <key>|[enumerate]

  setextradata              global|<uuid|vmname>
                            <key>
                            [<value>] (no value deletes key)

  setproperty               machinefolder default|<folder> |
                            hwvirtexclusive on|off |
                            vrdeauthlibrary default|<library> |
                            websrvauthlibrary default|null|<library> |
                            vrdeextpack null|<library> |
                            autostartdbpath null|<folder> |
                            loghistorycount <value>
                            defaultfrontend default|<name>
                            logginglevel <log setting>
                            proxymode system|noproxy|manual
                            proxyurl <url>

  usbfilter                 add <index,0-N>
                            --target <uuid|vmname>|global
                            --name <string>
                            --action ignore|hold (global filters only)
                            [--active yes|no] (yes)
                            [--vendorid <XXXX>] (null)
                            [--productid <XXXX>] (null)
                            [--revision <IIFF>] (null)
                            [--manufacturer <string>] (null)
                            [--product <string>] (null)
                            [--remote yes|no] (null, VM filters only)
                            [--serialnumber <string>] (null)
                            [--maskedinterfaces <XXXXXXXX>]

  usbfilter                 modify <index,0-N>
                            --target <uuid|vmname>|global
                            [--name <string>]
                            [--action ignore|hold] (global filters only)
                            [--active yes|no]
                            [--vendorid <XXXX>|""""]
                            [--productid <XXXX>|""""]
                            [--revision <IIFF>|""""]
                            [--manufacturer <string>|""""]
                            [--product <string>|""""]
                            [--remote yes|no] (null, VM filters only)
                            [--serialnumber <string>|""""]
                            [--maskedinterfaces <XXXXXXXX>]

  usbfilter                 remove <index,0-N>
                            --target <uuid|vmname>|global

  guestproperty             get <uuid|vmname>
                            <property> [--verbose]

  guestproperty             set <uuid|vmname>
                            <property> [<value> [--flags <flags>]]

  guestproperty             delete|unset <uuid|vmname>
                            <property>

  guestproperty             enumerate <uuid|vmname>
                            [--patterns <patterns>]

  guestproperty             wait <uuid|vmname> <patterns>
                            [--timeout <msec>] [--fail-on-timeout]

  guestcontrol              <uuid|vmname> [--verbose|-v] [--quiet|-q]
                              [--username <name>] [--domain <domain>]
                              [--passwordfile <file> | --password <password>]

                              run [common-options]
                              [--exe <path to executable>] [--timeout <msec>]
                              [-E|--putenv <NAME>[=<VALUE>]] [--unquoted-args]
                              [--ignore-operhaned-processes] [--profile]
                              [--no-wait-stdout|--wait-stdout]
                              [--no-wait-stderr|--wait-stderr]
                              [--dos2unix] [--unix2dos]
                              -- <program/arg0> [argument1] ... [argumentN]]

                              start [common-options]
                              [--exe <path to executable>] [--timeout <msec>]
                              [-E|--putenv <NAME>[=<VALUE>]] [--unquoted-args]
                              [--ignore-operhaned-processes] [--profile]
                              -- <program/arg0> [argument1] ... [argumentN]]

                              copyfrom [common-options]
                              [--follow] [-R|--recursive]
                              <guest-src0> [guest-src1 [...]] <host-dst>

                              copyfrom [common-options]
                              [--follow] [-R|--recursive]
                              [--target-directory <host-dst-dir>]
                              <guest-src0> [guest-src1 [...]]

                              copyto [common-options]
                              [--follow] [-R|--recursive]
                              <host-src0> [host-src1 [...]] <guest-dst>

                              copyto [common-options]
                              [--follow] [-R|--recursive]
                              [--target-directory <guest-dst>]
                              <host-src0> [host-src1 [...]]

                              mkdir|createdir[ectory] [common-options]
                              [--parents] [--mode <mode>]
                              <guest directory> [...]

                              rmdir|removedir[ectory] [common-options]
                              [-R|--recursive]
                              <guest directory> [...]

                              removefile|rm [common-options] [-f|--force]
                              <guest file> [...]

                              mv|move|ren[ame] [common-options]
                              <source> [source1 [...]] <dest>

                              mktemp|createtemp[orary] [common-options]
                              [--secure] [--mode <mode>] [--tmpdir <directory>]
                              <template>

                              stat [common-options]
                              <file> [...]

  guestcontrol              <uuid|vmname> [--verbose|-v] [--quiet|-q]

                              list <all|sessions|processes|files> [common-opts]

                              closeprocess [common-options]
                              <   --session-id <ID>
                                | --session-name <name or pattern>
                              <PID1> [PID1 [...]]

                              closesession [common-options]
                              <  --all | --session-id <ID>
                                | --session-name <name or pattern> >

                              updatega|updateguestadditions|updateadditions
                              [--source <guest additions .ISO>]
                              [--wait-start] [common-options]
                              [-- [<argument1>] ... [<argumentN>]]

                              watch [common-options]

  metrics                   list [*|host|<vmname> [<metric_list>]]
                                                 (comma-separated)

  metrics                   setup
                            [--period <seconds>] (default: 1)
                            [--samples <count>] (default: 1)
                            [--list]
                            [*|host|<vmname> [<metric_list>]]

  metrics                   query [*|host|<vmname> [<metric_list>]]

  metrics                   enable
                            [--list]
                            [*|host|<vmname> [<metric_list>]]

  metrics                   disable
                            [--list]
                            [*|host|<vmname> [<metric_list>]]

  metrics                   collect
                            [--period <seconds>] (default: 1)
                            [--samples <count>] (default: 1)
                            [--list]
                            [--detach]
                            [*|host|<vmname> [<metric_list>]]

  natnetwork                add --netname <name>
                            --network <network>
                            [--enable|--disable]
                            [--dhcp on|off]
                            [--port-forward-4 <rule>]
                            [--loopback-4 <rule>]
                            [--ipv6 on|off]
                            [--port-forward-6 <rule>]
                            [--loopback-6 <rule>]

  natnetwork                remove --netname <name>

  natnetwork                modify --netname <name>
                            [--network <network>]
                            [--enable|--disable]
                            [--dhcp on|off]
                            [--port-forward-4 <rule>]
                            [--loopback-4 <rule>]
                            [--ipv6 on|off]
                            [--port-forward-6 <rule>]
                            [--loopback-6 <rule>]

  natnetwork                start --netname <name>

  natnetwork                stop --netname <name>

  natnetwork                list [<pattern>]

  hostonlyif                ipconfig <name>
                            [--dhcp |
                            --ip<ipv4> [--netmask<ipv4> (def: 255.255.255.0)] |
                            --ipv6<ipv6> [--netmasklengthv6<length> (def: 64)]]
                            create |
                            remove <name>

  usbdevsource              add <source name>
                            --backend <backend>
                            --address <address>
  usbdevsource              remove <source name>
VBoxManage snapshot  <uuid|vmname>VBoxManage snapshot  <uuid|vmname>  take  <snapshot-name> [--description=description] [--live] [--uniquename Number,Timestamp,Space,Force]VBoxManage snapshot  <uuid|vmname>  delete  <snapshot-name>VBoxManage snapshot  <uuid|vmname>  restore  <snapshot-name>VBoxManage snapshot  <uuid|vmname>  restorecurrent VBoxManage snapshot  <uuid|vmname>  edit  < snapshot-name  |   --current > [--description=description] [--name=new-name]VBoxManage snapshot  <uuid|vmname>  list  [[--details] |  [--machinereadable]]VBoxManage snapshot  <uuid|vmname>  showvminfo  <snapshot-name>
VBoxManage clonevm  <vmname|uuid> [--basefolder=basefolder] [--groups=group,...] [ --mode=machine  |   --mode=machinechildren  |   --mode=all ] [--name=name] [--options=option,...] [--register] [--snapshot=snapshot-name] [--uuid=uuid]
VBoxManage mediumio  < --disk=uuid|filename  |   --dvd=uuid|filename  |   --floppy=uuid|filename > [--password-file=-|filename]  formatfat  [--quick]VBoxManage mediumio  < --disk=uuid|filename  |   --dvd=uuid|filename  |   --floppy=uuid|filename > [--password-file=-|filename]  cat  [--hex] [--offset=byte-offset] [--size=bytes] [--output=-|filename]VBoxManage mediumio  < --disk=uuid|filename  |   --dvd=uuid|filename  |   --floppy=uuid|filename > [--password-file=-|filename]  stream  [--format=image-format] [--variant=image-variant] [--output=-|filename]
VBoxManage sharedfolder add  < uuid  |   vmname > <--name=name> <--hostpath=hostpath> [--readonly] [--transient] [--automount] [--auto-mount-point=path]VBoxManage sharedfolder remove  < uuid  |   vmname > <--name=name> [--transient]
VBoxManage dhcpserver add  < --network=netname  |   --interface=ifname > <--server-ip=address> <--netmask=mask> <--lower-ip=address> <--upper-ip=address> < --enable  |   --disable > [[--global] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--incl-mac=address...] [--excl-mac=address...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--incl-vendor=string...] [--excl-vendor=string...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--incl-user=string...] [--excl-user=string...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--vm=name|uuid> [--nic=1-N] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...] [<--mac-address=address> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...]VBoxManage dhcpserver modify  < --network=netname  |   --interface=ifname > [--server-ip=address] [--lower-ip=address] [--upper-ip=address] [--netmask=mask] [ --enable  |   --disable ] [[--global] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--del-mac=address...] [--incl-mac=address...] [--excl-mac=address...] [--del-mac-wild=pattern...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--del-vendor=string...] [--incl-vendor=string...] [--excl-vendor=string...] [--del-vendor-wild=pattern...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--del-user=string...] [--incl-user=string...] [--excl-user=string...] [--del-user-wild=pattern...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--zap-conditions] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--vm=name|uuid> [--nic=1-N] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...] [<--mac-address=address> [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...]VBoxManage dhcpserver remove  < --network=netname  |   --interface=ifname >VBoxManage dhcpserver restart  < --network=netname  |   --interface=ifname >VBoxManage dhcpserver findlease  < --network=netname  |   --interface=ifname > <--mac-address=mac>
VBoxManage debugvm  <uuid|vmname>  dumpvmcore  [--filename=name]VBoxManage debugvm  <uuid|vmname>  info  <item> [args...]VBoxManage debugvm  <uuid|vmname>  injectnmi VBoxManage debugvm  <uuid|vmname>  log  [[--release] |  [--debug]] [group-settings...]VBoxManage debugvm  <uuid|vmname>  logdest  [[--release] |  [--debug]] [destinations...]VBoxManage debugvm  <uuid|vmname>  logflags  [[--release] |  [--debug]] [flags...]VBoxManage debugvm  <uuid|vmname>  osdetect VBoxManage debugvm  <uuid|vmname>  osinfo VBoxManage debugvm  <uuid|vmname>  osdmesg  [--lines=lines]VBoxManage debugvm  <uuid|vmname>  getregisters  [--cpu=id] [reg-set.reg-name...]VBoxManage debugvm  <uuid|vmname>  setregisters  [--cpu=id] [reg-set.reg-name=value...]VBoxManage debugvm  <uuid|vmname>  show  [[--human-readable] |  [--sh-export] |  [--sh-eval] |  [--cmd-set]] [settings-item...]VBoxManage debugvm  <uuid|vmname>  stack  [--cpu=id]VBoxManage debugvm  <uuid|vmname>  statistics  [--reset] [--descriptions] [--pattern=pattern]
VBoxManage extpack install  [--replace] [--accept-license=sha256] <tarball>VBoxManage extpack uninstall  [--force] <name>VBoxManage extpack cleanup 
VBoxManage unattended detect  <--iso=install-iso> [--machine-readable]VBoxManage unattended install  <uuid|vmname> <--iso=install-iso> [--user=login] [--password=password] [--password-file=file] [--full-user-name=name] [--key=product-key] [--install-additions] [--no-install-additions] [--additions-iso=add-iso] [--install-txs] [--no-install-txs] [--validation-kit-iso=testing-iso] [--locale=ll_CC] [--country=CC] [--time-zone=tz] [--hostname=fqdn] [--package-selection-adjustment=keyword] [--dry-run] [--auxiliary-base-path=path] [--image-index=number] [--script-template=file] [--post-install-template=file] [--post-install-command=command] [--extra-install-kernel-parameters=params] [--language=lang] [--start-vm=session-type]
VBoxManage cloud  <--provider=name> <--profile=name>  list   instances  [--state=string] [--compartment-id=string]VBoxManage cloud  <--provider=name> <--profile=name>  list   images  <--compartment-id=string> [--state=string]VBoxManage cloud  <--provider=name> <--profile=name>  instance   create  <--domain-name=name> <<--image-id=id> |  <--boot-volume-id=id>> <--display-name=name> <--shape=type> <--subnet=id> [--boot-disk-size=size in GB] [--publicip=true/false] [--privateip=IP address] [--public-ssh-key=key string...] [--launch-mode=NATIVE/EMULATED/PARAVIRTUALIZED]VBoxManage cloud  <--provider=name> <--profile=name>  instance   info  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   terminate  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   start  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   pause  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   create  <--display-name=name> [--bucket-name=name] [--object-name=name] [--instance-id=unique id]VBoxManage cloud  <--provider=name> <--profile=name>  image   info  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   delete  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   import  <--id=unique id> [--bucket-name=name] [--object-name=name]VBoxManage cloud  <--provider=name> <--profile=name>  image   export  <--id=unique id> <--display-name=name> [--bucket-name=name] [--object-name=name]VBoxManage cloud  <--provider=name> <--profile=name>  network setup  <--local-gateway-iso=path> [--gateway-os-name=string] [--gateway-os-version=string] [--gateway-shape=string] [--tunnel-network-name=string] [--tunnel-network-range=string] [--guest-additions-iso=path] [--proxy=string]VBoxManage cloud  <--provider=name> <--profile=name>  network create  <--name=string> <--network-id=string> [ --enable  |   --disable ]VBoxManage cloud network update  <--name=string> [--network-id=string] [ --enable  |   --disable ]VBoxManage cloud   network delete  <--name=string>VBoxManage cloud   network info  <--name=string>
VBoxManage cloudprofile  <--provider=name> <--profile=name>  add  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]VBoxManage cloudprofile  <--provider=name> <--profile=name>  update  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]VBoxManage cloudprofile  <--provider=name> <--profile=name>  delete VBoxManage cloudprofile  <--provider=name> <--profile=name>  show 

      Each time VBoxManage is invoked, only one
      command can be executed. However, a command might support several
      subcommands which then can be invoked in one single call. The
      following sections provide detailed reference information on the
      different commands.
    8.3. General Options
-v|--version: Show the version of this tool
          and exit.
        
--nologo: Suppress the output of the logo
          information. This option is useful for scripts.
        
--settingspw: Specifiy a settings password.
        
--settingspwfile: Specify a file containing
          the settings password.
        
      The settings password is used for certain settings which need to
      be stored in encrypted form for security reasons. At the moment,
      the only encrypted setting is the iSCSI initiator secret, see
      Section 8.17, “VBoxManage storageattach”. As long as no
      settings password is specified, this information is stored in
      plain text. After using the
      --settingspw|--settingspwfile option once, it
      must be always used. Otherwise, the encrypted setting cannot be
      unencrypted.
    8.4. VBoxManage list
      The list command gives relevant information
      about your system and information about Oracle VM VirtualBox's current
      settings.
    
      The following subcommands are available with VBoxManage
      list:
    
vms: Lists all virtual machines currently
          registered with Oracle VM VirtualBox. By default this displays a
          compact list with each VM's name and UUID. If you also specify
          --long or -l, this will be a
          detailed list as with the showvminfo
          command, see Section 8.5, “VBoxManage showvminfo”.
        
runningvms: Lists all currently running
          virtual machines by their unique identifiers (UUIDs) in the
          same format as with vms.
        
ostypes: Lists all guest operating systems
          presently known to Oracle VM VirtualBox, along with the identifiers
          used to refer to them with the modifyvm
          command.
        
hostdvds, hostfloppies:
          Lists the DVD, floppy, bridged networking, and host-only
          networking interfaces on the host, along with the name used to
          access them from within Oracle VM VirtualBox.
        
intnets: Displays information about the
          internal networks.
        
bridgedifs, hostonlyifs,
          natnets, dhcpservers:
          Lists the bridged network interfaces, host-only network
          interfaces, NAT network interfaces, and DHCP servers currently
          available on the host. See
          Chapter 6, Virtual Networking.
        
hostinfo: Displays information about the
          host system, such as CPUs, memory size, and operating system
          version.
        
hostcpuids: Lists the CPUID parameters for
          the host CPUs. This can be used for a more fine grained
          analyis of the host's virtualization capabilities.
        
hddbackends: Lists all known virtual disk
          back-ends of Oracle VM VirtualBox. For each such format, such as
          VDI, VMDK, or RAW, this subcommand lists the back-end's
          capabilities and configuration.
        
hdds, dvds,
          floppies: Shows information about virtual
          disk images currently in use by Oracle VM VirtualBox, including all
          their settings, the unique identifiers (UUIDs) associated with
          them by Oracle VM VirtualBox and all files associated with them.
          This is the command-line equivalent of the Virtual Media
          Manager. See Section 5.3, “The Virtual Media Manager”.
        
usbhost: Shows information about USB
          devices attached to the host, including information useful for
          constructing USB filters and whether they are currently in use
          by the host.
        
usbfilters: Lists all global USB filters
          registered with Oracle VM VirtualBox and displays the filter
          parameters. Global USB filters are for devices which are
          accessible to all virtual machines.
        
systemproperties: Displays some global
          Oracle VM VirtualBox settings, such as minimum and maximum guest RAM
          and virtual hard disk size, folder settings and the current
          authentication library in use.
        
extpacks: Displays all Oracle VM VirtualBox
          extension packs that are currently installed. See
          Section 1.5, “Installing Oracle VM VirtualBox and Extension Packs” and
          Section 8.41, “VBoxManage extpack”.
        
groups: Displays details of the VM Groups.
          See Section 1.9, “Using VM Groups”.
        
webcams: Displays a list of webcams
          attached to the running VM. The output format is a list of
          absolute paths or aliases that were used for attaching the
          webcams to the VM using the webcam attach command.
        
screenshotformats: Displays a list of
          available screenshot formats.
        
cloudproviders: Displays a list of cloud
          providers that are supported by Oracle VM VirtualBox. Oracle Cloud Infrastructure is an
          example of a cloud provider.
        
cloudprofiles: Displays a list of cloud
          profiles that have been configured.
        
          Cloud profiles are used when exporting VMs to a cloud service.
          See Section 1.14.5, “Exporting an Appliance to Oracle Cloud Infrastructure”.
        8.5. VBoxManage showvminfo
      The showvminfo command shows information about
      a particular virtual machine. This is the same information as
      VBoxManage list vms --long would show for all
      virtual machines.
    
      You will see information as shown in the following example.
    $ VBoxManage showvminfo ""Windows XP""
VirtualBox Command Line Management Interface Version version-number
(C) 2005-2018 Oracle Corporation
All rights reserved.

Name:            Windows XP
Guest OS:        Other/Unknown
UUID:            1bf3464d-57c6-4d49-92a9-a5cc3816b7e7
Config file:     /home/username/.config/VirtualBox/Machines/Windows XP/Windows XP.xml
Memory size:     512MB
VRAM size:       12MB
Number of CPUs:  2
Boot menu mode:  message and menu
Boot Device (1): DVD
Boot Device (2): HardDisk
Boot Device (3): Not Assigned
Boot Device (4): Not Assigned
ACPI:            on
IOAPIC:          on
...
    
      Use the --machinereadable option to produce the
      same output, but in machine readable format with a property=value
      string on each line. For example:
    
...
groups=""/""
ostype=""Oracle (64-bit)""
UUID=""457af700-bc0a-4258-aa3c-13b03da171f2""
...
 8.6. VBoxManage registervm/unregistervm
      The registervm command enables
      you to import a virtual machine definition in an XML file into
      Oracle VM VirtualBox. The machine must not conflict with one already
      registered in Oracle VM VirtualBox and it may not have any hard or
      removable disks attached. It is advisable to place the definition
      file in the machines folder before registering it.
    Note
        When creating a new virtual machine with VBoxManage
        createvm, as shown in
        Section 8.7, “VBoxManage createvm”, you can directly specify
        the --register option to avoid having to
        register it separately.
      
      The unregistervm command unregisters a virtual
      machine. If --delete is also specified, the
      following files will also be deleted automatically:
    
          All hard disk image files, including differencing files, which
          are used by the machine and not shared with other machines.
        
          Saved state files that the machine created. One if the machine
          was in Saved state and one for each online snapshot.
        
          The machine XML file and its backups.
        
          The machine log files.
        
          The machine directory, if it is empty after having deleted all
          of the above files.
        8.7. VBoxManage createvm
      The VBoxManage createvm command creates a new
      XML virtual machine definition file.
    
      You must specify the name of the VM by using --name
      name. This name is used by
      default as the file name of the settings file that has the
      .xml extension and the machine folder, which
      is a subfolder of the
      .config/VirtualBox/Machines folder. Note that
      the machine folder path name varies based on the OS type and the
      Oracle VM VirtualBox version.
    
      Ensure that the VM name conforms to the host OS's file name
      requirements. If you later rename the VM, the file and folder
      names will be updated to match the new name automatically.
    
      The --basefolder path
      option specifies the machine folder path name. Note that the names
      of the file and the folder do not change if you rename the VM.
    
      The --group group-ID,
      ... option assigns the VM to the specified groups. Note
      that group IDs always start with
      / so that they can be nested. By
      default, each VM is assigned membership to the
      / group.
    
      The --ostype ostype
      option specifies the guest OS to run in the VM. Run the
      VBoxManage list ostypes command to see the
      available OS types.
    
      The --uuid uuid option
      specifies the universal unique identifier (UUID) of the VM. The
      UUID must be unique within the namespace of the host or of its VM
      group memberships. By default, the VBoxManage
      command automatically generates the UUID.
    
      The --default option applies a
      default hardware configuration for the specified guest OS. By
      default, the VM is created with minimal hardware.
    
      The --register option registers the VM with your
      Oracle VM VirtualBox installation. By default, the VBoxManage
      createvm command creates only the XML configuration for
      the VM but does not registered the VM. If you do not register the
      VM at creation, you can run the VBoxManage
      registervm command after you create the VM.
    8.8. VBoxManage modifyvm
      This command changes the properties of a registered virtual
      machine which is not running. Most of the properties that this
      command makes available correspond to the VM settings that
      Oracle VM VirtualBox graphical user interface displays in each VM's
      Settings dialog. These are
      described in Chapter 3, Configuring Virtual Machines. However, some of
      the more advanced settings are only available through the
      VBoxManage interface.
    
      These commands require that the machine is powered off, neither
      running nor in a Saved state. Some machine settings can also be
      changed while a machine is running. Those settings will then have
      a corresponding subcommand with the VBoxManage
      controlvm subcommand. See
      Section 8.13, “VBoxManage controlvm”.
    8.8.1. General Settings
        The following general settings are available through
        VBoxManage modifyvm:
      
--name <name>:
            Changes the VM's name and can be used to rename the internal
            virtual machine files, as described in
            Section 8.7, “VBoxManage createvm”.
          
--groups <group>,
            ...: Changes the group membership of a VM.
            Groups always start with a
            / and can be nested. By
            default VMs are in group /.
          
--description <desc>:
            Changes the VM's description, which is a way to record
            details about the VM in a way which is meaningful for the
            user. The GUI interprets HTML formatting, the command line
            allows arbitrary strings potentially containing multiple
            lines.
          
--ostype <ostype>:
            Specifies what guest operating system is supposed to run in
            the VM. To learn about the various identifiers that can be
            used here, use VBoxManage list ostypes.
          
--iconfile
            <filename>: Specifies the absolute
            path on the host file system for the Oracle VM VirtualBox icon to
            be displayed in the VM.
          
--memory
            <memorysize>: Sets the amount of RAM,
            in MB, that the virtual machine should allocate for itself
            from the host. See Section 1.7, “Creating Your First Virtual Machine”.
          
--pagefusion on|off:
            Enables and disables the Page Fusion feature. Page Fusion is
            disabled by default. The Page Fusion feature minimises
            memory duplication between VMs with similar configurations
            running on the same host. See
            Section 4.10.2, “Page Fusion”.
          
--vram <vramsize>:
            Sets the amount of RAM that the virtual graphics card should
            have. See Section 3.6, “Display Settings”.
          
--acpi on|off and
            --ioapic on|off: Determines
            whether the VM has ACPI and I/O APIC support. See
            Section 3.5.1, “Motherboard Tab”.
          
--pciattach <host PCI address [@ guest
            PCI bus address]>: Attaches a specified
            PCI network controller on the host to a specified PCI bus on
            the guest.


          
--pcidetach <host PCI
            address>: Detaches a specified PCI
            network controller on the host from the attached PCI bus on
            the guest.


          
--hardwareuuid
            <uuid>: The UUID presented to the
            guest through memory tables (DMI/SMBIOS), hardware, and
            guest properties. By default this is the same as the VM
            UUID. This setting is useful when cloning a VM. Teleporting
            takes care of this automatically.
          
--cpus <cpucount>:
            Sets the number of virtual CPUs for the virtual machine, see
            Section 3.5.2, “Processor Tab”. If CPU hot-plugging
            is enabled, this then sets the maximum
            number of virtual CPUs that can be plugged into the virtual
            machines.
          
--cpuhotplug on|off:
            Enables CPU hot-plugging. When enabled, virtual CPUs can be
            added to and removed from a virtual machine while it is
            running. See Section 9.4, “CPU Hot-Plugging”.
          
--plugcpu|unplugcpu
            <id>: If CPU hot-plugging is enabled,
            this setting adds or removes a virtual CPU on the virtual
            machine. <id>
            specifies the index of the virtual CPU to be added or
            removed and must be a number from 0 to the maximum number of
            CPUs configured with the
            --cpus option. CPU 0 can
            never be removed.
          
--cpuexecutioncap
            <1-100>: Controls how much CPU time a
            virtual CPU can use. A value of 50 implies a single virtual
            CPU can use up to 50% of a single host CPU.
          
--pae on|off: Enables and
            disables PAE. See Section 3.5.2, “Processor Tab”.
          
--longmode on|off: Enables
            and disables long mode. See
            Section 3.5.2, “Processor Tab”.
          
--spec-ctrl on|off: Enables
            and disables the exposure of speculation control interfaces
            to the guest, provided they are available on the host.
            Depending on the host CPU and workload, enabling speculation
            control may significantly reduce performance.
          
--cpu-profile <host|intel
            80[86|286|386]>: Enables specification
            of a profile for guest CPU emulation. Specify either one
            based on the host system CPU (host), or one from a number of
            older Intel Micro-architectures: 8086, 80286, 80386.
          
--hpet on|off: Enables and
            disables a High Precision Event Timer (HPET) which can
            replace the legacy system timers. This is turned off by
            default. Note that Windows supports a HPET only from Vista
            onwards.
          
--hwvirtex on|off: Enables
            and disables the use of hardware virtualization extensions,
            such as Intel VT-x or AMD-V, in the processor of your host
            system. See Section 10.3, “Hardware Virtualization”.
          
--triplefaultreset on|off:
            Enables resetting of the guest instead of triggering a Guru
            Meditation. Some guests raise a triple fault to reset the
            CPU so sometimes this is desired behavior. Works only for
            non-SMP guests.
          
--apic on|off: Enables and
            disables I/O APIC. With I/O APIC, operating systems can use
            more than 16 interrupt requests (IRQs) thus avoiding IRQ
            sharing for improved reliability. This setting is enabled by
            default. See Section 3.5.1, “Motherboard Tab”.
          
--x2apic on|off: Enables
            and disables CPU x2APIC support. CPU x2APIC support helps
            operating systems run more efficiently on high core count
            configurations, and optimizes interrupt distribution in
            virtualized environments. This setting is enabled by
            default. Disable this setting when using host or guest
            operating systems that are incompatible with x2APIC support.
          
--paravirtprovider
            none|default|legacy|minimal|hyperv|kvm:
            Specifies which paravirtualization interface to provide to
            the guest operating system. Specifying
            none explicitly turns off
            exposing any paravirtualization interface. The option
            default selects an
            appropriate interface when starting the VM, depending on the
            guest OS type. This is the default option chosen when
            creating new VMs. The
            legacy option is used for
            VMs which were created with older Oracle VM VirtualBox versions
            and will pick a paravirtualization interface when starting
            the VM with Oracle VM VirtualBox 5.0 and newer. The
            minimal provider is
            mandatory for Mac OS X guests.
            kvm and
            hyperv are recommended for
            Linux and Windows guests respectively. These options are
            explained in Section 10.5, “Paravirtualization Providers”.
          
--paravirtdebug <keyword=value>
            [,<keyword=value> ...]: Specifies
            debugging options specific to the paravirtualization
            provider configured for this VM. See the provider specific
            options in Section 9.29, “Paravirtualized Debugging” for a list of
            supported keyword-value pairs for each provider.
          
--nestedpaging on|off: If
            hardware virtualization is enabled, this additional setting
            enables or disables the use of the nested paging feature in
            the processor of your host system. See
            Section 10.3, “Hardware Virtualization” and
            Section 13.4.1, “CVE-2018-3646”.
          
--largepages on|off: If
            hardware virtualization and nested
            paging are enabled, for Intel VT-x only, an additional
            performance improvement of up to 5% can be obtained by
            enabling this setting. This causes the hypervisor to use
            large pages to reduce TLB use and overhead.
          
--vtxvpid on|off: If
            hardware virtualization is enabled, for Intel VT-x only,
            this additional setting enables or disables the use of the
            tagged TLB (VPID) feature in the processor of your host
            system. See Section 10.3, “Hardware Virtualization”.
          
--vtxux on|off: If hardware
            virtualization is enabled, for Intel VT-x only, this setting
            enables or disables the use of the unrestricted guest mode
            feature for executing your guest.
          
--nested-hw-virt on|off: If
            hardware virtualization is enabled, this setting enables or
            disables passthrough of hardware virtualization features to
            the guest. See Section 9.33, “Nested Virtualization”.
          
--accelerate3d on|off: If
            the Guest Additions are installed, this setting enables or
            disables hardware 3D acceleration. See
            Section 4.5.1, “Hardware 3D Acceleration (OpenGL and Direct3D 8/9)”.
          
--accelerate2dvideo on|off:
            If the Guest Additions are installed, this setting enables
            or disables 2D video acceleration. See
            Section 4.5.2, “Hardware 2D Video Acceleration for Windows Guests”.
          
--chipset piix3|ich9: By
            default, Oracle VM VirtualBox emulates an Intel PIIX3 chipset.
            Usually there is no reason to change the default setting
            unless this is required to relax some of its constraints.
            See Section 3.5.1, “Motherboard Tab”.
          
            You can influence the BIOS logo that is displayed when a
            virtual machine starts up with a number of settings. By
            default, an Oracle VM VirtualBox logo is displayed.
          
            With --bioslogofadein
            on|off and
            --bioslogofadeout on|off,
            you can determine whether the logo should fade in and out,
            respectively.
          
            With --bioslogodisplaytime
            <msec> you can set how long the logo
            should be visible, in milliseconds.
          
            With --bioslogoimagepath
            <imagepath> you can replace the image
            that is shown with your own logo. The image must be an
            uncompressed 256 color BMP file without color space
            information (Windows 3.0 format). The image must not be
            bigger than 640 x 480.
          
--biosbootmenu
            disabled|menuonly|messageandmenu: Specifies
            whether the BIOS enables the user to select a temporary boot
            device. The menuonly option
            suppresses the message, but the user can still press F12 to
            select a temporary boot device.
          
--biosapic
            x2apic|apic|disabled: Specifies the
            firmware APIC level to be used. Options are: x2apic, apic or
            disabled (no apic or x2apic) respectively.
          
            Note that if x2apic is specified and x2APIC is unsupported
            by the VCPU, biosapic downgrades to apic, if supported.
            Otherwise biosapic downgrades to disabled. Similarly, if
            apic is specified, and APIC is unsupported, a downgrade to
            disabled results.
          
--biossystemtimeoffset
            <ms>: Specifies a fixed time offset,
            in milliseconds, of the guest relative to the host time. If
            the offset is positive, the guest time runs ahead of the
            host time.
          
--biospxedebug on|off:
            Enables or disables additional debugging output when using
            the Intel PXE boot ROM. The output is written to the release
            log file. See Section 12.1.2, “Collecting Debugging Information”.
          
--system-uuid-le on|off:
            Enables or disables representing the system UUID in little
            endian form. The default value is on for
            new VMs. For old VMs the setting is off
            to keep the content of the DMI/SMBIOS table unchanged, which
            can be important for Windows license activation.
          
--boot<1-4>
            none|floppy|dvd|disk|net: Specifies the
            boot order for the virtual machine. There are four
            slots, which the VM will try to access
            from 1 to 4, and for each of which you can set a device that
            the VM should attempt to boot from.
          
--rtcuseutc on|off: Sets
            the real-time clock (RTC) to operate in UTC time. See
            Section 3.5.1, “Motherboard Tab”.
          
--graphicscontroller
            none|vboxvga|vmsvga|vboxsvga: Specifies the
            use of a graphics controller, with an option to choose a
            specific type. See Section 3.6.1, “Screen Tab”.
          
--snapshotfolder
            default|<path>: Specifies the folder
            where snapshots are kept for a virtual machine.
          
--firmware
            bios|efi|efi32|efi64: Specifies the
            firmware to be used to boot the VM: Available options are:
            BIOS, or one of the EFI options: efi, efi32, or efi64. Use
            EFI options with care.
          
--guestmemoryballoon
            <size> Sets the default size of the
            guest memory balloon. This is the memory allocated by the
            Oracle VM VirtualBox Guest Additions from the guest operating
            system and returned to the hypervisor for reuse by other
            virtual machines.
            <size> must be
            specified in megabytes. The default size is 0 megabytes. See
            Section 4.10.1, “Memory Ballooning”.
          
--defaultfrontend
            default|<name>: Specifies the default
            frontend to be used when starting this VM. See
            Section 8.12, “VBoxManage startvm”.
          
--vm-process-priority
            default|flat|low|normal|high: Specifies the
            priority scheme of the VM process to be used when starting
            this VM and during VM execution. See
            Section 8.12, “VBoxManage startvm”.
          8.8.2. Networking Settings
        The following networking settings are available through
        VBoxManage modifyvm. With all these settings,
        the decimal number directly following the option name, 1-N in
        the list below, specifies the virtual network adapter whose
        settings should be changed.
      
--nic<1-N>
            none|null|nat|natnetwork|bridged|intnet|hostonly|generic:
            Configures the type of networking for each of the VM's
            virtual network cards. Options are: not present
            (none), not connected to
            the host (null), use
            network address translation
            (nat), use the new network
            address translation engine
            (natnetwork), bridged
            networking (bridged), or
            use internal networking
            (intnet), host-only
            networking (hostonly), or
            access rarely used sub-modes
            (generic). These options
            correspond to the modes described in
            Section 6.2, “Introduction to Networking Modes”.
          
--nictype<1-N>
            Am79C970A|Am79C973|Am79C970|82540EM|82543GC|82545EM|virtio:
            Enables you to specify the networking hardware that
            Oracle VM VirtualBox presents to the guest for a specified VM
            virtual network card. See Section 6.1, “Virtual Networking Hardware”.
          
--cableconnected<1-N>
            on|off: Enables you to temporarily
            disconnect a virtual network interface, as if a network
            cable had been pulled from a real network card. This might
            be useful, for example for resetting certain software
            components in the VM.
          
            With the nictrace options,
            you can optionally trace network traffic by dumping it to a
            file, for debugging purposes.
          
            With --nictrace<1-N>
            on|off, you can enable network tracing for
            a particular virtual network card.
          
            If enabled, you must specify with
            --nictracefile<1-N>
            <filename> the absolute path of the
            file the trace should be logged to.
          
--nicproperty<1-N>
            <paramname>=""paramvalue"": This
            option, in combination with
            nicgenericdrv enables you
            to pass parameters to rarely-used network backends.
          
            These parameters are backend engine-specific, and are
            different between UDP Tunnel and the VDE backend drivers.
            For examples, see Section 6.8, “UDP Tunnel Networking”.
          
--nicspeed<1-N>
            <kbps>: Only has an effect if generic
            networking has been enabled for a particular virtual network
            card. See the --nic option.
            This mode enables access to rarely used networking
            sub-modes, such as VDE network or UDP Tunnel. This option
            specifies the throughput rate in KBps.
          
--nicbootprio<1-N>
            <priority>: Specifies the order in
            which NICs are tried for booting over the network, using
            PXE. The priority is an integer in the 0 to 4 range.
            Priority 1 is the highest, priority 4 is low. Priority 0,
            which is the default unless otherwise specified, is the
            lowest.
          
            Note that this option only has an effect when the Intel PXE
            boot ROM is used.
          
--nicpromisc<1-N>
            deny|allow-vms|allow-all: Enables you to
            specify how promiscuous mode is handled for the specified VM
            virtual network card. This setting is only relevant for
            bridged networking. deny,
            the default setting, hides any traffic not intended for the
            VM. allow-vms hides all
            host traffic from the VM, but allows the VM to see traffic
            to and from other VMs.
            allow-all removes this
            restriction completely.
          
--nicbandwidthgroup<1-N>
            none|<name>: Adds and removes an
            assignment of a bandwidth group for the specified virtual
            network interface. Specifying
            none removes any current
            bandwidth group assignment from the specified virtual
            network interface. Specifying
            <name> adds an
            assignment of a bandwidth group to the specified virtual
            network interface.
          
            See Section 6.10, “Limiting Bandwidth for Network Input/Output”.
          
--bridgeadapter<1-N>
            none|<devicename>: Only has an effect
            if bridged networking has been enabled for a virtual network
            card. See the --nic option.
            Use this option to specify which host interface the given
            virtual network interface will use. See
            Section 6.5, “Bridged Networking”.
          
--hostonlyadapter<1-N>
            none|<devicename>: Only has an effect
            if host-only networking has been enabled for a virtual
            network card. See the --nic
            option. Use this option to specify which host-only
            networking interface the given virtual network interface
            will use. See Section 6.7, “Host-Only Networking”.
          
--intnet<1-N>
            network: Only has an effect if internal
            networking has been enabled for a virtual network card. See
            the --nic option. Use this
            option to specify the name of the internal network. See
            Section 6.6, “Internal Networking”.
          
--nat-network<1-N> <network
            name>: If the networking type is set to
            natnetwork, not
            nat, then this setting
            specifies the name of the NAT network this adapter is
            connected to. Optional.
          
--nicgenericdrv<1-N> <backend
            driver>: Only has an effect if generic
            networking has been enabled for a virtual network card. See
            the --nic option. This mode
            enables you to access rarely used networking sub-modes, such
            as VDE network or UDP Tunnel.
          
--macaddress<1-N>
            auto|<mac>: With this option you can
            set the MAC address of a particular network adapter on the
            VM. Normally, each network adapter is assigned a random
            address by Oracle VM VirtualBox at VM creation.
          8.8.2.1. NAT Networking Settings
          The following NAT networking settings are available through
          VBoxManage modifyvm. With all these
          settings, the decimal number directly following the option
          name, 1-N in the list below, specifies the virtual network
          adapter whose settings should be changed.
        
--natnet<1-N>
              <network>|default: If the
              networking type is set to
              nat, not
              natnetwork, then this
              setting specifies the IP address range to be used for this
              network. See Section 9.8, “Fine Tuning the Oracle VM VirtualBox NAT Engine”.
            
--natpf<1-N>
              [<name>],tcp|udp,[<hostip>],<hostport>,[<guestip>],
              <guestport>: Defines a NAT
              port-forwarding rule. See Section 6.3.1, “Configuring Port Forwarding with NAT”.
            
--natpf<1-N> delete
              <name>: Deletes a NAT
              port-forwarding rule. See Section 6.3.1, “Configuring Port Forwarding with NAT”.
            
--nattftpprefix<1-N>
              <prefix>: Defines a prefix for the
              built-in TFTP server. For example, where the boot file is
              located. See Section 6.3.2, “PXE Booting with NAT” and
              Section 9.8.2, “Configuring the Boot Server (Next Server) of a NAT Network Interface”.
            
--nattftpfile<1-N>
              <bootfile>: Defines the TFT boot
              file. See Section 9.8.2, “Configuring the Boot Server (Next Server) of a NAT Network Interface”.
            
--nattftpserver<1-N>
              <tftpserver>: Defines the TFTP
              server address to boot from. See
              Section 9.8.2, “Configuring the Boot Server (Next Server) of a NAT Network Interface”.
            
--nattbindip<1-N>
              <ip;>: Oracle VM VirtualBox's NAT engine
              normally routes TCP/IP packets through the default
              interface assigned by the host's TCP/IP stack. Use this
              setting to instruct the NAT engine to bind to a specified
              IP address instead. See
              Section 9.8.3, “Tuning TCP/IP Buffers for NAT”.
            
--natdnspassdomain<1-N>
              on|off: Specifies whether the built-in
              DHCP server passes the domain name for network name
              resolution.
            
--natdnsproxy<1-N>
              on|off: Makes the NAT engine proxy all
              guest DNS requests to the host's DNS servers. See
              Section 9.8.5, “Enabling DNS Proxy in NAT Mode”.
            
--natdnshostresolver<1-N>
              on|off: Makes the NAT engine use the
              host's resolver mechanisms to handle DNS requests. See
              Section 9.8.5, “Enabling DNS Proxy in NAT Mode”.
            
--natsettings<1-N>
              [<mtu>],[<socksnd>],[<sockrcv>],[<tcpsnd>],
              [<tcprcv>]: Controls several NAT
              settings. See Section 9.8.3, “Tuning TCP/IP Buffers for NAT”.
            
--nataliasmode<1-N>
              default|[log],[proxyonly],[sameports]:
              Defines behaviour of the NAT engine core: log - enables
              logging, proxyonly - switches off aliasing mode and makes
              NAT transparent, sameports - enforces the NAT engine to
              send packets through the same port as they originated on,
              default - disable all aliasing modes. See
              Section 9.8.7, “Configuring Aliasing of the NAT Engine”.
            8.8.3. Miscellaneous Settings
        The following hardware settings, such as serial port, audio,
        clipboard, drag and drop, monitor, and USB settings are
        available through VBoxManage modifyvm:
      
--mouse
            <ps2|usb|usbtablet|usbmultitouch>:
            Specifies the mode of the mouse to be used in the VM.
            Available options are: ps2, usb, usbtablet, usbmultitouch.
          
--keyboard <ps2|usb>:
            Specifies the mode of the keyboard to be used in the VM.
            Available options are: ps2, usb.
          
--uart<1-N> off|<I/O base>
            <IRQ>: Configures virtual serial
            ports for the VM. See Section 3.10, “Serial Ports”.
          
--uartmode<1-N>
            <arg>: Controls how Oracle VM VirtualBox
            connects a given virtual serial port, configured with the
            --uartX setting, to the
            host on which the virtual machine is running. As described
            in Section 3.10, “Serial Ports”, for each such port, you
            can specify <arg> as
            one of the following options:
          
disconnected: Even
                though the serial port is shown to the guest, it has no
                ""other end"". This is like a real COM port without a
                cable.
              
server
                <pipename>: On a Windows host,
                this tells Oracle VM VirtualBox to create a named pipe on the
                host named
                <pipename> and
                connect the virtual serial device to it. Note that
                Windows requires that the name of a named pipe begins
                with \\.\pipe\.
              
                On a Linux host, instead of a named pipe, a local domain
                socket is used.
              
client
                <pipename>: Operates as for
                server, except that the
                pipe, or local domain socket, is not created by
                Oracle VM VirtualBox but is assumed to exist already.
              
tcpserver <port>:
                Configures Oracle VM VirtualBox to create a TCP socket on the
                host with TCP
                <port> and
                connect the virtual serial device to it. Note that
                UNIX-like systems require ports over 1024 for normal
                users.
              
tcpclient
                <hostname:port>: Operates as for
                tcpserver, except that
                the TCP socket is not created by Oracle VM VirtualBox, but is
                assumed to exist already.
              
file <file>:
                Redirects the serial port output to a raw file
                <file> specified by its absolute path on the host
                file system.
              
<devicename>: If,
                instead of the above options, the device name of a
                physical hardware serial port of the host is specified,
                the virtual serial port is connected to that hardware
                port. On a Windows host, the device name will be a COM
                port such as COM1. On a
                Linux host, the device name will be
                /dev/ttyS0 or similar. This enables
                you to wire up a real serial port to a virtual machine.
              
uarttype <1-N>
            16450|16550A|16750: Configures the UART
            type for a virtual serial port. The default UART type is
            16550A.
          
--lptmode<1-N>
            <Device>: Specifies the Device Name
            of the parallel port that the Parallel Port feature will be
            using. Use this before
--lpt. This feature depends
            on the host operating system. For Windows hosts, use a
            device name such as lpt1. On Linux hosts, use a device name
            such as /dev/lp0.
          
--lpt<1-N> <I/O base>
            <IRQ>: Specifies the I/O address of
            the parallel port and the IRQ number that the Parallel Port
            feature will be using. Optional. Use this
            after
--lptmod. I/O base address
            and IRQ are the values that guest sees. For example, the
            values avalable under guest Device Manager.
          
--audio
            none|null|dsound|oss|alsa|pulse|coreaudio:
            Specifies whether the VM should have audio support, and if
            so, which type. The list of supported audio types depends on
            the host and can be determined with VBoxManage
            modifyvm.
          
--audiocontroller
            ac97|hda|sb16: Specifies the audio
            controller to be used with the VM.
          
--audiocodec
            stac9700|ad1980|stac9221|sb16: Specifies
            the audio codec to be used with the VM.
          
--audioin on: Specifies
            whether capturing audio from the host is enabled or
            disabled.
          
--audioout on: Specifies
            whether audio playback from the guest is enabled or
            disabled.
          
--clipboard-mode
            disabled|hosttoguest|guesttohost|bidirectional:
            Configues how the guest or host operating system's clipboard
            should be shared with the host or guest. See
            Section 3.4, “General Settings”. This setting requires
            that the Guest Additions be installed in the virtual
            machine.
          
--clipboard-file-transfers
            enabled|disabled: Specifies if clipboard
            file transfers are allowed between host and guest OSes or
            not.
          
--draganddrop
            disabled|hosttoguest|guesttohost|bidirectional:
            Specifies the drag and drop mode to use between the host and
            the virtual machine. See Section 4.4, “Drag and Drop”.
            This requires that the Guest Additions be installed in the
            virtual machine.
          
--monitorcount
            <count>: Enables multi-monitor
            support. See Section 3.6, “Display Settings”.
          
--usb on|off: Enables and
            disables the VM's virtual USB controller. See
            Section 3.11.1, “USB Settings”.
          
--usbehci on|off: Enables
            and disables the VM's virtual USB 2.0 controller. See
            Section 3.11.1, “USB Settings”.
          
--usbxhci on|off: Enables
            and disables the VM's virtual USB 3.0 controller. See
            Section 3.11.1, “USB Settings”.
          
--usbrename <oldname>
            <newname>: Enables renaming of the
            VM's virtual USB controller from <oldname> to
            <newname>.
          8.8.4. Recording Settings
        The VBoxManage modifyvm command enables you
        to modify recording settings for video recording, audio
        recording, or both.
      
        Use the following options to update the recording settings:
      
--recording on|off enables or disables the
            recording of a VM session into a WebM/VP8 file. When this
            option value is on,
            recording begins when the VM session starts.
          
--recordingscreens
            all|screen-ID
            [screen-ID ...] enables
            you to specify which VM screens to record. The recording for
            each screen that you specify is saved to its own file.
          
--recordingfile
            filename specifies the
            file in which to save the recording.
          
--recordingmaxsize
            MB specifies the maximum
            size of the recorded video file in megabytes. The recording
            stops when the file reaches the specified size. If this
            value is zero, the recording continues until you stop the
            recording.
          
--recordingmaxtime
            seconds specifies the
            maximum amount time to record in seconds. The recording
            stops after the specified number of seconds elapses. If this
            value is zero, the recording continues until you stop the
            recording.
          
--recordingopts
            keyword=value[,keyword=value
            ...] specifies additional video-recording options
            in a comma-separated keyword-value format. For example,
            foo=bar,a=b.
          
            Only use this option only if you are an advanced user. For
            information about keywords, see Oracle VM
            VirtualBox Programming Guide and Reference.
          
--recordingvideofps
            fps specifies the
            maximum number of video frames per second (FPS) to record.
            Frames that have a higher frequency are skipped. Increasing
            this value reduces the number of skipped frames and
            increases the file size.
          
--recordingvideorate
            bit-rate specifies the
            bit rate of the video in kilobits per second. Increasing
            this value improves the appearance of the video at the cost
            of an increased file size.
          
--recordingvideores
            widthxheight
            specifies the video resolution of the recorded video in
            pixels.
          8.8.5. Remote Machine Settings
        The following settings that affect remote machine behavior are
        available through VBoxManage modifyvm:
      
--vrde on|off: Enables and
            disables the VirtualBox Remote Desktop Extension (VRDE)
            server.
          
--vrdeproperty
            ""TCP/Ports|Address=<value>"": Sets the
            port numbers and IP address on the VM that the VRDE server
            can bind to.
          
                For TCP/Ports, <value> should be a port or a range
                of ports that the VRDE server can bind to.
                default or
                0 means port 3389, the
                standard port for RDP. See the description for the
                --vrdeport option in
                Section 8.8.5, “Remote Machine Settings”.
              
                For TCP/Address, <value> should be the IP address
                of the host network interface that the VRDE server will
                bind to. If specified, the server will accept
                connections only on the specified host network
                interface. See the description for the
                --vrdeaddress option in
                Section 8.8.5, “Remote Machine Settings”.
              
--vrdeproperty
            ""VideoChannel/Enabled|Quality|DownscaleProtection=<value>"":
            Sets the VRDP video redirection properties.
          
                For VideoChannel/Enabled, <value> can be set to
                ""1"", switching the VRDP video channel on. See
                Section 7.1.9, “VRDP Video Redirection”.
              
                For VideoChannel/Quality, <value> should be set
                between 10 and 100% inclusive, representing a JPEG
                compression level on the VRDE server video channel.
                Lower values mean lower quality but higher compression.
                See Section 7.1.9, “VRDP Video Redirection”.
              
                For VideoChannel/DownscaleProtection, <value> can
                be set to ""1"" to enable the videochannel downscale
                protection feature. When enabled, if a video's size
                equals the shadow buffer size, then it is regarded as a
                full screen video, and is displayed. But if its size is
                between fullscreen and the downscale threshold then it
                is not displayed, as it could be an
                application window, which would be unreadable when
                downscaled. When the downscale protection feature is
                disabled, an attempt is always made to display videos.
              
--vrdeproperty
            ""Client/DisableDisplay|DisableInput|DisableAudio|DisableUSB=1"":
            Disables one of the VRDE server features: Display, Input,
            Audio or USB respectively. To reenable a feature, use
            ""Client/DisableDisplay="" for example. See
            Section 7.1.10, “VRDP Customization”.
          
--vrdeproperty
            ""Client/DisableClipboard|DisableUpstreamAudio=1"":
            Disables one of the VRDE server features: Clipboard or
            UpstreamAudio respectively. To reenable a feature, use
            ""Client/DisableClipboard="" for example. See
            Section 7.1.10, “VRDP Customization”.
          
--vrdeproperty
            ""Client/DisableRDPDR=1"": Disables the VRDE
            server feature: RDP device redirection for smart cards. To
            reenable this feature, use ""Client/DisableRDPR="".
          
--vrdeproperty
            ""H3DRedirect/Enabled=1"": Enables the VRDE
            server feature: 3D redirection. To disable this feature, use
            ""H3DRedirect/Enabled="".
          
--vrdeproperty
            ""Security/Method|ServerCertificate|ServerPrivateKey|CACertificate=<value>"":
            Sets the desired security method and path of server
            certificate, path of server private key, path of CA
            certificate, that are used for a connection.
          
--vrdeproperty
                ""Security/Method=<value>"" sets
                the desired security method, which is used for a
                connection. Valid values are:
              
Negotiate: Both
                    Enhanced (TLS) and Standard RDP Security connections
                    are allowed. The security method is negotiated with
                    the client. This is the default setting.
                  
RDP: Only Standard
                    RDP Security is accepted.
                  
TLS: Only Enhanced
                    RDP Security is accepted. The client must support
                    TLS.
                  
                See Section 7.1.6, “RDP Encryption”.
              
--vrdeproperty
                ""Security/ServerCertificate=<value>""
                where <value> is the absolute path of the server
                certificate. See Section 7.1.6, “RDP Encryption”.
              
--vrdeproperty
                ""Security/ServerPrivateKey=<value>""
                where <value> is the absolute path of the server
                private key. See Section 7.1.6, “RDP Encryption”.
              
--vrdeproperty
                ""Security/CACertificate=<value>""
                where <value> is the absolute path of the CA self
                signed certificate. See Section 7.1.6, “RDP Encryption”.
              
--vrdeproperty
            ""Audio/RateCorrectionMode|LogPath=<value>""
            sets the audio connection mode, or path of the audio
            logfile.
          
--vrdeproperty
                ""Audio/RateCorrectionMode=<value>""
                where <value> is the desired rate correction mode.
                Allowed values are:
              
VRDP_AUDIO_MODE_VOID:
                    No mode specified, use to unset any Audio mode
                    already set.
                  
VRDP_AUDIO_MODE_RC:
                    Rate correction mode.
                  
VRDP_AUDIO_MODE_LPF:
                    Low pass filter mode.
                  
VRDP_AUDIO_MODE_CS:
                    Client sync mode to prevent underflow or overflow of
                    the client queue.
                  
--vrdeproperty
                ""Audio/LogPath=<value>"" where
                <value> is the absolute path of the Audio log
                file.
              
--vrdeextpack
            default|<name>: Specifies the library
            to use for accessing the VM remotely. The default is to use
            the RDP code which is part of the Oracle VM VirtualBox Extension
            Pack.
          
--vrdeport
            default|<ports>: A port or a range of
            ports the VRDE server can bind to.
            default or
            0 means port 3389, the
            standard port for RDP. You can specify a comma-separated
            list of ports or ranges of ports. Use a dash between two
            port numbers to specify a range. The VRDE server will bind
            to one of the available ports from the
            specified list. Only one machine can use a given port at a
            time. For example, the option  --vrdeport
            5000,5010-5012 will tell the server to bind
            to one of following ports: 5000, 5010, 5011, or 5012.
          
--vrdeaddress <IP
            address>: The IP address of the host
            network interface the VRDE server will bind to. If
            specified, the server will accept connections only on the
            specified host network interface.
          
            The setting can be used to specify whether the VRDP server
            should accept either IPv4, IPv6, or both connections:
          
                Only IPv4: --vrdeaddress
                ""0.0.0.0""

                Only IPv6: --vrdeaddress
                ""::""

                Both IPv6 and IPv4: --vrdeaddress
                """"

                This is the default setting.
              
--vrdeauthtype
            null|external|guest: Enables you to
            indicate use of authorization, and specify how authorization
            will be performed. See Section 7.1.5, “RDP Authentication”.
          
--vrdeauthlibrary
            default|<name>: Specifies the library
            used for RDP authentication. See
            Section 7.1.5, “RDP Authentication”.
          
--vrdemulticon on|off:
            Enables multiple connections to be made to the same VRDE
            server, if the server supports this feature. See
            Section 7.1.7, “Multiple Connections to the VRDP Server”.
          
--vrdereusecon on|off: This
            specifies the VRDE server behavior when multiple connections
            are disabled. When this option is enabled, the server will
            allow a new client to connect and will drop the existing
            connection. When this option is disabled, the default
            setting, a new connection will not be accepted if there is
            already a client connected to the server.
          
--vrdevideochannel on|off:
            Enables video redirection, if it is supported by the VRDE
            server. See Section 7.1.9, “VRDP Video Redirection”.
          
--vrdevideochannelquality
            <percent>: Specifies the image
            quality for video redirection. See
            Section 7.1.9, “VRDP Video Redirection”.
          8.8.6. Teleporting Settings
        With the following commands for VBoxManage
        modifyvm you can configure a machine to be a target
        for teleporting. See Section 7.2, “Teleporting”.
      
--teleporter on|off:
            Enables and disables the teleporter feature whereby when the
            machine is started, it waits to receive a teleporting
            request from the network instead of booting normally.
            Teleporting requests are received on the port and address
            specified using the following parameters.
          
--teleporterport
            <port>,
            --teleporteraddress
            <address>: These settings must be
            used with --teleporter.
            They specify the port and address the virtual machine should
            listen to in order to receive a teleporting request sent
            from another virtual machine.
            <port> can be any
            free TCP/IP port number, such as 6000.
            <address> can be any
            IP address or hostname and specifies the TCP/IP socket to
            bind to. The default is 0.0.0.0, which means any address.
          
--teleporterpassword
            <password>: If this optional setting
            is used, then the teleporting request will only succeed if
            the source machine specifies the same password as the one
            given with this command.
          
--teleporterpasswordfile
            <password>: If this optional setting
            is used, then the teleporting request will only succeed if
            the source machine specifies the same password as the one
            specified in the file give with this command. Use
            stdin to read the password
            from stdin.
          
--cpuid <leaf> <eax> <ebx>
            <ecx> <edx>: Advanced users can
            use this setting before a teleporting operation, to restrict
            the virtual CPU capabilities that Oracle VM VirtualBox presents to
            the guest operating system. This must be run on both the
            source and the target machines involved in the teleporting
            and will then modify what the guest sees when it executes
            the CPUID machine
            instruction. This might help with misbehaving applications
            that wrongly assume that certain CPU capabilities are
            present. The meaning of the parameters is hardware
            dependent, refer to the AMD or Intel processor
            documentation.
          8.8.7. Debugging Settings
        The following settings are only relevant for low-level VM
        debugging. Regular users will never need these settings.
      
--tracing-enabled on|off:
            Enables the tracebuffer. This consumes some memory for the
            tracebuffer and adds extra overhead.
          
--tracing-config
            <config-string>: Enables tracing
            configuration. In particular, this defines which group of
            tracepoints are enabled.
          
--tracing-allow-vm-access
            on|off: Enables and disables VM access to
            the tracebuffer. By default, this setting is disabled.
          8.8.8. USB Card Reader Settings
        The following setting defines access to a USB Card Reader by the
        guest environment. USB card readers are typically used for
        accessing data on memory cards such as CompactFlash (CF), Secure
        Digital (SD), or MultiMediaCard (MMC).
      
--usbcardreader on|off:
            Enables and disables the USB card reader interface.
          8.8.9. Autostarting VMs During Host System Boot
        These settings configure the VM autostart feature, which
        automatically starts the VM at host system boot-up. Note that
        there are prerequisites that need to be addressed before using
        this feature. See Section 9.21, “Starting Virtual Machines During System Boot”.
      
--autostart-enabled on|off:
            Enables and disables VM autostart at host system boot-up,
            using the specified user name.
          
--autostart-delay
            <seconds>: Specifies a delay, in
            seconds, following host system boot-up, before the VM
            autostarts.
          8.9. VBoxManage movevm
      This command moves a virtual machine to a new location on the
      host.
    
      Associated files of the virtual machine, such as settings files
      and disk image files, are moved to the new location. The
      Oracle VM VirtualBox configuration is updated automatically.
    
      The movevm subcommand requires the name of the
      virtual machine which should be moved.
    
      Also required is the type of move operation, specified by
      --type basic. Other types of move
      operation may be supported in future releases.
    
      The --folder setting configures
      the new location on the host file system. Enter a relative
      pathname or a full pathname.
    8.10. VBoxManage import
      This command imports one or more virtual machines into
      Oracle VM VirtualBox. You can import from either of the following:
    
          A virtual appliance in OVF format.
        
          A cloud service, such as Oracle Cloud Infrastructure. Only a single cloud instance
          can be imported.
        
      See Section 1.14, “Importing and Exporting Virtual Machines” for more details on importing VMs into
      Oracle VM VirtualBox.
    8.10.1. Import from OVF
        The import subcommand takes at least the path
        name of an OVF file as input and expects the disk images, if
        needed, to be in the same directory as the OVF file. Many
        additional command-line options are supported. These enable you
        to control in detail what is being imported and to modify the
        import parameters, depending on the content of the OVF file.
      
        It is therefore recommended to first run the
        import subcommand with the
        --dry-run or
        -n option. This will then print
        a description of the appliance's contents to the screen how it
        would be imported into Oracle VM VirtualBox, together with the
        optional command-line options to influence the import behavior.
      
        Use of the --options
        keepallmacs|keepnatmacs|keepdisknames option
        enables additional fine tuning of the import operation. The
        first two options enable you to specify how the MAC addresses of
        every virtual network card should be handled. They can either be
        reinitialized, which is the default setting, left unchanged
        (keepallmacs) or left unchanged
        when the network type is NAT
        (keepnatmacs). If you add
        keepdisknames all new disk
        images are assigned the same names as the originals, otherwise
        they are renamed.
      
        As an example, the following is a screen output for a sample
        appliance containing a Windows XP guest:
      VBoxManage import WindowsXp.ovf --dry-run
      Interpreting WindowsXp.ovf...
      OK.
      Virtual system 0:
       0: Suggested OS type: ""WindowsXP""
          (change with ""--vsys 0 --ostype <type>""; use ""list ostypes"" to list all)
       1: Suggested VM name ""Windows XP Professional_1""
          (change with ""--vsys 0 --vmname <name>"")
       2: Suggested VM group ""/""
          (change with ""--vsys 0 --group <group>"")
       3: Suggested VM settings file name ""/home/klaus/VirtualBox VMs/dummy2 2/dummy2 2.vbox""
          (change with ""--vsys 0 --settingsfile <filename>"")
       4: Suggested VM base folder ""/home/klaus/VirtualBox VMs""
          (change with ""--vsys 0 --basefolder <path>"")
       5: End-user license agreement
          (display with ""--vsys 0 --eula show"";
          accept with ""--vsys 0 --eula accept"")
       6: Number of CPUs: 1
          (change with ""--vsys 0 --cpus <n>"")
       7: Guest memory: 956 MB (change with ""--vsys 0 --memory <MB>"")
       8: Sound card (appliance expects ""ensoniq1371"", can change on import)
          (disable with ""--vsys 0 --unit 5 --ignore"")
       9: USB controller
          (disable with ""--vsys 0 --unit 6 --ignore"")
      10: Network adapter: orig bridged, config 2, extra type=bridged
      11: Floppy
          (disable with ""--vsys 0 --unit 8 --ignore"")
      12: SCSI controller, type BusLogic
          (change with ""--vsys 0 --unit 9 --scsitype {BusLogic|LsiLogic}"";
          disable with ""--vsys 0 --unit 9 --ignore"")
      13: IDE controller, type PIIX4
          (disable with ""--vsys 0 --unit 10 --ignore"")
      14: Hard disk image: source image=WindowsXp.vmdk,
            target path=/home/user/disks/WindowsXp.vmdk, controller=9;channel=0
          (change controller with ""--vsys 0 --unit 11 --controller <id>"";
          disable with ""--vsys 0 --unit 11 --ignore"")
        The individual configuration items are numbered, and depending
        on their type support different command-line options. The import
        subcommand can be directed to ignore many such items with a
        --vsys X --unit Y --ignore
        option, where X is the number of the virtual system and Y the
        item number, as printed on the screen. X is zero, unless there
        are several virtual system descriptions in the appliance.
      
        In the above example, Item #1 specifies the name of the target
        machine in Oracle VM VirtualBox. Items #12 and #13 specify hard disk
        controllers, respectively. Item #14 describes a hard disk image.
        In this case, the additional
        --controller option indicates
        which item the disk image should be connected to, with the
        default coming from the OVF file.
      
        You can combine several items for the same virtual system using
        the --vsys option. For example,
        to import a machine as described in the OVF, but without the
        sound card and without the USB controller, and with the disk
        image connected to the IDE controller instead of the SCSI
        controller, use the following command:
      VBoxManage import WindowsXp.ovf
  --vsys 0 --unit 8 --ignore --unit 9 --ignore --unit 14 --controller 138.10.2. Import from Oracle Cloud Infrastructure
        As the result of this operation, a file with the suffix
        .oci is downloaded to the local host. This
        file is a TAR archive which contains a bootable instance image
        in QCOW2 format and a JSON file with some metadata related to
        the imported instance.
      
        The downloaded file is deleted after a successful import. If
        import fails, the downloaded file may not be deleted and the
        VBoxSVC log file may indicate the location where the file was
        stored.
      
        During import the bootable image is extracted from the archive
        and converted into VMDK format. The JSON file is also extracted
        and stored in the VM machine folder.
      
        The command syntax for importing an Oracle Cloud Infrastructure instance begins with
        VBoxManage import OCI:// --cloud.
      
        You can list the available Oracle Cloud Infrastructure VM instances and their IDs by
        using the following command:
      VBoxManage cloud --provider=OCI --profile=cloud-profile-name list instances
        To import a VM from a cloud service such as Oracle Cloud Infrastructure, use the
        --cloud option to specify the import from the
        Cloud. Some of the following options are settings for the VM,
        for others you must enter an Oracle Cloud Identifier (OCID) for
        a resource. Use the Oracle Cloud Infrastructure Console to view
        OCIDs.
      
        The following parameters can be specified:
      
--vmname: Specifies a new name for the
            imported VM. This name is used as the VM name by
            Oracle VM VirtualBox.
          
--cloudinstanceid: The ID of an existing
            instance in the Cloud.
          
--cloudprofile: Specifies the cloud profile
            that is used to connect to the cloud service provider. The
            cloud profile contains your Oracle Cloud Infrastructure account details, such as
            your user OCID and the fingerprint for your public key. To
            use a cloud profile, you must have the required permissions
            on Oracle Cloud Infrastructure.
          
--cloudbucket: Specifies the bucket name in
            which to store the object created from an instance bootable
            volume. In Oracle Cloud Infrastructure, a bucket is a logical container for
            storing objects.
          
        The following import options have the same meaning as for OVF
        import:
      
--ostype: An OS type supported by
            Oracle VM VirtualBox. Use the VBoxManage list
            ostypes command to see the whole list of supported
            OSes. If the type was not set, the
            Unknown type is used.
          
--basefolder: The folder where the new VM
            is stored.
          
--description: A string describing the VM.
          
--memory: The amount of RAM memory assigned
            for the VM, in MB. If this option is not set either the
            default memory size for the OS type is used, or the value is
            taken from the Oracle Cloud Infrastructure instance.
          
--cpus: the number of virtual CPUs assigned
            for the VM. If this option is not set, either the default
            virtual CPUs setting for the OS type is used, or the value
            is taken from the Oracle Cloud Infrastructure instance.
          
        The import options --disk,
        --controller, --scsitype,
        --unit, --settingsfile are not
        valid for cloud import.
      
        The following example shows a typical command line for importing
        an instance from Oracle Cloud Infrastructure:
      # VBoxManage import OCI:// --cloud --vmname import_from_oci --memory 4000
  --cpus 3 --ostype FreeBSD_64 --cloudprofile ""standard user""
  --cloudinstanceid ocid1.instance.oc1.iad.abuwc... --cloudbucket myBucket8.11. VBoxManage export
      This command exports one or more virtual machines from
      Oracle VM VirtualBox. You can export to either of the following:
    
          A virtual appliance in OVF format, including copying their
          virtual disk images to compressed VMDK.
        
          A cloud service, such as Oracle Cloud Infrastructure. A single VM can be exported in
          VMDK format.
        
      See Section 1.14, “Importing and Exporting Virtual Machines” for more details on exporting VMs from
      Oracle VM VirtualBox.
    8.11.1. Export to OVF
        List the machine, or the machines, that you would like to export
        to the same OVF file and specify the target OVF file after an
        additional --output or
        -o option. Note that the
        directory of the target OVF file will also receive the exported
        disk images in the compressed VMDK format, regardless of the
        original format, and should have enough disk space left for
        them.
      
        Beside a simple export of a given virtual machine, you can
        append several product information to the appliance file. Use
        --product,
        --producturl,
        --vendor,
        --vendorurl,
        --version and
        --description to specify this
        additional information. For legal reasons you may add a license
        text or the content of a license file by using the
        --eula and
        --eulafile option respectively.
      
        As with OVF import, you use the --vsys
        X option to apply these options to the correct
        virtual machine.
      
        For virtualization products which are not fully compatible with
        the OVF standard 1.0 you can enable an OVF 0.9 legacy mode with
        the --legacy09 option. Other
        options are --ovf09,
        --ovf10,
        --ovf20.
      
        To specify options controlling the exact content of the
        appliance file, you can use --options to
        request the creation of a manifest file, which enables detection
        of corrupted appliances on import, the additional export of DVD
        images, and the exclusion of MAC addresses. You can specify a
        list of options, such as --options
        manifest,nomacs. For details, check the help output of
        VBoxManage export.
      8.11.2. Export to Oracle Cloud Infrastructure
        By default, an exported disk image is converted into stream VMDK
        format. This ensures compatibility with Oracle Cloud Infrastructure.
      
        List the machine that you want to export to Oracle Cloud Infrastructure and specify
        the target cloud service provider by using the
        --output or
        -o option.
      
        To export a VM to a cloud service such as Oracle Cloud Infrastructure, use the
        --cloud option to specify the VM to export.
        This option works in the same way as the --vsys
        option for OVF export.
      
        Some of the following options are settings for the VM instance.
        As a result, you must enter an Oracle Cloud Identifier (OCID)
        for a resource. Use the Oracle Cloud Infrastructure Console to view OCIDs.
      
--output/-o: Specifies the short name of
            the cloud service provider to which you export. For Oracle Cloud Infrastructure,
            enter OCI://.
          
--cloud
number-of-virtual-system:
            Specifies a number that identifies the VM that you are
            exporting. Numbering starts at
            0 for the first VM.
          
--vmname name:
            Specifies the name of the exported VM. This name is used as
            the VM instance name in Oracle Cloud Infrastructure.
          
--cloudprofile
cloud-profile-name: Specifies the
            cloud profile that is used to connect to the cloud service
            provider. The cloud profile contains your Oracle Cloud Infrastructure account
            details, such as your user OCID and the fingerprint for your
            public key. See Section 1.14.5, “Exporting an Appliance to Oracle Cloud Infrastructure”.
          
            To use a cloud profile, you must have the required
            permissions on Oracle Cloud Infrastructure.
          
--cloudshape
shape: Specifies the shape used
            for the VM instance. The shape defines the number of CPUs
            and the amount of memory allocated to the VM instance. The
            shape must be compatible with the exported image.
          
--clouddomain
domain: Specifies the
            availability domain to use for the VM instance. Enter the
            full name of the availability domain.
          
--clouddisksize
disk-size-in-GB: Specifies the
            disk size used for the exported disk image in gigabytes. The
            minimum value is 50 GB and the maximum value is 300 GB.
          
--cloudbucket
bucket-name: Specifies the bucket
            in which to store the uploaded files. In Oracle Cloud Infrastructure, a bucket is
            a logical container for storing objects.
          
--cloudocivcn
OCI-vcn-ID: Specifies the virtual
            cloud network (VCN) to use for the VM instance. Enter the
            OCID for the VCN.
          
--cloudocisubnet
OCI-subnet-ID: Specifies the
            subnet of the VCN to use for the VM instance. Enter the OCID
            for the subnet.
          
--cloudkeepobject true | false: Specifies
            whether to store the exported disk image in Oracle Object
            Storage.
          
--cloudlaunchinstance true | false:
            Specifies whether to start the VM instance after the export
            to Oracle Cloud Infrastructure completes.
          
--cloudpublicip true | false: Specifies
            whether to enable a public IP address for the VM instance.
          
        The following example shows a typical command line for exporting
        a VM to Oracle Cloud Infrastructure.
      # VBoxManage export myVM --output OCI:// --cloud 0 --vmname myVM_Cloud \
--cloudprofile ""standard user"" --cloudbucket myBucket \
--cloudshape VM.Standard2.1 --clouddomain US-ASHBURN-AD-1 --clouddisksize 50  \
--cloudocivcn ocid1.vcn.oc1.iad.aaaa... --cloudocisubnet ocid1.subnet.oc1.iad.aaaa... \
--cloudkeepobject true --cloudlaunchinstance true --cloudpublicip true8.12. VBoxManage startvm
      This command starts a virtual machine that is currently in the
      Powered Off or Saved states.
    
      The optional --type specifier
      determines whether the machine will be started in a window or
      whether the output should go through
      VBoxHeadless, with VRDE enabled or not. See
      Section 7.1.2, “VBoxHeadless, the Remote Desktop Server”. The list of types is subject to
      change, and it is not guaranteed that all types are accepted by
      any product variant.
    
      The global or per-VM default value for the VM frontend type will
      be taken if the type is not explicitly specified. If none of these
      are set, the GUI variant will be started.
    
      The following values are allowed:
    
gui

            Starts a VM showing a GUI window. This is the default.
          
headless

            Starts a VM without a window for remote display only.
          
separate

            Starts a VM with a detachable UI. Technically, it is a
            headless VM with user interface in a separate process. This
            is an experimental feature as it lacks certain
            functionality, such as 3D acceleration.
          Note
        If you experience problems with starting virtual machines with
        particular frontends and there is no conclusive error
        information, consider starting virtual machines directly by
        running the respective front-end, as this can give additional
        error information.
      8.13. VBoxManage controlvm
      The controlvm subcommand enables you to change
      the state of a virtual machine that is currently running. The
      following can be specified:
    
VBoxManage controlvm <vm> pause:
          Temporarily puts a virtual machine on hold, without
          permanently changing its state. The VM window is gray, to
          indicate that the VM is currently paused. This is equivalent
          to selecting the Pause item
          in the Machine menu of the
          GUI.
        
          Use VBoxManage controlvm <vm> resume:
          Undoes a previous pause command. This is
          equivalent to selecting the
          Resume item in the
          Machine menu of the GUI.
        
VBoxManage controlvm <vm> reset: Has
          the same effect on a virtual machine as pressing the Reset
          button on a real computer. A cold reboot of the virtual
          machine is done, which immediately restarts and reboots the
          guest operating system. The state of the VM is not saved
          beforehand, and data may be lost. This is equivalent to
          selecting the Reset item in
          the Machine menu of the GUI.
        
VBoxManage controlvm <vm> poweroff:
          Has the same effect on a virtual machine as pulling the power
          cable on a real computer. The state of the VM is not saved
          beforehand, and data may be lost. This is equivalent to
          selecting the Close item in
          the Machine menu of the GUI,
          or clicking the VM window's close button, and then selecting
          Power Off the Machine in the
          displayed dialog.
        
          After this, the VM's state will be Powered Off. From that
          state, it can be started again. See
          Section 8.12, “VBoxManage startvm”.
        
VBoxManage controlvm <vm> savestate:
          Saves the current state of the VM to disk and then stops the
          VM. This is equivalent to selecting the
          Close item in the
          Machine menu of the GUI or
          clicking the VM window's close button, and then selecting
          Save the Machine State in the
          displayed dialog.
        
          After this, the VM's state will be Saved. From this state, it
          can be started again. See
          Section 8.12, “VBoxManage startvm”.
        
VBoxManage controlvm <vm>
          acpipowerbutton: Sends an ACPI shutdown signal to
          the VM, as if the power button on a real computer had been
          pressed. So long as the VM is running a fairly modern guest
          operating system providing ACPI support, this should trigger a
          proper shutdown mechanism from within the VM.
        
VBoxManage controlvm <vm> keyboardputscancode
          <hex> [<hex>...]: Sends commands using
          keycodes to the VM. Keycodes are documented in the public
          domain. For example:
          http://www.win.tue.nl/~aeb/linux/kbd/scancodes-1.html.
        
VBoxManage controlvm ""VM name"" teleport --hostname
          <name> --port <port> [--passwordfile <file>
          | --password <password>]: Makes the machine
          the source of a teleporting operation and initiates a teleport
          to the given target. See Section 7.2, “Teleporting”. If
          the optional password is specified, it must match the password
          that was given to the modifyvm command for
          the target machine. See
          Section 8.8.6, “Teleporting Settings”.
        
      The following extra options are available with
      controlvm that do not directly affect the VM's
      running state:
    
setlinkstate<1-N>
          on|off: Connects or disconnects virtual
          network cables from their network interfaces.
        
nic<1-N>
          null|nat|bridged|intnet|hostonly|generic|natnetwork[<devicename>]:
          Specifies the type of networking that should be made available
          on the specified VM virtual network card. They available types
          are: not connected to the host
          (null), use network address
          translation (nat), bridged
          networking (bridged),
          communicate with other virtual machines using internal
          networking (intnet),
          host-only networking
          (hostonly), natnetwork
          networking (natnetwork), or
          access to rarely used submodes
          (generic). These options
          correspond to the modes which are described in detail in
          Section 6.2, “Introduction to Networking Modes”.
        
          With the nictrace options,
          you can optionally trace network traffic by dumping it to a
          file, for debugging purposes.
        
nictrace<1-N> on|off:
          Enables network tracing for a particular virtual network card.
        
          Before enabling you should specify a file name to which the
          trace should be logged. This can be done with the
          nictracefile<1-N>
          <filename> option to
          VBoxManage controlvm at runtime or with the
          <filename> option to
          VBoxManage modifyvm otherwise.
        
nicpromisc<1-N>
          deny|allow-vms|allow-all: Specifies how the
          promiscious mode is handled for the specified VM virtual
          network card. This setting is only relevant for bridged
          networking. The default setting of
          deny hides any traffic not
          intended for this VM.
          allow-vms hides all host
          traffic from this VM but enables the VM to see traffic to and
          from other VMs. allow-all
          removes this restriction completely.
        
nicproperty<1-N>
          <paramname>=""paramvalue"": This option,
          in combination with
          nicgenericdrv enables you to
          pass parameters to rarely-used network backends.
        
          Those parameters are backend engine-specific, and are
          different between UDP Tunnel and the VDE backend drivers. See
          Section 6.8, “UDP Tunnel Networking”.
        
natpf<1-N>
          [<name>],tcp|udp,[<hostip>],<hostport>,[<guestip>],
          <guestport>: Specifies a NAT
          port-forwarding rule. See Section 6.3.1, “Configuring Port Forwarding with NAT”.
        
natpf<1-N> delete
          <name>: Deletes a NAT port-forwarding
          rule. See Section 6.3.1, “Configuring Port Forwarding with NAT”.
        
          The guestmemoryballoon<balloon size in
          MB>: Changes the size of the guest memory
          balloon. This is the memory allocated by the Oracle VM VirtualBox
          Guest Additions from the guest operating system and returned
          to the hypervisor for reuse by other virtual machines. This
          must be specified in megabytes. See
          Section 4.10.1, “Memory Ballooning”.
        
usbattach<uuid|address> [--capturefile
          <filename>]

          and usbdetach <uuid|address>
          [--capturefile <filename>]: Makes host
          USB devices visible or invisible to the virtual machine on the
          fly, without the need for creating filters first. The USB
          devices can be specified by UUID (unique identifier) or by
          address on the host system. Use the
          --capturefile option to
          specify the absolute path of a file for writing activity
          logging data.
        
          You can use VBoxManage list usbhost to
          locate this information.
        
audioin on: Selects whether
          capturing audio from the host is enabled or disabled.
        
audioout on: Selects whether
          audio playback from the guest is enabled or disabled.
        
clipboard mode
          disabled|hosttoguest|guesttohost|bidirectional:
          Selects how the guest or host operating system's clipboard
          should be shared with the host or guest. See
          Section 3.4, “General Settings”. This requires that the
          Guest Additions be installed in the virtual machine.
        
clipboard filetransfers
          enabled|disabled: Specifies if clipboard file
          transfers are allowed between host and guest OSes or not.
        
draganddrop
          disabled|hosttoguest|guesttohost|bidirectional:
          Selects the current drag and drop mode being used between the
          host and the virtual machine. See
          Section 4.4, “Drag and Drop”. This requires that the Guest
          Additions be installed in the virtual machine.
        
vrde on|off: Enables and
          disables the VRDE server, if it is installed.
        
vrdeport
          default|<ports>: Changes the port or a
          range of ports that the VRDE server can bind to.
          default or
          0 means port 3389, the
          standard port for RDP. See the description for the
          --vrdeport option in
          Section 8.8.5, “Remote Machine Settings”.
        
vrdeproperty
          ""TCP/Ports|Address=<value>"": Sets the
          port numbers and IP address on the VM to which the VRDE server
          can bind.
        
              For TCP/Ports, <value> should be a port or a range
              of ports to which the VRDE server can bind.
              default or
              0 means port 3389, the
              standard port for RDP. See the description for the
              --vrdeport option in
              Section 8.8.5, “Remote Machine Settings”.
            
              For TCP/Address, <value>: The IP address of the host
              network interface that the VRDE server will bind to. If
              specified, the server will accept connections only on the
              specified host network interface. See the description for
              the --vrdeaddress option
              in
              Section 8.8.5, “Remote Machine Settings”.
            
vrdeproperty
          ""VideoChannel/Enabled|Quality|DownscaleProtection=<value>"":
          Sets the VRDP video redirection properties.
        
              For VideoChannel/Enabled, <value> can be set to ""1""
              switching the VRDP video channel on. See
              Section 7.1.9, “VRDP Video Redirection”.
            
              For VideoChannel/Quality, <value> should be set
              between 10 and 100% inclusive, representing a JPEG
              compression level on the VRDE server video channel. Lower
              values mean lower quality but higher compression. See
              Section 7.1.9, “VRDP Video Redirection”.
            
              For VideoChannel/DownscaleProtection, <value> can be
              set to ""1"" to enable the videochannel downscale protection
              feature. When enabled, if a video's size equals the shadow
              buffer size, then it is regarded as a full screen video,
              and is displayed. If its size is between fullscreen and
              the downscale threshold it is not displayed, as it could
              be an application window, which would be unreadable when
              downscaled. When the downscale protection feature is
              disabled, an attempt is always made to display videos.
            
vrdeproperty
          ""Client/DisableDisplay|DisableInput|DisableAudio|DisableUSB=1"":
          Disables one of the VRDE server features: Display, Input,
          Audio, or USB. To reenable a feature, use
          ""Client/DisableDisplay="" for example. See
          Section 7.1.10, “VRDP Customization”.
        
vrdeproperty
          ""Client/DisableClipboard|DisableUpstreamAudio=1"".
          Disables one of the VRDE server features: Clipboard or
          UpstreamAudio. To reenable a feature, use
          ""Client/DisableClipboard="" for example. See
          Section 7.1.10, “VRDP Customization”.
        
vrdeproperty
          ""Client/DisableRDPDR=1"": Disables the VRDE
          server feature: RDP device redirection for smart cards. To
          reenable this feature, use ""Client/DisableRDPR="".
        
vrdeproperty
          ""H3DRedirect/Enabled=1"": Enables the VRDE
          server feature: 3D redirection. To disable this feature, use
          ""H3DRedirect/Enabled="".
        
vrdeproperty
          ""Security/Method|ServerCertificate|ServerPrivateKey|CACertificate=<value>"":
          Sets the desired security method, path of the server
          certificate, path of the server private key, and path of CA
          certificate, used for a connection.
        
vrdeproperty
              ""Security/Method=<value>"": Sets the
              desired security method, which is used for a connection.
              Valid values are as follows:
            
Negotiate: Both
                  Enhanced (TLS) and Standard RDP Security connections
                  are allowed. The security method is negotiated with
                  the client. This is the default setting.
                
RDP: Only Standard
                  RDP Security is accepted.
                
TLS: Only Enhanced
                  RDP Security is accepted. The client must support TLS.
                
              See Section 7.1.6, “RDP Encryption”.
            
vrdeproperty
              ""Security/ServerCertificate=<value>""
              where <value> is the absolute path of the server
              certificate. See Section 7.1.6, “RDP Encryption”.
            
vrdeproperty
              ""Security/ServerPrivateKey=<value>""
              where <value> is the absolute path of the server
              private key. See Section 7.1.6, “RDP Encryption”.
            
vrdeproperty
              ""Security/CACertificate=<value>""
              where <value> is the absolute path of the CA self
              signed certificate. See Section 7.1.6, “RDP Encryption”.
            
vrdeproperty
          ""Audio/RateCorrectionMode|LogPath=<value>"":
          Sets the audio connection mode, or path of the audio logfile.
        
vrdeproperty
              ""Audio/RateCorrectionMode=<value>""
              where <value> is the desired rate correction mode,
              allowed values are:
            
VRDP_AUDIO_MODE_VOID:
                  No mode specified, use to unset any Audio mode already
                  set.
                
VRDP_AUDIO_MODE_RC:
                  Rate correction mode.
                
VRDP_AUDIO_MODE_LPF:
                  Low pass filter mode.
                
VRDP_AUDIO_MODE_CS:
                  Client sync mode to prevent underflow or overflow of
                  the client queue.
                
vrdeproperty
              ""Audio/LogPath=<value>"" where
              <value> is the absolute path of the audio log file.
            
vrdevideochannelquality
          <percent>: Sets the image quality for
          video redirection. See Section 7.1.9, “VRDP Video Redirection”.
        
setvideomodehint: Requests
          that the guest system change to a particular video mode. This
          requires that the Guest Additions be installed, and will not
          work for all guest systems.
        
screenshotpng: Takes a
          screenshot of the guest display and saves it in PNG format.
        
recording on|off enables or
          disables the recording of a VM session into a WebM/VP8 file.
          When this option value is on,
          recording begins when the VM session starts.
        
recordingscreens
          all|screen-ID
          [screen-ID ...]
          enables you to specify which VM screens to record. The
          recording for each screen that you specify is saved to its own
          file. You cannot modify this setting while recording is
          enabled.
        
recordingfile
          filename specifies
          the file in which to save the recording. You cannot modify
          this setting while recording is enabled.
        
recordingvideores
          widthxheight
          specifies the resolution of the recorded video in pixels. You
          cannot modify this setting while recording is enabled.
        
recordingvideorate
          bit-rate specifies
          the bit rate of the video in kilobits per second. Increasing
          this value improves the appearance of the video at the cost of
          an increased file size. You cannot modify this setting while
          recording is enabled.
        
recordingvideofps
          fps specifies the
          maximum number of video frames per second (FPS) to record.
          Frames that have a higher frequency are skipped. Increasing
          this value reduces the number of skipped frames and increases
          the file size. You cannot modify this setting while recording
          is enabled.
        
recordingmaxtime
          seconds specifies
          the maximum amount time to record in seconds. The recording
          stops after the specified number of seconds elapses. If this
          value is zero, the recording continues until you stop the
          recording.
        
recordingmaxsize
          MB specifies the
          maximum size of the recorded video file in megabytes. The
          recording stops when the file reaches the specified size. If
          this value is zero, the recording continues until you stop the
          recording. You cannot modify this setting while recording is
          enabled.
        
recordingopts
          keyword=value[,keyword=value
          ...] specifies additional recording options
          in a comma-separated keyword-value format. For example,
          foo=bar,a=b. You cannot
          modify this setting while recording is enabled.
        
          Only use this option only if you are an advanced user. For
          information about keywords, see Oracle VM VirtualBox
          Programming Guide and Reference.
        
setcredentials: Used for
          remote logins on Windows guests. See
          Section 9.1, “Automated Guest Logins”.
        
teleport --host <name> --port
          <port>: Configures a VM as a target for
          teleporting. <name> specifies the virtual machine name.
          <port> specifies the port on the virtual machine which
          should listen for teleporting requests from other virtual
          machines. It can be any free TCP/IP port number, such as 6000.
          See Section 7.2, “Teleporting”.
        
--maxdowntime
              <msec>: Specifies the maximum
              downtime, in milliseconds, for the teleporting target VM.
              Optional.
            
--password
              <password>: The teleporting request
              will only succeed if the source machine specifies the same
              password as the one given with this command. Optional.
            
--passwordfile <password
              file>: The teleporting request will
              only succeed if the source machine specifies the same
              password as the one specified in the password file with
              the path specified with this command. Use
              stdin to read the
              password from stdin. Optional.
            
plugcpu|unplugcpu <id>:
          If CPU hot-plugging is enabled, this setting adds and removes
          a virtual CPU to the virtual machine.
          <id> specifies the
          index of the virtual CPU to be added or removed and must be a
          number from 0 to the maximum number of CPUs configured. CPU 0
          can never be removed.
        
          The cpuexecutioncap
          <1-100>: Controls how much CPU time a
          virtual CPU can use. A value of 50 implies a single virtual
          CPU can use up to 50% of a single host CPU.
        
vm-process-priority
          default|flat|low|normal|high: Changes the
          priority scheme of the VM process. See
          Section 8.12, “VBoxManage startvm”.
        
webcam attach <path|alias>
          [<keyword=value>[;<keyword=value>...]]:
          Attaches a webcam to a running VM. Specify the absolute path
          of the webcam on the host operating system, or use its alias,
          obtained by using the command: VBoxManage list
          webcams.
        
          Note that alias '.0' means the default video input device on
          the host operating system, '.1', '.2', etc. mean first,
          second, etc. video input device. The device order is
          host-specific.
        
          The optional settings parameter is a
          ; delimited list of
          name-value pairs, enabling configuration of the emulated
          webcam device.
        
          The following settings are supported:
        
          MaxFramerate: Specifies the highest rate in frames per second,
          at which video frames are sent to the guest. Higher frame
          rates increase CPU load, so this setting can be useful when
          there is a need to reduce CPU load. The default setting is
          no maximum limit, thus
          enabling the guest to use all frame rates supported by the
          host webcam.
        
          MaxPayloadTransferSize: Specifies the maximum number of bytes
          the emulated webcam can send to the guest in one buffer. The
          default setting is 3060 bytes, which is used by some webcams.
          Higher values can slightly reduce CPU load, if the guest is
          able to use larger buffers. Note that higher
          MaxPayloadTransferSize values may be not supported by some
          guest operating systems.
        
webcam detach
          <path|alias>: Detaches a webcam from a
          running VM. Specify the absolute path of the webcam on the
          host, or use its alias obtained from the webcam
          list command.
        
          Please note the following points, relating to specific host
          operating systems:
        
              Windows hosts: When the webcam device is detached from the
              host, the emulated webcam device is automatically detached
              from the guest.
            
              Mac OS X hosts: OS X version 10.7 or newer is required.
            
              When the webcam device is detached from the host, the
              emulated webcam device remains attached to the guest and
              must be manually detached using the VBoxManage
              controlvm webcam detach command.
            
              Linux hosts: When the webcam is detached from the host,
              the emulated webcam device is automatically detached from
              the guest only if the webcam is streaming video. If the
              emulated webcam is inactive, it should be manually
              detached using the VBoxManage controlvm webcam
              detach command.
            
webcam list: Lists webcams
          attached to the running VM. The output is a list of absolute
          paths or aliases that were used for attaching the webcams to
          the VM using the webcam attach command.
        
addencpassword <id> <password
          file>|- [--removeonsuspend
          <yes|no>]: Supplies an encrypted VM
          specified by <id> with the encryption password to enable
          a headless start. Either specify the absolute path of a
          password file on the host file system: <password file>,
          or use - to instruct
          VBoxManage to prompt the user for the
          encryption password.
        
--removeonsuspend
          <yes|no>: Specifies whether to remove
          the passsword or keep the password in VM memory when the VM is
          suspended. If the VM has been suspended and the password has
          been removed, the user needs to resupply the password before
          the VM can be resumed. This feature is useful in cases where
          the user does not want the password to be stored in VM memory,
          and the VM is suspended by a host suspend event.
        Note
            On Oracle VM VirtualBox versions 5.0 and later, data stored on
            hard disk images can be transparently encrypted for the
            guest. Oracle VM VirtualBox uses the AES algorithm in XTS mode and
            supports 128 or 256 bit data encryption keys (DEK). The DEK
            is stored encrypted in the medium properties, and is
            decrypted during VM startup by supplying the encryption
            password.
          
          The VBoxManage encryptmedium command is
          used to create a DEK encrypted medium. See
          Section 9.28.2, “Encrypting Disk Images”. When starting an
          encrypted VM from the Oracle VM VirtualBox GUI, the user will be
          prompted for the encryption password.
        
          For a headless encrypted VM start, use the following command:
        
          VBoxManage startvm ""vmname"" --type headless
        
          Then supply the required encryption password as follows:
        
          VBoxManage ""vmname"" controlvm ""vmname"" addencpassword ...
        
removeencpassword <id>:
          Removes encryption password authorization for password
          <id> for all encrypted media attached to the VM.
        
removeallencpasswords:
          Removes encryption password authorization for all passwords
          for all encrypted media attached to the VM.
        
changeuartmode <1-N>:
          Changes the connection mode for a given virtual serial port.
        8.14. VBoxManage discardstate
      This command discards the saved state of a virtual machine which
      is not currently running. This will cause the VM's operating
      system to restart next time you start it. This is the equivalent
      of pulling out the power cable on a physical machine, and should
      be avoided if possible.
    8.15. VBoxManage adoptstate
      If you have a Saved state file (.sav) that is
      separate from the VM configuration, you can use this command to
      adopt the file. This will change the VM to
      saved state and when you start it, Oracle VM VirtualBox will attempt to
      restore it from the saved state file you indicated. This command
      should only be used in special setups.
    8.16. VBoxManage closemedium
      This command removes a hard disk, DVD, or floppy image from a
      Oracle VM VirtualBox media registry.
    VBoxManage closemedium      [disk|dvd|floppy] <uuid|filename>
                            [--delete]
      Optionally, you can request that the image be deleted. You will
      get appropriate diagnostics that the deletion failed, however the
      image will become unregistered in any case.
    8.17. VBoxManage storageattach
      This command attaches, modifies, and removes a storage medium
      connected to a storage controller that was previously added with
      the storagectl command. The syntax is as
      follows:
    VBoxManage storageattach    <uuid|vmname>
                            --storagectl <name>
                            [--port <number>]
                            [--device <number>]
                            [--type dvddrive|hdd|fdd]
                            [--medium none|emptydrive|additions|
                                      <uuid>|<filename>|host:<drive>|iscsi]
                            [--mtype normal|writethrough|immutable|shareable
                                     readonly|multiattach]
                            [--comment <text>]
                            [--setuuid <uuid>]
                            [--setparentuuid <uuid>]
                            [--passthrough on|off]
                            [--tempeject on|off]
                            [--nonrotational on|off]
                            [--discard on|off]
                            [--hotpluggable on|off]
                            [--bandwidthgroup name|none]
                            [--forceunmount]
                            [--server <name>|<ip>]
                            [--target <target>]
                            [--tport <port>]
                            [--lun <lun>]
                            [--encodedlun <lun>]
                            [--username <username>]
                            [--password <password>]
                            [--passwordfile <file>]
                            [--initiator <initiator>]
                            [--intnet]
      A number of parameters are commonly required. Some parameters are
      required only for iSCSI targets.
    
      The common parameters are as follows:
    
uuid|vmname

            The VM UUID or VM Name. Mandatory.
          
--storagectl

            Name of the storage controller. Mandatory. The list of the
            storage controllers currently attached to a VM can be
            obtained with VBoxManage showvminfo. See
            Section 8.5, “VBoxManage showvminfo”.
          
--port

            The number of the storage controller's port which is to be
            modified. Mandatory, unless the storage controller has only
            a single port.
          
--device

            The number of the port's device which is to be modified.
            Mandatory, unless the storage controller has only a single
            device per port.
          
--type

            Define the type of the drive to which the medium is being
            attached, detached, or modified. This argument can only be
            omitted if the type of medium can be determined from either
            the medium given with the
            --medium argument or from a
            previous medium attachment.
          
--medium

            Specifies what is to be attached. The following values are
            supported:
          
none: Any existing
                device should be removed from the given slot.
              
emptydrive: For a
                virtual DVD or floppy drive only, this makes the device
                slot behave like a removeable drive into which no media
                has been inserted.
              
additions: For a
                virtual DVD drive only, this attaches the
                VirtualBox Guest Additions image to
                the given device slot.
              
                If a UUID is specified, it must be the UUID of a storage
                medium that is already known to Oracle VM VirtualBox. For
                example, because it has been attached to another virtual
                machine. See Section 8.4, “VBoxManage list” for
                details of how to list known media. This medium is then
                attached to the given device slot.
              
                If a filename is specified, it must be the full path of
                an existing disk image in ISO, RAW, VDI, VMDK, or other
                format. The disk image is then attached to the given
                device slot.
              
host:<drive>: For
                a virtual DVD or floppy drive only, this connects the
                given device slot to the specified DVD or floppy drive
                on the host computer.
              
iscsi: For virtual hard
                disks only, this is used for specifying an iSCSI target.
                In this case, additional parameters must be given. These
                are described below.
              
            Some of the above changes, in particular for removeable
            media such as floppies and CDs/DVDs, can be effected while a
            VM is running. Others, such as device changes or changes in
            hard disk device slots, require the VM to be powered off.
          
--mtype

            Defines how this medium behaves with respect to snapshots
            and write operations. See Section 5.4, “Special Image Write Modes”.
          
--comment

            An optional description that you want to have stored with
            this medium. For example, for an iSCSI target, ""Big storage
            server downstairs"". This is purely descriptive and not
            needed for the medium to function correctly.
          
--setuuid, --setparentuuid

            Modifies the UUID or parent UUID of a medium before
            attaching it to a VM. This is an expert option.
            Inappropriate use can make the medium unusable or lead to
            broken VM configurations if any other VM is referring to the
            same media already. The most frequently used variant is
            --setuuid """", which assigns
            a new random UUID to an image. This option is useful for
            resolving duplicate UUID errors if you duplicated an image
            using a file copy utility.
          
--passthrough

            For a virtual DVD drive only, you can enable DVD writing
            support. This feature is currently experimental, see
            Section 5.9, “CD/DVD Support”.
          
--tempeject

            For a virtual DVD drive only, you can configure the behavior
            for guest-triggered medium eject. If this is set to on, the
            eject has only a temporary effect. If the VM is powered off
            and restarted the originally configured medium will be still
            in the drive.
          
--nonrotational

            Enables you to enable the non-rotational flag for virtual
            hard disks. Some guests, such as Windows 7 or later, treat
            such disks like SSDs and do not perform disk fragmentation
            on such media.
          
--discard

            Enables the auto-discard feature for a virtual hard disks.
            This specifies that a VDI image will be shrunk in response
            to the trim command from the guest OS. The following
            requirements must be met:
          
                The disk format must be VDI.
              
                The size of the cleared area must be at least 1 MB.
              
                Oracle VM VirtualBox will only trim whole 1 MB blocks. The
                VDIs themselves are organized into 1 MB blocks, so this
                will only work if the space being trimmed is at least a
                1 MB contiguous block at a 1 MB boundary. On Windows,
                occasional defragmentation with defrag.exe
                /D, or on Linux running btrfs
                filesystem defrag as a background cron job may
                be beneficial.
              Note
              The Guest OS must be configured to issue the
              trim command, and typically this means
              that the guest OS is made to see the disk as an SSD. Ext4
              supports the -o discard mount flag. Mac OS X probably
              requires additional settings. Windows should automatically
              detect and support SSDs, at least in versions 7, 8, and
              10. The Linux exFAT driver from Samsung supports the
              trim command.
            
            It is unclear whether Microsoft's implementation of exFAT
            supports this feature, even though that file system was
            originally designed for flash.
          
            Alternatively, there are other methods to issue trim. For
            example, the Linux fstrim command, part
            of the util-linux package. Earlier solutions required a user
            to zero out unused areas, using zerofree or similar, and to
            compact the disk. This is only possible when the VM is
            offline.
          
--bandwidthgroup

            Sets the bandwidth group to use for the given device. See
            Section 5.8, “Limiting Bandwidth for Disk Images”.
          
--forceunmount

            For a virtual DVD or floppy drive only, this forcibly
            unmounts the DVD/CD/Floppy or mounts a new DVD/CD/Floppy
            even if the previous one is locked down by the guest for
            reading. See Section 5.9, “CD/DVD Support”.
          
      When iscsi is used with the
      --medium parameter for iSCSI
      support, additional parameters must or can be used. See also
      Section 5.10, “iSCSI Servers”.
    
--server

            The host name or IP address of the iSCSI target. Required.
          
--target

            Target name string. This is determined by the iSCSI target
            and used to identify the storage resource. Required.
          
--tport

            TCP/IP port number of the iSCSI service on the target.
            Optional.
          
--lun

            Logical Unit Number of the target resource. Optional. Often,
            this value is zero.
          
--encodedlun

            Hex-encoded Logical Unit Number of the target resource.
            Optional. Often, this value is zero.
          
--username, --password,
          --passwordfile

            Username and password, called the initiator secret, for
            target authentication, if required. Optional.
          Note
              Username and password are stored without encryption, in
              clear text, in the XML machine configuration file if no
              settings password is provided. When a settings password is
              specified for the first time, the password is stored in
              encrypted form. As an alternative to providing the
              password on the command line, a reference to a file
              containing the text can be provided using the
              passwordfile option.
            
--initiator

            iSCSI Initiator. Optional.
          
            Microsoft iSCSI Initiator is a system, such as a server that
            attaches to an IP network and initiates requests and
            receives responses from an iSCSI target. The SAN components
            in Microsoft iSCSI Initiator are largely analogous to Fibre
            Channel SAN components, and they include the following:
          
                To transport blocks of iSCSI commands over the IP
                network, an iSCSI driver must be installed on the iSCSI
                host. An iSCSI driver is included with Microsoft iSCSI
                Initiator.
              
                A gigabit Ethernet adapter that transmits 1000 megabits
                per second (Mbps) is recommended for the connection to
                an iSCSI target. Like standard 10/100 adapters, most
                gigabit adapters use a preexisting Category 5 or
                Category 6E cable. Each port on the adapter is
                identified by a unique IP address.
              
                An iSCSI target is any device that receives iSCSI
                commands. The device can be an end node, such as a
                storage device, or it can be an intermediate device,
                such as a network bridge between IP and Fibre Channel
                devices. Each port on the storage array controller or
                network bridge is identified by one or more IP addresses
              
--intnet

            If specified, connect to the iSCSI target using Internal
            Networking. This needs further configuration, see
            Section 9.7.3, “Access iSCSI Targets Using Internal Networking”.
          8.18. VBoxManage storagectl
      This command attaches, modifies, and removes a storage controller.
      After this, virtual media can be attached to the controller with
      the storageattach command.
    
      The syntax for this command is as follows:
    VBoxManage storagectl       <uuid|vmname>
                            --name <name>
                            [--add ide|sata|scsi|floppy|sas|usb|pcie]
                            [--controller LSILogic|LSILogicSAS|BusLogic|
                                          IntelAhci|PIIX3|PIIX4|ICH6|I82078|
                                          USB|NVMe|VirtIO]
                            [--portcount <1-30>]
                            [--hostiocache on|off]
                            [--bootable on|off]
                            [--rename <name>]
                            [--remove]
      The parameters are as follows:
    
uuid|vmname

            The VM UUID or VM Name. Mandatory.
          
--name

            Specifies the name of the storage controller. Mandatory.
          
--add

            Specifies the type of the system bus to which the storage
            controller must be connected.
          
--controller

            Enables a choice of chipset type being emulated for the
            given storage controller.
          
--portcount

            This specifies the number of ports the storage controller
            should support.
          
--hostiocache

            Configures the use of the host I/O cache for all disk images
            attached to this storage controller. See
            Section 5.7, “Host Input/Output Caching”.
          
--bootable

            Specifies whether this controller is bootable.
          
--rename

            Specifies a new name for the storage controller.
          
--remove

            Removes the storage controller from the VM configuration.
          8.19. VBoxManage bandwidthctl
      This command creates, deletes, modifies, and shows bandwidth
      groups of the given virtual machine.
    VBoxManage bandwidthctl    <uuid|vmname>
                           add <name> --type disk|network --limit <MBps>[k|m|g|K|M|G] |
                           set <name> --limit <MBps>[k|m|g|K|M|G] |
                           remove <name> |
                           list [--machinereadable]
      The following subcommands are available:
    
add: Creates a new bandwidth group of a
          given type.
        
set: Modifies the limit for an existing
          bandwidth group.
        
remove: Deletes a bandwidth group.
        
list: Shows all bandwidth groups defined
          for the given VM. Use the
          --machinereadable option to
          produce the same output, but in machine readable format. This
          is of the form: name=""value"" on a line by line basis.
        
      The parameters are as follows:
    
uuid|vmname

            The VM UUID or VM Name. Mandatory.
          
--name

            Name of the bandwidth group. Mandatory.
          
--type

            Type of the bandwidth group. Mandatory. Two types are
            supported: disk and
            network. See
            Section 5.8, “Limiting Bandwidth for Disk Images” or
            Section 6.10, “Limiting Bandwidth for Network Input/Output” for the
            description of a particular type.
          
--limit

            Specifies the limit for the given bandwidth group. This can
            be changed while the VM is running. The default unit is
            megabytes per second. The unit can be changed by specifying
            one of the following suffixes:
            k for kilobits per second,
            m for megabits per second,
            g for gigabits per second,
            K for kilobytes per second,
            M for megabytes per second,
            G for gigabytes per second.
          Note
        The network bandwidth limits apply only to the traffic being
        sent by virtual machines. The traffic being received by VMs is
        unlimited.
      Note
        To remove a bandwidth group it must not be referenced by any
        disks or adapters in the running VM.
      8.20. VBoxManage showmediuminfo
      This command shows information about a medium, notably its size,
      its size on disk, its type, and the virtual machines which use it.
    Note
        For compatibility with earlier versions of Oracle VM VirtualBox, the
        showvdiinfo command is also supported and
        mapped internally to the showmediuminfo
        command.
      VBoxManage showmediuminfo     [disk|dvd|floppy] <uuid|filename>
      The medium must be specified either by its UUID, if the medium is
      registered, or by its filename. Registered images can be listed
      using VBoxManage list hdds, VBoxManage
      list dvds, or VBoxManage list
      floppies, as appropriate. See
      Section 8.4, “VBoxManage list”.
    8.21. VBoxManage createmedium
      This command creates a new medium. The syntax is as follows:
    VBoxManage createmedium     [disk|dvd|floppy]    --filename <filename>
                            [--size <megabytes>|--sizebyte <bytes>]
                            [--diffparent <uuid>|<filename>
                            [--format VDI|VMDK|VHD] (default: VDI)
                            [--variant Standard,Fixed,Split2G,Stream,ESX]
      The parameters are as follows:
    
--filename <filename>

            Specifies a file name <filename> as an absolute path
            on the host file system. Mandatory.
          
--size <megabytes>

            Specifies the image capacity, in 1 MB units. Optional.
          
--diffparent
          <uuid>|<filename>

            Specifies the differencing image parent, either as a UUID or
            by the absolute pathname of the file on the host file
            system. Useful for sharing a base box disk image among
            several VMs.
          
--format VDI|VMDK|VHD

            Specifies the file format for the output file. Available
            options are VDI, VMDK, VHD. The default format is VDI.
            Optional.
          
--variant

            Specifies any required file format variants for the output
            file. This is a comma-separated list of variant flags.
            Options are Standard,Fixed,Split2G,Stream,ESX. Not all
            combinations are supported, and specifying mutually
            incompatible flags results in an error message. Optional.
          Note
        For compatibility with earlier versions of Oracle VM VirtualBox, the
        createvdi and createhd
        commands are also supported and mapped internally to the
        createmedium command.
      8.22. VBoxManage modifymedium
      With the modifymedium command, you can change
      the characteristics of a disk image after it has been created.
    VBoxManage modifymedium  [disk|dvd|floppy]    <uuid|filename>
                         [--type normal|writethrough|immutable|shareable|
                                 readonly|multiattach]
                         [--autoreset on|off]
                         [--property <name=[value]>]
                         [--compact]
                         [--resize <megabytes>|--resizebyte <bytes>]
                         [--move <path>]
                         [--setlocation <path>]Note
        For compatibility with earlier versions of Oracle VM VirtualBox, the
        modifyvdi and modifyhd
        commands are also supported and mapped internally to the
        modifymedium command.
      
      The disk image to modify must be specified either by its UUID, if
      the medium is registered, or by its filename. Registered images
      can be listed using VBoxManage list hdds, see
      Section 8.4, “VBoxManage list”. A filename must be specified
      as a valid path, either as an absolute path or as a relative path
      starting from the current directory.
    
      The following options are available:
    
          With the --type argument, you
          can change the type of an existing image between the normal,
          immutable, write-through and other modes. See
          Section 5.4, “Special Image Write Modes”.
        
          For immutable hard disks only, the --autoreset
          on|off option determines whether the disk is
          automatically reset on every VM startup. See
          Section 5.4, “Special Image Write Modes”. By default, autoreset is on.
        
          The --compact option can be
          used to compact disk images. Compacting removes blocks that
          only contains zeroes. Using this option will shrink a
          dynamically allocated image. It will reduce the
          physical size of the image without
          affecting the logical size of the virtual disk. Compaction
          works both for base images and for differencing images created
          as part of a snapshot.
        
          For this operation to be effective, it is required that free
          space in the guest system first be zeroed out using a suitable
          software tool. For Windows guests, you can use the
          sdelete tool provided by Microsoft. Run
          sdelete -z in the guest to zero the free
          disk space, before compressing the virtual disk image. For
          Linux, use the zerofree utility which
          supports ext2/ext3 filesystems. For Mac OS X guests, use the
          diskutil secureErase freespace 0
          / command from an elevated Terminal.
        
          Please note that compacting is currently only available for
          VDI images. A similar effect can be achieved by zeroing out
          free blocks and then cloning the disk to any other dynamically
          allocated format. You can use this workaround until compacting
          is also supported for disk formats other than VDI.
        
          The --resize x option, where
          x is the desired new total space in megabytes enables you to
          change the capacity of an existing image. This adjusts the
          logical size of a virtual disk without
          affecting the physical size much.
        
          This option currently works only for VDI and VHD formats, and
          only for the dynamically allocated variants. It can only be
          used to expand, but not shrink, the capacity. For example, if
          you originally created a 10 GB disk which is now full, you can
          use the --resize 15360
          command to change the capacity to 15 GB (15,360 MB) without
          having to create a new image and copy all data from within a
          virtual machine. Note however that this only changes the drive
          capacity. You will typically next need to use a partition
          management tool inside the guest to adjust the main partition
          to fill the drive.
        
          The --resizebyte x option
          does almost the same thing, except that x is expressed in
          bytes instead of megabytes.
        
          The --move <path>
          option can be used to relocate a medium to a different
          location <path> on the host file system. The path can be
          either relative to the current directory or absolute.
        
          The --setlocation
          <path> option can be used to set the
          new location <path> of the medium on the host file
          system if the medium has been moved for any reasons. The path
          can be either relative to the current directory or absolute.
        Note
            The new location is used as is, without any sanity checks.
            The user is responsible for setting the correct path.
          8.23. VBoxManage clonemedium
      This command duplicates a virtual disk, DVD, or floppy medium to a
      new medium, usually an image file, with a new unique identifier
      (UUID). The new image can be transferred to another host system or
      reimported into Oracle VM VirtualBox using the Virtual Media Manager.
      See Section 5.3, “The Virtual Media Manager” and Section 5.6, “Cloning Disk Images”.
      The syntax is as follows:
    VBoxManage clonemedium      [disk|dvd|floppy] <uuid|inputfile> <uuid|outputfile>

                            [--format VDI|VMDK|VHD|RAW|<other>]
                            [--variant Standard,Fixed,Split2G,Stream,ESX]
                            [--existing]
      The medium to clone as well as the target image must be described
      either by its UUIDs, if the mediums are registered, or by its
      filename. Registered images can be listed by VBoxManage
      list hdds. See Section 8.4, “VBoxManage list”. A
      filename must be specified as valid path, either as an absolute
      path or as a relative path starting from the current directory.
    
      The following options are available:
    
--format

            Set a file format for the output file different from the
            file format of the input file.
          
--variant

            Set a file format variant for the output file. This is a
            comma-separated list of variant flags. Not all combinations
            are supported, and specifying inconsistent flags will result
            in an error message.
          
--existing

            Perform the clone operation to an already existing
            destination medium. Only the portion of the source medium
            which fits into the destination medium is copied. This means
            if the destination medium is smaller than the source only a
            part of it is copied, and if the destination medium is
            larger than the source the remaining part of the destination
            medium is unchanged.
          Note
        For compatibility with earlier versions of Oracle VM VirtualBox, the
        clonevdi and clonehd
        commands are still supported and mapped internally to the
        clonemedium command.
      8.24. VBoxManage mediumproperty
      This command sets, gets, or deletes a medium property. The syntax
      is as follows:
    VBoxManage mediumproperty [disk|dvd|floppy] set <uuid|filename>
                                                <property> <value>
          Use <disk|dvd|floppy>
          to optionally specify the type of medium: disk (hard drive),
          dvd, or floppy.
        
          Use <uuid|filename> to
          supply either the UUID or absolute path of the medium or
          image.
        
          Use <property> to
          supply the name of the property.
        
          Use <value> to supply
          the property value.
        VBoxManage mediumproperty [disk|dvd|floppy] get <uuid|filename>
                                                <property>
          Use <disk|dvd|floppy>
          to optionally specify the type of medium: disk (hard drive),
          dvd, or floppy.
        
          Use <uuid|filename> to
          supply either the UUID or absolute path of the medium or
          image.
        
          Use <property> to
          supply the name of the property.
        VBoxManage mediumproperty [disk|dvd|floppy] delete <uuid|filename>
                                                   <property>
          Use <disk|dvd|floppy>
          to optionally specify the type of medium: disk (hard drive),
          dvd, or floppy.
        
          Use <uuid|filename> to
          supply either the UUID or absolute path of the medium or
          image.
        
          Use <property> to
          supply the name of the property.
        8.25. VBoxManage encryptmedium
      This command is used to create a DEK encrypted medium or image.
      See Section 9.28.2, “Encrypting Disk Images”.
    
      The syntax is as follows:
    VBoxManage encryptmedium <uuid|filename>
                         [--newpassword <file|->]
                         [--oldpassword <file|->]
                         [--cipher <cipher id>]
                         [--newpasswordid <password id>]
          Use <uuid|filename> to
          supply the UUID or absolute path of the medium or image to be
          encrypted.
        
          Use --newpassword
          <file|-> to supply a new encryption
          password. Either specify the absolute pathname of a password
          file on the host operating system, or
          - to prompt you for the
          password on the command line. Always use the
          --newpasswordid option with
          this option.
        
          Use --oldpassword
          <file|-> to supply any old encryption
          password. Either specify the absolute pathname of a password
          file on the host operating system, or
          - to prompt you for the old
          password on the command line.
        
          Use this option to gain access to an encrypted medium or image
          to either change its password using
          --newpassword or change its
          encryption using --cipher.
        
          Use --cipher <cipher>
          to specify the cipher to use for encryption. This can be
          either AES-XTS128-PLAIN64 or
          AES-XTS256-PLAIN64.
        
          Use this option to change any existing encryption on the
          medium or image, or to set up new encryption on it for the
          first time.
        
          Use --newpasswordid <password
          id> to supply the new password identifier.
          This can be chosen by the user, and is used for correct
          identification when supplying multiple passwords during VM
          startup.
        
          If the user uses the same password when encrypting multiple
          images and also the same password identifier, the user needs
          to supply the password only once during VM startup.
        8.26. VBoxManage checkmediumpwd
      This command is used to check the current encryption password on a
      DEK encrypted medium or image. See
      Section 9.28.2, “Encrypting Disk Images”.
    
      The syntax is as follows:
    VBoxManage checkmediumpwd <uuid|filename>
                                      <pwd file|->
          Use <uuid|filename> to
          supply the UUID or absolute path of the medium or image to be
          checked.
        
          Use <pwd file|-> to
          supply the password identifier to be checked. Either specify
          the absolute pathname of a password file on the host operating
          system, or - to prompt you
          for the password on the command line.
        8.27. VBoxManage convertfromraw
      This command converts a raw disk image to an Oracle VM VirtualBox Disk
      Image (VDI) file. The syntax is as follows:
    VBoxManage convertfromraw   <filename> <outputfile>
                            [--format VDI|VMDK|VHD]
                            [--variant Standard,Fixed,Split2G,Stream,ESX]
                            [--uuid <uuid>]
VBoxManage convertfromraw   stdin <outputfile> <bytes>
                            [--format VDI|VMDK|VHD]
                            [--variant Standard,Fixed,Split2G,Stream,ESX]
                            [--uuid <uuid>]
      The parameters are as follows:
    
--bytes

            The size of the image file, in bytes, provided through
            stdin.
          
--format

            Select the disk image format to create. The default format
            is VDI. Other options are VMDK and VHD.
          
--variant

            Choose a file format variant for the output file. This is a
            comma-separated list of variant flags. Not all combinations
            are supported, and specifying inconsistent flags will result
            in an error message.
          
--uuid

            Specify the UUID of the output file.
          
      The stdin form of the command forces
      VBoxManage to read the content of the disk
      image from standard input. This useful when using the command in a
      pipe.
    Note
        For compatibility with earlier versions of Oracle VM VirtualBox, the
        convertdd command is also supported and
        mapped internally to the convertfromraw
        command.
      8.28. VBoxManage getextradata/setextradata
      These commands enable you to attach and retrieve string data for a
      virtual machine or for an Oracle VM VirtualBox configuration, by
      specifying global instead of a
      virtual machine name. You must specify a keyword as a text string
      to associate the data with, which you can later use to retrieve
      it. For example:
    VBoxManage setextradata Fedora5 installdate 2006.01.01
VBoxManage setextradata SUSE10 installdate 2006.02.02
      This example would associate the string ""2006.01.01"" with the
      keyword installdate for the virtual machine Fedora5, and
      ""2006.02.02"" on the machine SUSE10. You could then retrieve the
      information as follows:
    VBoxManage getextradata Fedora5 installdate
      This would return the following:
    VirtualBox Command Line Management Interface Version version-number
(C) 2005-2018 Oracle Corporation
All rights reserved.

Value: 2006.01.01
      You could retrieve the information for all keywords as follows:
    VBoxManage getextradata Fedora5 enumerate
      To remove a keyword, the setextradata command
      must be run without specifying data, only the keyword. For
      example:
    VBoxManage setextradata Fedora5 installdate8.29. VBoxManage setproperty
      This command is used to change global settings which affect the
      entire Oracle VM VirtualBox installation. Some of these correspond to
      the settings in the Global
      Settings dialog in the graphical user interface. The
      following properties are available:
    
machinefolder

            Specifies the default folder in which virtual machine
            definitions are kept. See Section 10.1, “Where Oracle VM VirtualBox Stores its Files”.
          
hwvirtexclusive

            Specifies whether Oracle VM VirtualBox will make exclusive use of
            the hardware virtualization extensions (Intel VT-x or AMD-V)
            of the host system's processor. See
            Section 10.3, “Hardware Virtualization”. If you wish to share these
            extensions with other hypervisors running at the same time,
            you must disable this setting. Doing so has negative
            performance implications.
          
vrdeauthlibrary

            Specifies which library to use when external authentication
            has been selected for a particular virtual machine. See
            Section 7.1.5, “RDP Authentication”.
          
websrvauthlibrary

            Specifies which library the web service uses to authenticate
            users. For details about the Oracle VM VirtualBox web service, see
            the Oracle VM VirtualBox SDK reference,
            Chapter 11, Oracle VM VirtualBox Programming Interfaces.
          
vrdeextpack

            Specifies which library implements the VirtualBox Remote
            Desktop Extension.
          
loghistorycount

            Selects how many rotated VM logs are retained.
          
autostartdbpath

            Selects the path to the autostart database. See
            Section 9.21, “Starting Virtual Machines During System Boot”.
          
defaultfrontend

            Selects the global default VM frontend setting. See
            Section 8.12, “VBoxManage startvm”.
          
logginglevel

            Configures the VBoxSVC release logging details. See
            http://www.virtualbox.org/wiki/VBoxLogging.
          
proxymode

            Configures the mode for an HTTP proxy server.
          
proxyurl

            Configures the URL for an HTTP proxy server. Used when a
            manual proxy is configured using the
            manual setting of the
            proxymode property.
          8.30. VBoxManage usbfilter add/modify/removeVBoxManage usbfilter        add <index,0-N>
                          --target <uuid|vmname>global
                          --name <string>
                          --action ignore|hold (global filters only)
                         [--active yes|no (yes)]
                         [--vendorid <XXXX> (null)]
                         [--productid <XXXX> (null)]
                         [--revision <IIFF> (null)]
                         [--manufacturer <string> (null)]
                         [--product <string> (null)]
                         [--remote yes|no (null, VM filters only)]
                         [--serialnumber <string> (null)]
                         [--maskedinterfaces <XXXXXXXX>]
    VBoxManage usbfilter        modify <index,0-N>
                          --target <uuid|vmname>global
                         [--name <string>]
                         [--action ignore|hold (global filters only)]
                         [--active yes|no]
                         [--vendorid <XXXX>]
                         [--productid <XXXX>]
                         [--revision <IIFF>]
                         [--manufacturer <string>]
                         [--product <string>]
                         [--remote yes|no (null, VM filters only)]
                         [--serialnumber <string>]
                         [--maskedinterfaces <XXXXXXXX>]
    VBoxManage usbfilter        remove <index,0-N>
                          --target <uuid|vmname>global
    
      The usbfilter commands are used for working
      with USB filters in virtual machines, or global filters which
      affect the whole Oracle VM VirtualBox setup. Global filters are applied
      before machine-specific filters, and may be used to prevent
      devices from being captured by any virtual machine. Global filters
      are always applied in a particular order, and only the first
      filter which fits a device is applied. For example, if the first
      global filter says to hold, or make available, a particular
      Kingston memory stick device and the second filter says to ignore
      all Kingston devices. That particular Kingston memory stick will
      be available to any machine with the appropriate filter, but no
      other Kingston device will.
    
      When creating a USB filter using usbfilter add,
      you must supply three or four mandatory parameters. The index
      specifies the position in the list at which the filter should be
      placed. If there is already a filter at that position, then it and
      the following ones will be shifted back one place. Otherwise, the
      new filter will be added onto the end of the list. The
      target parameter selects the
      virtual machine that the filter should be attached to or use
      global to apply it to all virtual
      machines. name is a name for the
      new filter. For global filters,
      action says whether to allow VMs
      access to devices that fit the filter description (hold) or not to
      give them access (ignore). In addition, you should specify
      parameters to filter by. You can find the parameters for devices
      attached to your system using VBoxManage list
      usbhost. Finally, you can specify whether the filter
      should be active. For local filters, whether they are for local
      devices, remote devices over an RDP connection, or either.
    
      When you modify a USB filter using usbfilter
      modify, you must specify the filter by index and by
      target, which is either a virtual machine or
      global. See the output of
      VBoxManage list usbfilters to find global
      filter indexes and VBoxManage showvminfo to
      find indexes for individual machines. The properties which can be
      changed are the same as for usbfilter add. To
      remove a filter, use usbfilter remove and
      specify the index and the target.
    
      The following is a list of the additional usbfilter
      add and usbfilter modify options,
      with details of how to use them.
    
--action ignore|hold:
          Specifies whether devices that fit the filter description are
          allowed access by machines (hold), or have access denied
          (ignore). Applies to global filters only.
        
--active yes|no: Specifies
          whether the USB Filter is active or temporarily disabled. For
          usbfilter create the default
          is active.
        
--vendorid <XXXX>|"""":
          Specifies a vendor ID filter. The string representation for an
          exact match has the form XXXX, where X is the hexadecimal
          digit, including leading zeroes.
        
--productid <XXXX>|"""":
          Specifies a product ID filter. The string representation for
          an exact match has the form XXXX, where X is the hexadecimal
          digit, including leading zeroes.
        
--revision <IIFF>|"""":
          Specifies a revision ID filter. The string representation for
          an exact match has the form IIFF, where I is the decimal digit
          of the integer part of the revision, and F is the decimal
          digit of its fractional part, including leading and trailing
          zeros. Note that for interval filters, it is best to use the
          hexadecimal form, because the revision is stored as a 16-bit
          packed BCD value. Therefore, the expression int:0x0100-0x0199
          will match any revision from 1.0 to 1.99 inclusive.
        
--manufacturer
          <string>|"""": Specifies a manufacturer
          ID filter, as a string.
        
--product <string>|"""":
          Specifies a product ID filter, as a string.
        
--remote yes|no"""": Specifies
          a remote filter, indicating whether the device is physically
          connected to a remote VRDE client or to a local host machine.
          Applies to VM filters only.
        
--serialnumber
          <string>|"""": Specifies a serial number
          filter, as a string.
        
--maskedinterfaces
          <XXXXXXXX>: Specifies a masked
          interface filter, for hiding one or more USB interfaces from
          the guest. The value is a bit mask where the set bits
          correspond to the USB interfaces that should be hidden, or
          masked off. This feature only works on Linux hosts.
        8.31. VBoxManage guestproperty
      The guestproperty commands enable you to get or
      set properties of a running virtual machine. See
      Section 4.7, “Guest Properties”. Guest properties are
      arbitrary keyword-value string pairs which can be written to and
      read from by either the guest or the host, so they can be used as
      a low-volume communication channel for strings, provided that a
      guest is running and has the Guest Additions installed. In
      addition, a number of values whose keywords begin with
      /VirtualBox/are automatically set
      and maintained by the Guest Additions.
    
      The following subcommands are available, where
      <vm> can either be a VM
      name or a VM UUID, as with the other VBoxManage
      commands:
    
enumerate <vm> [--patterns
          <pattern>]: Lists all the guest
          properties that are available for the given VM, including the
          value. This list will be very limited if the guest's service
          process cannot be contacted, for example because the VM is not
          running or the Guest Additions are not installed.
        
          If --patterns <pattern>
          is specified, it acts as a filter to only list properties that
          match the given pattern. The pattern can contain the following
          wildcard characters:
        
* (asterisk): Represents
              any number of characters. For example,
              ""/VirtualBox*"" would
              match all properties beginning with ""/VirtualBox"".
            
? (question mark):
              Represents a single arbitrary character. For example,
              ""fo?"" would match both
              ""foo"" and ""for"".
            
| (pipe symbol): Can be
              used to specify multiple alternative patterns. For
              example, ""s*|t*"" would
              match anything starting with either ""s"" or ""t"".
            
get <vm>
          <property>: Retrieves the value of a
          single property only. If the property cannot be found, for
          example because the guest is not running, the following
          message is shown:
        No value set!
set <vm> <property> [<value>
          [--flags <flags>]]: Enables you to set
          a guest property by specifying the keyword and value. If
          <value> is omitted, the
          property is deleted. With
          --flags, you can specify
          additional behavior. You can combine several flags by
          separating them with commas.
        
TRANSIENT: The value will
              not be stored with the VM data when the VM exits.
            
TRANSRESET: The value
              will be deleted as soon as the VM restarts or exits.
            
RDONLYGUEST: The value
              can only be changed by the host, but the guest can only
              read it.
            
RDONLYHOST: The value can
              only be changed by the guest, but the host can only read
              it.
            
READONLY: The value
              cannot be changed at all.
            
wait <vm> <pattern> --timeout
          <timeout>: Waits for a particular value
          described by the pattern string to change or to be deleted or
          created. The pattern rules are the same as for the
          enumerate subcommand.
        
delete <vm>
          <property>: Deletes a guest property
          which has been set previously.
        8.32. VBoxManage guestcontrol
      The guestcontrol commands enable control of the
      guest from the host. See
      Section 4.9, “Guest Control of Applications” for an introduction.
    
      The guestcontrol command has two sets of
      subcommands. The first set requires guest credentials to be
      specified, the second does not.
    
      The first set of subcommands is of the following form:
    VBoxManage guestcontrol <uuid|vmname> <sub-command>
            [--username <name> ]
            [--passwordfile <file> | --password <password>]
            [--domain <domain> ]
            [-v|--verbose] [-q|quiet] ...
    
      The common options are as follows:
    
           [--username <name> ]
           [--passwordfile <file> | --password <password>]
           [--domain <domain> ]
           [-v|--verbose] [-q|quiet]
    
      The common options for the first set of subcommands are explained
      in the following list.
    
<uuid|vmname>

            Specifies the VM UUID or VM name. Mandatory.
          
--username <name>

            Specifies the user name on guest OS under which the process
            should run. This user name must already exist on the guest
            OS. If unspecified, the host user name is used. Optional
          
--passwordfile
          <file>|--password

            Specifies the absolute path on guest file system of password
            file containing the password for the specified user account
            or password for the specified user account. Optional. If
            both are omitted, empty password is assumed.
          
--domain <domain>

            User domain for Windows guests. Optional.
          
-v|--verbose

            Makes the subcommand execution more verbose. Optional
          
-q|--quiet

            Makes the subcommand execution quieter. Optional.
          
      The first set of subcommands are as follows:
    
run: Executes a guest
          program, forwarding stdout, stderr, and stdin to and from the
          host until it completes.
        VBoxManage guestcontrol <uuid|vmname> run [common-options]
            --exe <path to executable> [--timeout <msec>]
           [-E|--putenv <NAME>[=<VALUE>]] [--unquoted-args]
           [--ignore-operhaned-processes] [--profile]
           [--no-wait-stdout|--wait-stdout]
           [--no-wait-stderr|--wait-stderr]
           [--dos2unix] [--unix2dos]
            -- <program/arg0> [argument1] ... [argumentN]]
          
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
--exe <path to
              executable>

                Specifies the absolute path of the executable on the
                guest OS file system. Mandatory. For example:
                C:\Windows\System32\calc.exe.
              
--timeout <msec>

                Specifies the maximum time, in microseconds, that the
                executable can run, during which
                VBoxManage receives its output.
                Optional. If unspecified, VBoxManage
                waits indefinitely for the process to end, or an error
                occurs.
              
-E|--putenv
              <NAME>=<VALUE>

                Sets, modifies, and unsets environment variables in the
                environment in which the program will run. Optional.
              
                The guest process is created with the standard default
                guest OS environment. Use this option to modify that
                default environment. To set or modify a variable use:
                <NAME>=<VALUE>.
                To unset a variable use:
                <NAME>=

                Any spaces in names and values should be enclosed by
                quotes.
              
                To set, modify, and unset multiple variables, use
                multiple instances of the
                --E|--putenv option.
              
--unquoted-args

                Disables escaped double quoting, such as \""fred\"", on
                arguments passed to the executed program. Optional.
              
--ignore-operhaned-processes

                Ignore orphaned processes. Not yet implemented.
                Optional.
              
--profile

                Use Profile. Not yet implemented. Optional.
              
--no-wait-stdout|--wait-stdout

                Does not wait or waits until the guest process ends and
                receives its exit code and reason/flags. In the case of
                --wait-stdout,
                VBoxManage receives its stdout while
                the process runs. Optional.
              
--no-wait-stderr|--wait-stderr

                Does not wait or waits until the guest process ends and
                receives its exit code, error messages, and flags. In
                the case of
                --wait-stderr,
                VBoxManage receives its stderr while
                the process runs. Optional.
              
--dos2unix

                Converts output from DOS/Windows guests to
                UNIX/Linux-compatible line endings, CR + LF to LF. Not
                yet implemented. Optional.
              
--unix2dos

                Converts output from a UNIX/Linux guests to
                DOS/Windows-compatible line endings, LF to CR + LF. Not
                yet implemented. Optional.
              
[-- <program/arg0>
              [<argument1>] ...
              [<argumentN>]]

                Specifies the program name, followed by one or more
                arguments to pass to the program. Optional.
              
                Any spaces in arguments should be enclosed by quotes.
              Note
            On Windows there are certain limitations for graphical
            applications. See Chapter 14, Known Limitations.
          
          Examples of using the guestcontrol run
          command are as follows:
        VBoxManage --nologo guestcontrol ""My VM"" run --exe ""/bin/ls""
          --username foo --passwordfile bar.txt --wait-exit --wait-stdout -- -l /usrVBoxManage --nologo guestcontrol ""My VM"" run --exe ""c:\\windows\\system32\\ipconfig.exe""
          --username foo --passwordfile bar.txt --wait-exit --wait-stdout
          Note that the double backslashes in the second example are
          only required on UNIX hosts.
        Note
            For certain commands a user name of an existing user account
            on the guest must be specified. Anonymous executions are not
            supported for security reasons. A user account password,
            however, is optional and depends on the guest's OS security
            policy or rules. If no password is specified for a given
            user name, an empty password will be used. On certain OSes
            like Windows the security policy may needs to be adjusted in
            order to allow user accounts with an empty password set.
            Also, global domain rules might apply and therefore cannot
            be changed.
          
          Starting at Oracle VM VirtualBox 4.1.2 guest process execution by
          default is limited to serve up to five guest processes at a
          time. If a new guest process gets started which would exceed
          this limit, the oldest not running guest process will be
          discarded in order to be able to run that new process. Also,
          retrieving output from this old guest process will not be
          possible anymore then. If all five guest processes are still
          active and running, starting a new guest process will result
          in an appropriate error message.
        
          To raise or lower the guest process execution limit, either
          use the guest property
          /VirtualBox/GuestAdd/VBoxService/--control-procs-max-kept
          or VBoxService command line by specifying
          --control-procs-max-kept
          needs to be modified. A restart of the guest OS is required
          afterwards. To serve unlimited guest processes, a value of
          0 needs to be set, but this
          is not recommended.
        
start: Executes a guest
          program until it completes.
        VBoxManage guestcontrol <uuid|vmname> start [common-options]
           [--exe <path to executable>] [--timeout <msec>]
           [-E|--putenv <NAME>[=<VALUE>]] [--unquoted-args]
           [--ignore-operhaned-processes] [--profile]
            -- <program/arg0> [argument1] ... [argumentN]]
          
          Where the options are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
--exe <path to
              executable>

                Specifies the absolute path of the executable on the
                guest OS file system. Mandatory. For example:
                C:\Windows\System32\calc.exe

--timeout <msec>

                Specifies the maximum time, in microseconds, that the
                executable can run. Optional. If unspecified,
                VBoxManage waits indefinitely for the
                process to end, or an error occurs.
              
-E|--putenv
              <NAME>=<VALUE>

                Sets, modifies, and unsets environment variables in the
                environment in which the program will run. Optional.
              
                The guest process is created with the standard default
                guest OS environment. Use this option to modify that
                default environment. To set or modify a variable use:
                <NAME>=<VALUE>.
                To unset a variable use:
                <NAME>=

                Any spaces in names and values should be enclosed by
                quotes.
              
                To set, modify, or unset multiple variables, use
                multiple instances of the
                --E|--putenv option.
              
--unquoted-args

                Disables escaped double quoting, such as \""fred\"", on
                arguments passed to the executed program. Optional.
              
--ignore-operhaned-processes

                Ignores orphaned processes. Not yet implemented.
                Optional.
              
--profile

                Use a profile. Not yet implemented. Optional.
              
[-- <program/arg0>
              [<argument1>] ...
              [<argumentN>]]

                Specifies the program name, followed by one or more
                arguments to pass to the program. Optional.
              
                Any spaces in arguments should be enclosed by quotes.
              Note
            On Windows there are certain limitations for graphical
            applications. See Chapter 14, Known Limitations.
          
          Examples of using the guestcontrol start
          command are as follows:
        VBoxManage --nologo guestcontrol ""My VM"" start --exe ""/bin/ls""
          --username foo --passwordfile bar.txt --wait-exit --wait-stdout -- -l /usrVBoxManage --nologo guestcontrol ""My VM"" start --exe ""c:\\windows\\system32\\ipconfig.exe""
          --username foo --passwordfile bar.txt --wait-exit --wait-stdout
          Note that the double backslashes in the second example are
          only required on UNIX hosts.
        Note
            For certain commands a user name of an existing user account
            on the guest must be specified. Anonymous executions are not
            supported for security reasons. A user account password,
            however, is optional and depends on the guest's OS security
            policy or rules. If no password is specified for a given
            user name, an empty password will be used. On certain OSes
            like Windows the security policy may needs to be adjusted in
            order to allow user accounts with an empty password set.
            Also, global domain rules might apply and therefore cannot
            be changed.
          
          Starting at Oracle VM VirtualBox 4.1.2 guest process execution by
          default is limited to serve up to five guest processes at a
          time. If a new guest process gets started which would exceed
          this limit, the oldest not running guest process will be
          discarded in order to be able to run that new process. Also,
          retrieving output from this old guest process will not be
          possible anymore then. If all five guest processes are still
          active and running, starting a new guest process will result
          in an appropriate error message.
        
          To raise or lower the guest process execution limit, either
          use the guest property
          /VirtualBox/GuestAdd/VBoxService/--control-procs-max-kept
          or VBoxService command line by specifying
          --control-procs-max-kept
          needs to be modified. A restart of the guest OS is required
          afterwards. To serve unlimited guest processes, a value of
          0 needs to be set, but this
          is not recommended.
        
copyfrom: Copies files from
          the guest to the host file system. Only available with Guest
          Additions 4.0 or later installed.
        VBoxManage guestcontrol <uuid|vmname> copyfrom [common-options]
           [--follow] [--R|recursive]
            --target-directory <host-dst-dir>
            <guest-src0> [<guest-src1> [...]] 
          Where the parameters are as follows:
        
<uid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
--follow

                Enables symlink following on the guest file system.
                Optional.
              
-R|--recursive

                Enables recursive copying of files and directories from
                the specified guest file system directory. Optional.
              
--target-directory
              <host-dst-dir>

                Specifies the absolute path of the host file system
                destination directory. Mandatory. For example:
                C:\Temp.
              
<guest-src0> [<guest-src1>
              [...]]

                Specifies the absolute paths of guest file system files
                to be copied. Mandatory. For example:
                C:\Windows\System32\calc.exe.
                Wildcards can be used in the expressions. For example:
                C:\Windows\System*\*.dll.
              
copyto: Copies files from the
          host to the guest file system. Only available with Guest
          Additions 4.0 or later installed.
        VBoxManage guestcontrol <uuid|vmname> copyto [common-options]
           [--follow] [--R|recursive]
            --target-directory <guest-dst>
            <host-src0> [<host-src1> [...]] 
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
--follow

                Enables symlink following on the host file system.
                Optional.
              
-R|--recursive

                Enables recursive copying of files and directories from
                the specified host file system directory. Optional.
              
--target-directory
              <guest-dst>

                Specifies the absolute path of the guest file system
                destination directory. Mandatory. For example:
                C:\Temp.
              
<host-src0> [<host-src1>
              [...]]

                Specifies the absolute paths of host file system files
                to be copied. Mandatory. For example:
                C:\Windows\System32\calc.exe.
                Wildcards can be used in the expressions. For example:
                C:\Windows\System*\*.dll.
              
md|mkdir|createdir|createdirectory:
          Creates one or more directories on the guest file system. Only
          available with Guest Additions 4.0 or later installed.
        VBoxManage guestcontrol <uuid|vmname>  md|mkdir|createdir|createdirectory [common-options]
            [--parents] [--mode <mode>]
            <guest-dir0> [<guest-dir1> [...]] 
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
--parents

                Creates any absent parent directories of the specified
                directory. Optional.
              
                For example: If specified directory is
                D:\Foo\Bar and
                D:\Foo is absent, it will be
                created. In such a case, had the
                --parents option not
                been used, this command would have failed.
              
--mode <mode>

                Specifies the permission mode on the specified
                directories, and any parents, if the
                --parents option is
                used. Currently octal modes only, such as.
                0755, are supported.
              
<guest-dir0> [<guest-dir1>
              [...]]

                Specifies a list of absolute paths of directories to be
                created on guest file system. Mandatory. For example:
                D:\Foo\Bar.
              
                All parent directories must already exist unless the
                switch --parents is
                used. For example, in the above example
                D:\Foo. The specified user must
                have sufficient rights to create the specified
                directories, and any parents that need to be created.
              
rmdir|removedir|removedirectory:
          Deletes specified guest file system directories. Only
          available with installed Guest Additions 4.3.2 and later.
        VBoxManage guestcontrol <uuid|vmname> rmdir|removedir|removedirectory [common-options]
           [--recursive|-R]
            <guest-dir0> [<guest-dir1> [...]]
          
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
--recursive

                Recursively removes directories and contents. Optional.
              
<guest-dir0> [<guest-dir1>
              [...]]

                Specifies a list of the absolute paths of directories to
                be deleted on guest file system. Mandatory. Wildcards
                are allowed. For example:
                D:\Foo\*Bar. The specified user
                must have sufficient rights to delete the specified
                directories.
              
rm|removefile: Deletes
          specified files on the guest file system. Only available with
          installed Guest Additions 4.3.2 and later.
        VBoxManage guestcontrol <uuid|vmname> rm|removefile [common-options]
           [-f|--force]
            <guest-file0> [<guest-file1> [...]] 
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
-f|--force

                Enforce operation and override any requests for
                confirmations. Optional.
              
<guest-file0> [<guest-file1>
              [...]]

                Specifies a list of absolute paths of files to be
                deleted on guest file system. Mandatory. Wildcards are
                allowed. For example:
                D:\Foo\Bar\text*.txt. The specified
                user should have sufficient rights to delete the
                specified files.
              
mv|move|ren|rename: Renames
          files and/or directories on the guest file system. Only
          available with installed Guest Additions 4.3.2 and later.
        VBoxManage guestcontrol <uuid|vmname> mv|move|ren|rename [common-options]
           <guest-source0> [<guest-source1> [...]] <guest-dest>
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
<guest-source0>
              [<guest-source1> [...]]

                Specifies absolute paths of files or a single directory
                to be moved and renamed on guest file system. Mandatory.
                Wildcards are allowed in file names. The specified user
                should have sufficient rights to access the specified
                files.
              
<dest>

                Specifies the absolute path of the destination file or
                directory to which the files are to be moved. Mandatory.
                If only one file to be moved, <dest> can be file
                or directory, else it must be a directory. The specified
                user must have sufficient rights to access the
                destination file or directory.
              
mktemp|createtemp|createtemporary:
          Creates a temporary file or directory on the guest file
          system, to assist subsequent copying of files from the host to
          the guest file systems. By default, the file or directory is
          created in the guest's platform specific temp directory. Not
          currently supported. Only available with installed Guest
          Additions 4.2 and later.
        VBoxManage guestcontrol <uuid|vmname> mktemp|createtemp|createtemporary [common-options]
           [--directory] [--secure] [--mode <mode>] [--tmpdir <directory>]
            <template>
            
          The parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
--directory

                Creates a temporary directory instead of a file,
                specified by the <template> parameter. Optional.
              
--secure

                Enforces secure file and directory creation. Optional.
                The permission mode is set to
                0755. Operation fails
                if it cannot be performed securely.
              
--mode <mode>

                Specifies the permission mode of the specified
                directory. Optional. Currently only octal modes, such as
                0755, are supported.
              
--tmpdir
              <directory>

                Specifies the absolute path of the directory on the
                guest file system where the file or directory specified
                will be created. Optional. If unspecified, the
                platform-specific temp directory is used.
              
<template>

                Specifies a file name without a directory path,
                containing at least one sequence of three consecutive X
                characters, or ending in X. Mandatory.
              
stat: Displays file or file
          system statuses on the guest.
        VBoxManage guestcontrol <uuid|vmname> stat [common-options]
           <file0> [<file1> [...]]
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
<file0> [<file1>
              [...]]

                Specifies absolute paths of files or file systems on the
                guest file system. Mandatory. For example:
                /home/foo/a.out. The specified user
                should have sufficient rights to access the specified
                files or file systems.
              
      The second set of subcommands is of the form:
    VBoxManage guestcontrol <uuid|vmname> <sub-command>
           [-v|--verbose] [-q|quiet] ...
    
      The common options are as follows:
    
            [-v|--verbose] [-q|--quiet]
    
      Details of the common options for the second set of subcommands
      are as follows:
    
-v|--verbose

            Makes the subcommand execution more verbose. Optional.
          
-q|--quiet

            Makes the subcommand execution quieter. Optional.
          
      The second set of subcommands are as follows:
    
list: Lists guest control
          configuration and status data. For example: open guest
          sessions, guest processes, and files.
        VBoxManage guestcontrol <uuid|vmname> list [common-opts]
           <all|sessions|processes|files> 
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
all|sessions|processes|files

                Indicates whether to list all available data or guest
                sessions, processes or files. Mandatory.
              
closeprocess: Terminates
          guest processes specified by PIDs running in a guest session,
          specified by the session ID or name.
        VBoxManage guestcontrol <uuid|vmname> closeprocess [common-options]
           --session-id <ID> | --session-name <name or pattern>
           <PID0> [<PID1> [...]] 
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
--session-id <ID>

                Specifies the guest session by its ID. Optional.
              
--session-name <name or
              pattern>

                Specifies the guest session by its name, or multiple
                sessions using a pattern containing wildcards. Optional.
              
<PID0> [<PID1>
              [...]]

                Specifies a list of process identifiers (PIDs) of guest
                processes to be terminated. Mandatory.
              
closesession: Closes
          specified guest sessions, specified either by session ID or
          name.
        VBoxManage guestcontrol <uuid|vmname> closesession [common-options]
           --session-id <ID> | --session-name <name or pattern> | --all 
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
--session-id <ID>

                Specifies the guest session to be closed by ID.
                Optional.
              
--session-name <name or
              pattern>

                Specifies the guest session to be closed by name.
                Optional. Multiple sessions can be specified by using a
                pattern containing wildcards.
              
--all

                Close all guest sessions. Optional.
              
updatega|updateadditions|updateguestadditions:
          Ugrades Guest Additions already installed on the guest. Only
          available for already installed Guest Additions 4.0 and later.
        VBoxManage guestcontrol <uuid|vmname> updatega|updateadditions|updateguestadditions
           [common-options]
           [--source <New .ISO path>]
           [--wait-start]
           [-- <argument0> [<argument1> [...]]]
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              
--source <New .ISO
              path>
            
                Specifies the absolute path on the guest file system of
                the .ISO file for the Guest Additions update. Mandatory.
              
--wait-start

                Indicates that VBoxManage starts the
                usual updating process on the guest and then waits until
                the actual Guest Additions updating begins, at which
                point VBoxManage self-terminates.
                Optional.
              
                Default behavior is that VBoxManage
                waits for completion of the Guest Additions update
                before terminating. Use of this option is sometimes
                necessary, as a running VBoxManage
                can affect the interaction between the installer and the
                guest OS.
              
[-- <argument0> [<argument1>
              [...]]]

                Specifies optional command line arguments to be supplied
                to the Guest Additions updater. Useful for retrofitting
                features which are not currently installed.
              
                Arguments containing spaces should be enclosed by
                quotes.
              
watch: Prints current guest
          control activity.
        VBoxManage guestcontrol <uuid|vmname> watch [common-options]
          
          Where the parameters are as follows:
        
<uuid|vmname>

                Specifies the VM UUID or VM name. Mandatory.
              8.33. VBoxManage metrics
      This command supports monitoring the usage of system resources.
      Resources are represented by various metrics associated with the
      host system or a particular VM. For example, the host system has a
      CPU/Load/User metric that shows
      the percentage of time CPUs spend executing in user mode over a
      specific sampling period.
    
      Metric data is collected and retained internally. It may be
      retrieved at any time with the VBoxManage metrics
      query subcommand. The data is available as long as the
      background VBoxSVC process is
      alive. That process terminates shortly after all VMs and frontends
      have been closed.
    
      By default no metrics are collected at all. Metrics collection
      does not start until VBoxManage metrics setup
      is invoked with a proper sampling interval and the number of
      metrics to be retained. The interval is measured in seconds. For
      example, to enable collecting the host processor and memory usage
      metrics every second and keeping the five most current samples,
      the following command can be used:
    VBoxManage metrics setup --period 1 --samples 5 host CPU/Load,RAM/Usage
      Metric collection can only be enabled for started VMs. Collected
      data and collection settings for a particular VM will disappear as
      soon as it shuts down. Use the VBoxManage metrics
      list subcommand to see which metrics are currently
      available. You can also use the --list option
      with any subcommand that modifies metric settings to find out
      which metrics were affected.
    
      Note that the VBoxManage metrics setup
      subcommand discards all samples that may have been previously
      collected for the specified set of objects and metrics.
    
      To enable or disable metrics collection without discarding the
      data, VBoxManage metrics enable and
      VBoxManage metrics disable subcommands can be
      used. Note that these subcommands expect metrics as parameters,
      not submetrics such as CPU/Load
      or RAM/Usage. In other words
      enabling CPU/Load/User while
      disabling CPU/Load/Kernel is not
      supported.
    
      The host and VMs have different sets of associated metrics.
      Available metrics can be listed with VBoxManage metrics
      list subcommand.
    
      A complete metric name may include an aggregate function. The name
      has the following form:
      Category/Metric[/SubMetric][:aggregate].
      For example, RAM/Usage/Free:min
      stands for the minimum amount of available memory over all
      retained data if applied to the host object.
    
      Subcommands may apply to all objects and metrics or can be limited
      to one object and a list of metrics. If no objects or metrics are
      given in the parameters, the subcommands will apply to all
      available metrics of all objects. You may use an asterisk
      ""*"" to explicitly specify that
      the command should be applied to all objects or metrics. Use
      host as the object name to limit
      the scope of the command to host-related metrics. To limit the
      scope to a subset of metrics, use a metric list with names
      separated by commas.
    
      For example, to query metric data on the CPU time spent in user
      and kernel modes by the virtual machine named
      test, use the following command:
    VBoxManage metrics query test CPU/Load/User,CPU/Load/Kernel
      The following list summarizes the available subcommands:
    
list

            Shows the parameters of the currently existing metrics. Note
            that VM-specific metrics are only available when a
            particular VM is running.
          
setup

            Sets the interval between taking two samples of metric data
            and the number of samples retained internally. The retained
            data is available for displaying with the
            query subcommand. The
            --list option shows which
            metrics have been modified as the result of the command
            execution.
          
enable

            Resumes data collection after it has been stopped with the
            disable subcommand. Note that specifying
            submetrics as parameters will not enable underlying metrics.
            Use --list to find out if
            the command worked as expected.
          
disable

            Suspends data collection without affecting collection
            parameters or collected data. Note that specifying
            submetrics as parameters will not disable underlying
            metrics. Use --list to find
            out if the command worked as expected.
          
query

            Retrieves and displays the currently retained metric data.
          Note
              The query subcommand does not remove or
              flush retained data. If you query often enough you will
              see how old samples are gradually being phased out by new
              samples.
            
collect

            Sets the interval between taking two samples of metric data
            and the number of samples retained internally. The collected
            data is displayed periodically until Ctrl+C is pressed,
            unless the --detach option
            is specified. With the
            --detach option, this
            subcommand operates the same way as
            setup does. The
            --list option shows which
            metrics match the specified filter.
          8.34. VBoxManage natnetwork
      NAT networks use the Network Address Translation (NAT) service,
      which works in a similar way to a home router. It groups systems
      using it into a network and prevents outside systems from directly
      accessing those inside, while letting systems inside communicate
      with each other and outside systems using TCP and UDP over IPv4
      and IPv6.
    
      A NAT service is attached to an internal network. Virtual machines
      to make use of one should be attached to it. The name of an
      internal network is chosen when the NAT service is created, and
      the internal network will be created if it does not already exist.
      The following is an example command to create a NAT network:
    VBoxManage natnetwork add --netname natnet1 --network ""192.168.15.0/24"" --enable
      Here, natnet1 is the name of the
      internal network to be used and
      192.168.15.0/24 is the network
      address and mask of the NAT service interface. By default, in this
      static configuration the gateway will be assigned the address
      192.168.15.1, the address after the interface address, though this
      is subject to change.
    
      To add a DHCP server to the NAT network after creation, run the
      following command:
    VBoxManage natnetwork modify --netname natnet1 --dhcp on
      The subcommands for VBoxManage natnetwork are
      as follows:
    VBoxManage natnetwork add --netname <name>
                         [--network <network>]
                         [--enable|--disable]
                         [--dhcp on|off]
                         [--port-forward-4 <rule>]
                         [--loopback-4 <rule>]
                         [--ipv6 on|off]
                         [--port-forward-6 <rule>]
                         [--loopback-6 <rule>]
    
VBoxManage natnetwork add: Creates a new
      internal network interface, and adds a NAT network service. This
      command is a prerequisite for enabling attachment of VMs to the
      NAT network. Parameters are as follows:
    
--netname <name>

            Where <name> is the name of the new internal network
            interface on the host OS.
          
--network <network>

            Where <network> specifies the static or DHCP network
            address and mask of the NAT service interface. The default
            is a static network address.
          
--enable|--disable

            Enables and disables the NAT network service.
          
--dhcp on|off

            Enables and disables a DHCP server specified by
            --netname. Use of this
            option also indicates that it is a DHCP server.
          
--port-forward-4 <rule>

            Enables IPv4 port forwarding, with a rule specified by
            <rule>.
          
--loopback-4 <rule>

            Enables the IPv4 loopback interface, with a rule specified
            by <rule>.
          
--ipv6 on|off

            Enables and disables IPv6. The default setting is IPv4,
            disabling IPv6 enables IPv4.
          
--port-forward-6 <rule>

            Enables IPv6 port forwarding, with a rule specified by
            <rule>.
          
--loopback-6 <rule>

            Enables the IPv6 loopback interface, with a rule specified
            by <rule>.
          VBoxManage natnetwork remove --netname <name> 
VBoxManage natnetwork remove: Removes a NAT
      network service. Parameters are as follows:
    
--netname <name>

            Where <name> specifies an existing NAT network
            service. Does not remove any DHCP server enabled on the
            network.
          VBoxManage natnetwork modify --netname <name>
                            [--network <network>]
                            [--enable|--disable]
                            [--dhcp on|off]
                            [--port-forward-4 <rule>]
                            [--loopback-4 <rule>]
                            [--ipv6 on|off]
                            [--port-forward-6 <rule>]
                            [--loopback-6 <rule>]
    
VBoxManage natnetwork modify: Modifies an
      existing NAT network service. Parameters are as follows:
    
--netname <name>

            Where <name> specifies an existing NAT network
            service.
          
--network <network>

            Where <network> specifies the new static or DHCP
            network address and mask of the NAT service interface. The
            default is a static network address.
          
--enable|--disable

            Enables and disables the NAT network service.
          
--dhcp on|off

            Enables and disables a DHCP server. If a DHCP server is not
            present, using enable adds a new DHCP server.
          
--port-forward-4 <rule>

            Enables IPv4 port forwarding, with a rule specified by
            <rule>.
          
--loopback-4 <rule>

            Enables the IPv4 loopback interface, with a rule specified
            by <rule>.
          
--ipv6 on|off

            Enables and disables IPv6. The default setting is IPv4,
            disabling IPv6 enables IPv4.
          
--port-forward-6 <rule>

            Enables IPv6 port forwarding, with a rule specified by
            <rule>.
          
--loopback-6 <rule>

            Enables IPv6 loopback interface, with a rule specified by
            <rule>.
          VBoxManage natnetwork start --netname <name>
    
VBoxManage natnetwork start: Starts the
      specified NAT network service and any associated DHCP server.
      Parameters are as follows:
    
--netname <name>

            Where <name> specifies an existing NAT network
            service.
          VBoxManage natnetwork stop --netname <name>
    
VBoxManage natnetwork stop: Stops the specified
      NAT network service and any DHCP server. Parameters are as
      follows:
    
--netname <name>

            Where <name> specifies an existing NAT network
            service.
          VBoxManage natnetwork list [<pattern>] 
VBoxManage natnetwork list: Lists all NAT
      network services, with optional filtering. Parameters are as
      follows:
    
[<pattern>]

            Where <pattern> is an optional filtering pattern.
          8.35. VBoxManage hostonlyif
      The hostonlyif command enables you to change
      the IP configuration of a host-only network interface. For a
      description of host-only networking, see
      Section 6.7, “Host-Only Networking”. Each host-only interface is
      identified by a name and can either use the internal DHCP server
      or a manual IP configuration, both IP4 and IP6.
    
      The following list summarizes the available subcommands:
    
ipconfig ""<name>""

            Configures a host-only interface.
          
create

            Creates a new vboxnet<N> interface on the host OS.
            This command is essential before you can attach VMs to a
            host-only network.
          
remove vboxnet<N>

            Removes a vboxnet<N> interface from the host OS.
          8.36. VBoxManage usbdevsource
      The usbdevsource commands enable you to add and
      remove USB devices globally.
    
      The following command adds a USB device.
    VBoxManage usbdevsource add <source name>
                            --backend <backend>
                            --address <address>
    
      Where the command line options are as follows:
    
<source name>:
          Specifies the ID of the source USB device to be added.
          Mandatory.
        
--backend <backend>:
          Specifies the USB proxy service backend to use. Mandatory.
        
 --address <address>:
          Specifies the backend specific address. Mandatory.
        
      The following command removes a USB device.
    VBoxManage usbdevsource remove <source name>
    
      Where the command line options are as follows:
    
<source name>:
          Specifies the ID of the source USB device to be removed.
          Mandatory.
        8.37. VBoxManage unattendedUnattended guest OS installation.SynopsisVBoxManage unattended detect  <--iso=install-iso> [--machine-readable]VBoxManage unattended install  <uuid|vmname> <--iso=install-iso> [--user=login] [--password=password] [--password-file=file] [--full-user-name=name] [--key=product-key] [--install-additions] [--no-install-additions] [--additions-iso=add-iso] [--install-txs] [--no-install-txs] [--validation-kit-iso=testing-iso] [--locale=ll_CC] [--country=CC] [--time-zone=tz] [--hostname=fqdn] [--package-selection-adjustment=keyword] [--dry-run] [--auxiliary-base-path=path] [--image-index=number] [--script-template=file] [--post-install-template=file] [--post-install-command=command] [--extra-install-kernel-parameters=params] [--language=lang] [--start-vm=session-type]Descriptionunattended detectVBoxManage unattended detect  <--iso=install-iso> [--machine-readable]
        Detects the guest operating system (OS) on the specified installation ISO
        and displays the result.  This can be used as input when creating a VM for
        the ISO to be installed in.
      
--iso=install-iso
The installation ISO to run the detection on.
--machine-readable
Produce output that is simpler to parse from a script.unattended installVBoxManage unattended install  <uuid|vmname> <--iso=install-iso> [--user=login] [--password=password] [--password-file=file] [--full-user-name=name] [--key=product-key] [--install-additions] [--no-install-additions] [--additions-iso=add-iso] [--install-txs] [--no-install-txs] [--validation-kit-iso=testing-iso] [--locale=ll_CC] [--country=CC] [--time-zone=tz] [--hostname=fqdn] [--package-selection-adjustment=keyword] [--dry-run] [--auxiliary-base-path=path] [--image-index=number] [--script-template=file] [--post-install-template=file] [--post-install-command=command] [--extra-install-kernel-parameters=params] [--language=lang] [--start-vm=session-type]
        Reconfigures the specified VM for installation and optionally starts it up.
      
uuid|vmname
Either the UUID or the name (case sensitive) of a VM.
--iso=install-iso
The installation ISO to run the detection on.
--user=login
The login name. (default: vboxuser)
--password=password
The login password.  This is used for the user given by --user as well as the
              root/administrator user.  (default: changeme)
--password-file=file
Alternative to --password for providing the password.  Special filename
              stdin can be used to read the password from standard input.
--full-user-name=name
The full user name.  (default: --user)
--key=product-key
The guest OS product key.  Not all guest OSes requires this.--install-additions, --no-install-additionsWhether to install the VirtualBox guest additions.  (default: --no-install-addations)
--additions-iso=add-iso
Path to the VirtualBox guest additions ISO.  (default: installed/downloaded GAs)--install-txs, --no-install-txsWhether to install the test execution service (TXS) from the VirtualBox ValidationKit.
              This is useful when preparing VMs for testing or similar.  (default: --no-install-txs)
--validation-kit-iso=testing-iso
Path to the VirtualBox ValidationKit ISO.  This is required if --install-txs
              is specified. 
--locale=ll_CC
The base locale specification for the guest, like en_US, de_CH, or nn_NO.  (default: host or en_US)
--country=CC
The two letter country code if it differs from the specified by --location.
--time-zone=tz
The time zone to set up the guest OS with. (default: host time zone or UTC)
--hostname=fqdn
The fully qualified domain name of the guest machine.
              (default: vmname.myguest.virtualbox.org)
--package-selection-adjustment=keyword
Adjustments to the guest OS packages/components selection.  This can be specfied more than once.  Currently
              the only recognized keyword is minimal which triggers a minimal installation for
              some of the guest OSes.
--dry-run
Do not create any files or make any changes to the VM configuration.
--start-vm=session-type
Start the VM using the front end given by session-type. This is the same as
              the --type option for the startvm command, but we have add
              none for indicating that the VM should not be started.
              (default: none)Advanced options:
--auxiliary-base-path=path
The path prefix to the media related files generated for the installation.
              (default: vm-config-dir/Unattended-vm-uuid-)
--image-index=number
Windows installation image index. (default: 1)
--script-template=file
The unattended installation script template.  (default: IMachine::OSTypeId dependent)
--post-install-template=file
The post installation script template.  (default: IMachine::OSTypeId dependent)
--post-install-command=command
A single command to run after the installation is completed.  The exact format and exactly
              when this is run is guest OS installer dependent.
--extra-install-kernel-parameters=params

              List of extra linux kernel parameters to use during the installation. (default: IMachine::OSTypeId dependent)
            
--language=lang

              Specifies the UI language for a Windows installation.  The lang is
              generally on the form {ll}-{CC}.  See detectedOSLanguages results from VBoxManage unattended detect.
              (default: detectedOSLanguages[0])8.38. VBoxManage snapshotManage Oracle VM VirtualBox virtual machine snapshots.SynopsisVBoxManage snapshot  <uuid|vmname>VBoxManage snapshot  <uuid|vmname>  take  <snapshot-name> [--description=description] [--live] [--uniquename Number,Timestamp,Space,Force]VBoxManage snapshot  <uuid|vmname>  delete  <snapshot-name>VBoxManage snapshot  <uuid|vmname>  restore  <snapshot-name>VBoxManage snapshot  <uuid|vmname>  restorecurrent VBoxManage snapshot  <uuid|vmname>  edit  < snapshot-name  |   --current > [--description=description] [--name=new-name]VBoxManage snapshot  <uuid|vmname>  list  [[--details] |  [--machinereadable]]VBoxManage snapshot  <uuid|vmname>  showvminfo  <snapshot-name>Description
      The VBoxManage snapshot command manages
      snapshots.
    
      Oracle VM VirtualBox uses the snapshot to capture the state of a virtual
      machine (VM). You can later use the snapshot to revert to the
      state described by the snapshot.
    
      A snapshot is a complete copy of a VM's settings. If you take the
      snapshot while the VM is running, the snapshot also includes the
      VM's state file.
    
      After you take a snapshot, Oracle VM VirtualBox creates a
      differencing hard disk for each normal hard
      disk that is associated with the host machine. When you restore a
      snapshot, Oracle VM VirtualBox uses these differencing files to quickly
      reset the contents of the VM's virtual hard disks.
    
      For each VBoxManage snapshot command, you must
      specify the name or the universal unique identifier (UUID) of the
      VM for which you want to take a snapshot.
    General Command Operand
uuid|vmname

              Specifies the UUID or name of the VM.
            Take a Snapshot of a Virtual MachineVBoxManage snapshot  <uuid|vmname>  take  <snapshot-name> [--description=description] [--live] [--uniquename Number,Timestamp,Space,Force]
        The VBoxManage snapshot take command takes a
        snapshot of the current state of the VM. You must supply a name
        for the snapshot and can optionally supply a description. The
        new snapshot is inserted into the snapshots tree as a child of
        the current snapshot and then becomes the new current snapshot.
      
--description=description

              Specifies a description of the snapshot.
            
--live

              Specifies that the VM is not stopped while you create the
              snapshot. This operation is know as live snapshotting.
            
--uniquename Number,Timestamp,Space,Force

              TBD.
            
snapshot-name

              Specifies the name of the snapshot to create.
            Delete a SnapshotVBoxManage snapshot  <uuid|vmname>  delete  <snapshot-name>
        The VBoxManage snapshot delete command
        removes the specified snapshot.
      
        The delete operation may take some time to finish. This is
        because the differencing images that are associated with the
        snapshot may need to be merged with their child differencing
        images.
      
snapshot-name

              Specifies the UUID or name of the snapshot.
            Restore a SnapshotVBoxManage snapshot  <uuid|vmname>  restore  <snapshot-name>
        The VBoxManage snapshot restore command
        restores the specified snapshot. This operation resets the VM's
        settings and current state to that of the snapshot. The state of
        the VM on which you restore a snapshot is lost. When restored,
        the specified snapshot becomes the new current snapshot and
        subsequent snapshots are children of that snapshot.
      
snapshot-name

              Specifies the UUID or name of the snapshot.
            Restore the Current SnapshotVBoxManage snapshot  <uuid|vmname>  restorecurrent 
        The VBoxManage snapshot restorecurrent
        command restores the current snapshot. The current snapshot is
        the one from which the current state is derived. This command is
        equivalent to using the VBoxManage snapshot
        restore command and specifying the name or UUID of the
        current snapshot.
      Change the Name or Description of an Existing SnapshotVBoxManage snapshot  <uuid|vmname>  edit  < snapshot-name  |   --current > [--description=description] [--name=new-name]
        The VBoxManage snapshot edit command enables
        you to change the name or the description of a specified
        snapshot.
      
snapshot-name

              Specifies the UUID or name of the snapshot to edit.
            
              This option is mutually exclusive with the
              --current option.
            
--current

              Specifies that you update the current version of the
              snapshot.
            
              This option is mutually exclusive with a specific snapshot
              name or its UUID.
            
--description=description

              Specifies a new description for the snapshot.
            
--name=new-name

              Specifies a new name for the snapshot.
            List the SnapshotsVBoxManage snapshot  <uuid|vmname>  list  [[--details] |  [--machinereadable]]
        The VBoxManage snapshot list command lists
        all the snapshots for a VM.
      
--details

              Specifies that the output shows detailed information about
              the snapshot.
            
              This option is mutually exclusive with the
              --machinereadable option.
            
--machinereadable

              Specifies that the output is shown in a machine-readable
              format.
            
              This option is mutually exclusive with the
              --details option.
            Show Information About a Snapshot's SettingsVBoxManage snapshot  <uuid|vmname>  showvminfo  <snapshot-name>
        The VBoxManage snapshot showvminfo command
        enables you to view the VM settings that are part of an existing
        snapshot.
      
snapshot-name

              Specifies the UUID or name of the snapshot.
            Examples
      The following command creates a snapshot of the
      ol7u4 VM. The snapshot is called
      ol7u4-snap-001. The command uses
      the --description option to provide a description
      of the snapshot contents.
    
$ VBoxManage snapshot ol7u4 take ol7u4-snap-001 \
--description=""Oracle Linux 7.4""

      The following command lists the snapshots for the
      ol7u4 VM.
    
$ VBoxManage snapshot ol7u4 list

      The following command changes the description for the
      ol7u4-snap-001 snapshot of the
      ol7u4 VM.
    
$ VBoxManage snapshot ol7u4 edit ol7u4-snap-001 \
--description=""Oracle Linux 7.4 with UEK4 kernel""

      The following command shows VM settings for the
      ol7u1-snap-001 snapshot of the
      ol7u4 VM.
    
$ VBoxManage snapshot ol7u4 showvminfo ol7u4-snap-001
Name:            ol7u4
Groups:          /
Guest OS:        Oracle (64-bit)
UUID:            43349d78-2ab3-4cb8-978f-0e755cd98090
Config file:     C:\Users\user1\VirtualBox VMs\ol7u4\ol7u4.vbox
...
Snapshots:

   Name: ol7u4-snap-001 (UUID: 1cffc37d-5c37-4b86-b9c5-a0f157a55f43)
   Description: Oracle Linux 7.4 with UEK4 kernel
8.39. VBoxManage clonevmCreate a clone of an existing Oracle VM VirtualBox virtual machine.SynopsisVBoxManage clonevm  <vmname|uuid> [--basefolder=basefolder] [--groups=group,...] [ --mode=machine  |   --mode=machinechildren  |   --mode=all ] [--name=name] [--options=option,...] [--register] [--snapshot=snapshot-name] [--uuid=uuid]Description
      The VBoxManage clonevm command creates a clone
      of an existing virtual machine (VM). The clone can be a full copy
      of the VM or a linked copy of a VM.
    
      You must specify the name or the universal unique identifier
      (UUID) of the VM you want to clone.
    Command Operand and Options
      The following list describes the operand and the options that you
      can use with the VBoxManage clonevm command:
    
vmname|uuid

            Specifies the name or UUID of the VM to clone.
          
--basefolder=basefolder

            Specifies the name of the folder in which to save the
            configuration for the new VM.
          
--groups=group,...

            Assigns the clone to the specified group or groups. If you
            specify more than one group, separate each group name with a
            comma.
          
            Note that each group is identified by a group ID that starts
            with a slash character (/)
            so that groups can be nested. By default, a clone is always
            assigned membership to the
            / group.
          
--mode=machine|machineandchildren|all

            Specifies which of the following cloning modes to use:
          machine mode clones the
                current state of the existing VM without any snapshots.
                This is the default mode.
              machineandchildren mode
                clones the snapshot specified by by the
                --snapshot option and all child
                snapshots.
              all mode clones all
                snapshots and the current state of the existing VM.
              
--name=name

            Specifies a new name for the new VM. The default value is
            original-name
            Clone where
            original-name is the original
            name of the VM.
          
--options=option,...

            Specifies how to create the new clone.The --options argument can be used multiple
            times to enable multiple options, or the options can be given as a
            comma separated list.  The options are case insensitive.The following options (case-insensitive) are recognized:
Link

                  Creates a linked clone from a snapshot only.
                
KeepAllMACs

                  Specifies that the new clone reuses the MAC addresses
                  of each virtual network card from the existing VM.
                
                  If you do not specify this option or the
                  --options=keepnatmacs option, the
                  default behavior is to reinitialize the MAC addresses
                  of each virtual network card.
                
KeepNATMACs

                  Specifies that the new clone reuses the MAC addresses
                  of each virtual network card from the existing VM when
                  the network type is NAT.
                
                  If you do not specify this option or the
                  KeepAllMACs option, the
                  default behavior is to reinitialize the MAC addresses
                  of each virtual network card.
                
KeepDiskNames

                  Specifies that the new clone reuses the disk image
                  names from the existing VM. By default, disk images
                  are renamed.
                
KeepHwUUIDs

                  Specifies that the new clone reuses the hardware IDs
                  from the existing VM. By default, new UUIDs are used.
                
--register

            Automatically registers the new clone in this Oracle VM VirtualBox
            installation. You can manually register the new VM later by
            using the VBoxManage registervm command.
            See Section 8.6, “VBoxManage registervm/unregistervm”.
          
--snapshot=snapshot-name

            Specifies the snapshot on which to base the new VM. By
            default, the clone is created from the current state of the
            specified VM.
          
--uuid=uuid

            Specifies the UUID for the new VM. Ensure that this ID is
            unique for the Oracle VM VirtualBox instance if you decide to
            register this new VM. By default, Oracle VM VirtualBox provides a
            new UUID.
          Examples
      The following command creates and registers an exact clone of the
      ol7 VM. The clone is called
      ol7-dev-001.
    
      The new clone includes all of the source VM's snapshots. The new
      VM also reuses all network interface MAC addresses, disk names,
      and UUIDs from the source VM.
    
$ VBoxManage clonevm ol7 --name=""ol7-dev-001"" --register --mode=all \
    --options=keepallmacs --options=keepdisknames --options=keephwuuids

      The following command creates and registers a clone of the
      Snapshot 1 snapshot of the
      ol7 VM. The clone is called
      ol7-dev-002.
    
$ VBoxManage clonevm ol7 --name=""ol7-dev-002"" --register --snapshot=""Snapshot 1""
See Also
Section 8.6, “VBoxManage registervm/unregistervm”
8.40. VBoxManage sharedfolderAdd and remove shared folders.SynopsisVBoxManage sharedfolder add  < uuid  |   vmname > <--name=name> <--hostpath=hostpath> [--readonly] [--transient] [--automount] [--auto-mount-point=path]VBoxManage sharedfolder remove  < uuid  |   vmname > <--name=name> [--transient]Description
      Shared folders enable you to share data between the host system
      and guests. To use shared folders, you must first install the
      Oracle VM VirtualBox Guest Additions software on the guest OS.
    
      The shared folder is associated with a share name and the full
      path name of the folder or directory on the host system. The share
      name is a unique name within the namespace of the host OS.
    Add a Shared FolderVBoxManage sharedfolder add  < uuid  |   vmname > <--name=name> <--hostpath=hostpath> [--readonly] [--transient] [--automount] [--auto-mount-point=path]
        The VBoxManage sharedfolder add command
        creates a shared folder. The folder you specify is on the host
        computer. When configured, the contents of the folder on the
        host system can be shared with the guest OS.
      uuid|vmname
              Specifies the name or UUID of the guest VM that shares a
              folder with the host system.
            --name=name
              Specifies the name of the share, which is a unique name
              within the namespace of the host OS.
            --hostpath=hostpath
              Specifies the absolute path of the folder or directory on
              the host OS to share with the guest OS.
            --readonly
              Specifies that the share has only read-only access to
              files at the host path.
            
              By default, shared folders have read-write access to the
              files at the host path. However on Linux distributions,
              shared folders are mounted with 770 file permissions with
              the root user and the
              vboxsf group. By using this option, the
              file permissions become 700.
            --transient
              Specifies that the share is transient, which means that it
              can be added and removed at runtime and does not persist
              after the VM stops.
            --automount
              Specifies that the share is automatically mounted.
            --auto-mount-point=path
               Specifies the mount point of the share.  This guest OS specific.
             
               For Windows and OS/2 guest this must be an unused drive letter.
               If left blank (or if the drive letter is already in use), the
               last unused drive letter is used instead (i.e. searching from
               Z: thru A:).
             
               For Linux, Solaris and other unix guest, it must be an absolute
               path like /mnt/mysharedfolder.  If left
               empty the default location is
               /media/sf_sharename.
             Remove a Shared FolderVBoxManage sharedfolder remove  < uuid  |   vmname > <--name=name> [--transient]
        The VBoxManage sharedfolder remove command
        removes a shared folder.
      uuid|vmname
              Specifies the name or UUID of the guest VM that shares a
              folder with the host system.
            --name=name
              Specifies the name of the share to remove.
            --transient
              Specifies that the share is transient, which means that it
              can be added and removed at runtime and does not persist
              after the VM stops.
            Examples
      The following command creates a shared folder called
      o7share for the ol7 VM.
      The share is mounted automatically when the VM is started.
    $ VBoxManage sharedfolder add ol7 --name ol7share --hostpath ""/home/user/ol7share"" --automount
      The following command removes the shared folder called
      o7share for the ol7 VM.
    $ VBoxManage sharedfolder remove ol7 --name ol7share8.41. VBoxManage extpackExtension package management.SynopsisVBoxManage extpack install  [--replace] [--accept-license=sha256] <tarball>VBoxManage extpack uninstall  [--force] <name>VBoxManage extpack cleanup Descriptionextpack installVBoxManage extpack install  [--replace] [--accept-license=sha256] <tarball>
        Installs a new extension pack on the system.  This command will fail if an older
        version of the same extension pack is already installed.  The
        --replace option can be used to uninstall any
        old package before the new one is installed.
      
--replace
Uninstall existing extension pack version.
--accept-license=sha256
Accept the license text with the given SHA-256 hash value.VBoxManage will display the SHA-256 value when performing a manual
            installation.  The hash can of course be calculated by looking inside
            the extension pack and using sha256sum or similar on the license file.
tarball
The file containing the extension pack to be installed.extpack uninstallVBoxManage extpack uninstall  [--force] <name>
        Uninstalls an extension pack from the system.  The subcommand will also succeed
        in the case where the specified extension pack is not present on the system.
        You can use VBoxManage list extpacks to show
        the names of the extension packs which are currently installed.
      
--force
Overrides most refusals to uninstall an extension pack
name
The name of the extension pack to be uninstalled.extpack cleanupVBoxManage extpack cleanup 
        Used to remove temporary files and directories that may have been left behind
        if a previous install or uninstall command failed.
      Examples
          How to list extension packs:
$ VBoxManage list extpacks
Extension Packs: 1
Pack no. 0:   Oracle VM VirtualBox Extension Pack
Version:      4.1.12
Revision:     77218
Edition:
Description:  USB 2.0 Host Controller, VirtualBox RDP, PXE ROM with E1000 support.
VRDE Module:  VBoxVRDP
Usable:       true
Why unusable:How to remove an extension pack:
$ VBoxManage extpack uninstall ""Oracle VM VirtualBox Extension Pack""
0%...10%...20%...30%...40%...50%...60%...70%...80%...90%...100%
Successfully uninstalled ""Oracle VM VirtualBox Extension Pack"".8.42. VBoxManage dhcpserverDHCP server management.SynopsisVBoxManage dhcpserver add  < --network=netname  |   --interface=ifname > <--server-ip=address> <--netmask=mask> <--lower-ip=address> <--upper-ip=address> < --enable  |   --disable > [[--global] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--incl-mac=address...] [--excl-mac=address...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--incl-vendor=string...] [--excl-vendor=string...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--incl-user=string...] [--excl-user=string...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--vm=name|uuid> [--nic=1-N] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...] [<--mac-address=address> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...]VBoxManage dhcpserver modify  < --network=netname  |   --interface=ifname > [--server-ip=address] [--lower-ip=address] [--upper-ip=address] [--netmask=mask] [ --enable  |   --disable ] [[--global] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--del-mac=address...] [--incl-mac=address...] [--excl-mac=address...] [--del-mac-wild=pattern...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--del-vendor=string...] [--incl-vendor=string...] [--excl-vendor=string...] [--del-vendor-wild=pattern...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--del-user=string...] [--incl-user=string...] [--excl-user=string...] [--del-user-wild=pattern...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--zap-conditions] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--vm=name|uuid> [--nic=1-N] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...] [<--mac-address=address> [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...]VBoxManage dhcpserver remove  < --network=netname  |   --interface=ifname >VBoxManage dhcpserver restart  < --network=netname  |   --interface=ifname >VBoxManage dhcpserver findlease  < --network=netname  |   --interface=ifname > <--mac-address=mac>Description
      The dhcpserver commands enable you to control the DHCP
       server that is built into VirtualBox.  You may find this useful when
       using internal or host-only networking.  Theoretically, you can also
       enable it for a bridged network, but that may cause conflicts with other
       DHCP servers in your physical network.
    Common optionsThe subcommands of dhcpserver all operate on an
        internal network that can be identified via its name or in the host-only
        case via the host-only interface name:--network=netnameThe internal network name.  This is the same as you
            would use as value to the VBoxManage modifyvm --intnet
            option when configuring a VM for internal networking.  Or you see as
            VBoxNetworkName in the output from
            VBoxManage list intnets,
            VBoxManage list natnets, or
            VBoxManage list hostonlyifs.
          --interface=ifnameThe host only interface name.  This would be same value
            as you would use for the VBoxManage modifyvm --hostonlyadapter
            option when configuring a VM to use a host-only network.  The value
            can also be found in the Name row in VBoxManage list hostonlyifs.
          dhcpserver addVBoxManage dhcpserver add  < --network=netname  |   --interface=ifname > <--server-ip=address> <--netmask=mask> <--lower-ip=address> <--upper-ip=address> < --enable  |   --disable > [[--global] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--incl-mac=address...] [--excl-mac=address...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--incl-vendor=string...] [--excl-vendor=string...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--incl-user=string...] [--excl-user=string...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds]...] [<--vm=name|uuid> [--nic=1-N] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...] [<--mac-address=address> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address]...]
        Adds a new DHCP server to a network or host-only interface.
      
        Options configuring the DHCP server core:
      
--server-ip=address
The IP address the DHCP server should use.--lower-ip=address, --upper-ip=addressThe IP address range for the DHCP server to manage.  This
            should not include the address of the DHCP server itself, but it must be
            in the same network as it.  The boundraries are inclusive, so both the
            lower and upper addresses will be handed out to clients.
--netmask=mask
The network mask.  Typically 255.255.255.0.--enable, --disableWhether to enable the DHCP server or disable it.  If not specified,
            the server will be created in disabled state and no IP addresses handed out.
        Options selecting the scope:
      
--global
Set the configuration scope to global.  Any subsequent
            --set-opt options will be apply to all the DHCP clients.
--vm=vmname|uuid
Set the configuration scope to the first NIC of the specified VM.  Any
            subsequent --set-opt options will apply just to that interface,
            nothing else.
--nic=1-N
Set the configuration scope to a NIC other than first of
            the VM specified the in --vm.
          
--mac-address=address
Set the configuration scope to the specified MAC address.
--group=name
Set the configuration scope to the specified group.
        Options configuring the currently selected scope:
      
--set-opt=dhcp-opt-no value
Adds the specified DHCP option number (0-255) and value.  The
            value format is option specific (typically human readable) and will be
            validated by the API and the DHCP server.
          
--set-opt-hex=dhcp-opt-no hexstring
Adds the specified DHCP option number (0-255) and value.  The option value
            is specified as a raw series of hex bytes, optionally separated by colons.  No validation
            is performed on these by the API or the DHCP server, they will be pass as specified to the
            client.
          
--force-opt=dhcp-opt-no
Forces the specified DHCP option number (0-255) onto to be
            sent to the client whether it requested it or not (provided the option is
            configured with a value at some level).
          
--suppress-opt=dhcp-opt-no
Prevents the specified DHCP option number (0-255) from being
            sent to the client when present in this or a high configuration scope.
          
--min-lease-time=seconds
Sets the minimum lease time for the current scope in seconds.
            Zero means taking the value from a higher option level or use default.
          
--default-lease-time=seconds
Sets the default lease time for the current scope in seconds.
            Zero means taking the value from a higher option level or use default.
          
--max-lease-time=seconds
Sets the maximum lease time for the current scope in seconds.
            Zero means taking the value from a higher option level or use default.
          
--fixed-address=address
Fixed address assignment for a --vm or
            --mac-address configuration scope.  Any empty
            address turns it back to dynamic address assignment.
          
        Options configuring group membership conditions (excludes overrides includes):
      
--incl-mac=address
Include the specific MAC address in the group.
--excl-mac=address
Exclude the specific MAC address from the group.
--incl-mac-wild=pattern
Include the specific MAC address pattern in the group.
--excl-mac-wild=pattern
Exclude the specific MAC address pattern from the group.
--incl-vendor=string
Include the specific vendor class ID  in the group.
--excl-vendor=string
Exclude the specific vendor class ID from the group.
--incl-vendor-wild=pattern
Include the specific vendor class ID pattern in the group.
--excl-vendor-wild=pattern
Exclude the specific vendor class ID pattern from the group.
--incl-user=string
Include the specific user class ID  in the group.
--excl-user=string
Exclude the specific user class ID from the group.
--incl-user-wild=pattern
Include the specific user class ID pattern in the group.
--excl-user-wild=pattern
Exclude the specific user class ID pattern from the group.dhcpserver modifyVBoxManage dhcpserver modify  < --network=netname  |   --interface=ifname > [--server-ip=address] [--lower-ip=address] [--upper-ip=address] [--netmask=mask] [ --enable  |   --disable ] [[--global] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--group=name> [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--del-mac=address...] [--incl-mac=address...] [--excl-mac=address...] [--del-mac-wild=pattern...] [--incl-mac-wild=pattern...] [--excl-mac-wild=pattern...] [--del-vendor=string...] [--incl-vendor=string...] [--excl-vendor=string...] [--del-vendor-wild=pattern...] [--incl-vendor-wild=pattern...] [--excl-vendor-wild=pattern...] [--del-user=string...] [--incl-user=string...] [--excl-user=string...] [--del-user-wild=pattern...] [--incl-user-wild=pattern...] [--excl-user-wild=pattern...] [--zap-conditions] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--remove-config]...] [<--vm=name|uuid> [--nic=1-N] [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...] [<--mac-address=address> [--del-opt=dhcp-opt-no...] [--set-opt=dhcp-opt-no value...] [--set-opt-hex=dhcp-opt-no hexstring...] [--force-opt=dhcp-opt-no...] [--unforce-opt=dhcp-opt-no...] [--supress-opt=dhcp-opt-no...] [--unsupress-opt=dhcp-opt-no...] [--min-lease-time=seconds] [--default-lease-time=seconds] [--max-lease-time=seconds] [--fixed-address=address] [--remove-config]...]
        This modifies an existing DHCP server configuration.  It takes the same
        options as the add command with the addition of the following
        on scope configuration:
      
--del-opt=dhcp-opt-no
Counterpart to --set-opt that will cause the specified
            DHCP option number (0-255) to be deleted from the server settings.  Like with
            --set-opt the scope of the deletion is governed by the
            --global, --vm, --mac-address
            and --group options.
          
--unforce-opt=dhcp-opt-no
Removes the specified DHCP option number (0-255) from the forced
            option list (i.e. the reverse of --force-opt).  Like with
            --set-opt the scope of the deletion is governed by the
            --global, --vm, --mac-address
            and --group options.
          
--unsuppress-opt=dhcp-opt-no
Removes the specified DHCP option number (0-255) from the supressed
            option list (i.e. the reverse of --suppress-opt). Like with
            --set-opt the scope of the deletion is governed by the
            --global, --vm, --mac-address
            and --group options.
          
--remove-config
Removes the configuration currently being scoped.  The
          --global scope is not removable.  The configuration scope will
           change to --global after this option.
          
        And the addition of these group membership condition options:
      
--del-mac=address
Delete the specific MAC address from the group conditions.
--del-mac-wild=pattern
Delete the specific MAC address pattern from the group conditions.
--del-vendor=string
Delete the specific vendor class ID from the group conditions.
--del-vendor-wild=pattern
Delete the specific vendor class ID pattern from the group conditions.
--del-user=string
Delete the specific user class ID pattern from the group conditions.
--del-user-wild=pattern
Delete the specific user class ID pattern from the group conditions.
--zap-conditions
Deletes all the group conditions.dhcpserver removeVBoxManage dhcpserver remove  < --network=netname  |   --interface=ifname >
        Removes the specified DHCP server.
      dhcpserver restartVBoxManage dhcpserver restart  < --network=netname  |   --interface=ifname >
        Restarts the specified DHCP server.  The DHCP server must be running.
      dhcpserver findleaseVBoxManage dhcpserver findlease  < --network=netname  |   --interface=ifname > <--mac-address=mac>
        Performs a lease database lookup.  This is mainly for getting the IP
        address of a running VM.
      
--mac-address=mac
The MAC address to lookup in the lease database.Common DHCP Options:1 - SubnetMaskIPv4 netmask. Set to the value of the --netmask option by default.2 - TimeOffsetUTC offset in seconds (32-bit decimal value).3 - RoutersSpace separated list of IPv4 router addresses.4 - TimeServersSpace separated list of IPv4 time server (RFC 868) addresses.5 - NameServersSpace separated list of IPv4 name server (IEN 116) addresses.6 - DomainNameServersSpace separated list of IPv4 DNS addresses.7 - LogServersSpace separated list of IPv4 log server addresses.8 - CookieServersSpace separated list of IPv4 cookie server (RFC 865) addresses.9 - LPRServersSpace separated list of IPv4 line printer server (RFC 1179) addresses.10 - ImpressServersSpace separated list of IPv4 imagen impress server addresses.11 - ResourseLocationServersSpace separated list of IPv4 resource location (RFC 887) addresses.12 - HostNameThe client name. See RFC 1035 for character limits. 13 - BootFileSizeNumber of 512 byte blocks making up the boot file (16-bit decimal value).14 - MeritDumpFileClient core file.15 - DomainNameDomain name for the client.16 - SwapServerIPv4 address of the swap server that the client should use.17 - RootPathThe path to the root disk the client should use.18 - ExtensionPathPath to a file containing additional DHCP options (RFC2123).19 - IPForwardingWhether IP forwarding should be enabled by the client (boolean).20 - OptNonLocalSourceRoutingWhether non-local datagrams should be forwarded by the client (boolean)21 - PolicyFilterList of IPv4 addresses and masks paris controlling non-local source routing.22 - MaxDgramReassemblySizeThe maximum datagram size the client should reassemble (16-bit decimal value).23 - DefaultIPTTLThe default time-to-leave on outgoing (IP) datagrams (8-bit decimal value).24 - PathMTUAgingTimeoutRFC1191 path MTU discovery timeout value in seconds (32-bit decimal value).25 - PathMTUPlateauTableRFC1191 path MTU discovery size table, sorted in ascending order (list of 16-bit decimal values).26 - InterfaceMTUThe MTU size for the interface (16-bit decimal value).27 - AllSubnetsAreLocalIndicates whether the MTU size is the same for all subnets (boolean).28 - BroadcastAddressBroadcast address (RFC1122) for the client to use (IPv4 address).29 - PerformMaskDiscoveryWhether to perform subnet mask discovery via ICMP (boolean).30 - MaskSupplierWhether to respond to subnet mask requests via ICMP (boolean).31 - PerformRouterDiscoveryWhether to perform router discovery (RFC1256) (boolean).32 - RouterSolicitationAddressWhere to send router solicitation requests (RFC1256) (IPv4 address).33 - StaticRouteList of network and router address pairs addresses.34 - TrailerEncapsulationWhether to negotiate the use of trailers for ARP (RTF893) (boolean).35 - ARPCacheTimeoutThe timeout in seconds for ARP cache entries (32-bit decimal value).36 - EthernetEncapsulationWhether to use IEEE 802.3 (RTF1042) rather than of v2 (RFC894) ethernet encapsulation (boolean).37 - TCPDefaultTTLDefault time-to-live for TCP sends (non-zero 8-bit decimal value).38 - TCPKeepaliveIntervalThe interface in seconds between TCP keepalive messages (32-bit decimal value).39 - TCPKeepaliveGarbageWhether to include a byte of garbage in TCP keepalive messages for backward compatibility (boolean).40 - NISDomainThe NIS (Sun Network Information Services) domain name (string).41 - NISServersSpace separated list of IPv4 NIS server addresses.42 - NTPServersSpace separated list of IPv4 NTP (RFC1035) server addresses.43 - VendorSpecificInfoVendor specific information. Only accessible using --set-opt-hex.44 - NetBIOSNameServersSpace separated list of IPv4 NetBIOS name server (NBNS) addresses (RFC1001,RFC1002).45 - NetBIOSDatagramServersSpace separated list of IPv4 NetBIOS datagram distribution server (NBDD) addresses (RFC1001,RFC1002).46 - NetBIOSNodeTypeNetBIOS node type (RFC1001,RFC1002): 1=B-node, 2=P-node, 4=M-node, and 8=H-node (8-bit decimal value).47 - NetBIOSScopeNetBIOS scope (RFC1001,RFC1002). Only accessible using --set-opt-hex.48 - XWindowsFontServersSpace separated list of IPv4 X windows font server addresses.49 - XWindowsDisplayManagerSpace separated list of IPv4 X windows display manager addresses.62 - NetWareIPDomainNameNetware IP domain name (RFC2242) (string).63 - NetWareIPInformationNetware IP information (RFC2242). Only accessible using --set-opt-hex.64 - NISPlusDomainThe NIS+ domain name (string).65 - NISPlusServersSpace separated list of IPv4 NIS+ server addresses.66 - TFTPServerNameTFTP server name (string).67 - BootfileNameBootfile name (string).68 - MobileIPHomeAgentsSpace separated list of IPv4 mobile IP agent addresses.69 - SMTPServersSpace separated list of IPv4 simple mail transport protocol (SMPT) server addresses.70 - POP3ServersSpace separated list of IPv4 post office protocol 3 (POP3) server addresses.71 - NNTPServersSpace separated list of IPv4 network news transport protocol (NTTP) server addresses.72 - WWWServersSpace separated list of default IPv4 world wide web (WWW) server addresses.73 - FingerServersSpace separated list of default IPv4 finger server addresses.74 - IRCServersSpace separated list of default IPv4 internet relay chat (IRC) server  addresses.75 - StreetTalkServersSpace separated list of IPv4 StreetTalk server addresses.76 - STDAServersSpace separated list of IPv4 StreetTalk directory assistance (STDA) server addresses.78 - SLPDirectoryAgentAddresses of one or more service location protocol (SLP) directory agent, and an indicator of whether their use is mandatory. Only accessible using --set-opt-hex.79 - SLPServiceScopeList of service scopes for the service location protocol (SLP) and whether using the list is mandator. Only accessible using --set-opt-hex.119 - DomainSearchDomain search list, see RFC3397 and section 4.1.4 in RFC1035 for encoding.  Only accessible using --set-opt-hex.8.43. VBoxManage debugvmIntrospection and guest debugging.SynopsisVBoxManage debugvm  <uuid|vmname>  dumpvmcore  [--filename=name]VBoxManage debugvm  <uuid|vmname>  info  <item> [args...]VBoxManage debugvm  <uuid|vmname>  injectnmi VBoxManage debugvm  <uuid|vmname>  log  [[--release] |  [--debug]] [group-settings...]VBoxManage debugvm  <uuid|vmname>  logdest  [[--release] |  [--debug]] [destinations...]VBoxManage debugvm  <uuid|vmname>  logflags  [[--release] |  [--debug]] [flags...]VBoxManage debugvm  <uuid|vmname>  osdetect VBoxManage debugvm  <uuid|vmname>  osinfo VBoxManage debugvm  <uuid|vmname>  osdmesg  [--lines=lines]VBoxManage debugvm  <uuid|vmname>  getregisters  [--cpu=id] [reg-set.reg-name...]VBoxManage debugvm  <uuid|vmname>  setregisters  [--cpu=id] [reg-set.reg-name=value...]VBoxManage debugvm  <uuid|vmname>  show  [[--human-readable] |  [--sh-export] |  [--sh-eval] |  [--cmd-set]] [settings-item...]VBoxManage debugvm  <uuid|vmname>  stack  [--cpu=id]VBoxManage debugvm  <uuid|vmname>  statistics  [--reset] [--descriptions] [--pattern=pattern]DescriptionThe ""debugvm"" commands are for experts who want to tinker with the
      exact details of virtual machine execution.  Like the VM debugger
      described in Section 12.1.4, “The Built-In VM Debugger”, these commands are only useful if you are
      very familiar with the details of the PC architecture and how to debug
      software.Common optionsThe subcommands of debugvm all operate on a running virtual
      machine:
uuid|vmname
Either the UUID or the name (case sensitive) of a VM.debugvm dumpvmcoreVBoxManage debugvm  <uuid|vmname>  dumpvmcore  [--filename=name]
        Creates a system dump file of the specified VM.  This file will have
        the standard ELF core format (with custom sections); see
        Section 12.1.5, “VM Core Format”.
      
        This corresponds to the writecore command in the debugger.
      
--filename=filename
The name of the output file.debugvm infoVBoxManage debugvm  <uuid|vmname>  info  <item> [args...]
        Displays info items relating to the VMM, device emulations and
        associated drivers.
      
        This corresponds to the info command in the debugger.
      
info
Name of the info item to display.  The special name
            help will list all the available info items and
            hints about optional arguments.
args
Optional argument string for the info item handler.  Most info items
            does not take any extra arguments.  Arguments not recognized are generally
            ignored.debugvm injectnmiVBoxManage debugvm  <uuid|vmname>  injectnmi 
        Causes a non-maskable interrupt (NMI) to be injected into the guest. This
        might be useful for certain debugging scenarios. What happens exactly is
        dependent on the guest operating system, but an NMI can crash the whole
        guest operating system. Do not use unless you know what you're doing.
      debugvm logVBoxManage debugvm  <uuid|vmname>  log  [[--release] |  [--debug]] [group-settings...]
        Changes the group settings for either debug (--debug)
        or release (--release) logger of the VM process.
      
        The group-settings are typically strings on the form
        em.e.f.l, hm=~0
        and -em.f.  Basic wildcards are supported for
        group matching.  The all group is an alias for
        all the groups.
      
        Please do keep in mind that the group settings are applied as modifications
        to the current ones.
      
        This corresponds to the log command in the debugger.
      debugvm logdestVBoxManage debugvm  <uuid|vmname>  logdest  [[--release] |  [--debug]] [destinations...]
        Changes the destination settings for either debug (--debug)
        or release (--release) logger of the VM process.  For details
        on the destination format, the best source is src/VBox/Runtime/common/log/log.cpp.
      
        The destinations is one or more mnemonics, optionally
        prefixed by ""no"" to disable them.  Some of them take values after a "":"" or ""=""
        separator.  Multiple mnemonics can be separated by space or given as separate
        arguments on the command line.
      
        List of available destination:
      
file[=file], nofile
Specifies a log file.  It no filname is given, one will be
              generated based on the current UTC time and VM process name and placed in
              the current directory of the VM process.  Note that this will currently not
              have any effect if the log file has already been opened.
          
dir=directory, nodir
Specifies the output directory for log files.  Note that this
              will currently not  have any effect if the log file has already been opened.
          
history=count, nohistory
A non-zero value enables log historization, with the value
            specifying how many old log files to keep.
          
histsize=bytes
The max size of a log file before it is historized.  Default is infinite.
histtime=seconds
The max age (in seconds) of a log file before it is historized.  Default is infinite.
ringbuffer, noringbuffer
Only log to the log buffer until an explicit flush (e.g. via an assertion)
              occurs.  This is fast and saves diskspace.
stdout, nostdout
Write the log content to standard output.
stdout, nostdout
Write the log content to standard error.
debugger, nodebugger
Write the log content to the debugger, if supported by the host OS.
com, nocom
Writes logging to the COM port. This is only applicable for raw-mode and ring-0 logging.
user, nouser
Custom destination which has no meaning to VM processes..
        This corresponds to the logdest command in the debugger.
      debugvm logflagsVBoxManage debugvm  <uuid|vmname>  logflags  [[--release] |  [--debug]] [flags...]
        Changes the flags on either debug (--debug) or release
        (--release) logger of the VM process.  Please note that the
        modifications are applied onto the existing changes, they are not replacing them.
      
        The flags are a list of flag mnemonics, optionally
        prefixed by a ""no"", ""!"", ""~"" or ""-"" to negate their meaning.  The ""+"" prefix
        can be used to undo previous negation or use as a separator, though better use
        whitespace or separate arguments for that.
      
        List of log flag mnemonics, with their counter form where applicable
        (asterisk indicates defaults):
      
enabled*, disabled
Enables or disables logging.
buffered, unbuffered*
Enabling buffering of log output before it hits the destinations.
writethrough(/writethru)
Whether to open the destination file with writethru buffering settings or not.
flush
Enables flushing of the output file (to disk) after each log statement.
lockcnts
Prefix each log line with lock counts for the current thread.
cpuid
Prefix each log line with the ID of the current CPU.
pid
Prefix each log line with the current process ID.
flagno
Prefix each log line with the numberic flags corresponding to the log statement.
flag
Prefix each log line with the flag mnemonics corresponding to the log statement.
groupno
Prefix each log line with the log group number for the log statement producing it.
group
Prefix each log line with the log group name for the log statement producing it.
tid
Prefix each log line with the current thread identifier.
thread
Prefix each log line with the current thread name.
time
Prefix each log line with the current UTC wall time.
timeprog
Prefix each log line with the current monotonic time since the start of the program.
msprog
Prefix each log line with the current monotonic timestamp value in milliseconds since the start of the program.
ts
Prefix each log line with the current monotonic timestamp value in nanoseconds.
tsc
Prefix each log line with the current CPU timestamp counter (TSC) value.
rel, abs*
Selects the whether ts and
              tsc prefixes should be displayed as relative to the
              previous log line or as absolute time.
hex*, dec
Selects the whether the ts and
              tsc prefixes should be formatted as hexadecimal
              or decimal.
custom
Custom log prefix, has by default no meaning for VM processes.
usecrlf, uself*
Output with DOS style (CRLF) or just UNIX style (LF) line endings.
overwrite*, append
Overwrite the destination file or append to it.
        This corresponds to the logflags command in the debugger.
      debugvm osdetectVBoxManage debugvm  <uuid|vmname>  osdetect 
        Make the VMM's debugger facility (re)-detect the guest operating system (OS).
        This will first load all debugger plug-ins.
      
        This corresponds to the detect command in the debugger.
      debugvm osinfoVBoxManage debugvm  <uuid|vmname>  osinfo 
        Displays information about the guest operating system (OS) previously
        detected by the VMM's debugger facility.
      debugvm osdmesgVBoxManage debugvm  <uuid|vmname>  osdmesg  [--lines=lines]
        Displays the guest OS kernel log, if detected and supported.
      
--lines=lines
Number of lines of the log to display, counting from
          the end. The default is infinite.debugvm getregistersVBoxManage debugvm  <uuid|vmname>  getregisters  [--cpu=id] [reg-set.reg-name...]
        Retrieves register values for guest CPUs and emulated devices.
      
reg-set.reg-name
One of more registers, each having one of the following forms:register-set.register-name.sub-fieldregister-set.register-namecpu-register-name.sub-fieldcpu-register-nameallThe all form will cause all registers
              to be shown (no sub-fields).  The registers names are case-insensitive.
            
--cpu=id
Selects the CPU register set when specifying just a
            CPU register (3rd and 4th form).  The default is 0.debugvm setregistersVBoxManage debugvm  <uuid|vmname>  setregisters  [--cpu=id] [reg-set.reg-name=value...]
        Changes register values for guest CPUs and emulated devices.
      
reg-set.reg-name=value
One of more register assignment, each having one of the following forms:register-set.register-name.sub-field=valueregister-set.register-name=valuecpu-register-name.sub-field=valuecpu-register-name=valueThe value format should be in the same style as what
              getregisters displays, with the exception that
              both octal and decimal can be used instead of hexadecimal.
--cpu=id
Selects the CPU register set when specifying just a
            CPU register (3rd and 4th form).  The default is 0.debugvm showVBoxManage debugvm  <uuid|vmname>  show  [[--human-readable] |  [--sh-export] |  [--sh-eval] |  [--cmd-set]] [settings-item...]
        Shows logging settings for the VM.
      
--human-readable
Selects human readable output.
--sh-export
Selects output format as bourne shell style export commands.
--sh-eval
Selects output format as bourne shell style eval command input.
--cmd-set
Selects output format as DOS style SET commands.
settings-item
What to display. One or more of the following:logdbg-settings - debug log settings.logrel-settings - release log settings.log-settings - alias for both debug and release log settings.debugvm stackVBoxManage debugvm  <uuid|vmname>  stack  [--cpu=id]
        Unwinds the guest CPU stacks to the best of our ability.  It is
        recommended to first run the osdetect command, as this
        gives both symbols and perhaps unwind information.
      
--cpu=id
Selects a single guest CPU to display the stack for.  The default is all CPUs.debugvm statisticsVBoxManage debugvm  <uuid|vmname>  statistics  [--reset] [--descriptions] [--pattern=pattern]
        Displays or resets VMM statistics.
      
        Retrieves register values for guest CPUs and emulated devices.
      
--pattern=pattern
DOS/NT-style wildcards patterns for selecting statistics.  Multiple
            patterns can be specified by using the '|' (pipe) character as separator.
--reset
Select reset instead of display mode.8.44. VBoxManage cloudprofileManage the cloud profiles.SynopsisVBoxManage cloudprofile  <--provider=name> <--profile=name>  add  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]VBoxManage cloudprofile  <--provider=name> <--profile=name>  update  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]VBoxManage cloudprofile  <--provider=name> <--profile=name>  delete VBoxManage cloudprofile  <--provider=name> <--profile=name>  show DescriptionCommon optionsThe subcommands of cloudprofile implement the standard CRUD operations for a cloud profile.
        The next common options must be placed between the ""cloud"" and  the following sub-commands:--provider=nameShort cloud provider name.--profile=nameCloud profile name. cloudprofile addVBoxManage cloudprofile  <--provider=name> <--profile=name>  add  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]
        Add new cloud profile for a specified cloud provider.
      
--clouduser
The name which fully identifies the user in the specified cloud provider.
--fingerprint
Fingerprint for the key pair being used.
--keyfile
Full path and filename of the private key. 
--passphrase
Passphrase used for the key, if it is encrypted.
--tenancy
ID of your tenancy. 
--compartment
ID of your compartment.
--region
Region name. Region is where you plan to deploy an application.cloudprofile showVBoxManage cloudprofile  <--provider=name> <--profile=name>  show 
        Display information about a cloud profile for a specified cloud provider.
      cloudprofile updateVBoxManage cloudprofile  <--provider=name> <--profile=name>  update  [--clouduser=unique id] [--fingerprint=MD5 string] [--keyfile=path] [--passphrase=string] [--tenancy=unique id] [--compartment=unique id] [--region=string]
        Modify a cloud profile for the specified cloud provider.
      
--clouduser
The name which fully identifies the user in the specified cloud provider.
--fingerprint
Fingerprint for the key pair being used.
--keyfile
Full path and filename of the private key. 
--passphrase
Passphrase used for the key, if it is encrypted.
--tenancy
ID of your tenancy. 
--compartment
ID of your compartment.
--region
Region name. Region is where you plan to deploy an application.cloudprofile deleteVBoxManage cloudprofile  <--provider=name> <--profile=name>  delete 
        Delete a cloud profile for a specified cloud provider.
      8.45. VBoxManage cloudManage the cloud entities.SynopsisVBoxManage cloud  <--provider=name> <--profile=name>  list   instances  [--state=string] [--compartment-id=string]VBoxManage cloud  <--provider=name> <--profile=name>  list   images  <--compartment-id=string> [--state=string]VBoxManage cloud  <--provider=name> <--profile=name>  instance   create  <--domain-name=name> <<--image-id=id> |  <--boot-volume-id=id>> <--display-name=name> <--shape=type> <--subnet=id> [--boot-disk-size=size in GB] [--publicip=true/false] [--privateip=IP address] [--public-ssh-key=key string...] [--launch-mode=NATIVE/EMULATED/PARAVIRTUALIZED]VBoxManage cloud  <--provider=name> <--profile=name>  instance   info  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   terminate  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   start  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  instance   pause  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   create  <--display-name=name> [--bucket-name=name] [--object-name=name] [--instance-id=unique id]VBoxManage cloud  <--provider=name> <--profile=name>  image   info  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   delete  <--id=unique id>VBoxManage cloud  <--provider=name> <--profile=name>  image   import  <--id=unique id> [--bucket-name=name] [--object-name=name]VBoxManage cloud  <--provider=name> <--profile=name>  image   export  <--id=unique id> <--display-name=name> [--bucket-name=name] [--object-name=name]VBoxManage cloud  <--provider=name> <--profile=name>  network setup  <--local-gateway-iso=path> [--gateway-os-name=string] [--gateway-os-version=string] [--gateway-shape=string] [--tunnel-network-name=string] [--tunnel-network-range=string] [--guest-additions-iso=path] [--proxy=string]VBoxManage cloud  <--provider=name> <--profile=name>  network create  <--name=string> <--network-id=string> [ --enable  |   --disable ]VBoxManage cloud network update  <--name=string> [--network-id=string] [ --enable  |   --disable ]VBoxManage cloud   network delete  <--name=string>VBoxManage cloud   network info  <--name=string>DescriptionCommon optionsThe word ""cloud"" is an umbrella for all commands related to the interconnection with the Cloud.
        The next common options must be placed between the ""cloud"" and  the following sub-commands:--provider=nameShort cloud provider name.--profile=nameCloud profile name. cloud list instancesVBoxManage cloud  <--provider=name> <--profile=name>  list   instances  [--state=string] [--compartment-id=string]
        Displays the list of the instances for a specified compartment.
      --state""running/paused/terminated""The state of cloud instance. The possible states are ""running/paused/terminated"" at moment.
            If the state isn't provided the list of instances with all possible states is returned.
            
--compartment-id
A compartment is the logical container used to organize and isolate cloud resources.
            The different cloud providers can have the different names for this entity.
            cloud list imagesVBoxManage cloud  <--provider=name> <--profile=name>  list   images  <--compartment-id=string> [--state=string]
        Displays the list of the images for a specified compartment.
      --state""available/disabled/deleted""The state of cloud image. The possible states are ""available/disabled/deleted"" at moment.
            If the state isn't provided the list of images with all possible states is returned.
            
--compartment-id
A compartment is the logical container used to organize and isolate cloud resources.
              The different cloud providers can have the different names for this entity.
              cloud instance createVBoxManage cloud  <--provider=name> <--profile=name>  instance   create  <--domain-name=name> <<--image-id=id> |  <--boot-volume-id=id>> <--display-name=name> <--shape=type> <--subnet=id> [--boot-disk-size=size in GB] [--publicip=true/false] [--privateip=IP address] [--public-ssh-key=key string...] [--launch-mode=NATIVE/EMULATED/PARAVIRTUALIZED]
        Creates new instance in the Cloud.
        There are two standard ways to create an instance in the Cloud:
         1. Create an instance from an existing custom image.
         2. Create an instance from an existing bootable volume. This bootable volume shouldn't  be attached to any instance.
        For the 1st approach next parameters are required: image-id and  boot-disk-size.
        For the 2nd approach next parameters are required: boot-volume-id;
        The rest parameters are common for both cases:
         display-name, launch-mode, subnet-id, publicIP, privateIP, shape, domain.
      
--domain-name
Cloud domain where new instance is created.
--image-id
Unique identifier which fully identifies a custom image in the Cloud.
--boot-volume-id
Unique identifier which fully identifies a boot volume in the Cloud.
--display-name
Name for new instance in the Cloud.
--shape
 The shape of instance, defines the number of CPUs and RAM memory.
--subnet
 Unique identifier which fully identifies an existing subnet in the Cloud which will be used by the instance.
--boot-disk-size
 The size of bootable image in GB. Default is 50GB.
--publicip
Whether the instance will have a public IP or not.
--privateip
Private IP address for the created instance.
--public-ssh-key
Public SSH key used to connect to the instance via SSH.
                This parameter may be repeated if you plan to use more than one key as:
                ""--public-ssh-key=firstSSHKey --public-ssh-key=secondSSHKey"".
              
--launch-mode
The most known values here may be EMULATED, NATIVE, PARAVIRTUALIZED. cloud instance info
        Display information about a cloud instance with a specified id.
      
--id
Unique identifier which fully identify the instance in the Cloud.cloud instance termination
        Delete a cloud instance with a specified id.
      
--id
Unique identifier which fully identify the instance in the Cloud.cloud instance start
        Start a cloud instance with a specified id.
      
--id
Unique identifier which fully identify the instance in the Cloud.cloud instance pause
        Pause a cloud instance with a specified id.
      
--id
Unique identifier which fully identify the instance in the Cloud.cloud image createVBoxManage cloud  <--provider=name> <--profile=name>  image   create  <--display-name=name> [--bucket-name=name] [--object-name=name] [--instance-id=unique id]
        Creates new image in the Cloud.
        There are two standard ways to create an image in the Cloud:
        1. Create an image from an object in the Cloud Storage;
        2. Create an image from an existing cloud instance.
        For the 1st approach next parameters are required:
        bucket-name - cloud bucket name where an object is located;
        object-name - name of object in the bucket;
        display-name - name for new image in the Cloud.
        For the 2d approach next parameters are required:
        instance-id - Id of instance in the Cloud;
        display-name - name for new image in the Cloud.
      
--display-name
Name for new image in the Cloud.
--bucket-name
Cloud bucket name where an object is located.
--object-name
Name of object in the bucket.
--instance-id
Unique identifier which fully identifies the instance in the Cloud.cloud image infoVBoxManage cloud  <--provider=name> <--profile=name>  image   info  <--id=unique id>
        Display information about a cloud image with a specified id.
      
--id
Unique identifier which fully identifies the image in the Cloud.cloud image deleteVBoxManage cloud  <--provider=name> <--profile=name>  image   delete  <--id=unique id>
        Delete an image with a specified id from the Cloud.
      
--id
Unique identifier which fully identifies the image in the Cloud.cloud image importVBoxManage cloud  <--provider=name> <--profile=name>  image   import  <--id=unique id> [--bucket-name=name] [--object-name=name]
        Import an image with a specified id from the Cloud to a local host.
        The result is an object in the local ""temp"" folder on the local host.
        Possible approach may have two general steps:
        1. Create an object from an image in the Cloud Storage;
        2. Download the object to the local host.
        So the next parameters may be required:
        bucket-name - cloud bucket name where the object will be created;
        object-name - name of object in the bucket. if parameter ""object-name"" is absent a displayed image name is used.
        If the first step isn't needed only the parameter ""id"" is required.
      
--id
Unique identifier which fully identifies the image in the Cloud.
--bucket-name
Cloud bucket name where an object will be created.
--object-name

                Name of created object in the bucket. The downloaded object will have this name.
              cloud image exportVBoxManage cloud  <--provider=name> <--profile=name>  image   export  <--id=unique id> <--display-name=name> [--bucket-name=name] [--object-name=name]
        Export an existing VBox image with a specified uuid from a local host to the Cloud.
        The result is new image in the Cloud.
        Possible approach may have two general steps:
        1. Upload VBox image to the Cloud Storage;
        2. Create an image from the uploaded object.
        So the next parameters may be required:
        bucket-name -cloud bucket name where the object will be uploaded;
        object-name - name of object in the bucket. If parameter ""object-name"" is absent the image id is used;
        display-name - name for new image in the Cloud.
        If the first step isn't needed the parameters ""id"" and ""display-name"" are required only.
      
--id
Unique identifier of the image in the VirtualBox.
--display-name
Name for new image in the Cloud.
--bucket-name
Cloud bucket name where the image (object) will be uploaded.
--object-name
Name of object in the bucket.cloud network setupVBoxManage cloud  <--provider=name> <--profile=name>  network setup  <--local-gateway-iso=path> [--gateway-os-name=string] [--gateway-os-version=string] [--gateway-shape=string] [--tunnel-network-name=string] [--tunnel-network-range=string] [--guest-additions-iso=path] [--proxy=string]
        Set up a cloud network environment for the specified cloud profile.
      
--local-gateway-iso
The local path to an installation media for a local gateway.
--gateway-os-name
The name of OS to use for a cloud gateway.
--gateway-os-version
The version of OS to use for a cloud gateway.
--gateway-shape
The instance shape to use for a cloud gateway. 
--tunnel-network-name
The name of VCN/subnet to use for tunneling.
--tunnel-network-range
The IP address range to use for tunneling. 
--guest-additions-iso
The local path to an installation media for VirtualBox guest additions.
--proxy
The proxy URL to be used in local gateway installation.cloud network createVBoxManage cloud  <--provider=name> <--profile=name>  network create  <--name=string> <--network-id=string> [ --enable  |   --disable ]
        Create a new cloud network descriptor associated with an existing cloud subnet.
      
--name
The name to assign to the cloud network descriptor.
--network-id
The unique identifier of an existing subnet in the cloud.--enable, --disableWhether to enable the network descriptor or disable it.  If not specified,
            the network will be enabled.cloud network updateVBoxManage cloud network update  <--name=string> [--network-id=string] [ --enable  |   --disable ]
        Modify an existing cloud network descriptor.
      
--name
The name of an existing cloud network descriptor.
--network-id
The unique identifier of an existing subnet in the cloud.--enable, --disableWhether to enable the network descriptor or disable it.cloud network deleteVBoxManage cloud   network delete  <--name=string>
        Delete an existing cloud network descriptor.
      
--name
The name of an existing cloud network descriptor.cloud network infoVBoxManage cloud   network info  <--name=string>
        Display information about a cloud network descriptor.
      
--name
The name of an existing cloud network descriptor.8.46. vboximg-mountFUSE mount a virtual disk image for Mac OS and Linux hosts.Synopsisvboximg-mount  < -?  |   -h  |   --help >vboximg-mount  <--image=image-UUID> [--guest-filesystem] [-o=FUSE-option[,FUSE-option]] [--root] [--rw] <mountpoint>vboximg-mount  <--list> [--image=image-UUID] [--guest-filesystem] [--verbose] [--vm=vm-UUID] [--wide]Description
      The vboximg-mount command enables you to make
      Oracle VM VirtualBox disk images available to a Mac OS or Linux host
      operating system (OS) for privileged or non-priviliged access. You
      can mount any version of the disk from its available history of
      snapshots. Use this command to mount, view, and optionally modify
      the contents of an Oracle VM VirtualBox virtual disk image, and you can
      also use this command to view information about registered virtual
      machines (VMs).
    
      This command uses the Filesystem in Userspace (FUSE) technology to
      provide raw access to an Oracle VM VirtualBox virtual disk image.
    
      When you use the --image option to specify a base
      image identifier, only the base image is mounted. Any related
      snapshots are disregarded. Alternatively, if you use the
      --image option to specify a snapshot, the state
      of the FUSE-mounted virtual disk is synthesized from the implied
      chain of snapshots, including the base image.
    
      The vboximg-mount command includes experimental
      read-only access to file systems inside a VM disk image. This
      feature enables you to extract some files from the VM disk image
      without starting the VM and without requiring third-party file
      system drivers on the host system. Oracle VM VirtualBox supports the
      FAT, NTFS, ext2, ext3,
      and ext4 file systems.
    
      The virtual disk is exposed as a device node within a FUSE-based
      file system that overlays the specified mount point.
    
      The FUSE file system includes a directory that contains a number
      of files. The file system can also contain a directory that
      includes a symbolic link that has the same base name (see the
      basename(1) man page) as the virtual disk base
      image and points to the location of the virtual disk base image.
      The directory can be of the following types:
    vhdd provides access to the raw disk
          image data as a flat image
        volID provides
          access to an individual volume on the specified disk image
        fsID provides
          access to a supported file system without requiring a host
          file system driver
        General Command Optionsvboximg-mount  < -?  |   -h  |   --help >
        Use the following options to obtain information about the
        vboximg-mount command and its options.
      --help, --h, or--?
              Shows usage information.
            Mounting an Oracle VM VirtualBox Disk Imagevboximg-mount  <--image=image-UUID> [--guest-filesystem] [-o=FUSE-option[,FUSE-option]] [--root] [--rw] <mountpoint>
        Use the vboximg-mount command to mount an
        Oracle VM VirtualBox virtual disk image on a Mac OS or Linux host
        system. When mounted, you can view the contents of the disk
        image or modify the contents of the disk image.
      
        You can use the vboximg-mount command to
        restrict FUSE-based access to a subsection of the virtual disk.
      
--image=disk-image

              Specifies the Universally Unique Identifier (UUID), name,
              or path of the Oracle VM VirtualBox disk image.
            
              The short form of the --image option is
              -i.
            
--guest-filesystem

              Enables experimental read-only support for guest file
              systems. When you specify this option, all known file
              systems are made available to access.
            
              The short form of the --guest-filesystem
              option is -g.
            
-o=FUSE-option[,FUSE-option...]

              Specifies FUSE mount options.
            
              The vboximg-mount command enables you
              to use the FUSE mount options that are described in the
              mount.fuse(8) man page.
            
--root

              Overrides the security measure that restricts file access
              to the file system owner by also granting file access to
              the root user.
            
              Same as the -o allow_root option. See the
              -o option description.
            
              This option is incompatible with the -o
              allow_other option.
            
--rw

              Mounts the specified image as read-write, which is
              required if you want to modify its contents. By default,
              images are mounted as read-only.
            
mount-point

              Specifies the path name of a directory on which to mount
              the Oracle VM VirtualBox disk image.
            Viewing Oracle VM VirtualBox Disk Image Informationvboximg-mount  <--list> [--image=image-UUID] [--guest-filesystem] [--verbose] [--vm=vm-UUID] [--wide]
        Use the vboximg-mount command to view
        information about registered VMs or an Oracle VM VirtualBox virtual
        disk image.
      
--image=disk-image

              Specifies the UUID, name, or path of the Oracle VM VirtualBox
              disk image.
            
              The short form of the --image option is
              -i.
            
--guest-filesystem

              Enables experimental read-only support for guest file
              systems. When you specify this option, all known file
              systems are made available to access.
            
              The short form of the --guest-filesystem
              option is -g.
            
--list

              Shows information about the disks that are associated with
              the registered VMs. If you specify a disk image, this
              option shows information about the partitions of the
              specified image.
            
              When you specify the --verbose option,
              the output includes detailed information about the VMs and
              media, including snapshot images and file paths.
            
              The short form of the --list option is
              -l.
            
--verbose

              Shows or logs detailed information.
            
              The short form of the --verbose option is
              -v.
            
--vm=vm-UUID

              Outputs information about the VM that is associated with
              the specified UUID.
            
--wide

              Outputs information in a wide format. This output includes
              the lock state information of running VMs. For VMs that
              are not running, the state is created.
            
              The wide output uses a tree-like structure in the VM
              column to show the relationship between a VM base image
              and its snapshots.
            Examples
      The following example shows how to mount a virtual disk image on
      the host operating system (OS).
    $ mkdir fuse_mount_point
$ vboximg-mount --image=b490e578-08be-4f7d-98e9-4c0ef0952377 fuse_mount_point
$ ls fuse_mount_point
ubu.vdi[32256:2053029880]   vhdd
$ sudo mount fuse_mount_point/vhdd /mnt
      The mkdir command creates a mount point called
      fuse_mount_point on the host OS. The
      vboximg-mount command is then used to mount the
      specified disk image on the fuse_mount_point
      mount point. The mount includes all snapshots for the disk image.
    
      The ls command shows the contents of
      fuse_mount_point. The
      mount command is then used to mount the
      FUSE-mounted device node, vhdd, on the
      /mnt mount point. The vhdd
      device node represents the virtual disk image.
    
      The following example shows how to make the known file systems of
      the b490e578-08be-4f7d-98e9-4c0ef0952377 disk
      image accessible when the image is mounted on the
      fuse_mount_point mount point:
    $ vboximg-mount --image=b490e578-08be-4f7d-98e9-4c0ef0952377 \
--guest-filesystem fuse_mount_point

      The following command outputs detailed information about all
      registered VMs and their snapshots:
    $ vboximg-mount --list --verbose
      The following command shows an excerpt of the list output in wide
      format.
    $ vboximg-mount --list --wide

VM  Image                 Size Type State   UUID (hierarchy)
------------------------------------------  ------------------------------------
Proxy                                       0833f5bc-6304-42e1-b799-cdc81c576c60
 |
 +- Proxy.vdi             4.8G VDI  rlock   d5f84afb-0794-4952-ab71-6bbcbee07737
 |  +- <snapshot>        12.3G VDI  rlock     dffc67aa-3023-477f-8033-b27e3daf4f54
 |  +- <snapshot>         8.8G VDI  rlock       3b2755bd-5f2a-4171-98fe-647d510b6274
 |  +- <snapshot>        14.6G VDI  rlock         e2ccdb5f-49e8-4123-8623-c61f363cc5cf
 |  +- <snapshot>         7.4G VDI  wlock           3c1e6794-9091-4be3-9e80-11aba40c2649

------------------------------------------  ------------------------------------
Oracle Linux 7                              5365ab5f-470d-44c0-9863-dad532ee5905
 |
 +- Oracle Linux 7.vdi     7.0G VDI created 96d2e92e-0d4e-46ab-a0f1-008fdbf997e7
 | +- <snapshot>          15.9G VDI created   f9cc866a-9166-42e9-a503-bbfe9b7312e8
 |
 +- kernel.vdi            11.1G VDI created 79a370bd-0c4f-480a-30bb-10cdea68423f

      The output shows that the Proxy VM is running the fourth snapshot
      of the Proxy.vdi virtual disk image. The
      running state is indicated by the wlock value
      in the State column.
    
      The Oracle Linux 7 VM is not running. It has two images:
      Oracle Linux 7.vdi and
      kernel.vdi. The Oracle Linux
      7.vdi image has a snapshot.
    
      The following command shows information about the VM with the
      specified UUID:
    
$ vboximg-mount --list --vm=b1d5563b-2a5b-4013-89f1-26c81d6bbfa0
-----------------------------------------------------------------
VM:   ubu
UUID: b1d5563b-2a5b-4013-89f1-26c81d6bbfa0

  Image:   ubu.vdi
  UUID:    b490e578-08be-4f7d-98e9-4c0ef0952377

       Snapshot: 35afe1e0-0a51-44f3-a228-caf172f3306f
       Size:     12.1G

       Snapshot: 874279c1-4425-4282-ada8-a9c07c00bbf9
       Size:     13.6G

  Image:   kernel.vdi
  UUID:    79a370bd-6eb7-4dbf-8bc6-d29118f127e0",,"# VBoxManage

> Command-line interface to VirtualBox.
> Includes all the functionality of the GUI and more.
> More information: <https://www.virtualbox.org/manual/ch08.html#vboxmanage-intro>.

- List all VirtualBox virtual machines:

`VBoxManage list vms`

- Show information about a particular virtual machine:

`VBoxManage showvminfo {{name|uuid}}`

- Start a virtual machine:

`VBoxManage startvm {{name|uuid}}`

- Start a virtual machine in headless mode:

`VBoxManage startvm {{name|uuid}} -type headless`

- Shutdown the virtual machine and save its current state:

`VBoxManage controlvm {{name|uuid}} savestate`

- Shutdown down the virtual machine without saving its state:

`VBoxManage controlvm {{name|uuid}} poweroff`

- Update VBox extension packs:

`VBoxManage extpack install --replace {{VboxExtensionPackFileName}}`
"
wine,https://wiki.winehq.org/,"


WineHQ Wiki
















☰

WineHQ
Wiki
AppDB
Bugzilla
Forums










 







Main page
Discussion
View source
History 




Main Page

From WineHQ Wiki

Jump to: navigation, search

Translations of this page:  Français  Deutsch  한국어 (Translators, please see Discussion page.)

Wine
Wine enables Linux, Mac, FreeBSD, and Solaris users to run Windows applications without a copy of Microsoft Windows. Wine is free software under constant development. Other platforms may benefit as well.

Most popular links
Frequently Asked Questions: If you're having a general problem with Wine, please read the FAQ!
Wine documentation: If the FAQ didn't help, try reading the manual! 😃
The Wine Application Database: For help with a particular app, look up its entry in the AppDB.
Wine Users support forum: For asking questions that you can't find an answer to in the above.
Known Issues: Check here before you report a bug.
winetricks: A useful tool for using common workarounds to current deficiencies in Wine.
macOS: Running Wine on macOS.
About the Wine project
A brief overview of Wine Features and goals.
Some short articles about the Importance Of Wine.
An overview of Wine Project Organization.
Who's Who in the Wine project, Acknowledgements for major contributors, and a list of all registered wiki homepages.
The history of the Wine project and recent News.
Information about Wine's Licensing.
Contribute
User support: Help users by answering questions on the User's Forum or IRC.
Developers: If you want to help with Wine or build it from source.
AppDB Maintainers: If you are (or want to become) an AppDB Maintainer.
Debuggers can help by testing Wine and narrowing down problems, or help triage bugs reported by other users.
Writers can contribute by documenting the program, maintaining the wiki, and translating various parts of the project.
Designers can, among other tasks, draw icons for programs, or improve the style and function of the website.
Wine Development Fund: Please consider making a donation to support the Wine project.
Web Content Tasks contains things you can do by merely editing this wiki.
Public Relations: ways to help spread the word about Wine.
Category:ToDo: A list of all ToDo items in the Wiki.
Other useful links
List of all pages in this wiki (useful for wiki editors).
A List of Commands for all the little tools that come with Wine.
Third Party Applications and ""unofficial"" tools that might come in handy.
Useful Registry Keys and various settings for configuring Wine.
Instructions for Regression Testing.
Applications which officially test against Wine as a platform.
More information
The Wine project Source Code can be downloaded or browsed online.
You can browse archived discussions or subscribe to the Wine mailing lists.
Information on development progress and the status of Wine.
Assorted files such as site icons and images, and database dumps of Bugzilla, AppDB, and the wiki can be downloaded from WineHQ's download server.
View WineHQ site statistics and rough estimates of Wine's Usage Statistics.




Retrieved from ""https://wiki.winehq.org/index.php?title=Main_Page&oldid=3166""
 






Navigation


Main page
Recent changes
Random page
Help about MediaWiki




Tools


What links here
Related changes
Special pages
Printable version
Permanent link
Page information




Personal Menu


Create accountLog in 








 This page was last edited on 15 January 2019, at 10:46.
Privacy policy
About WineHQ Wiki
Disclaimers




                Hosted By
                    

",,"# wine

> Run Windows programs on Unix.
> More information: <https://wiki.winehq.org/>.

- Run ipconfig.exe program:

`wine {{ipconfig}} {{/all}}`

- Run cmd.exe in background:

`wine start {{cmd}}`

- Run Windows-like Package Manager:

`wine uninstaller`

- Install MSI packages:

`wine msiexec /i {{package}}`
"
fatlabel,,,,"# fatlabel

> Sets or gets the label of a FAT32 partition.

- Get the label of a FAT32 partition:

`fatlabel {{/dev/sda1}}`

- Set the label of a FAT32 partition:

`fatlabel {{/dev/sdc3}} ""{{new_label}}""`
"
line,,,,"# line

> Read a single line of input.

- Read input:

`line`
"
daemonize,http://software.clapper.org/daemonize/,"


daemonize — A tool to run a command as a daemon








daemonize — A tool to run a command as a daemon



Home
Code
Other Software






Table of Contents


Introduction
daemonize runs a command as a Unix daemon. As defined in W. Richard
Stevens’ 1990 book, UNIX Network Programming (Addison-Wesley, 1990),
a daemon is “a process that executes ‘in the background’ (i.e., without an
associated terminal or login shell) either waiting for some event to occur,
or waiting to perform some specified task on a periodic basis.” Upon
startup, a typical daemon program will:

Close all open file descriptors (especially standard input, standard
output and standard error)
Change its working directory to the root filesystem, to ensure that it
doesn’t tie up another filesystem and prevent it from being unmounted
Reset its umask value
Run in the background (i.e., fork)
Disassociate from its process group (usually a shell), to insulate itself
from signals (such as HUP) sent to the process group
Ignore all terminal I/O signals
Disassociate from the control terminal (and take steps not to reacquire one)
Handle any SIGCLD signals

Most programs that are designed to be run as daemons do that work for
themselves. However, you’ll occasionally run across one that does not. When
you must run a daemon program that does not properly make itself into a
true Unix daemon, you can use daemonize to force it to run as a true
daemon.
See the man page for full details.
Notes


If the host operating system provides the daemon(3) library routine,
daemonize will use it. Otherwise, daemonize uses its own version of
daemon(3). This choice is made at compile time. (BSD 4.4-derived
operating systems tend to provide their own daemon(3) routine.)


FreeBSD 5.0 introduced a daemon(1) command that is similar to, but
less functional, than daemonize.


Getting daemonize
daemonize is written in C. Given the number of Unix-like operating
systems, and the number of releases of each, it is impractical for me to
provide binaries of daemonize for every combination of Unix-like
operating system and operating system release.
If you’re on a Mac, you can use homebrew
to instsall daemonize, like so:
$ brew install daemonize

If you’re on any other Unix-like operating system, you must build
daemonize from source code, as described below.
There are two ways to get the source code:
Download a release zip
You can download a release zip file, containing the source, from the
releases page. Just unzip the file to unpack the source
directory.
Clone the Git repository
You can also simply clone the git repository, using one of the following
commands.
$ git clone git://github.com/bmc/daemonize.git
$ git clone http://github.com/bmc/daemonize.git

Installation
Once you’ve unpacked the source, change your working directory to the
daemonize directory. From there, building and installing the code is
fairly typical:
$ sh configure
$ make
$ sudo make install

For a detailed report of the available configure options:
$ sh configure --help

Notes
I have personally compiled and tested daemonize on the following platforms:

FreeBSD 4.x, 8.0-RELEASE, 8.1-RELEASE and 8.2-RELEASE
Red Hat Enterprise Linux 4 / CentOS 4
Solaris (SunOS 5.8, 5.10)
Fedora Core 5
Ubuntu 8 through 15
Mac OS X 10.4 (Tiger) and 10.6 through 10.11.

The accompanying “configure” script was generated with GNU autoconf
version 2.69. It should work, as is, for most Unix systems.
Change Log
See the daemonize Change Log for a description of the changes in
each version.
Author
Brian Clapper, bmc@clapper.org
Web Page

Home Page
GitHub repo

License
With the exception of the install-sh script and the getopt.c source,
this software is released under BSD license. See the license for details.
Copyright
With the exception of the “install-sh” script and the “getopt.c” source,
this software is copyright 2003-2015, Brian M. Clapper
Patches
I gladly accept patches from their original authors. Feel free to email
patches to me or to fork the GitHub repository and send me a
pull request. Along with any patch you send:

Please state that the patch is your original work.
Please indicate that you license the work to the daemonize
project under a BSD License.




",,"# daemonize

> Run a command (that does not daemonize itself) as a Unix daemon.
> More information: <http://software.clapper.org/daemonize/>.

- Run a command as a daemon:

`daemonize {{command}} {{command_arguments}}`

- Write the pid to the specified file:

`daemonize -p {{path/to/pidfile}} {{command}} {{command_arguments}}`

- Use a lock file to ensure that only one instance runs at a time:

`daemonize -l {{path/to/lockfile}} {{command}} {{command_arguments}}`

- Use the specified user account:

`sudo daemonize -u {{user}} {{command}} {{command_arguments}}`
"
modprobe,,,,"# modprobe

> Add or remove modules from the Linux kernel.

- Pretend to load a module into the kernel, but don't actually do it:

`sudo modprobe --dry-run {{module_name}}`

- Load a module into the kernel:

`sudo modprobe {{module_name}}`

- Remove a module from the kernel:

`sudo modprobe --remove {{module_name}}`

- Remove a module and those that depend on it from the kernel:

`sudo modprobe --remove-dependencies {{module_name}}`

- Show a kernel module's dependencies:

`sudo modprobe --show-depends {{module_name}}`
"
mkisofs,,,,"# mkisofs

> Create ISO files from directories.
> Also aliased as `genisoimage`.

- Create an ISO from a directory:

`mkisofs -o {{filename.iso}} {{path/to/source_directory}}`

- Set the disc label when creating an ISO:

`mkisofs -o {{filename.iso}} -V {{""label_name""}} {{path/to/source_directory}}`
"
fcrackzip,,,,"# fcrackzip

> ZIP archive password cracking utility.

- Brute-force a password with a length of 4 to 8 characters, and contains only alphanumeric characters (order matters):

`fcrackzip --brute-force --length 4-8 --charset aA1 {{archive}}`

- Brute-force a password in verbose mode with a length of 3 characters that only contains lowercase characters, `$` and `%`:

`fcrackzip -v --brute-force --length 3 --charset a:$% {{archive}}`

- Brute-force a password that contains only lowercase and special characters:

`fcrackzip --brute-force --length 4 --charset a! {{archive}}`

- Brute-force a password containing only digits, starting from the password `12345`:

`fcrackzip --brute-force --length 5 --charset 1 --init-password 12345 {{archive}}`

- Crack a password using a wordlist:

`fcrackzip --use-unzip --dictionary --init-password {{wordlist}} {{archive}}`

- Benchmark cracking performance:

`fcrackzip --benchmark`
"
gpasswd,,,,"# gpasswd

> Administer ""/etc/group"" and ""/etc/gshadow"".

- Define group administrators:

`sudo gpasswd -A {{user1,user2}} {{group}}`

- Set the list of group members:

`sudo gpasswd -M {{user1,user2}} {{group}}`

- Create a password for the named group:

`gpasswd {{group}}`

- Add a user to the named group:

`gpasswd -a {{user}} {{group}}`

- Remove a user from the named group:

`gpasswd -d {{user}} {{group}}`
"
slapt-get,,,,"# slapt-get

> An apt like system for Slackware package management.
> Package sources need to be configured in the slapt-getrc file.

- Update the list of available packages and versions:

`slapt-get --update`

- Install a package, or update it to the latest available version:

`slapt-get --install {{package_name}}`

- Remove a package:

`slapt-get --remove {{package_name}}`

- Upgrade all installed packages to their latest available versions:

`slapt-get --upgrade {{package_name}}`

- Locate packages of interest by the package name, disk set, or version:

`slapt-get --search {{package_name}}`

- Show information about a package:

`slapt-get --show {{package_name}}`
"
quotacheck,,,"
QUOTACHECK(8)		  BSD System Manager's Manual		 QUOTACHECK(8)

NAME
     quotacheck -- filesystem quota consistency checker

SYNOPSIS
     quotacheck [-g] [-u] [-v] filesystem ...
     quotacheck [-g] [-u] [-v] -a

DESCRIPTION
     Quotacheck examines each filesystem, builds a table of current disk
     usage, and compares this table against that recorded in the disk quota
     file for the filesystem.  If any inconsistencies are detected, both the
     quota file and the current system copy of the incorrect quotas are
     updated (the latter only occurs if an active filesystem is checked).  By
     default both user and group quotas are checked.

     Available options:

     -a      If the -a flag is supplied in place of any filesystem names,
	     quotacheck will check all the read-write filesystems with an
	     existing mount option file at its root.  The mount option file
	     specifies the types of quotas that are to be checked.

     -g      Only group quotas are checked. The mount option file,
	     .quota.ops.group, must exist at the root of the filesystem.

     -u      Only user quotas are checked.  The mount option file,
	     .quota.ops.user, must exist at the root of the filesystem.

     -v      quotacheck reports discrepancies between the calculated and
	     recorded disk quotas.

     Specifying both -g and -u is equivalent to the default.  Parallel passes
     are run on the filesystems required, in an identical fashion to fsck(8).

     Normally quotacheck operates silently.

     Quotacheck expects each filesystem being checked to have quota data files
     named .quota.user and/or .quota.group located at the filesystem root.  If
     a binary data file is not present, quotacheck will create it.  The
     default filename and root location cannot be overridden.

     Quotacheck is normally run at fsck time.

     Quotacheck accesses the raw device in calculating the actual disk usage
     for each user.  Thus, the filesystems checked should be quiescent while
     quotacheck is running.

FILES
     Each of the following quota files is located at the root of the mounted
     filesystem.  The mount option files are empty files whose existence indi-
     cates that quotas are to be enabled for that filesystem. The binary data
     files will be created by quotacheck, if they don't already exist.

     .quota.user       data file containing user quotas
     .quota.group      data file containing group quotas
     .quota.ops.user   mount option file used to enable user quotas
     .quota.ops.group  mount option file used to enable group quotas

SEE ALSO
     quota(1), quotactl(2), edquota(8), fsck(8), quotaon(8), repquota(8)

HISTORY
     The quotacheck command appeared in 4.2BSD.

4.2 Berkeley Distribution      October 17, 2002      4.2 Berkeley Distribution
","# quotacheck

> Scan a filesystem for disk usage; create, check and repair quota files.
> It is best to run quota check with quotas turned off to prevent damage or loss to quota files.

- Check quotas on all mounted non-NFS filesystems:

`sudo quotacheck --all`

- Force check even if quotas are enabled (this can cause damage or loss to quota files):

`sudo quotacheck --force {{mountpoint}}`

- Check quotas on a given filesystem in debug mode:

`sudo quotacheck --debug {{mountpoint}}`

- Check quotas on a given filesystem, displaying the progress:

`sudo quotacheck --verbose {{mountpoint}}`

- Check user quotas:

`sudo quotacheck --user {{user}} {{mountpoint}}`

- Check group quotas:

`sudo quotacheck --group {{group}} {{mountpoint}}`
"
datamash,,,,"# datamash

> Tool to perform basic numeric, textual and statistical operations on input textual data files.

- Get max, min, mean and median of a single column of numbers:

`seq 3 | datamash max 1 min 1 mean 1 median 1`

- Get the mean of a single column of float numbers (floats must use "","" and not "".""):

`echo -e '1.0\n2.5\n3.1\n4.3\n5.6\n5.7' | tr '.' ',' | datamash mean 1`

- Get the mean of a single column of numbers with a given decimal precision:

`echo -e '1\n2\n3\n4\n5\n5' | datamash -R {{number_of_decimals_wanted}} mean 1`

- Get the mean of a single column of numbers ignoring ""Na"" and ""NaN"" (literal) strings:

`echo -e '1\n2\nNa\n3\nNaN' | datamash --narm mean 1`
"
bmon,,,,"# bmon

> Monitor bandwidth and capture network related statistics.

- Display the list of all the interfaces:

`bmon -a`

- Display data transfer rates in bits per second:

`bmon -b`

- Set policy to define which network interface(s) is/are displayed:

`bmon -p {{interface_1,interface_2,interface_3}}`

- Set interval (in seconds) in which rate per counter is calculated:

`bmon -R {{2.0}}`
"
eix,,,,"# eix

> Utilities for searching local Gentoo packages.
> Update local package cache using `eix-update`.

- Search for a package:

`eix {{package_name}}`

- Search for installed packages:

`eix --installed {{package_name}}`

- Seach in package descriptions:

`eix --description ""{{description}}""`

- Seach by package license:

`eix --license {{license}}`

- Exclude results from search:

`eix --not --license {{license}}`
"
